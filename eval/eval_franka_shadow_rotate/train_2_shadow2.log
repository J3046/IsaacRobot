################################################################################
                      [1m Learning iteration 0/1500 [0m                       

                       Computation: 10839 steps/s (collection: 8.766s, learning 0.303s)
             Mean action noise std: 1.00
          Mean value_function loss: 0.0013
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 25.5767
                       Mean reward: 0.00
               Mean episode length: 21.21
    Episode_Reward/reaching_object: 0.0005
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0002
          Episode_Reward/joint_vel: -0.0002
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 98304
                    Iteration time: 9.07s
                      Time elapsed: 00:00:09
                               ETA: 03:46:43

################################################################################
                      [1m Learning iteration 1/1500 [0m                       

                       Computation: 14066 steps/s (collection: 6.833s, learning 0.155s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0002
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 25.6615
                       Mean reward: 0.00
               Mean episode length: 45.83
    Episode_Reward/reaching_object: 0.0013
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0005
          Episode_Reward/joint_vel: -0.0006
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 196608
                    Iteration time: 6.99s
                      Time elapsed: 00:00:16
                               ETA: 03:20:35

################################################################################
                      [1m Learning iteration 2/1500 [0m                       

                       Computation: 14539 steps/s (collection: 6.615s, learning 0.147s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0001
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 25.6663
                       Mean reward: 0.00
               Mean episode length: 69.78
    Episode_Reward/reaching_object: 0.0022
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0009
          Episode_Reward/joint_vel: -0.0010
      Episode_Termination/time_out: 17.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 294912
                    Iteration time: 6.76s
                      Time elapsed: 00:00:22
                               ETA: 03:09:54

################################################################################
                      [1m Learning iteration 3/1500 [0m                       

                       Computation: 14334 steps/s (collection: 6.702s, learning 0.156s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0024
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 25.6869
                       Mean reward: 0.00
               Mean episode length: 93.42
    Episode_Reward/reaching_object: 0.0033
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0012
          Episode_Reward/joint_vel: -0.0015
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 393216
                    Iteration time: 6.86s
                      Time elapsed: 00:00:29
                               ETA: 03:05:06

################################################################################
                      [1m Learning iteration 4/1500 [0m                       

                       Computation: 14355 steps/s (collection: 6.663s, learning 0.185s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0032
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 25.7369
                       Mean reward: 0.01
               Mean episode length: 117.74
    Episode_Reward/reaching_object: 0.0045
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0016
          Episode_Reward/joint_vel: -0.0019
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 491520
                    Iteration time: 6.85s
                      Time elapsed: 00:00:36
                               ETA: 03:02:08

################################################################################
                      [1m Learning iteration 5/1500 [0m                       

                       Computation: 14653 steps/s (collection: 6.570s, learning 0.138s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0005
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 25.8018
                       Mean reward: 0.01
               Mean episode length: 141.96
    Episode_Reward/reaching_object: 0.0059
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0019
          Episode_Reward/joint_vel: -0.0023
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 589824
                    Iteration time: 6.71s
                      Time elapsed: 00:00:43
                               ETA: 02:59:32

################################################################################
                      [1m Learning iteration 6/1500 [0m                       

                       Computation: 15120 steps/s (collection: 6.346s, learning 0.156s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0001
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 25.8874
                       Mean reward: 0.01
               Mean episode length: 165.77
    Episode_Reward/reaching_object: 0.0080
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0023
          Episode_Reward/joint_vel: -0.0027
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 688128
                    Iteration time: 6.50s
                      Time elapsed: 00:00:49
                               ETA: 02:56:54

################################################################################
                      [1m Learning iteration 7/1500 [0m                       

                       Computation: 14838 steps/s (collection: 6.481s, learning 0.144s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 25.9086
                       Mean reward: 0.02
               Mean episode length: 189.36
    Episode_Reward/reaching_object: 0.0090
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0027
          Episode_Reward/joint_vel: -0.0031
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 786432
                    Iteration time: 6.62s
                      Time elapsed: 00:00:56
                               ETA: 02:55:18

################################################################################
                      [1m Learning iteration 8/1500 [0m                       

                       Computation: 17868 steps/s (collection: 5.379s, learning 0.122s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 25.9308
                       Mean reward: 0.03
               Mean episode length: 213.10
    Episode_Reward/reaching_object: 0.0112
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0030
          Episode_Reward/joint_vel: -0.0035
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 884736
                    Iteration time: 5.50s
                      Time elapsed: 00:01:01
                               ETA: 02:50:55

################################################################################
                      [1m Learning iteration 9/1500 [0m                       

                       Computation: 58247 steps/s (collection: 1.574s, learning 0.114s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 25.9243
                       Mean reward: 0.04
               Mean episode length: 237.13
    Episode_Reward/reaching_object: 0.0146
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0034
          Episode_Reward/joint_vel: -0.0039
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 983040
                    Iteration time: 1.69s
                      Time elapsed: 00:01:03
                               ETA: 02:37:55

################################################################################
                      [1m Learning iteration 10/1500 [0m                      

                       Computation: 60717 steps/s (collection: 1.508s, learning 0.111s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 25.9082
                       Mean reward: 0.06
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0173
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0037
          Episode_Reward/joint_vel: -0.0043
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1081344
                    Iteration time: 1.62s
                      Time elapsed: 00:01:05
                               ETA: 02:27:07

################################################################################
                      [1m Learning iteration 11/1500 [0m                      

                       Computation: 63327 steps/s (collection: 1.459s, learning 0.094s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 25.8991
                       Mean reward: 0.06
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0175
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0037
          Episode_Reward/joint_vel: -0.0043
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1179648
                    Iteration time: 1.55s
                      Time elapsed: 00:01:06
                               ETA: 02:17:58

################################################################################
                      [1m Learning iteration 12/1500 [0m                      

                       Computation: 65091 steps/s (collection: 1.409s, learning 0.102s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 25.9045
                       Mean reward: 0.07
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0210
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0037
          Episode_Reward/joint_vel: -0.0043
      Episode_Termination/time_out: 17.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1277952
                    Iteration time: 1.51s
                      Time elapsed: 00:01:08
                               ETA: 02:10:09

################################################################################
                      [1m Learning iteration 13/1500 [0m                      

                       Computation: 63427 steps/s (collection: 1.407s, learning 0.143s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0001
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 25.9219
                       Mean reward: 0.09
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0248
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0037
          Episode_Reward/joint_vel: -0.0043
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1376256
                    Iteration time: 1.55s
                      Time elapsed: 00:01:09
                               ETA: 02:03:31

################################################################################
                      [1m Learning iteration 14/1500 [0m                      

                       Computation: 62795 steps/s (collection: 1.456s, learning 0.109s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0001
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 25.9364
                       Mean reward: 0.10
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0245
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0038
          Episode_Reward/joint_vel: -0.0043
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1474560
                    Iteration time: 1.57s
                      Time elapsed: 00:01:11
                               ETA: 01:57:47

################################################################################
                      [1m Learning iteration 15/1500 [0m                      

                       Computation: 62979 steps/s (collection: 1.455s, learning 0.106s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0001
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 25.9587
                       Mean reward: 0.14
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0328
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0038
          Episode_Reward/joint_vel: -0.0043
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1572864
                    Iteration time: 1.56s
                      Time elapsed: 00:01:12
                               ETA: 01:52:46

################################################################################
                      [1m Learning iteration 16/1500 [0m                      

                       Computation: 64633 steps/s (collection: 1.427s, learning 0.094s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0002
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 25.9792
                       Mean reward: 0.21
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0429
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0038
          Episode_Reward/joint_vel: -0.0043
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1671168
                    Iteration time: 1.52s
                      Time elapsed: 00:01:14
                               ETA: 01:48:17

################################################################################
                      [1m Learning iteration 17/1500 [0m                      

                       Computation: 62043 steps/s (collection: 1.473s, learning 0.111s)
             Mean action noise std: 1.03
          Mean value_function loss: 0.0003
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 26.0120
                       Mean reward: 0.26
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0560
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0038
          Episode_Reward/joint_vel: -0.0043
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 1769472
                    Iteration time: 1.58s
                      Time elapsed: 00:01:16
                               ETA: 01:44:22

################################################################################
                      [1m Learning iteration 18/1500 [0m                      

                       Computation: 59779 steps/s (collection: 1.533s, learning 0.111s)
             Mean action noise std: 1.03
          Mean value_function loss: 0.0005
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 26.0091
                       Mean reward: 0.28
               Mean episode length: 249.94
    Episode_Reward/reaching_object: 0.0679
    Episode_Reward/rotating_object: 0.0001
        Episode_Reward/action_rate: -0.0038
          Episode_Reward/joint_vel: -0.0043
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 1867776
                    Iteration time: 1.64s
                      Time elapsed: 00:01:17
                               ETA: 01:40:57

################################################################################
                      [1m Learning iteration 19/1500 [0m                      

                       Computation: 56709 steps/s (collection: 1.631s, learning 0.102s)
             Mean action noise std: 1.03
          Mean value_function loss: 0.0007
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 26.0525
                       Mean reward: 0.36
               Mean episode length: 248.63
    Episode_Reward/reaching_object: 0.0839
    Episode_Reward/rotating_object: 0.0004
        Episode_Reward/action_rate: -0.0038
          Episode_Reward/joint_vel: -0.0042
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 1966080
                    Iteration time: 1.73s
                      Time elapsed: 00:01:19
                               ETA: 01:37:58

################################################################################
                      [1m Learning iteration 20/1500 [0m                      

                       Computation: 55522 steps/s (collection: 1.673s, learning 0.097s)
             Mean action noise std: 1.03
          Mean value_function loss: 0.0008
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 26.1013
                       Mean reward: 0.56
               Mean episode length: 245.60
    Episode_Reward/reaching_object: 0.1029
    Episode_Reward/rotating_object: 0.0011
        Episode_Reward/action_rate: -0.0037
          Episode_Reward/joint_vel: -0.0042
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 2064384
                    Iteration time: 1.77s
                      Time elapsed: 00:01:21
                               ETA: 01:35:19

################################################################################
                      [1m Learning iteration 21/1500 [0m                      

                       Computation: 52813 steps/s (collection: 1.739s, learning 0.122s)
             Mean action noise std: 1.03
          Mean value_function loss: 0.0011
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 26.1228
                       Mean reward: 0.64
               Mean episode length: 242.98
    Episode_Reward/reaching_object: 0.1192
    Episode_Reward/rotating_object: 0.0019
        Episode_Reward/action_rate: -0.0037
          Episode_Reward/joint_vel: -0.0042
      Episode_Termination/time_out: 13.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 2162688
                    Iteration time: 1.86s
                      Time elapsed: 00:01:23
                               ETA: 01:33:01

################################################################################
                      [1m Learning iteration 22/1500 [0m                      

                       Computation: 54912 steps/s (collection: 1.687s, learning 0.103s)
             Mean action noise std: 1.03
          Mean value_function loss: 0.0014
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 26.1576
                       Mean reward: 0.68
               Mean episode length: 242.18
    Episode_Reward/reaching_object: 0.1370
    Episode_Reward/rotating_object: 0.0012
        Episode_Reward/action_rate: -0.0037
          Episode_Reward/joint_vel: -0.0042
      Episode_Termination/time_out: 13.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.1250
--------------------------------------------------------------------------------
                   Total timesteps: 2260992
                    Iteration time: 1.79s
                      Time elapsed: 00:01:24
                               ETA: 01:30:50

################################################################################
                      [1m Learning iteration 23/1500 [0m                      

                       Computation: 51137 steps/s (collection: 1.792s, learning 0.131s)
             Mean action noise std: 1.04
          Mean value_function loss: 0.0051
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 26.1962
                       Mean reward: 0.75
               Mean episode length: 239.44
    Episode_Reward/reaching_object: 0.1512
    Episode_Reward/rotating_object: 0.0035
        Episode_Reward/action_rate: -0.0037
          Episode_Reward/joint_vel: -0.0042
      Episode_Termination/time_out: 12.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 7.2083
--------------------------------------------------------------------------------
                   Total timesteps: 2359296
                    Iteration time: 1.92s
                      Time elapsed: 00:01:26
                               ETA: 01:28:57

################################################################################
                      [1m Learning iteration 24/1500 [0m                      

                       Computation: 54058 steps/s (collection: 1.714s, learning 0.104s)
             Mean action noise std: 1.04
          Mean value_function loss: 0.0024
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 26.2561
                       Mean reward: 0.91
               Mean episode length: 237.76
    Episode_Reward/reaching_object: 0.1631
    Episode_Reward/rotating_object: 0.0053
        Episode_Reward/action_rate: -0.0037
          Episode_Reward/joint_vel: -0.0042
      Episode_Termination/time_out: 9.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 7.1250
--------------------------------------------------------------------------------
                   Total timesteps: 2457600
                    Iteration time: 1.82s
                      Time elapsed: 00:01:28
                               ETA: 01:27:08

################################################################################
                      [1m Learning iteration 25/1500 [0m                      

                       Computation: 51511 steps/s (collection: 1.798s, learning 0.111s)
             Mean action noise std: 1.04
          Mean value_function loss: 0.0029
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 26.2733
                       Mean reward: 0.88
               Mean episode length: 236.62
    Episode_Reward/reaching_object: 0.1808
    Episode_Reward/rotating_object: 0.0079
        Episode_Reward/action_rate: -0.0037
          Episode_Reward/joint_vel: -0.0043
      Episode_Termination/time_out: 10.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 8.9583
--------------------------------------------------------------------------------
                   Total timesteps: 2555904
                    Iteration time: 1.91s
                      Time elapsed: 00:01:30
                               ETA: 01:25:31

################################################################################
                      [1m Learning iteration 26/1500 [0m                      

                       Computation: 54566 steps/s (collection: 1.702s, learning 0.100s)
             Mean action noise std: 1.05
          Mean value_function loss: 0.0046
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 26.3520
                       Mean reward: 1.16
               Mean episode length: 233.92
    Episode_Reward/reaching_object: 0.1996
    Episode_Reward/rotating_object: 0.0086
        Episode_Reward/action_rate: -0.0036
          Episode_Reward/joint_vel: -0.0043
      Episode_Termination/time_out: 9.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 8.9583
--------------------------------------------------------------------------------
                   Total timesteps: 2654208
                    Iteration time: 1.80s
                      Time elapsed: 00:01:32
                               ETA: 01:23:56

################################################################################
                      [1m Learning iteration 27/1500 [0m                      

                       Computation: 54715 steps/s (collection: 1.704s, learning 0.093s)
             Mean action noise std: 1.05
          Mean value_function loss: 0.0061
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 26.4196
                       Mean reward: 1.17
               Mean episode length: 228.87
    Episode_Reward/reaching_object: 0.2139
    Episode_Reward/rotating_object: 0.0184
        Episode_Reward/action_rate: -0.0037
          Episode_Reward/joint_vel: -0.0044
      Episode_Termination/time_out: 8.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 9.7917
--------------------------------------------------------------------------------
                   Total timesteps: 2752512
                    Iteration time: 1.80s
                      Time elapsed: 00:01:34
                               ETA: 01:22:28

################################################################################
                      [1m Learning iteration 28/1500 [0m                      

                       Computation: 51502 steps/s (collection: 1.810s, learning 0.099s)
             Mean action noise std: 1.06
          Mean value_function loss: 0.0082
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 26.4731
                       Mean reward: 1.25
               Mean episode length: 228.92
    Episode_Reward/reaching_object: 0.2325
    Episode_Reward/rotating_object: 0.0205
        Episode_Reward/action_rate: -0.0036
          Episode_Reward/joint_vel: -0.0044
      Episode_Termination/time_out: 7.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 11.0833
--------------------------------------------------------------------------------
                   Total timesteps: 2850816
                    Iteration time: 1.91s
                      Time elapsed: 00:01:35
                               ETA: 01:21:11

################################################################################
                      [1m Learning iteration 29/1500 [0m                      

                       Computation: 52969 steps/s (collection: 1.752s, learning 0.104s)
             Mean action noise std: 1.06
          Mean value_function loss: 0.0102
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 26.5446
                       Mean reward: 1.34
               Mean episode length: 225.05
    Episode_Reward/reaching_object: 0.2579
    Episode_Reward/rotating_object: 0.0392
        Episode_Reward/action_rate: -0.0036
          Episode_Reward/joint_vel: -0.0046
      Episode_Termination/time_out: 7.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 9.7083
--------------------------------------------------------------------------------
                   Total timesteps: 2949120
                    Iteration time: 1.86s
                      Time elapsed: 00:01:37
                               ETA: 01:19:56

################################################################################
                      [1m Learning iteration 30/1500 [0m                      

                       Computation: 51467 steps/s (collection: 1.800s, learning 0.110s)
             Mean action noise std: 1.06
          Mean value_function loss: 0.0144
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 26.6199
                       Mean reward: 1.65
               Mean episode length: 226.09
    Episode_Reward/reaching_object: 0.2768
    Episode_Reward/rotating_object: 0.0352
        Episode_Reward/action_rate: -0.0036
          Episode_Reward/joint_vel: -0.0045
      Episode_Termination/time_out: 7.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 9.9167
--------------------------------------------------------------------------------
                   Total timesteps: 3047424
                    Iteration time: 1.91s
                      Time elapsed: 00:01:39
                               ETA: 01:18:49

################################################################################
                      [1m Learning iteration 31/1500 [0m                      

                       Computation: 48634 steps/s (collection: 1.907s, learning 0.115s)
             Mean action noise std: 1.07
          Mean value_function loss: 0.0415
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 26.7001
                       Mean reward: 1.52
               Mean episode length: 220.61
    Episode_Reward/reaching_object: 0.2873
    Episode_Reward/rotating_object: 0.0325
        Episode_Reward/action_rate: -0.0036
          Episode_Reward/joint_vel: -0.0047
      Episode_Termination/time_out: 9.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 9.9583
--------------------------------------------------------------------------------
                   Total timesteps: 3145728
                    Iteration time: 2.02s
                      Time elapsed: 00:01:41
                               ETA: 01:17:51

################################################################################
                      [1m Learning iteration 32/1500 [0m                      

                       Computation: 52514 steps/s (collection: 1.781s, learning 0.091s)
             Mean action noise std: 1.07
          Mean value_function loss: 0.1011
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 26.7351
                       Mean reward: 2.61
               Mean episode length: 224.53
    Episode_Reward/reaching_object: 0.3238
    Episode_Reward/rotating_object: 0.0748
        Episode_Reward/action_rate: -0.0036
          Episode_Reward/joint_vel: -0.0048
      Episode_Termination/time_out: 10.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 8.6250
--------------------------------------------------------------------------------
                   Total timesteps: 3244032
                    Iteration time: 1.87s
                      Time elapsed: 00:01:43
                               ETA: 01:16:49

################################################################################
                      [1m Learning iteration 33/1500 [0m                      

                       Computation: 52126 steps/s (collection: 1.790s, learning 0.096s)
             Mean action noise std: 1.08
          Mean value_function loss: 0.0337
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 26.8404
                       Mean reward: 2.21
               Mean episode length: 219.04
    Episode_Reward/reaching_object: 0.3362
    Episode_Reward/rotating_object: 0.0640
        Episode_Reward/action_rate: -0.0037
          Episode_Reward/joint_vel: -0.0047
      Episode_Termination/time_out: 10.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 8.5417
--------------------------------------------------------------------------------
                   Total timesteps: 3342336
                    Iteration time: 1.89s
                      Time elapsed: 00:01:45
                               ETA: 01:15:52

################################################################################
                      [1m Learning iteration 34/1500 [0m                      

                       Computation: 51695 steps/s (collection: 1.812s, learning 0.089s)
             Mean action noise std: 1.08
          Mean value_function loss: 0.0737
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 26.9333
                       Mean reward: 2.41
               Mean episode length: 217.66
    Episode_Reward/reaching_object: 0.3591
    Episode_Reward/rotating_object: 0.1472
        Episode_Reward/action_rate: -0.0037
          Episode_Reward/joint_vel: -0.0048
      Episode_Termination/time_out: 10.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 8.0417
--------------------------------------------------------------------------------
                   Total timesteps: 3440640
                    Iteration time: 1.90s
                      Time elapsed: 00:01:47
                               ETA: 01:14:59

################################################################################
                      [1m Learning iteration 35/1500 [0m                      

                       Computation: 51897 steps/s (collection: 1.797s, learning 0.097s)
             Mean action noise std: 1.09
          Mean value_function loss: 0.0452
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 27.0420
                       Mean reward: 2.21
               Mean episode length: 219.48
    Episode_Reward/reaching_object: 0.3688
    Episode_Reward/rotating_object: 0.1089
        Episode_Reward/action_rate: -0.0037
          Episode_Reward/joint_vel: -0.0049
      Episode_Termination/time_out: 11.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 8.4583
--------------------------------------------------------------------------------
                   Total timesteps: 3538944
                    Iteration time: 1.89s
                      Time elapsed: 00:01:49
                               ETA: 01:14:08

################################################################################
                      [1m Learning iteration 36/1500 [0m                      

                       Computation: 52378 steps/s (collection: 1.783s, learning 0.094s)
             Mean action noise std: 1.10
          Mean value_function loss: 0.1127
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 27.1282
                       Mean reward: 2.79
               Mean episode length: 227.98
    Episode_Reward/reaching_object: 0.3913
    Episode_Reward/rotating_object: 0.1933
        Episode_Reward/action_rate: -0.0038
          Episode_Reward/joint_vel: -0.0051
      Episode_Termination/time_out: 10.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 6.6667
--------------------------------------------------------------------------------
                   Total timesteps: 3637248
                    Iteration time: 1.88s
                      Time elapsed: 00:01:51
                               ETA: 01:13:19

################################################################################
                      [1m Learning iteration 37/1500 [0m                      

                       Computation: 50341 steps/s (collection: 1.863s, learning 0.090s)
             Mean action noise std: 1.10
          Mean value_function loss: 0.5261
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 27.2243
                       Mean reward: 3.16
               Mean episode length: 233.31
    Episode_Reward/reaching_object: 0.4460
    Episode_Reward/rotating_object: 0.2435
        Episode_Reward/action_rate: -0.0040
          Episode_Reward/joint_vel: -0.0056
      Episode_Termination/time_out: 11.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.2500
--------------------------------------------------------------------------------
                   Total timesteps: 3735552
                    Iteration time: 1.95s
                      Time elapsed: 00:01:53
                               ETA: 01:12:35

################################################################################
                      [1m Learning iteration 38/1500 [0m                      

                       Computation: 50476 steps/s (collection: 1.847s, learning 0.100s)
             Mean action noise std: 1.11
          Mean value_function loss: 0.8852
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 27.3524
                       Mean reward: 4.72
               Mean episode length: 231.88
    Episode_Reward/reaching_object: 0.4475
    Episode_Reward/rotating_object: 0.2768
        Episode_Reward/action_rate: -0.0040
          Episode_Reward/joint_vel: -0.0056
      Episode_Termination/time_out: 11.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.7083
--------------------------------------------------------------------------------
                   Total timesteps: 3833856
                    Iteration time: 1.95s
                      Time elapsed: 00:01:55
                               ETA: 01:11:54

################################################################################
                      [1m Learning iteration 39/1500 [0m                      

                       Computation: 51613 steps/s (collection: 1.798s, learning 0.107s)
             Mean action noise std: 1.12
          Mean value_function loss: 1.1502
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 27.4807
                       Mean reward: 5.45
               Mean episode length: 231.95
    Episode_Reward/reaching_object: 0.4539
    Episode_Reward/rotating_object: 0.5152
        Episode_Reward/action_rate: -0.0040
          Episode_Reward/joint_vel: -0.0057
      Episode_Termination/time_out: 11.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.1250
--------------------------------------------------------------------------------
                   Total timesteps: 3932160
                    Iteration time: 1.90s
                      Time elapsed: 00:01:56
                               ETA: 01:11:13

################################################################################
                      [1m Learning iteration 40/1500 [0m                      

                       Computation: 51734 steps/s (collection: 1.806s, learning 0.094s)
             Mean action noise std: 1.12
          Mean value_function loss: 1.4084
               Mean surrogate loss: -0.0004
                 Mean entropy loss: 27.5868
                       Mean reward: 7.15
               Mean episode length: 227.34
    Episode_Reward/reaching_object: 0.4682
    Episode_Reward/rotating_object: 0.5757
        Episode_Reward/action_rate: -0.0041
          Episode_Reward/joint_vel: -0.0059
      Episode_Termination/time_out: 11.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.0833
--------------------------------------------------------------------------------
                   Total timesteps: 4030464
                    Iteration time: 1.90s
                      Time elapsed: 00:01:58
                               ETA: 01:10:33

################################################################################
                      [1m Learning iteration 41/1500 [0m                      

                       Computation: 51369 steps/s (collection: 1.816s, learning 0.098s)
             Mean action noise std: 1.13
          Mean value_function loss: 1.9091
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 27.6776
                       Mean reward: 10.21
               Mean episode length: 235.57
    Episode_Reward/reaching_object: 0.4921
    Episode_Reward/rotating_object: 1.0546
        Episode_Reward/action_rate: -0.0042
          Episode_Reward/joint_vel: -0.0061
      Episode_Termination/time_out: 12.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.0000
--------------------------------------------------------------------------------
                   Total timesteps: 4128768
                    Iteration time: 1.91s
                      Time elapsed: 00:02:00
                               ETA: 01:09:56

################################################################################
                      [1m Learning iteration 42/1500 [0m                      

                       Computation: 51779 steps/s (collection: 1.786s, learning 0.112s)
             Mean action noise std: 1.13
          Mean value_function loss: 2.6448
               Mean surrogate loss: 0.0006
                 Mean entropy loss: 27.7683
                       Mean reward: 5.33
               Mean episode length: 226.66
    Episode_Reward/reaching_object: 0.4942
    Episode_Reward/rotating_object: 1.1087
        Episode_Reward/action_rate: -0.0043
          Episode_Reward/joint_vel: -0.0062
      Episode_Termination/time_out: 13.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.6667
--------------------------------------------------------------------------------
                   Total timesteps: 4227072
                    Iteration time: 1.90s
                      Time elapsed: 00:02:02
                               ETA: 01:09:20

################################################################################
                      [1m Learning iteration 43/1500 [0m                      

                       Computation: 50982 steps/s (collection: 1.828s, learning 0.100s)
             Mean action noise std: 1.14
          Mean value_function loss: 2.6103
               Mean surrogate loss: -0.0001
                 Mean entropy loss: 27.8393
                       Mean reward: 6.41
               Mean episode length: 233.58
    Episode_Reward/reaching_object: 0.5151
    Episode_Reward/rotating_object: 1.4363
        Episode_Reward/action_rate: -0.0043
          Episode_Reward/joint_vel: -0.0064
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.5833
--------------------------------------------------------------------------------
                   Total timesteps: 4325376
                    Iteration time: 1.93s
                      Time elapsed: 00:02:04
                               ETA: 01:08:46

################################################################################
                      [1m Learning iteration 44/1500 [0m                      

                       Computation: 50872 steps/s (collection: 1.833s, learning 0.099s)
             Mean action noise std: 1.15
          Mean value_function loss: 2.6968
               Mean surrogate loss: 0.0011
                 Mean entropy loss: 27.9434
                       Mean reward: 10.97
               Mean episode length: 234.98
    Episode_Reward/reaching_object: 0.5410
    Episode_Reward/rotating_object: 1.9982
        Episode_Reward/action_rate: -0.0045
          Episode_Reward/joint_vel: -0.0067
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 4423680
                    Iteration time: 1.93s
                      Time elapsed: 00:02:06
                               ETA: 01:08:15

################################################################################
                      [1m Learning iteration 45/1500 [0m                      

                       Computation: 50398 steps/s (collection: 1.854s, learning 0.097s)
             Mean action noise std: 1.15
          Mean value_function loss: 3.8881
               Mean surrogate loss: -0.0005
                 Mean entropy loss: 27.9984
                       Mean reward: 12.31
               Mean episode length: 242.49
    Episode_Reward/reaching_object: 0.5414
    Episode_Reward/rotating_object: 1.7444
        Episode_Reward/action_rate: -0.0046
          Episode_Reward/joint_vel: -0.0067
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 4521984
                    Iteration time: 1.95s
                      Time elapsed: 00:02:08
                               ETA: 01:07:44

################################################################################
                      [1m Learning iteration 46/1500 [0m                      

                       Computation: 53103 steps/s (collection: 1.752s, learning 0.099s)
             Mean action noise std: 1.15
          Mean value_function loss: 5.2001
               Mean surrogate loss: 0.0027
                 Mean entropy loss: 28.0317
                       Mean reward: 14.37
               Mean episode length: 238.07
    Episode_Reward/reaching_object: 0.5345
    Episode_Reward/rotating_object: 1.8948
        Episode_Reward/action_rate: -0.0046
          Episode_Reward/joint_vel: -0.0067
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 4620288
                    Iteration time: 1.85s
                      Time elapsed: 00:02:10
                               ETA: 01:07:12

################################################################################
                      [1m Learning iteration 47/1500 [0m                      

                       Computation: 52459 steps/s (collection: 1.768s, learning 0.106s)
             Mean action noise std: 1.15
          Mean value_function loss: 4.8415
               Mean surrogate loss: 0.0061
                 Mean entropy loss: 28.0507
                       Mean reward: 11.48
               Mean episode length: 238.82
    Episode_Reward/reaching_object: 0.5267
    Episode_Reward/rotating_object: 2.1717
        Episode_Reward/action_rate: -0.0046
          Episode_Reward/joint_vel: -0.0068
      Episode_Termination/time_out: 13.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 4718592
                    Iteration time: 1.87s
                      Time elapsed: 00:02:12
                               ETA: 01:06:42

################################################################################
                      [1m Learning iteration 48/1500 [0m                      

                       Computation: 50711 steps/s (collection: 1.821s, learning 0.117s)
             Mean action noise std: 1.15
          Mean value_function loss: 4.8417
               Mean surrogate loss: 0.0021
                 Mean entropy loss: 28.0598
                       Mean reward: 12.13
               Mean episode length: 236.62
    Episode_Reward/reaching_object: 0.5297
    Episode_Reward/rotating_object: 3.2272
        Episode_Reward/action_rate: -0.0047
          Episode_Reward/joint_vel: -0.0068
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 4816896
                    Iteration time: 1.94s
                      Time elapsed: 00:02:14
                               ETA: 01:06:16

################################################################################
                      [1m Learning iteration 49/1500 [0m                      

                       Computation: 52354 steps/s (collection: 1.786s, learning 0.092s)
             Mean action noise std: 1.16
          Mean value_function loss: 4.2494
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 28.0827
                       Mean reward: 19.63
               Mean episode length: 229.64
    Episode_Reward/reaching_object: 0.4978
    Episode_Reward/rotating_object: 3.6602
        Episode_Reward/action_rate: -0.0047
          Episode_Reward/joint_vel: -0.0066
      Episode_Termination/time_out: 13.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 4915200
                    Iteration time: 1.88s
                      Time elapsed: 00:02:16
                               ETA: 01:05:48

################################################################################
                      [1m Learning iteration 50/1500 [0m                      

                       Computation: 51340 steps/s (collection: 1.800s, learning 0.115s)
             Mean action noise std: 1.16
          Mean value_function loss: 4.3965
               Mean surrogate loss: 0.0078
                 Mean entropy loss: 28.1513
                       Mean reward: 16.45
               Mean episode length: 238.95
    Episode_Reward/reaching_object: 0.5190
    Episode_Reward/rotating_object: 3.3284
        Episode_Reward/action_rate: -0.0048
          Episode_Reward/joint_vel: -0.0068
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 5013504
                    Iteration time: 1.91s
                      Time elapsed: 00:02:17
                               ETA: 01:05:22

################################################################################
                      [1m Learning iteration 51/1500 [0m                      

                       Computation: 49029 steps/s (collection: 1.847s, learning 0.158s)
             Mean action noise std: 1.16
          Mean value_function loss: 4.5599
               Mean surrogate loss: 0.0044
                 Mean entropy loss: 28.1613
                       Mean reward: 20.78
               Mean episode length: 237.97
    Episode_Reward/reaching_object: 0.4917
    Episode_Reward/rotating_object: 2.9856
        Episode_Reward/action_rate: -0.0047
          Episode_Reward/joint_vel: -0.0067
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.1250
--------------------------------------------------------------------------------
                   Total timesteps: 5111808
                    Iteration time: 2.01s
                      Time elapsed: 00:02:19
                               ETA: 01:05:00

################################################################################
                      [1m Learning iteration 52/1500 [0m                      

                       Computation: 50970 steps/s (collection: 1.837s, learning 0.092s)
             Mean action noise std: 1.16
          Mean value_function loss: 5.6848
               Mean surrogate loss: 0.0084
                 Mean entropy loss: 28.1681
                       Mean reward: 14.64
               Mean episode length: 238.80
    Episode_Reward/reaching_object: 0.5063
    Episode_Reward/rotating_object: 2.4820
        Episode_Reward/action_rate: -0.0048
          Episode_Reward/joint_vel: -0.0069
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 5210112
                    Iteration time: 1.93s
                      Time elapsed: 00:02:21
                               ETA: 01:04:36

################################################################################
                      [1m Learning iteration 53/1500 [0m                      

                       Computation: 52270 steps/s (collection: 1.779s, learning 0.102s)
             Mean action noise std: 1.16
          Mean value_function loss: 6.7926
               Mean surrogate loss: 0.0027
                 Mean entropy loss: 28.1732
                       Mean reward: 21.96
               Mean episode length: 244.36
    Episode_Reward/reaching_object: 0.5077
    Episode_Reward/rotating_object: 3.2472
        Episode_Reward/action_rate: -0.0049
          Episode_Reward/joint_vel: -0.0069
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 5308416
                    Iteration time: 1.88s
                      Time elapsed: 00:02:23
                               ETA: 01:04:12

################################################################################
                      [1m Learning iteration 54/1500 [0m                      

                       Computation: 44267 steps/s (collection: 1.966s, learning 0.255s)
             Mean action noise std: 1.16
          Mean value_function loss: 6.5471
               Mean surrogate loss: -0.0001
                 Mean entropy loss: 28.1976
                       Mean reward: 25.55
               Mean episode length: 227.98
    Episode_Reward/reaching_object: 0.4882
    Episode_Reward/rotating_object: 3.6466
        Episode_Reward/action_rate: -0.0048
          Episode_Reward/joint_vel: -0.0069
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.7500
--------------------------------------------------------------------------------
                   Total timesteps: 5406720
                    Iteration time: 2.22s
                      Time elapsed: 00:02:26
                               ETA: 01:03:58

################################################################################
                      [1m Learning iteration 55/1500 [0m                      

                       Computation: 38954 steps/s (collection: 2.352s, learning 0.172s)
             Mean action noise std: 1.17
          Mean value_function loss: 6.2572
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 28.2456
                       Mean reward: 18.03
               Mean episode length: 239.10
    Episode_Reward/reaching_object: 0.4831
    Episode_Reward/rotating_object: 3.0888
        Episode_Reward/action_rate: -0.0048
          Episode_Reward/joint_vel: -0.0068
      Episode_Termination/time_out: 13.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.0833
--------------------------------------------------------------------------------
                   Total timesteps: 5505024
                    Iteration time: 2.52s
                      Time elapsed: 00:02:28
                               ETA: 01:03:52

################################################################################
                      [1m Learning iteration 56/1500 [0m                      

                       Computation: 37604 steps/s (collection: 2.455s, learning 0.159s)
             Mean action noise std: 1.17
          Mean value_function loss: 6.0587
               Mean surrogate loss: 0.0310
                 Mean entropy loss: 28.2820
                       Mean reward: 25.58
               Mean episode length: 231.27
    Episode_Reward/reaching_object: 0.4801
    Episode_Reward/rotating_object: 4.6327
        Episode_Reward/action_rate: -0.0048
          Episode_Reward/joint_vel: -0.0068
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.2500
--------------------------------------------------------------------------------
                   Total timesteps: 5603328
                    Iteration time: 2.61s
                      Time elapsed: 00:02:31
                               ETA: 01:03:48

################################################################################
                      [1m Learning iteration 57/1500 [0m                      

                       Computation: 52048 steps/s (collection: 1.787s, learning 0.102s)
             Mean action noise std: 1.17
          Mean value_function loss: 5.8639
               Mean surrogate loss: 0.0029
                 Mean entropy loss: 28.2881
                       Mean reward: 18.75
               Mean episode length: 223.11
    Episode_Reward/reaching_object: 0.4583
    Episode_Reward/rotating_object: 3.6926
        Episode_Reward/action_rate: -0.0047
          Episode_Reward/joint_vel: -0.0067
      Episode_Termination/time_out: 13.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 6.6667
--------------------------------------------------------------------------------
                   Total timesteps: 5701632
                    Iteration time: 1.89s
                      Time elapsed: 00:02:33
                               ETA: 01:03:27

################################################################################
                      [1m Learning iteration 58/1500 [0m                      

                       Computation: 52689 steps/s (collection: 1.750s, learning 0.115s)
             Mean action noise std: 1.17
          Mean value_function loss: 5.7390
               Mean surrogate loss: -0.0002
                 Mean entropy loss: 28.2995
                       Mean reward: 24.96
               Mean episode length: 216.57
    Episode_Reward/reaching_object: 0.4464
    Episode_Reward/rotating_object: 3.6872
        Episode_Reward/action_rate: -0.0046
          Episode_Reward/joint_vel: -0.0065
      Episode_Termination/time_out: 11.0833
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 7.1667
--------------------------------------------------------------------------------
                   Total timesteps: 5799936
                    Iteration time: 1.87s
                      Time elapsed: 00:02:34
                               ETA: 01:03:05

################################################################################
                      [1m Learning iteration 59/1500 [0m                      

                       Computation: 51177 steps/s (collection: 1.793s, learning 0.128s)
             Mean action noise std: 1.17
          Mean value_function loss: 5.2441
               Mean surrogate loss: -0.0002
                 Mean entropy loss: 28.3756
                       Mean reward: 29.19
               Mean episode length: 230.38
    Episode_Reward/reaching_object: 0.4711
    Episode_Reward/rotating_object: 3.6813
        Episode_Reward/action_rate: -0.0047
          Episode_Reward/joint_vel: -0.0069
      Episode_Termination/time_out: 12.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.8750
--------------------------------------------------------------------------------
                   Total timesteps: 5898240
                    Iteration time: 1.92s
                      Time elapsed: 00:02:36
                               ETA: 01:02:46

################################################################################
                      [1m Learning iteration 60/1500 [0m                      

                       Computation: 52798 steps/s (collection: 1.756s, learning 0.105s)
             Mean action noise std: 1.18
          Mean value_function loss: 5.2427
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 28.4343
                       Mean reward: 14.57
               Mean episode length: 228.58
    Episode_Reward/reaching_object: 0.4840
    Episode_Reward/rotating_object: 3.9178
        Episode_Reward/action_rate: -0.0048
          Episode_Reward/joint_vel: -0.0070
      Episode_Termination/time_out: 11.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.3333
--------------------------------------------------------------------------------
                   Total timesteps: 5996544
                    Iteration time: 1.86s
                      Time elapsed: 00:02:38
                               ETA: 01:02:25

################################################################################
                      [1m Learning iteration 61/1500 [0m                      

                       Computation: 53432 steps/s (collection: 1.724s, learning 0.116s)
             Mean action noise std: 1.18
          Mean value_function loss: 5.7321
               Mean surrogate loss: -0.0003
                 Mean entropy loss: 28.4894
                       Mean reward: 23.92
               Mean episode length: 239.83
    Episode_Reward/reaching_object: 0.5092
    Episode_Reward/rotating_object: 5.2041
        Episode_Reward/action_rate: -0.0050
          Episode_Reward/joint_vel: -0.0073
      Episode_Termination/time_out: 13.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 6094848
                    Iteration time: 1.84s
                      Time elapsed: 00:02:40
                               ETA: 01:02:05

################################################################################
                      [1m Learning iteration 62/1500 [0m                      

                       Computation: 52275 steps/s (collection: 1.779s, learning 0.101s)
             Mean action noise std: 1.19
          Mean value_function loss: 6.2142
               Mean surrogate loss: -0.0006
                 Mean entropy loss: 28.5611
                       Mean reward: 22.36
               Mean episode length: 239.30
    Episode_Reward/reaching_object: 0.5107
    Episode_Reward/rotating_object: 3.6638
        Episode_Reward/action_rate: -0.0051
          Episode_Reward/joint_vel: -0.0074
      Episode_Termination/time_out: 12.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 6193152
                    Iteration time: 1.88s
                      Time elapsed: 00:02:42
                               ETA: 01:01:46

################################################################################
                      [1m Learning iteration 63/1500 [0m                      

                       Computation: 51452 steps/s (collection: 1.803s, learning 0.108s)
             Mean action noise std: 1.19
          Mean value_function loss: 7.1452
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 28.6095
                       Mean reward: 18.62
               Mean episode length: 243.03
    Episode_Reward/reaching_object: 0.5149
    Episode_Reward/rotating_object: 4.3818
        Episode_Reward/action_rate: -0.0051
          Episode_Reward/joint_vel: -0.0074
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 6291456
                    Iteration time: 1.91s
                      Time elapsed: 00:02:44
                               ETA: 01:01:29

################################################################################
                      [1m Learning iteration 64/1500 [0m                      

                       Computation: 51157 steps/s (collection: 1.816s, learning 0.106s)
             Mean action noise std: 1.19
          Mean value_function loss: 6.8123
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 28.6732
                       Mean reward: 16.18
               Mean episode length: 243.23
    Episode_Reward/reaching_object: 0.4922
    Episode_Reward/rotating_object: 4.0451
        Episode_Reward/action_rate: -0.0051
          Episode_Reward/joint_vel: -0.0073
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 6389760
                    Iteration time: 1.92s
                      Time elapsed: 00:02:46
                               ETA: 01:01:12

################################################################################
                      [1m Learning iteration 65/1500 [0m                      

                       Computation: 52473 steps/s (collection: 1.768s, learning 0.106s)
             Mean action noise std: 1.20
          Mean value_function loss: 7.1764
               Mean surrogate loss: 0.0005
                 Mean entropy loss: 28.7253
                       Mean reward: 21.97
               Mean episode length: 242.01
    Episode_Reward/reaching_object: 0.4713
    Episode_Reward/rotating_object: 4.4724
        Episode_Reward/action_rate: -0.0051
          Episode_Reward/joint_vel: -0.0075
      Episode_Termination/time_out: 13.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 6488064
                    Iteration time: 1.87s
                      Time elapsed: 00:02:48
                               ETA: 01:00:55

################################################################################
                      [1m Learning iteration 66/1500 [0m                      

                       Computation: 53059 steps/s (collection: 1.749s, learning 0.104s)
             Mean action noise std: 1.20
          Mean value_function loss: 7.9891
               Mean surrogate loss: 0.0075
                 Mean entropy loss: 28.7461
                       Mean reward: 25.13
               Mean episode length: 240.42
    Episode_Reward/reaching_object: 0.4788
    Episode_Reward/rotating_object: 4.5998
        Episode_Reward/action_rate: -0.0051
          Episode_Reward/joint_vel: -0.0075
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 6586368
                    Iteration time: 1.85s
                      Time elapsed: 00:02:49
                               ETA: 01:00:37

################################################################################
                      [1m Learning iteration 67/1500 [0m                      

                       Computation: 52538 steps/s (collection: 1.769s, learning 0.102s)
             Mean action noise std: 1.20
          Mean value_function loss: 7.1423
               Mean surrogate loss: -0.0002
                 Mean entropy loss: 28.7526
                       Mean reward: 25.88
               Mean episode length: 246.77
    Episode_Reward/reaching_object: 0.4848
    Episode_Reward/rotating_object: 5.1226
        Episode_Reward/action_rate: -0.0052
          Episode_Reward/joint_vel: -0.0078
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 6684672
                    Iteration time: 1.87s
                      Time elapsed: 00:02:51
                               ETA: 01:00:21

################################################################################
                      [1m Learning iteration 68/1500 [0m                      

                       Computation: 54049 steps/s (collection: 1.721s, learning 0.098s)
             Mean action noise std: 1.20
          Mean value_function loss: 6.8971
               Mean surrogate loss: -0.0003
                 Mean entropy loss: 28.7937
                       Mean reward: 29.01
               Mean episode length: 238.16
    Episode_Reward/reaching_object: 0.4874
    Episode_Reward/rotating_object: 4.1035
        Episode_Reward/action_rate: -0.0052
          Episode_Reward/joint_vel: -0.0078
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 6782976
                    Iteration time: 1.82s
                      Time elapsed: 00:02:53
                               ETA: 01:00:03

################################################################################
                      [1m Learning iteration 69/1500 [0m                      

                       Computation: 54152 steps/s (collection: 1.721s, learning 0.094s)
             Mean action noise std: 1.20
          Mean value_function loss: 6.8608
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 28.8357
                       Mean reward: 22.90
               Mean episode length: 240.03
    Episode_Reward/reaching_object: 0.4609
    Episode_Reward/rotating_object: 5.4486
        Episode_Reward/action_rate: -0.0052
          Episode_Reward/joint_vel: -0.0077
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 6881280
                    Iteration time: 1.82s
                      Time elapsed: 00:02:55
                               ETA: 00:59:46

################################################################################
                      [1m Learning iteration 70/1500 [0m                      

                       Computation: 52572 steps/s (collection: 1.749s, learning 0.121s)
             Mean action noise std: 1.21
          Mean value_function loss: 7.5636
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 28.8958
                       Mean reward: 18.28
               Mean episode length: 234.80
    Episode_Reward/reaching_object: 0.4579
    Episode_Reward/rotating_object: 4.3718
        Episode_Reward/action_rate: -0.0053
          Episode_Reward/joint_vel: -0.0078
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 6979584
                    Iteration time: 1.87s
                      Time elapsed: 00:02:57
                               ETA: 00:59:31

################################################################################
                      [1m Learning iteration 71/1500 [0m                      

                       Computation: 53897 steps/s (collection: 1.719s, learning 0.105s)
             Mean action noise std: 1.21
          Mean value_function loss: 8.1851
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 28.9598
                       Mean reward: 21.78
               Mean episode length: 227.67
    Episode_Reward/reaching_object: 0.4571
    Episode_Reward/rotating_object: 3.9342
        Episode_Reward/action_rate: -0.0052
          Episode_Reward/joint_vel: -0.0079
      Episode_Termination/time_out: 13.1667
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 7077888
                    Iteration time: 1.82s
                      Time elapsed: 00:02:59
                               ETA: 00:59:15

################################################################################
                      [1m Learning iteration 72/1500 [0m                      

                       Computation: 53862 steps/s (collection: 1.734s, learning 0.092s)
             Mean action noise std: 1.22
          Mean value_function loss: 7.8555
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 29.0330
                       Mean reward: 24.16
               Mean episode length: 235.10
    Episode_Reward/reaching_object: 0.4581
    Episode_Reward/rotating_object: 3.9322
        Episode_Reward/action_rate: -0.0052
          Episode_Reward/joint_vel: -0.0079
      Episode_Termination/time_out: 13.4583
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 7176192
                    Iteration time: 1.83s
                      Time elapsed: 00:03:00
                               ETA: 00:59:00

################################################################################
                      [1m Learning iteration 73/1500 [0m                      

                       Computation: 53717 steps/s (collection: 1.739s, learning 0.091s)
             Mean action noise std: 1.22
          Mean value_function loss: 8.4137
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 29.1136
                       Mean reward: 29.95
               Mean episode length: 231.68
    Episode_Reward/reaching_object: 0.4658
    Episode_Reward/rotating_object: 5.8175
        Episode_Reward/action_rate: -0.0052
          Episode_Reward/joint_vel: -0.0078
      Episode_Termination/time_out: 13.5000
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 7274496
                    Iteration time: 1.83s
                      Time elapsed: 00:03:02
                               ETA: 00:58:45

################################################################################
                      [1m Learning iteration 74/1500 [0m                      

                       Computation: 53627 steps/s (collection: 1.736s, learning 0.097s)
             Mean action noise std: 1.23
          Mean value_function loss: 9.6101
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 29.1582
                       Mean reward: 20.22
               Mean episode length: 242.36
    Episode_Reward/reaching_object: 0.4716
    Episode_Reward/rotating_object: 4.3765
        Episode_Reward/action_rate: -0.0054
          Episode_Reward/joint_vel: -0.0082
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 7372800
                    Iteration time: 1.83s
                      Time elapsed: 00:03:04
                               ETA: 00:58:30

################################################################################
                      [1m Learning iteration 75/1500 [0m                      

                       Computation: 53980 steps/s (collection: 1.725s, learning 0.096s)
             Mean action noise std: 1.23
          Mean value_function loss: 9.4115
               Mean surrogate loss: 0.0082
                 Mean entropy loss: 29.1888
                       Mean reward: 31.46
               Mean episode length: 238.05
    Episode_Reward/reaching_object: 0.4987
    Episode_Reward/rotating_object: 5.8462
        Episode_Reward/action_rate: -0.0054
          Episode_Reward/joint_vel: -0.0083
      Episode_Termination/time_out: 13.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 7471104
                    Iteration time: 1.82s
                      Time elapsed: 00:03:06
                               ETA: 00:58:16

################################################################################
                      [1m Learning iteration 76/1500 [0m                      

                       Computation: 53759 steps/s (collection: 1.731s, learning 0.098s)
             Mean action noise std: 1.23
          Mean value_function loss: 8.6599
               Mean surrogate loss: -0.0004
                 Mean entropy loss: 29.2080
                       Mean reward: 23.67
               Mean episode length: 241.82
    Episode_Reward/reaching_object: 0.4971
    Episode_Reward/rotating_object: 3.9674
        Episode_Reward/action_rate: -0.0055
          Episode_Reward/joint_vel: -0.0084
      Episode_Termination/time_out: 13.6250
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 7569408
                    Iteration time: 1.83s
                      Time elapsed: 00:03:08
                               ETA: 00:58:02

################################################################################
                      [1m Learning iteration 77/1500 [0m                      

                       Computation: 51611 steps/s (collection: 1.802s, learning 0.103s)
             Mean action noise std: 1.23
          Mean value_function loss: 8.8176
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 29.2447
                       Mean reward: 19.94
               Mean episode length: 246.24
    Episode_Reward/reaching_object: 0.4988
    Episode_Reward/rotating_object: 4.4702
        Episode_Reward/action_rate: -0.0056
          Episode_Reward/joint_vel: -0.0084
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 7667712
                    Iteration time: 1.90s
                      Time elapsed: 00:03:10
                               ETA: 00:57:49

################################################################################
                      [1m Learning iteration 78/1500 [0m                      

                       Computation: 53818 steps/s (collection: 1.716s, learning 0.111s)
             Mean action noise std: 1.24
          Mean value_function loss: 9.2968
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 29.3088
                       Mean reward: 32.45
               Mean episode length: 242.85
    Episode_Reward/reaching_object: 0.4987
    Episode_Reward/rotating_object: 5.9904
        Episode_Reward/action_rate: -0.0056
          Episode_Reward/joint_vel: -0.0084
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 7766016
                    Iteration time: 1.83s
                      Time elapsed: 00:03:12
                               ETA: 00:57:36

################################################################################
                      [1m Learning iteration 79/1500 [0m                      

                       Computation: 53893 steps/s (collection: 1.720s, learning 0.104s)
             Mean action noise std: 1.24
          Mean value_function loss: 8.9838
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 29.3740
                       Mean reward: 22.21
               Mean episode length: 240.14
    Episode_Reward/reaching_object: 0.4976
    Episode_Reward/rotating_object: 5.7781
        Episode_Reward/action_rate: -0.0056
          Episode_Reward/joint_vel: -0.0084
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 7864320
                    Iteration time: 1.82s
                      Time elapsed: 00:03:13
                               ETA: 00:57:23

################################################################################
                      [1m Learning iteration 80/1500 [0m                      

                       Computation: 52743 steps/s (collection: 1.753s, learning 0.111s)
             Mean action noise std: 1.24
          Mean value_function loss: 9.2078
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 29.4236
                       Mean reward: 28.85
               Mean episode length: 239.72
    Episode_Reward/reaching_object: 0.4818
    Episode_Reward/rotating_object: 5.0868
        Episode_Reward/action_rate: -0.0057
          Episode_Reward/joint_vel: -0.0085
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 7962624
                    Iteration time: 1.86s
                      Time elapsed: 00:03:15
                               ETA: 00:57:11

################################################################################
                      [1m Learning iteration 81/1500 [0m                      

                       Computation: 53371 steps/s (collection: 1.748s, learning 0.094s)
             Mean action noise std: 1.25
          Mean value_function loss: 10.1654
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 29.4636
                       Mean reward: 36.31
               Mean episode length: 236.53
    Episode_Reward/reaching_object: 0.4810
    Episode_Reward/rotating_object: 6.7531
        Episode_Reward/action_rate: -0.0057
          Episode_Reward/joint_vel: -0.0084
      Episode_Termination/time_out: 13.3750
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 8060928
                    Iteration time: 1.84s
                      Time elapsed: 00:03:17
                               ETA: 00:56:58

################################################################################
                      [1m Learning iteration 82/1500 [0m                      

                       Computation: 53453 steps/s (collection: 1.743s, learning 0.096s)
             Mean action noise std: 1.25
          Mean value_function loss: 10.8405
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 29.4993
                       Mean reward: 27.71
               Mean episode length: 238.56
    Episode_Reward/reaching_object: 0.4935
    Episode_Reward/rotating_object: 5.2225
        Episode_Reward/action_rate: -0.0058
          Episode_Reward/joint_vel: -0.0087
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 8159232
                    Iteration time: 1.84s
                      Time elapsed: 00:03:19
                               ETA: 00:56:46

################################################################################
                      [1m Learning iteration 83/1500 [0m                      

                       Computation: 51703 steps/s (collection: 1.761s, learning 0.140s)
             Mean action noise std: 1.25
          Mean value_function loss: 11.8161
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 29.5246
                       Mean reward: 33.34
               Mean episode length: 240.26
    Episode_Reward/reaching_object: 0.4916
    Episode_Reward/rotating_object: 5.9737
        Episode_Reward/action_rate: -0.0057
          Episode_Reward/joint_vel: -0.0085
      Episode_Termination/time_out: 13.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 8257536
                    Iteration time: 1.90s
                      Time elapsed: 00:03:21
                               ETA: 00:56:35

################################################################################
                      [1m Learning iteration 84/1500 [0m                      

                       Computation: 53473 steps/s (collection: 1.746s, learning 0.093s)
             Mean action noise std: 1.25
          Mean value_function loss: 13.1275
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 29.5582
                       Mean reward: 31.51
               Mean episode length: 238.17
    Episode_Reward/reaching_object: 0.4897
    Episode_Reward/rotating_object: 6.3899
        Episode_Reward/action_rate: -0.0059
          Episode_Reward/joint_vel: -0.0088
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 8355840
                    Iteration time: 1.84s
                      Time elapsed: 00:03:23
                               ETA: 00:56:23

################################################################################
                      [1m Learning iteration 85/1500 [0m                      

                       Computation: 52959 steps/s (collection: 1.735s, learning 0.122s)
             Mean action noise std: 1.26
          Mean value_function loss: 12.8542
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 29.6060
                       Mean reward: 30.54
               Mean episode length: 236.72
    Episode_Reward/reaching_object: 0.4948
    Episode_Reward/rotating_object: 4.7316
        Episode_Reward/action_rate: -0.0058
          Episode_Reward/joint_vel: -0.0089
      Episode_Termination/time_out: 13.5833
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 8454144
                    Iteration time: 1.86s
                      Time elapsed: 00:03:24
                               ETA: 00:56:12

################################################################################
                      [1m Learning iteration 86/1500 [0m                      

                       Computation: 52173 steps/s (collection: 1.776s, learning 0.109s)
             Mean action noise std: 1.26
          Mean value_function loss: 13.0538
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 29.6613
                       Mean reward: 28.56
               Mean episode length: 245.36
    Episode_Reward/reaching_object: 0.4894
    Episode_Reward/rotating_object: 5.1524
        Episode_Reward/action_rate: -0.0059
          Episode_Reward/joint_vel: -0.0089
      Episode_Termination/time_out: 12.6667
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 8552448
                    Iteration time: 1.88s
                      Time elapsed: 00:03:26
                               ETA: 00:56:02

################################################################################
                      [1m Learning iteration 87/1500 [0m                      

                       Computation: 53086 steps/s (collection: 1.734s, learning 0.118s)
             Mean action noise std: 1.26
          Mean value_function loss: 12.8489
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 29.7040
                       Mean reward: 49.92
               Mean episode length: 244.69
    Episode_Reward/reaching_object: 0.4907
    Episode_Reward/rotating_object: 6.6587
        Episode_Reward/action_rate: -0.0060
          Episode_Reward/joint_vel: -0.0092
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 8650752
                    Iteration time: 1.85s
                      Time elapsed: 00:03:28
                               ETA: 00:55:51

################################################################################
                      [1m Learning iteration 88/1500 [0m                      

                       Computation: 53493 steps/s (collection: 1.747s, learning 0.091s)
             Mean action noise std: 1.27
          Mean value_function loss: 11.9476
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 29.7532
                       Mean reward: 35.65
               Mean episode length: 243.74
    Episode_Reward/reaching_object: 0.4889
    Episode_Reward/rotating_object: 7.8618
        Episode_Reward/action_rate: -0.0060
          Episode_Reward/joint_vel: -0.0090
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 8749056
                    Iteration time: 1.84s
                      Time elapsed: 00:03:30
                               ETA: 00:55:40

################################################################################
                      [1m Learning iteration 89/1500 [0m                      

                       Computation: 53480 steps/s (collection: 1.742s, learning 0.096s)
             Mean action noise std: 1.27
          Mean value_function loss: 14.0976
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 29.7926
                       Mean reward: 28.75
               Mean episode length: 242.48
    Episode_Reward/reaching_object: 0.4744
    Episode_Reward/rotating_object: 5.7041
        Episode_Reward/action_rate: -0.0060
          Episode_Reward/joint_vel: -0.0091
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 8847360
                    Iteration time: 1.84s
                      Time elapsed: 00:03:32
                               ETA: 00:55:29

################################################################################
                      [1m Learning iteration 90/1500 [0m                      

                       Computation: 52982 steps/s (collection: 1.733s, learning 0.122s)
             Mean action noise std: 1.27
          Mean value_function loss: 12.1652
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 29.8260
                       Mean reward: 40.87
               Mean episode length: 244.21
    Episode_Reward/reaching_object: 0.4782
    Episode_Reward/rotating_object: 6.8908
        Episode_Reward/action_rate: -0.0061
          Episode_Reward/joint_vel: -0.0093
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 8945664
                    Iteration time: 1.86s
                      Time elapsed: 00:03:34
                               ETA: 00:55:19

################################################################################
                      [1m Learning iteration 91/1500 [0m                      

                       Computation: 53672 steps/s (collection: 1.729s, learning 0.103s)
             Mean action noise std: 1.28
          Mean value_function loss: 14.9008
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 29.8632
                       Mean reward: 40.66
               Mean episode length: 246.65
    Episode_Reward/reaching_object: 0.4799
    Episode_Reward/rotating_object: 7.1770
        Episode_Reward/action_rate: -0.0061
          Episode_Reward/joint_vel: -0.0093
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 9043968
                    Iteration time: 1.83s
                      Time elapsed: 00:03:36
                               ETA: 00:55:09

################################################################################
                      [1m Learning iteration 92/1500 [0m                      

                       Computation: 54077 steps/s (collection: 1.720s, learning 0.098s)
             Mean action noise std: 1.28
          Mean value_function loss: 17.2160
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 29.9062
                       Mean reward: 35.44
               Mean episode length: 240.77
    Episode_Reward/reaching_object: 0.4603
    Episode_Reward/rotating_object: 5.9241
        Episode_Reward/action_rate: -0.0061
          Episode_Reward/joint_vel: -0.0095
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 9142272
                    Iteration time: 1.82s
                      Time elapsed: 00:03:37
                               ETA: 00:54:59

################################################################################
                      [1m Learning iteration 93/1500 [0m                      

                       Computation: 54139 steps/s (collection: 1.721s, learning 0.095s)
             Mean action noise std: 1.28
          Mean value_function loss: 20.8343
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 29.9504
                       Mean reward: 45.11
               Mean episode length: 246.40
    Episode_Reward/reaching_object: 0.4670
    Episode_Reward/rotating_object: 8.9555
        Episode_Reward/action_rate: -0.0062
          Episode_Reward/joint_vel: -0.0093
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 9240576
                    Iteration time: 1.82s
                      Time elapsed: 00:03:39
                               ETA: 00:54:48

################################################################################
                      [1m Learning iteration 94/1500 [0m                      

                       Computation: 53088 steps/s (collection: 1.743s, learning 0.109s)
             Mean action noise std: 1.28
          Mean value_function loss: 17.2942
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 29.9834
                       Mean reward: 38.45
               Mean episode length: 245.95
    Episode_Reward/reaching_object: 0.4648
    Episode_Reward/rotating_object: 7.7824
        Episode_Reward/action_rate: -0.0062
          Episode_Reward/joint_vel: -0.0096
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 9338880
                    Iteration time: 1.85s
                      Time elapsed: 00:03:41
                               ETA: 00:54:39

################################################################################
                      [1m Learning iteration 95/1500 [0m                      

                       Computation: 53360 steps/s (collection: 1.729s, learning 0.114s)
             Mean action noise std: 1.29
          Mean value_function loss: 22.0001
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 30.0327
                       Mean reward: 37.87
               Mean episode length: 244.41
    Episode_Reward/reaching_object: 0.4776
    Episode_Reward/rotating_object: 7.4327
        Episode_Reward/action_rate: -0.0063
          Episode_Reward/joint_vel: -0.0097
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 9437184
                    Iteration time: 1.84s
                      Time elapsed: 00:03:43
                               ETA: 00:54:29

################################################################################
                      [1m Learning iteration 96/1500 [0m                      

                       Computation: 54153 steps/s (collection: 1.708s, learning 0.108s)
             Mean action noise std: 1.29
          Mean value_function loss: 19.6488
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 30.0923
                       Mean reward: 36.56
               Mean episode length: 244.40
    Episode_Reward/reaching_object: 0.4631
    Episode_Reward/rotating_object: 7.9143
        Episode_Reward/action_rate: -0.0063
          Episode_Reward/joint_vel: -0.0094
      Episode_Termination/time_out: 12.9167
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 9535488
                    Iteration time: 1.82s
                      Time elapsed: 00:03:45
                               ETA: 00:54:20

################################################################################
                      [1m Learning iteration 97/1500 [0m                      

                       Computation: 53898 steps/s (collection: 1.729s, learning 0.095s)
             Mean action noise std: 1.29
          Mean value_function loss: 21.0381
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 30.1256
                       Mean reward: 46.31
               Mean episode length: 246.87
    Episode_Reward/reaching_object: 0.4796
    Episode_Reward/rotating_object: 8.3531
        Episode_Reward/action_rate: -0.0064
          Episode_Reward/joint_vel: -0.0098
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 9633792
                    Iteration time: 1.82s
                      Time elapsed: 00:03:47
                               ETA: 00:54:10

################################################################################
                      [1m Learning iteration 98/1500 [0m                      

                       Computation: 53744 steps/s (collection: 1.740s, learning 0.090s)
             Mean action noise std: 1.30
          Mean value_function loss: 21.7293
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 30.1541
                       Mean reward: 39.66
               Mean episode length: 246.03
    Episode_Reward/reaching_object: 0.4782
    Episode_Reward/rotating_object: 8.0444
        Episode_Reward/action_rate: -0.0064
          Episode_Reward/joint_vel: -0.0096
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 9732096
                    Iteration time: 1.83s
                      Time elapsed: 00:03:48
                               ETA: 00:54:01

################################################################################
                      [1m Learning iteration 99/1500 [0m                      

                       Computation: 54558 steps/s (collection: 1.706s, learning 0.096s)
             Mean action noise std: 1.30
          Mean value_function loss: 20.9056
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 30.1832
                       Mean reward: 39.75
               Mean episode length: 244.12
    Episode_Reward/reaching_object: 0.4659
    Episode_Reward/rotating_object: 7.3356
        Episode_Reward/action_rate: -0.0064
          Episode_Reward/joint_vel: -0.0095
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 9830400
                    Iteration time: 1.80s
                      Time elapsed: 00:03:50
                               ETA: 00:53:51

################################################################################
                     [1m Learning iteration 100/1500 [0m                      

                       Computation: 54100 steps/s (collection: 1.718s, learning 0.099s)
             Mean action noise std: 1.30
          Mean value_function loss: 21.5018
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 30.2039
                       Mean reward: 45.03
               Mean episode length: 242.70
    Episode_Reward/reaching_object: 0.4645
    Episode_Reward/rotating_object: 8.0510
        Episode_Reward/action_rate: -0.0064
          Episode_Reward/joint_vel: -0.0096
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 9928704
                    Iteration time: 1.82s
                      Time elapsed: 00:03:52
                               ETA: 00:53:42

################################################################################
                     [1m Learning iteration 101/1500 [0m                      

                       Computation: 53344 steps/s (collection: 1.745s, learning 0.098s)
             Mean action noise std: 1.30
          Mean value_function loss: 20.7789
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 30.2424
                       Mean reward: 50.65
               Mean episode length: 240.15
    Episode_Reward/reaching_object: 0.4535
    Episode_Reward/rotating_object: 9.3859
        Episode_Reward/action_rate: -0.0064
          Episode_Reward/joint_vel: -0.0095
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 10027008
                    Iteration time: 1.84s
                      Time elapsed: 00:03:54
                               ETA: 00:53:34

################################################################################
                     [1m Learning iteration 102/1500 [0m                      

                       Computation: 53510 steps/s (collection: 1.737s, learning 0.101s)
             Mean action noise std: 1.31
          Mean value_function loss: 22.5326
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 30.2831
                       Mean reward: 65.94
               Mean episode length: 242.78
    Episode_Reward/reaching_object: 0.4470
    Episode_Reward/rotating_object: 7.9428
        Episode_Reward/action_rate: -0.0064
          Episode_Reward/joint_vel: -0.0095
      Episode_Termination/time_out: 13.7500
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 10125312
                    Iteration time: 1.84s
                      Time elapsed: 00:03:56
                               ETA: 00:53:25

################################################################################
                     [1m Learning iteration 103/1500 [0m                      

                       Computation: 53010 steps/s (collection: 1.759s, learning 0.096s)
             Mean action noise std: 1.31
          Mean value_function loss: 25.4735
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 30.3242
                       Mean reward: 43.63
               Mean episode length: 236.71
    Episode_Reward/reaching_object: 0.4366
    Episode_Reward/rotating_object: 7.1738
        Episode_Reward/action_rate: -0.0064
          Episode_Reward/joint_vel: -0.0096
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 10223616
                    Iteration time: 1.85s
                      Time elapsed: 00:03:58
                               ETA: 00:53:17

################################################################################
                     [1m Learning iteration 104/1500 [0m                      

                       Computation: 53331 steps/s (collection: 1.746s, learning 0.098s)
             Mean action noise std: 1.31
          Mean value_function loss: 23.5561
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 30.3669
                       Mean reward: 51.19
               Mean episode length: 234.53
    Episode_Reward/reaching_object: 0.4436
    Episode_Reward/rotating_object: 9.7429
        Episode_Reward/action_rate: -0.0063
          Episode_Reward/joint_vel: -0.0095
      Episode_Termination/time_out: 13.2083
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 10321920
                    Iteration time: 1.84s
                      Time elapsed: 00:03:59
                               ETA: 00:53:09

################################################################################
                     [1m Learning iteration 105/1500 [0m                      

                       Computation: 52861 steps/s (collection: 1.755s, learning 0.105s)
             Mean action noise std: 1.31
          Mean value_function loss: 22.4415
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 30.4133
                       Mean reward: 46.26
               Mean episode length: 238.46
    Episode_Reward/reaching_object: 0.4443
    Episode_Reward/rotating_object: 9.5917
        Episode_Reward/action_rate: -0.0065
          Episode_Reward/joint_vel: -0.0098
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 10420224
                    Iteration time: 1.86s
                      Time elapsed: 00:04:01
                               ETA: 00:53:01

################################################################################
                     [1m Learning iteration 106/1500 [0m                      

                       Computation: 53726 steps/s (collection: 1.738s, learning 0.092s)
             Mean action noise std: 1.32
          Mean value_function loss: 22.4118
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 30.4415
                       Mean reward: 42.62
               Mean episode length: 241.01
    Episode_Reward/reaching_object: 0.4384
    Episode_Reward/rotating_object: 8.5582
        Episode_Reward/action_rate: -0.0064
          Episode_Reward/joint_vel: -0.0094
      Episode_Termination/time_out: 12.2917
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 10518528
                    Iteration time: 1.83s
                      Time elapsed: 00:04:03
                               ETA: 00:52:53

################################################################################
                     [1m Learning iteration 107/1500 [0m                      

                       Computation: 54135 steps/s (collection: 1.722s, learning 0.094s)
             Mean action noise std: 1.32
          Mean value_function loss: 22.1576
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 30.4732
                       Mean reward: 46.94
               Mean episode length: 234.69
    Episode_Reward/reaching_object: 0.4321
    Episode_Reward/rotating_object: 8.0219
        Episode_Reward/action_rate: -0.0065
          Episode_Reward/joint_vel: -0.0095
      Episode_Termination/time_out: 12.5000
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 10616832
                    Iteration time: 1.82s
                      Time elapsed: 00:04:05
                               ETA: 00:52:45

################################################################################
                     [1m Learning iteration 108/1500 [0m                      

                       Computation: 52796 steps/s (collection: 1.765s, learning 0.097s)
             Mean action noise std: 1.32
          Mean value_function loss: 20.8398
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 30.5141
                       Mean reward: 40.47
               Mean episode length: 235.28
    Episode_Reward/reaching_object: 0.4250
    Episode_Reward/rotating_object: 7.9650
        Episode_Reward/action_rate: -0.0065
          Episode_Reward/joint_vel: -0.0102
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.8333
--------------------------------------------------------------------------------
                   Total timesteps: 10715136
                    Iteration time: 1.86s
                      Time elapsed: 00:04:07
                               ETA: 00:52:37

################################################################################
                     [1m Learning iteration 109/1500 [0m                      

                       Computation: 52784 steps/s (collection: 1.750s, learning 0.112s)
             Mean action noise std: 1.33
          Mean value_function loss: 19.5401
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 30.5577
                       Mean reward: 46.57
               Mean episode length: 240.62
    Episode_Reward/reaching_object: 0.4160
    Episode_Reward/rotating_object: 10.3745
        Episode_Reward/action_rate: -0.0066
          Episode_Reward/joint_vel: -0.0101
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.7500
--------------------------------------------------------------------------------
                   Total timesteps: 10813440
                    Iteration time: 1.86s
                      Time elapsed: 00:04:09
                               ETA: 00:52:30

################################################################################
                     [1m Learning iteration 110/1500 [0m                      

                       Computation: 52472 steps/s (collection: 1.761s, learning 0.112s)
             Mean action noise std: 1.33
          Mean value_function loss: 23.0209
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 30.5940
                       Mean reward: 45.75
               Mean episode length: 238.08
    Episode_Reward/reaching_object: 0.4319
    Episode_Reward/rotating_object: 8.0263
        Episode_Reward/action_rate: -0.0067
          Episode_Reward/joint_vel: -0.0100
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 10911744
                    Iteration time: 1.87s
                      Time elapsed: 00:04:10
                               ETA: 00:52:22

################################################################################
                     [1m Learning iteration 111/1500 [0m                      

                       Computation: 53047 steps/s (collection: 1.745s, learning 0.109s)
             Mean action noise std: 1.33
          Mean value_function loss: 23.1041
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 30.6199
                       Mean reward: 36.67
               Mean episode length: 240.06
    Episode_Reward/reaching_object: 0.4214
    Episode_Reward/rotating_object: 9.3480
        Episode_Reward/action_rate: -0.0067
          Episode_Reward/joint_vel: -0.0101
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 11010048
                    Iteration time: 1.85s
                      Time elapsed: 00:04:12
                               ETA: 00:52:15

################################################################################
                     [1m Learning iteration 112/1500 [0m                      

                       Computation: 51938 steps/s (collection: 1.782s, learning 0.111s)
             Mean action noise std: 1.33
          Mean value_function loss: 22.0268
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 30.6487
                       Mean reward: 47.36
               Mean episode length: 238.50
    Episode_Reward/reaching_object: 0.4041
    Episode_Reward/rotating_object: 9.2758
        Episode_Reward/action_rate: -0.0067
          Episode_Reward/joint_vel: -0.0101
      Episode_Termination/time_out: 12.3750
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 11108352
                    Iteration time: 1.89s
                      Time elapsed: 00:04:14
                               ETA: 00:52:08

################################################################################
                     [1m Learning iteration 113/1500 [0m                      

                       Computation: 53006 steps/s (collection: 1.749s, learning 0.106s)
             Mean action noise std: 1.34
          Mean value_function loss: 26.5101
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 30.6846
                       Mean reward: 44.71
               Mean episode length: 241.26
    Episode_Reward/reaching_object: 0.4221
    Episode_Reward/rotating_object: 10.4948
        Episode_Reward/action_rate: -0.0067
          Episode_Reward/joint_vel: -0.0100
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 11206656
                    Iteration time: 1.85s
                      Time elapsed: 00:04:16
                               ETA: 00:52:01

################################################################################
                     [1m Learning iteration 114/1500 [0m                      

                       Computation: 50603 steps/s (collection: 1.852s, learning 0.091s)
             Mean action noise std: 1.34
          Mean value_function loss: 26.2776
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 30.7206
                       Mean reward: 42.97
               Mean episode length: 233.89
    Episode_Reward/reaching_object: 0.4115
    Episode_Reward/rotating_object: 9.5131
        Episode_Reward/action_rate: -0.0067
          Episode_Reward/joint_vel: -0.0101
      Episode_Termination/time_out: 13.6250
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 11304960
                    Iteration time: 1.94s
                      Time elapsed: 00:04:18
                               ETA: 00:51:55

################################################################################
                     [1m Learning iteration 115/1500 [0m                      

                       Computation: 52446 steps/s (collection: 1.769s, learning 0.106s)
             Mean action noise std: 1.34
          Mean value_function loss: 22.5652
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 30.7491
                       Mean reward: 44.11
               Mean episode length: 236.90
    Episode_Reward/reaching_object: 0.4010
    Episode_Reward/rotating_object: 9.0054
        Episode_Reward/action_rate: -0.0067
          Episode_Reward/joint_vel: -0.0101
      Episode_Termination/time_out: 13.0833
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 11403264
                    Iteration time: 1.87s
                      Time elapsed: 00:04:20
                               ETA: 00:51:49

################################################################################
                     [1m Learning iteration 116/1500 [0m                      

                       Computation: 53096 steps/s (collection: 1.746s, learning 0.105s)
             Mean action noise std: 1.34
          Mean value_function loss: 27.3554
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 30.7755
                       Mean reward: 48.34
               Mean episode length: 232.26
    Episode_Reward/reaching_object: 0.4180
    Episode_Reward/rotating_object: 9.0087
        Episode_Reward/action_rate: -0.0068
          Episode_Reward/joint_vel: -0.0101
      Episode_Termination/time_out: 13.2083
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.7500
--------------------------------------------------------------------------------
                   Total timesteps: 11501568
                    Iteration time: 1.85s
                      Time elapsed: 00:04:22
                               ETA: 00:51:42

################################################################################
                     [1m Learning iteration 117/1500 [0m                      

                       Computation: 53666 steps/s (collection: 1.726s, learning 0.105s)
             Mean action noise std: 1.34
          Mean value_function loss: 25.3030
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 30.8000
                       Mean reward: 46.49
               Mean episode length: 234.63
    Episode_Reward/reaching_object: 0.4082
    Episode_Reward/rotating_object: 8.9820
        Episode_Reward/action_rate: -0.0068
          Episode_Reward/joint_vel: -0.0101
      Episode_Termination/time_out: 11.3750
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 11599872
                    Iteration time: 1.83s
                      Time elapsed: 00:04:24
                               ETA: 00:51:35

################################################################################
                     [1m Learning iteration 118/1500 [0m                      

                       Computation: 52245 steps/s (collection: 1.772s, learning 0.109s)
             Mean action noise std: 1.35
          Mean value_function loss: 24.9554
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 30.8321
                       Mean reward: 36.50
               Mean episode length: 232.31
    Episode_Reward/reaching_object: 0.4070
    Episode_Reward/rotating_object: 7.9133
        Episode_Reward/action_rate: -0.0068
          Episode_Reward/joint_vel: -0.0101
      Episode_Termination/time_out: 13.5833
Episode_Termination/object_dropping: 0.7083
     Episode_Termination/robot_out: 4.4583
--------------------------------------------------------------------------------
                   Total timesteps: 11698176
                    Iteration time: 1.88s
                      Time elapsed: 00:04:25
                               ETA: 00:51:28

################################################################################
                     [1m Learning iteration 119/1500 [0m                      

                       Computation: 53284 steps/s (collection: 1.750s, learning 0.095s)
             Mean action noise std: 1.35
          Mean value_function loss: 29.5649
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 30.8638
                       Mean reward: 40.74
               Mean episode length: 230.54
    Episode_Reward/reaching_object: 0.3986
    Episode_Reward/rotating_object: 8.3954
        Episode_Reward/action_rate: -0.0068
          Episode_Reward/joint_vel: -0.0103
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 3.9583
--------------------------------------------------------------------------------
                   Total timesteps: 11796480
                    Iteration time: 1.84s
                      Time elapsed: 00:04:27
                               ETA: 00:51:22

################################################################################
                     [1m Learning iteration 120/1500 [0m                      

                       Computation: 52724 steps/s (collection: 1.772s, learning 0.093s)
             Mean action noise std: 1.35
          Mean value_function loss: 29.3469
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 30.8926
                       Mean reward: 53.96
               Mean episode length: 235.62
    Episode_Reward/reaching_object: 0.4072
    Episode_Reward/rotating_object: 9.4131
        Episode_Reward/action_rate: -0.0069
          Episode_Reward/joint_vel: -0.0104
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 11894784
                    Iteration time: 1.86s
                      Time elapsed: 00:04:29
                               ETA: 00:51:15

################################################################################
                     [1m Learning iteration 121/1500 [0m                      

                       Computation: 53326 steps/s (collection: 1.735s, learning 0.109s)
             Mean action noise std: 1.35
          Mean value_function loss: 27.4851
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 30.9209
                       Mean reward: 42.91
               Mean episode length: 226.68
    Episode_Reward/reaching_object: 0.4127
    Episode_Reward/rotating_object: 8.1754
        Episode_Reward/action_rate: -0.0069
          Episode_Reward/joint_vel: -0.0104
      Episode_Termination/time_out: 12.5833
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 4.3333
--------------------------------------------------------------------------------
                   Total timesteps: 11993088
                    Iteration time: 1.84s
                      Time elapsed: 00:04:31
                               ETA: 00:51:09

################################################################################
                     [1m Learning iteration 122/1500 [0m                      

                       Computation: 53519 steps/s (collection: 1.741s, learning 0.096s)
             Mean action noise std: 1.35
          Mean value_function loss: 29.5512
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 30.9399
                       Mean reward: 54.47
               Mean episode length: 230.56
    Episode_Reward/reaching_object: 0.4099
    Episode_Reward/rotating_object: 10.6390
        Episode_Reward/action_rate: -0.0069
          Episode_Reward/joint_vel: -0.0108
      Episode_Termination/time_out: 12.5833
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 4.7500
--------------------------------------------------------------------------------
                   Total timesteps: 12091392
                    Iteration time: 1.84s
                      Time elapsed: 00:04:33
                               ETA: 00:51:02

################################################################################
                     [1m Learning iteration 123/1500 [0m                      

                       Computation: 54196 steps/s (collection: 1.719s, learning 0.095s)
             Mean action noise std: 1.36
          Mean value_function loss: 28.0524
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 30.9787
                       Mean reward: 75.75
               Mean episode length: 240.53
    Episode_Reward/reaching_object: 0.4175
    Episode_Reward/rotating_object: 11.3281
        Episode_Reward/action_rate: -0.0069
          Episode_Reward/joint_vel: -0.0104
      Episode_Termination/time_out: 12.3750
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 4.5833
--------------------------------------------------------------------------------
                   Total timesteps: 12189696
                    Iteration time: 1.81s
                      Time elapsed: 00:04:35
                               ETA: 00:50:55

################################################################################
                     [1m Learning iteration 124/1500 [0m                      

                       Computation: 53308 steps/s (collection: 1.740s, learning 0.104s)
             Mean action noise std: 1.36
          Mean value_function loss: 31.4262
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 31.0208
                       Mean reward: 59.32
               Mean episode length: 236.22
    Episode_Reward/reaching_object: 0.4067
    Episode_Reward/rotating_object: 9.9446
        Episode_Reward/action_rate: -0.0070
          Episode_Reward/joint_vel: -0.0108
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 4.3750
--------------------------------------------------------------------------------
                   Total timesteps: 12288000
                    Iteration time: 1.84s
                      Time elapsed: 00:04:37
                               ETA: 00:50:49

################################################################################
                     [1m Learning iteration 125/1500 [0m                      

                       Computation: 53307 steps/s (collection: 1.751s, learning 0.094s)
             Mean action noise std: 1.36
          Mean value_function loss: 32.9538
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 31.0622
                       Mean reward: 38.85
               Mean episode length: 228.11
    Episode_Reward/reaching_object: 0.3952
    Episode_Reward/rotating_object: 9.6515
        Episode_Reward/action_rate: -0.0069
          Episode_Reward/joint_vel: -0.0103
      Episode_Termination/time_out: 12.2083
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 4.9583
--------------------------------------------------------------------------------
                   Total timesteps: 12386304
                    Iteration time: 1.84s
                      Time elapsed: 00:04:38
                               ETA: 00:50:43

################################################################################
                     [1m Learning iteration 126/1500 [0m                      

                       Computation: 52494 steps/s (collection: 1.761s, learning 0.112s)
             Mean action noise std: 1.37
          Mean value_function loss: 32.8357
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 31.1002
                       Mean reward: 51.85
               Mean episode length: 232.56
    Episode_Reward/reaching_object: 0.3986
    Episode_Reward/rotating_object: 10.3382
        Episode_Reward/action_rate: -0.0069
          Episode_Reward/joint_vel: -0.0103
      Episode_Termination/time_out: 12.8750
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 4.6667
--------------------------------------------------------------------------------
                   Total timesteps: 12484608
                    Iteration time: 1.87s
                      Time elapsed: 00:04:40
                               ETA: 00:50:37

################################################################################
                     [1m Learning iteration 127/1500 [0m                      

                       Computation: 52270 steps/s (collection: 1.764s, learning 0.117s)
             Mean action noise std: 1.37
          Mean value_function loss: 32.8531
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 31.1366
                       Mean reward: 50.71
               Mean episode length: 237.00
    Episode_Reward/reaching_object: 0.4007
    Episode_Reward/rotating_object: 11.2514
        Episode_Reward/action_rate: -0.0071
          Episode_Reward/joint_vel: -0.0111
      Episode_Termination/time_out: 12.5000
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 4.2500
--------------------------------------------------------------------------------
                   Total timesteps: 12582912
                    Iteration time: 1.88s
                      Time elapsed: 00:04:42
                               ETA: 00:50:31

################################################################################
                     [1m Learning iteration 128/1500 [0m                      

                       Computation: 52758 steps/s (collection: 1.751s, learning 0.113s)
             Mean action noise std: 1.37
          Mean value_function loss: 38.5665
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 31.1570
                       Mean reward: 74.42
               Mean episode length: 232.52
    Episode_Reward/reaching_object: 0.3964
    Episode_Reward/rotating_object: 10.6432
        Episode_Reward/action_rate: -0.0070
          Episode_Reward/joint_vel: -0.0105
      Episode_Termination/time_out: 12.4583
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 4.6667
--------------------------------------------------------------------------------
                   Total timesteps: 12681216
                    Iteration time: 1.86s
                      Time elapsed: 00:04:44
                               ETA: 00:50:25

################################################################################
                     [1m Learning iteration 129/1500 [0m                      

                       Computation: 53004 steps/s (collection: 1.747s, learning 0.108s)
             Mean action noise std: 1.37
          Mean value_function loss: 30.5644
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 31.1805
                       Mean reward: 55.04
               Mean episode length: 233.32
    Episode_Reward/reaching_object: 0.3974
    Episode_Reward/rotating_object: 10.8571
        Episode_Reward/action_rate: -0.0071
          Episode_Reward/joint_vel: -0.0105
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 4.5417
--------------------------------------------------------------------------------
                   Total timesteps: 12779520
                    Iteration time: 1.85s
                      Time elapsed: 00:04:46
                               ETA: 00:50:19

################################################################################
                     [1m Learning iteration 130/1500 [0m                      

                       Computation: 54231 steps/s (collection: 1.715s, learning 0.098s)
             Mean action noise std: 1.38
          Mean value_function loss: 26.8484
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 31.2185
                       Mean reward: 50.70
               Mean episode length: 226.69
    Episode_Reward/reaching_object: 0.3950
    Episode_Reward/rotating_object: 10.3090
        Episode_Reward/action_rate: -0.0072
          Episode_Reward/joint_vel: -0.0109
      Episode_Termination/time_out: 12.1250
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 12877824
                    Iteration time: 1.81s
                      Time elapsed: 00:04:48
                               ETA: 00:50:13

################################################################################
                     [1m Learning iteration 131/1500 [0m                      

                       Computation: 53056 steps/s (collection: 1.738s, learning 0.115s)
             Mean action noise std: 1.38
          Mean value_function loss: 32.9525
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 31.2525
                       Mean reward: 59.32
               Mean episode length: 225.63
    Episode_Reward/reaching_object: 0.4052
    Episode_Reward/rotating_object: 11.7861
        Episode_Reward/action_rate: -0.0071
          Episode_Reward/joint_vel: -0.0104
      Episode_Termination/time_out: 13.1250
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 4.2917
--------------------------------------------------------------------------------
                   Total timesteps: 12976128
                    Iteration time: 1.85s
                      Time elapsed: 00:04:49
                               ETA: 00:50:07

################################################################################
                     [1m Learning iteration 132/1500 [0m                      

                       Computation: 53713 steps/s (collection: 1.734s, learning 0.096s)
             Mean action noise std: 1.38
          Mean value_function loss: 28.2879
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 31.2760
                       Mean reward: 79.35
               Mean episode length: 235.19
    Episode_Reward/reaching_object: 0.3937
    Episode_Reward/rotating_object: 10.9586
        Episode_Reward/action_rate: -0.0071
          Episode_Reward/joint_vel: -0.0108
      Episode_Termination/time_out: 13.5000
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 4.5000
--------------------------------------------------------------------------------
                   Total timesteps: 13074432
                    Iteration time: 1.83s
                      Time elapsed: 00:04:51
                               ETA: 00:50:01

################################################################################
                     [1m Learning iteration 133/1500 [0m                      

                       Computation: 54260 steps/s (collection: 1.714s, learning 0.098s)
             Mean action noise std: 1.38
          Mean value_function loss: 36.4942
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 31.3089
                       Mean reward: 72.08
               Mean episode length: 233.69
    Episode_Reward/reaching_object: 0.3938
    Episode_Reward/rotating_object: 10.8623
        Episode_Reward/action_rate: -0.0072
          Episode_Reward/joint_vel: -0.0107
      Episode_Termination/time_out: 12.8333
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.7500
--------------------------------------------------------------------------------
                   Total timesteps: 13172736
                    Iteration time: 1.81s
                      Time elapsed: 00:04:53
                               ETA: 00:49:55

################################################################################
                     [1m Learning iteration 134/1500 [0m                      

                       Computation: 53278 steps/s (collection: 1.753s, learning 0.092s)
             Mean action noise std: 1.38
          Mean value_function loss: 31.4479
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 31.3294
                       Mean reward: 68.91
               Mean episode length: 233.65
    Episode_Reward/reaching_object: 0.4065
    Episode_Reward/rotating_object: 12.0535
        Episode_Reward/action_rate: -0.0072
          Episode_Reward/joint_vel: -0.0105
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.4167
--------------------------------------------------------------------------------
                   Total timesteps: 13271040
                    Iteration time: 1.85s
                      Time elapsed: 00:04:55
                               ETA: 00:49:49

################################################################################
                     [1m Learning iteration 135/1500 [0m                      

                       Computation: 53330 steps/s (collection: 1.742s, learning 0.101s)
             Mean action noise std: 1.39
          Mean value_function loss: 33.1620
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 31.3581
                       Mean reward: 49.19
               Mean episode length: 237.07
    Episode_Reward/reaching_object: 0.3847
    Episode_Reward/rotating_object: 13.0563
        Episode_Reward/action_rate: -0.0071
          Episode_Reward/joint_vel: -0.0107
      Episode_Termination/time_out: 13.1667
Episode_Termination/object_dropping: 0.6250
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 13369344
                    Iteration time: 1.84s
                      Time elapsed: 00:04:57
                               ETA: 00:49:44

################################################################################
                     [1m Learning iteration 136/1500 [0m                      

                       Computation: 52516 steps/s (collection: 1.758s, learning 0.114s)
             Mean action noise std: 1.39
          Mean value_function loss: 41.0011
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 31.3882
                       Mean reward: 66.24
               Mean episode length: 231.22
    Episode_Reward/reaching_object: 0.3996
    Episode_Reward/rotating_object: 12.4153
        Episode_Reward/action_rate: -0.0072
          Episode_Reward/joint_vel: -0.0104
      Episode_Termination/time_out: 13.0417
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 4.1250
--------------------------------------------------------------------------------
                   Total timesteps: 13467648
                    Iteration time: 1.87s
                      Time elapsed: 00:04:59
                               ETA: 00:49:38

################################################################################
                     [1m Learning iteration 137/1500 [0m                      

                       Computation: 55313 steps/s (collection: 1.685s, learning 0.093s)
             Mean action noise std: 1.39
          Mean value_function loss: 34.0777
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 31.4199
                       Mean reward: 78.56
               Mean episode length: 232.07
    Episode_Reward/reaching_object: 0.3948
    Episode_Reward/rotating_object: 11.7470
        Episode_Reward/action_rate: -0.0073
          Episode_Reward/joint_vel: -0.0107
      Episode_Termination/time_out: 13.5833
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 13565952
                    Iteration time: 1.78s
                      Time elapsed: 00:05:00
                               ETA: 00:49:32

################################################################################
                     [1m Learning iteration 138/1500 [0m                      

                       Computation: 53447 steps/s (collection: 1.744s, learning 0.096s)
             Mean action noise std: 1.40
          Mean value_function loss: 37.7270
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 31.4509
                       Mean reward: 62.62
               Mean episode length: 237.64
    Episode_Reward/reaching_object: 0.4146
    Episode_Reward/rotating_object: 13.5512
        Episode_Reward/action_rate: -0.0073
          Episode_Reward/joint_vel: -0.0103
      Episode_Termination/time_out: 13.1250
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 13664256
                    Iteration time: 1.84s
                      Time elapsed: 00:05:02
                               ETA: 00:49:27

################################################################################
                     [1m Learning iteration 139/1500 [0m                      

                       Computation: 54743 steps/s (collection: 1.705s, learning 0.090s)
             Mean action noise std: 1.40
          Mean value_function loss: 41.8572
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 31.4915
                       Mean reward: 76.25
               Mean episode length: 231.78
    Episode_Reward/reaching_object: 0.4150
    Episode_Reward/rotating_object: 12.8813
        Episode_Reward/action_rate: -0.0074
          Episode_Reward/joint_vel: -0.0103
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 13762560
                    Iteration time: 1.80s
                      Time elapsed: 00:05:04
                               ETA: 00:49:21

################################################################################
                     [1m Learning iteration 140/1500 [0m                      

                       Computation: 52942 steps/s (collection: 1.751s, learning 0.106s)
             Mean action noise std: 1.40
          Mean value_function loss: 37.5015
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 31.5164
                       Mean reward: 87.65
               Mean episode length: 231.28
    Episode_Reward/reaching_object: 0.4048
    Episode_Reward/rotating_object: 12.9757
        Episode_Reward/action_rate: -0.0074
          Episode_Reward/joint_vel: -0.0106
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 13860864
                    Iteration time: 1.86s
                      Time elapsed: 00:05:06
                               ETA: 00:49:15

################################################################################
                     [1m Learning iteration 141/1500 [0m                      

                       Computation: 54632 steps/s (collection: 1.688s, learning 0.112s)
             Mean action noise std: 1.40
          Mean value_function loss: 35.2301
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 31.5457
                       Mean reward: 69.94
               Mean episode length: 236.25
    Episode_Reward/reaching_object: 0.4308
    Episode_Reward/rotating_object: 15.3870
        Episode_Reward/action_rate: -0.0076
          Episode_Reward/joint_vel: -0.0105
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 13959168
                    Iteration time: 1.80s
                      Time elapsed: 00:05:08
                               ETA: 00:49:10

################################################################################
                     [1m Learning iteration 142/1500 [0m                      

                       Computation: 54793 steps/s (collection: 1.697s, learning 0.097s)
             Mean action noise std: 1.40
          Mean value_function loss: 34.8724
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 31.5691
                       Mean reward: 75.19
               Mean episode length: 228.03
    Episode_Reward/reaching_object: 0.4450
    Episode_Reward/rotating_object: 15.0221
        Episode_Reward/action_rate: -0.0076
          Episode_Reward/joint_vel: -0.0106
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 14057472
                    Iteration time: 1.79s
                      Time elapsed: 00:05:10
                               ETA: 00:49:04

################################################################################
                     [1m Learning iteration 143/1500 [0m                      

                       Computation: 53667 steps/s (collection: 1.721s, learning 0.111s)
             Mean action noise std: 1.41
          Mean value_function loss: 38.4952
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 31.5913
                       Mean reward: 74.52
               Mean episode length: 230.66
    Episode_Reward/reaching_object: 0.4179
    Episode_Reward/rotating_object: 13.5004
        Episode_Reward/action_rate: -0.0074
          Episode_Reward/joint_vel: -0.0104
      Episode_Termination/time_out: 13.0000
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.7500
--------------------------------------------------------------------------------
                   Total timesteps: 14155776
                    Iteration time: 1.83s
                      Time elapsed: 00:05:11
                               ETA: 00:48:59

################################################################################
                     [1m Learning iteration 144/1500 [0m                      

                       Computation: 52876 steps/s (collection: 1.747s, learning 0.112s)
             Mean action noise std: 1.41
          Mean value_function loss: 32.2532
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 31.6126
                       Mean reward: 80.29
               Mean episode length: 231.01
    Episode_Reward/reaching_object: 0.4365
    Episode_Reward/rotating_object: 16.3947
        Episode_Reward/action_rate: -0.0076
          Episode_Reward/joint_vel: -0.0106
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 14254080
                    Iteration time: 1.86s
                      Time elapsed: 00:05:13
                               ETA: 00:48:54

################################################################################
                     [1m Learning iteration 145/1500 [0m                      

                       Computation: 53421 steps/s (collection: 1.726s, learning 0.114s)
             Mean action noise std: 1.41
          Mean value_function loss: 38.8186
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 31.6341
                       Mean reward: 82.81
               Mean episode length: 236.45
    Episode_Reward/reaching_object: 0.4488
    Episode_Reward/rotating_object: 18.1037
        Episode_Reward/action_rate: -0.0077
          Episode_Reward/joint_vel: -0.0108
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 14352384
                    Iteration time: 1.84s
                      Time elapsed: 00:05:15
                               ETA: 00:48:48

################################################################################
                     [1m Learning iteration 146/1500 [0m                      

                       Computation: 54620 steps/s (collection: 1.692s, learning 0.108s)
             Mean action noise std: 1.41
          Mean value_function loss: 34.4027
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 31.6596
                       Mean reward: 64.41
               Mean episode length: 228.61
    Episode_Reward/reaching_object: 0.4358
    Episode_Reward/rotating_object: 15.4280
        Episode_Reward/action_rate: -0.0076
          Episode_Reward/joint_vel: -0.0106
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.9583
--------------------------------------------------------------------------------
                   Total timesteps: 14450688
                    Iteration time: 1.80s
                      Time elapsed: 00:05:17
                               ETA: 00:48:43

################################################################################
                     [1m Learning iteration 147/1500 [0m                      

                       Computation: 54140 steps/s (collection: 1.721s, learning 0.095s)
             Mean action noise std: 1.41
          Mean value_function loss: 42.1429
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 31.6950
                       Mean reward: 89.42
               Mean episode length: 232.81
    Episode_Reward/reaching_object: 0.4485
    Episode_Reward/rotating_object: 16.1334
        Episode_Reward/action_rate: -0.0077
          Episode_Reward/joint_vel: -0.0108
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 14548992
                    Iteration time: 1.82s
                      Time elapsed: 00:05:19
                               ETA: 00:48:38

################################################################################
                     [1m Learning iteration 148/1500 [0m                      

                       Computation: 54369 steps/s (collection: 1.711s, learning 0.097s)
             Mean action noise std: 1.42
          Mean value_function loss: 45.1663
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 31.7188
                       Mean reward: 95.37
               Mean episode length: 228.79
    Episode_Reward/reaching_object: 0.4524
    Episode_Reward/rotating_object: 17.5478
        Episode_Reward/action_rate: -0.0076
          Episode_Reward/joint_vel: -0.0102
      Episode_Termination/time_out: 12.9167
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 14647296
                    Iteration time: 1.81s
                      Time elapsed: 00:05:21
                               ETA: 00:48:32

################################################################################
                     [1m Learning iteration 149/1500 [0m                      

                       Computation: 53880 steps/s (collection: 1.711s, learning 0.113s)
             Mean action noise std: 1.42
          Mean value_function loss: 39.2768
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 31.7380
                       Mean reward: 62.34
               Mean episode length: 225.69
    Episode_Reward/reaching_object: 0.4529
    Episode_Reward/rotating_object: 14.7772
        Episode_Reward/action_rate: -0.0078
          Episode_Reward/joint_vel: -0.0109
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 14745600
                    Iteration time: 1.82s
                      Time elapsed: 00:05:22
                               ETA: 00:48:27

################################################################################
                     [1m Learning iteration 150/1500 [0m                      

                       Computation: 54918 steps/s (collection: 1.702s, learning 0.088s)
             Mean action noise std: 1.42
          Mean value_function loss: 36.4686
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 31.7624
                       Mean reward: 78.34
               Mean episode length: 236.95
    Episode_Reward/reaching_object: 0.4519
    Episode_Reward/rotating_object: 14.6529
        Episode_Reward/action_rate: -0.0078
          Episode_Reward/joint_vel: -0.0109
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 14843904
                    Iteration time: 1.79s
                      Time elapsed: 00:05:24
                               ETA: 00:48:22

################################################################################
                     [1m Learning iteration 151/1500 [0m                      

                       Computation: 53904 steps/s (collection: 1.734s, learning 0.090s)
             Mean action noise std: 1.42
          Mean value_function loss: 29.2463
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 31.7814
                       Mean reward: 80.97
               Mean episode length: 229.58
    Episode_Reward/reaching_object: 0.4325
    Episode_Reward/rotating_object: 17.3704
        Episode_Reward/action_rate: -0.0077
          Episode_Reward/joint_vel: -0.0108
      Episode_Termination/time_out: 12.7083
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 14942208
                    Iteration time: 1.82s
                      Time elapsed: 00:05:26
                               ETA: 00:48:17

################################################################################
                     [1m Learning iteration 152/1500 [0m                      

                       Computation: 55024 steps/s (collection: 1.695s, learning 0.092s)
             Mean action noise std: 1.42
          Mean value_function loss: 31.9053
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 31.7959
                       Mean reward: 75.72
               Mean episode length: 231.49
    Episode_Reward/reaching_object: 0.4387
    Episode_Reward/rotating_object: 15.2955
        Episode_Reward/action_rate: -0.0077
          Episode_Reward/joint_vel: -0.0107
      Episode_Termination/time_out: 12.8750
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 15040512
                    Iteration time: 1.79s
                      Time elapsed: 00:05:28
                               ETA: 00:48:11

################################################################################
                     [1m Learning iteration 153/1500 [0m                      

                       Computation: 54570 steps/s (collection: 1.695s, learning 0.107s)
             Mean action noise std: 1.42
          Mean value_function loss: 34.9166
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 31.8147
                       Mean reward: 103.77
               Mean episode length: 232.15
    Episode_Reward/reaching_object: 0.4574
    Episode_Reward/rotating_object: 16.5700
        Episode_Reward/action_rate: -0.0077
          Episode_Reward/joint_vel: -0.0105
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 15138816
                    Iteration time: 1.80s
                      Time elapsed: 00:05:30
                               ETA: 00:48:06

################################################################################
                     [1m Learning iteration 154/1500 [0m                      

                       Computation: 54813 steps/s (collection: 1.695s, learning 0.099s)
             Mean action noise std: 1.42
          Mean value_function loss: 35.0728
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 31.8308
                       Mean reward: 86.31
               Mean episode length: 237.36
    Episode_Reward/reaching_object: 0.4622
    Episode_Reward/rotating_object: 19.4025
        Episode_Reward/action_rate: -0.0079
          Episode_Reward/joint_vel: -0.0110
      Episode_Termination/time_out: 13.3333
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 15237120
                    Iteration time: 1.79s
                      Time elapsed: 00:05:31
                               ETA: 00:48:01

################################################################################
                     [1m Learning iteration 155/1500 [0m                      

                       Computation: 54820 steps/s (collection: 1.696s, learning 0.097s)
             Mean action noise std: 1.43
          Mean value_function loss: 36.1318
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 31.8427
                       Mean reward: 102.67
               Mean episode length: 237.07
    Episode_Reward/reaching_object: 0.4558
    Episode_Reward/rotating_object: 19.4073
        Episode_Reward/action_rate: -0.0080
          Episode_Reward/joint_vel: -0.0108
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 15335424
                    Iteration time: 1.79s
                      Time elapsed: 00:05:33
                               ETA: 00:47:56

################################################################################
                     [1m Learning iteration 156/1500 [0m                      

                       Computation: 55215 steps/s (collection: 1.687s, learning 0.094s)
             Mean action noise std: 1.43
          Mean value_function loss: 32.6747
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 31.8641
                       Mean reward: 111.34
               Mean episode length: 237.70
    Episode_Reward/reaching_object: 0.4422
    Episode_Reward/rotating_object: 17.9291
        Episode_Reward/action_rate: -0.0079
          Episode_Reward/joint_vel: -0.0111
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.7500
--------------------------------------------------------------------------------
                   Total timesteps: 15433728
                    Iteration time: 1.78s
                      Time elapsed: 00:05:35
                               ETA: 00:47:51

################################################################################
                     [1m Learning iteration 157/1500 [0m                      

                       Computation: 55221 steps/s (collection: 1.672s, learning 0.108s)
             Mean action noise std: 1.43
          Mean value_function loss: 35.7554
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 31.8865
                       Mean reward: 96.17
               Mean episode length: 236.68
    Episode_Reward/reaching_object: 0.4314
    Episode_Reward/rotating_object: 17.0714
        Episode_Reward/action_rate: -0.0079
          Episode_Reward/joint_vel: -0.0112
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 15532032
                    Iteration time: 1.78s
                      Time elapsed: 00:05:37
                               ETA: 00:47:46

################################################################################
                     [1m Learning iteration 158/1500 [0m                      

                       Computation: 55115 steps/s (collection: 1.693s, learning 0.090s)
             Mean action noise std: 1.43
          Mean value_function loss: 35.0205
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 31.9021
                       Mean reward: 83.84
               Mean episode length: 230.60
    Episode_Reward/reaching_object: 0.4429
    Episode_Reward/rotating_object: 18.2417
        Episode_Reward/action_rate: -0.0080
          Episode_Reward/joint_vel: -0.0112
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 15630336
                    Iteration time: 1.78s
                      Time elapsed: 00:05:38
                               ETA: 00:47:41

################################################################################
                     [1m Learning iteration 159/1500 [0m                      

                       Computation: 55706 steps/s (collection: 1.666s, learning 0.099s)
             Mean action noise std: 1.43
          Mean value_function loss: 34.0796
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 31.9221
                       Mean reward: 85.21
               Mean episode length: 238.77
    Episode_Reward/reaching_object: 0.4418
    Episode_Reward/rotating_object: 17.3364
        Episode_Reward/action_rate: -0.0080
          Episode_Reward/joint_vel: -0.0111
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 15728640
                    Iteration time: 1.76s
                      Time elapsed: 00:05:40
                               ETA: 00:47:35

################################################################################
                     [1m Learning iteration 160/1500 [0m                      

                       Computation: 54984 steps/s (collection: 1.678s, learning 0.110s)
             Mean action noise std: 1.43
          Mean value_function loss: 38.3053
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 31.9435
                       Mean reward: 107.06
               Mean episode length: 235.08
    Episode_Reward/reaching_object: 0.4695
    Episode_Reward/rotating_object: 19.2173
        Episode_Reward/action_rate: -0.0080
          Episode_Reward/joint_vel: -0.0106
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 15826944
                    Iteration time: 1.79s
                      Time elapsed: 00:05:42
                               ETA: 00:47:30

################################################################################
                     [1m Learning iteration 161/1500 [0m                      

                       Computation: 51607 steps/s (collection: 1.779s, learning 0.126s)
             Mean action noise std: 1.44
          Mean value_function loss: 32.0314
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 31.9621
                       Mean reward: 84.37
               Mean episode length: 238.79
    Episode_Reward/reaching_object: 0.4620
    Episode_Reward/rotating_object: 19.6679
        Episode_Reward/action_rate: -0.0080
          Episode_Reward/joint_vel: -0.0112
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 15925248
                    Iteration time: 1.90s
                      Time elapsed: 00:05:44
                               ETA: 00:47:26

################################################################################
                     [1m Learning iteration 162/1500 [0m                      

                       Computation: 53354 steps/s (collection: 1.729s, learning 0.114s)
             Mean action noise std: 1.44
          Mean value_function loss: 31.7518
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 31.9873
                       Mean reward: 96.53
               Mean episode length: 232.88
    Episode_Reward/reaching_object: 0.4374
    Episode_Reward/rotating_object: 16.8789
        Episode_Reward/action_rate: -0.0080
          Episode_Reward/joint_vel: -0.0113
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 16023552
                    Iteration time: 1.84s
                      Time elapsed: 00:05:46
                               ETA: 00:47:22

################################################################################
                     [1m Learning iteration 163/1500 [0m                      

                       Computation: 54713 steps/s (collection: 1.685s, learning 0.112s)
             Mean action noise std: 1.44
          Mean value_function loss: 36.3112
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 32.0155
                       Mean reward: 101.74
               Mean episode length: 237.03
    Episode_Reward/reaching_object: 0.4488
    Episode_Reward/rotating_object: 17.4972
        Episode_Reward/action_rate: -0.0081
          Episode_Reward/joint_vel: -0.0114
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 16121856
                    Iteration time: 1.80s
                      Time elapsed: 00:05:48
                               ETA: 00:47:17

################################################################################
                     [1m Learning iteration 164/1500 [0m                      

                       Computation: 52990 steps/s (collection: 1.740s, learning 0.115s)
             Mean action noise std: 1.44
          Mean value_function loss: 34.2806
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 32.0409
                       Mean reward: 102.42
               Mean episode length: 234.31
    Episode_Reward/reaching_object: 0.4534
    Episode_Reward/rotating_object: 21.2531
        Episode_Reward/action_rate: -0.0081
          Episode_Reward/joint_vel: -0.0108
      Episode_Termination/time_out: 13.2083
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 16220160
                    Iteration time: 1.86s
                      Time elapsed: 00:05:49
                               ETA: 00:47:13

################################################################################
                     [1m Learning iteration 165/1500 [0m                      

                       Computation: 53593 steps/s (collection: 1.714s, learning 0.121s)
             Mean action noise std: 1.45
          Mean value_function loss: 35.4685
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 32.0635
                       Mean reward: 93.87
               Mean episode length: 240.59
    Episode_Reward/reaching_object: 0.4449
    Episode_Reward/rotating_object: 19.4732
        Episode_Reward/action_rate: -0.0083
          Episode_Reward/joint_vel: -0.0115
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 16318464
                    Iteration time: 1.83s
                      Time elapsed: 00:05:51
                               ETA: 00:47:08

################################################################################
                     [1m Learning iteration 166/1500 [0m                      

                       Computation: 55535 steps/s (collection: 1.678s, learning 0.092s)
             Mean action noise std: 1.45
          Mean value_function loss: 39.7624
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 32.0892
                       Mean reward: 102.06
               Mean episode length: 235.24
    Episode_Reward/reaching_object: 0.4595
    Episode_Reward/rotating_object: 18.9826
        Episode_Reward/action_rate: -0.0082
          Episode_Reward/joint_vel: -0.0110
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 16416768
                    Iteration time: 1.77s
                      Time elapsed: 00:05:53
                               ETA: 00:47:03

################################################################################
                     [1m Learning iteration 167/1500 [0m                      

                       Computation: 53265 steps/s (collection: 1.728s, learning 0.117s)
             Mean action noise std: 1.45
          Mean value_function loss: 38.8175
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 32.1042
                       Mean reward: 108.78
               Mean episode length: 236.58
    Episode_Reward/reaching_object: 0.4921
    Episode_Reward/rotating_object: 20.0920
        Episode_Reward/action_rate: -0.0083
          Episode_Reward/joint_vel: -0.0109
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 16515072
                    Iteration time: 1.85s
                      Time elapsed: 00:05:55
                               ETA: 00:46:59

################################################################################
                     [1m Learning iteration 168/1500 [0m                      

                       Computation: 53532 steps/s (collection: 1.717s, learning 0.120s)
             Mean action noise std: 1.45
          Mean value_function loss: 42.8822
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 32.1261
                       Mean reward: 153.41
               Mean episode length: 236.79
    Episode_Reward/reaching_object: 0.4736
    Episode_Reward/rotating_object: 21.9104
        Episode_Reward/action_rate: -0.0083
          Episode_Reward/joint_vel: -0.0112
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 16613376
                    Iteration time: 1.84s
                      Time elapsed: 00:05:57
                               ETA: 00:46:55

################################################################################
                     [1m Learning iteration 169/1500 [0m                      

                       Computation: 54090 steps/s (collection: 1.704s, learning 0.114s)
             Mean action noise std: 1.45
          Mean value_function loss: 38.3884
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 32.1429
                       Mean reward: 104.23
               Mean episode length: 235.15
    Episode_Reward/reaching_object: 0.4926
    Episode_Reward/rotating_object: 21.4410
        Episode_Reward/action_rate: -0.0083
          Episode_Reward/joint_vel: -0.0110
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 16711680
                    Iteration time: 1.82s
                      Time elapsed: 00:05:59
                               ETA: 00:46:50

################################################################################
                     [1m Learning iteration 170/1500 [0m                      

                       Computation: 53718 steps/s (collection: 1.712s, learning 0.118s)
             Mean action noise std: 1.45
          Mean value_function loss: 38.3894
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 32.1568
                       Mean reward: 82.73
               Mean episode length: 235.34
    Episode_Reward/reaching_object: 0.4939
    Episode_Reward/rotating_object: 20.8615
        Episode_Reward/action_rate: -0.0083
          Episode_Reward/joint_vel: -0.0108
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 16809984
                    Iteration time: 1.83s
                      Time elapsed: 00:06:00
                               ETA: 00:46:46

################################################################################
                     [1m Learning iteration 171/1500 [0m                      

                       Computation: 54502 steps/s (collection: 1.680s, learning 0.124s)
             Mean action noise std: 1.45
          Mean value_function loss: 32.6304
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 32.1707
                       Mean reward: 103.30
               Mean episode length: 229.69
    Episode_Reward/reaching_object: 0.4983
    Episode_Reward/rotating_object: 21.1919
        Episode_Reward/action_rate: -0.0084
          Episode_Reward/joint_vel: -0.0106
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 16908288
                    Iteration time: 1.80s
                      Time elapsed: 00:06:02
                               ETA: 00:46:42

################################################################################
                     [1m Learning iteration 172/1500 [0m                      

                       Computation: 54107 steps/s (collection: 1.708s, learning 0.109s)
             Mean action noise std: 1.46
          Mean value_function loss: 37.7441
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 32.1934
                       Mean reward: 99.89
               Mean episode length: 240.39
    Episode_Reward/reaching_object: 0.4867
    Episode_Reward/rotating_object: 19.9781
        Episode_Reward/action_rate: -0.0084
          Episode_Reward/joint_vel: -0.0106
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 17006592
                    Iteration time: 1.82s
                      Time elapsed: 00:06:04
                               ETA: 00:46:37

################################################################################
                     [1m Learning iteration 173/1500 [0m                      

                       Computation: 52379 steps/s (collection: 1.768s, learning 0.109s)
             Mean action noise std: 1.46
          Mean value_function loss: 37.3393
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 32.2205
                       Mean reward: 117.56
               Mean episode length: 232.36
    Episode_Reward/reaching_object: 0.4942
    Episode_Reward/rotating_object: 21.3607
        Episode_Reward/action_rate: -0.0083
          Episode_Reward/joint_vel: -0.0107
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 17104896
                    Iteration time: 1.88s
                      Time elapsed: 00:06:06
                               ETA: 00:46:33

################################################################################
                     [1m Learning iteration 174/1500 [0m                      

                       Computation: 55381 steps/s (collection: 1.677s, learning 0.098s)
             Mean action noise std: 1.46
          Mean value_function loss: 40.1793
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 32.2390
                       Mean reward: 91.22
               Mean episode length: 238.57
    Episode_Reward/reaching_object: 0.4930
    Episode_Reward/rotating_object: 20.0480
        Episode_Reward/action_rate: -0.0084
          Episode_Reward/joint_vel: -0.0105
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 17203200
                    Iteration time: 1.78s
                      Time elapsed: 00:06:08
                               ETA: 00:46:29

################################################################################
                     [1m Learning iteration 175/1500 [0m                      

                       Computation: 53627 steps/s (collection: 1.724s, learning 0.110s)
             Mean action noise std: 1.46
          Mean value_function loss: 42.8049
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 32.2632
                       Mean reward: 100.53
               Mean episode length: 235.72
    Episode_Reward/reaching_object: 0.4786
    Episode_Reward/rotating_object: 22.0784
        Episode_Reward/action_rate: -0.0084
          Episode_Reward/joint_vel: -0.0106
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 17301504
                    Iteration time: 1.83s
                      Time elapsed: 00:06:09
                               ETA: 00:46:25

################################################################################
                     [1m Learning iteration 176/1500 [0m                      

                       Computation: 54411 steps/s (collection: 1.707s, learning 0.100s)
             Mean action noise std: 1.46
          Mean value_function loss: 41.1226
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 32.2899
                       Mean reward: 125.23
               Mean episode length: 236.59
    Episode_Reward/reaching_object: 0.5049
    Episode_Reward/rotating_object: 24.5893
        Episode_Reward/action_rate: -0.0085
          Episode_Reward/joint_vel: -0.0104
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 17399808
                    Iteration time: 1.81s
                      Time elapsed: 00:06:11
                               ETA: 00:46:20

################################################################################
                     [1m Learning iteration 177/1500 [0m                      

                       Computation: 54632 steps/s (collection: 1.699s, learning 0.100s)
             Mean action noise std: 1.47
          Mean value_function loss: 42.2725
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 32.3112
                       Mean reward: 120.97
               Mean episode length: 229.20
    Episode_Reward/reaching_object: 0.5121
    Episode_Reward/rotating_object: 24.0778
        Episode_Reward/action_rate: -0.0084
          Episode_Reward/joint_vel: -0.0100
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 17498112
                    Iteration time: 1.80s
                      Time elapsed: 00:06:13
                               ETA: 00:46:16

################################################################################
                     [1m Learning iteration 178/1500 [0m                      

                       Computation: 54706 steps/s (collection: 1.690s, learning 0.107s)
             Mean action noise std: 1.47
          Mean value_function loss: 45.4509
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 32.3192
                       Mean reward: 116.47
               Mean episode length: 240.55
    Episode_Reward/reaching_object: 0.5100
    Episode_Reward/rotating_object: 24.2589
        Episode_Reward/action_rate: -0.0086
          Episode_Reward/joint_vel: -0.0103
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 17596416
                    Iteration time: 1.80s
                      Time elapsed: 00:06:15
                               ETA: 00:46:12

################################################################################
                     [1m Learning iteration 179/1500 [0m                      

                       Computation: 54522 steps/s (collection: 1.693s, learning 0.110s)
             Mean action noise std: 1.47
          Mean value_function loss: 45.4340
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 32.3374
                       Mean reward: 123.82
               Mean episode length: 235.95
    Episode_Reward/reaching_object: 0.5028
    Episode_Reward/rotating_object: 24.8605
        Episode_Reward/action_rate: -0.0085
          Episode_Reward/joint_vel: -0.0103
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 17694720
                    Iteration time: 1.80s
                      Time elapsed: 00:06:17
                               ETA: 00:46:07

################################################################################
                     [1m Learning iteration 180/1500 [0m                      

                       Computation: 54422 steps/s (collection: 1.697s, learning 0.109s)
             Mean action noise std: 1.47
          Mean value_function loss: 30.9776
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 32.3530
                       Mean reward: 120.26
               Mean episode length: 229.51
    Episode_Reward/reaching_object: 0.4920
    Episode_Reward/rotating_object: 23.0433
        Episode_Reward/action_rate: -0.0084
          Episode_Reward/joint_vel: -0.0102
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 17793024
                    Iteration time: 1.81s
                      Time elapsed: 00:06:18
                               ETA: 00:46:03

################################################################################
                     [1m Learning iteration 181/1500 [0m                      

                       Computation: 54731 steps/s (collection: 1.699s, learning 0.097s)
             Mean action noise std: 1.47
          Mean value_function loss: 38.2731
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 32.3644
                       Mean reward: 125.50
               Mean episode length: 233.47
    Episode_Reward/reaching_object: 0.4980
    Episode_Reward/rotating_object: 22.9736
        Episode_Reward/action_rate: -0.0085
          Episode_Reward/joint_vel: -0.0102
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 17891328
                    Iteration time: 1.80s
                      Time elapsed: 00:06:20
                               ETA: 00:45:59

################################################################################
                     [1m Learning iteration 182/1500 [0m                      

                       Computation: 54343 steps/s (collection: 1.716s, learning 0.093s)
             Mean action noise std: 1.47
          Mean value_function loss: 41.6398
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 32.3818
                       Mean reward: 118.57
               Mean episode length: 238.77
    Episode_Reward/reaching_object: 0.5149
    Episode_Reward/rotating_object: 22.1500
        Episode_Reward/action_rate: -0.0085
          Episode_Reward/joint_vel: -0.0101
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 17989632
                    Iteration time: 1.81s
                      Time elapsed: 00:06:22
                               ETA: 00:45:55

################################################################################
                     [1m Learning iteration 183/1500 [0m                      

                       Computation: 54487 steps/s (collection: 1.688s, learning 0.117s)
             Mean action noise std: 1.47
          Mean value_function loss: 44.3625
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 32.4108
                       Mean reward: 136.45
               Mean episode length: 231.47
    Episode_Reward/reaching_object: 0.5162
    Episode_Reward/rotating_object: 23.9650
        Episode_Reward/action_rate: -0.0085
          Episode_Reward/joint_vel: -0.0103
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 18087936
                    Iteration time: 1.80s
                      Time elapsed: 00:06:24
                               ETA: 00:45:51

################################################################################
                     [1m Learning iteration 184/1500 [0m                      

                       Computation: 54206 steps/s (collection: 1.701s, learning 0.113s)
             Mean action noise std: 1.48
          Mean value_function loss: 41.8804
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 32.4359
                       Mean reward: 116.64
               Mean episode length: 236.04
    Episode_Reward/reaching_object: 0.5288
    Episode_Reward/rotating_object: 24.6082
        Episode_Reward/action_rate: -0.0086
          Episode_Reward/joint_vel: -0.0102
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 18186240
                    Iteration time: 1.81s
                      Time elapsed: 00:06:26
                               ETA: 00:45:47

################################################################################
                     [1m Learning iteration 185/1500 [0m                      

                       Computation: 55515 steps/s (collection: 1.679s, learning 0.092s)
             Mean action noise std: 1.48
          Mean value_function loss: 38.9623
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 32.4619
                       Mean reward: 118.12
               Mean episode length: 233.91
    Episode_Reward/reaching_object: 0.5304
    Episode_Reward/rotating_object: 24.1412
        Episode_Reward/action_rate: -0.0085
          Episode_Reward/joint_vel: -0.0100
      Episode_Termination/time_out: 13.4583
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 18284544
                    Iteration time: 1.77s
                      Time elapsed: 00:06:27
                               ETA: 00:45:42

################################################################################
                     [1m Learning iteration 186/1500 [0m                      

                       Computation: 55865 steps/s (collection: 1.667s, learning 0.093s)
             Mean action noise std: 1.48
          Mean value_function loss: 46.2441
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 32.4881
                       Mean reward: 122.97
               Mean episode length: 234.84
    Episode_Reward/reaching_object: 0.5364
    Episode_Reward/rotating_object: 23.6738
        Episode_Reward/action_rate: -0.0087
          Episode_Reward/joint_vel: -0.0101
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 18382848
                    Iteration time: 1.76s
                      Time elapsed: 00:06:29
                               ETA: 00:45:38

################################################################################
                     [1m Learning iteration 187/1500 [0m                      

                       Computation: 54695 steps/s (collection: 1.694s, learning 0.103s)
             Mean action noise std: 1.48
          Mean value_function loss: 44.9249
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 32.5148
                       Mean reward: 147.22
               Mean episode length: 233.69
    Episode_Reward/reaching_object: 0.5495
    Episode_Reward/rotating_object: 29.2748
        Episode_Reward/action_rate: -0.0088
          Episode_Reward/joint_vel: -0.0099
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 18481152
                    Iteration time: 1.80s
                      Time elapsed: 00:06:31
                               ETA: 00:45:34

################################################################################
                     [1m Learning iteration 188/1500 [0m                      

                       Computation: 54892 steps/s (collection: 1.692s, learning 0.099s)
             Mean action noise std: 1.49
          Mean value_function loss: 43.0862
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 32.5377
                       Mean reward: 142.57
               Mean episode length: 234.11
    Episode_Reward/reaching_object: 0.5322
    Episode_Reward/rotating_object: 27.3351
        Episode_Reward/action_rate: -0.0086
          Episode_Reward/joint_vel: -0.0101
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 18579456
                    Iteration time: 1.79s
                      Time elapsed: 00:06:33
                               ETA: 00:45:30

################################################################################
                     [1m Learning iteration 189/1500 [0m                      

                       Computation: 55567 steps/s (collection: 1.677s, learning 0.092s)
             Mean action noise std: 1.49
          Mean value_function loss: 44.0283
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 32.5653
                       Mean reward: 123.63
               Mean episode length: 229.05
    Episode_Reward/reaching_object: 0.5391
    Episode_Reward/rotating_object: 25.1671
        Episode_Reward/action_rate: -0.0089
          Episode_Reward/joint_vel: -0.0102
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 18677760
                    Iteration time: 1.77s
                      Time elapsed: 00:06:35
                               ETA: 00:45:26

################################################################################
                     [1m Learning iteration 190/1500 [0m                      

                       Computation: 54502 steps/s (collection: 1.702s, learning 0.102s)
             Mean action noise std: 1.49
          Mean value_function loss: 40.4364
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 32.5931
                       Mean reward: 135.35
               Mean episode length: 239.21
    Episode_Reward/reaching_object: 0.5268
    Episode_Reward/rotating_object: 25.6075
        Episode_Reward/action_rate: -0.0089
          Episode_Reward/joint_vel: -0.0102
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 18776064
                    Iteration time: 1.80s
                      Time elapsed: 00:06:36
                               ETA: 00:45:22

################################################################################
                     [1m Learning iteration 191/1500 [0m                      

                       Computation: 55005 steps/s (collection: 1.688s, learning 0.099s)
             Mean action noise std: 1.49
          Mean value_function loss: 39.9397
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 32.6203
                       Mean reward: 138.65
               Mean episode length: 235.55
    Episode_Reward/reaching_object: 0.5090
    Episode_Reward/rotating_object: 27.4434
        Episode_Reward/action_rate: -0.0088
          Episode_Reward/joint_vel: -0.0101
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 18874368
                    Iteration time: 1.79s
                      Time elapsed: 00:06:38
                               ETA: 00:45:18

################################################################################
                     [1m Learning iteration 192/1500 [0m                      

                       Computation: 54927 steps/s (collection: 1.698s, learning 0.092s)
             Mean action noise std: 1.50
          Mean value_function loss: 47.7999
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 32.6486
                       Mean reward: 149.52
               Mean episode length: 227.22
    Episode_Reward/reaching_object: 0.5010
    Episode_Reward/rotating_object: 26.8624
        Episode_Reward/action_rate: -0.0088
          Episode_Reward/joint_vel: -0.0102
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 18972672
                    Iteration time: 1.79s
                      Time elapsed: 00:06:40
                               ETA: 00:45:14

################################################################################
                     [1m Learning iteration 193/1500 [0m                      

                       Computation: 55484 steps/s (collection: 1.683s, learning 0.089s)
             Mean action noise std: 1.50
          Mean value_function loss: 50.0410
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 32.6749
                       Mean reward: 163.04
               Mean episode length: 240.37
    Episode_Reward/reaching_object: 0.5059
    Episode_Reward/rotating_object: 27.8847
        Episode_Reward/action_rate: -0.0088
          Episode_Reward/joint_vel: -0.0100
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 19070976
                    Iteration time: 1.77s
                      Time elapsed: 00:06:42
                               ETA: 00:45:09

################################################################################
                     [1m Learning iteration 194/1500 [0m                      

                       Computation: 54713 steps/s (collection: 1.697s, learning 0.100s)
             Mean action noise std: 1.50
          Mean value_function loss: 51.7200
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 32.6950
                       Mean reward: 120.02
               Mean episode length: 237.91
    Episode_Reward/reaching_object: 0.5397
    Episode_Reward/rotating_object: 28.2858
        Episode_Reward/action_rate: -0.0090
          Episode_Reward/joint_vel: -0.0101
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 19169280
                    Iteration time: 1.80s
                      Time elapsed: 00:06:44
                               ETA: 00:45:05

################################################################################
                     [1m Learning iteration 195/1500 [0m                      

                       Computation: 53971 steps/s (collection: 1.712s, learning 0.110s)
             Mean action noise std: 1.50
          Mean value_function loss: 53.2149
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 32.7122
                       Mean reward: 149.31
               Mean episode length: 239.88
    Episode_Reward/reaching_object: 0.5369
    Episode_Reward/rotating_object: 29.5292
        Episode_Reward/action_rate: -0.0091
          Episode_Reward/joint_vel: -0.0104
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 19267584
                    Iteration time: 1.82s
                      Time elapsed: 00:06:45
                               ETA: 00:45:02

################################################################################
                     [1m Learning iteration 196/1500 [0m                      

                       Computation: 54552 steps/s (collection: 1.689s, learning 0.113s)
             Mean action noise std: 1.50
          Mean value_function loss: 46.3455
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 32.7296
                       Mean reward: 150.84
               Mean episode length: 242.61
    Episode_Reward/reaching_object: 0.5448
    Episode_Reward/rotating_object: 28.1194
        Episode_Reward/action_rate: -0.0091
          Episode_Reward/joint_vel: -0.0102
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 19365888
                    Iteration time: 1.80s
                      Time elapsed: 00:06:47
                               ETA: 00:44:58

################################################################################
                     [1m Learning iteration 197/1500 [0m                      

                       Computation: 54709 steps/s (collection: 1.692s, learning 0.105s)
             Mean action noise std: 1.50
          Mean value_function loss: 46.9799
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 32.7423
                       Mean reward: 147.94
               Mean episode length: 236.39
    Episode_Reward/reaching_object: 0.5249
    Episode_Reward/rotating_object: 28.1817
        Episode_Reward/action_rate: -0.0092
          Episode_Reward/joint_vel: -0.0105
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 19464192
                    Iteration time: 1.80s
                      Time elapsed: 00:06:49
                               ETA: 00:44:54

################################################################################
                     [1m Learning iteration 198/1500 [0m                      

                       Computation: 55592 steps/s (collection: 1.679s, learning 0.090s)
             Mean action noise std: 1.50
          Mean value_function loss: 42.8073
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 32.7527
                       Mean reward: 129.25
               Mean episode length: 241.37
    Episode_Reward/reaching_object: 0.5408
    Episode_Reward/rotating_object: 28.5960
        Episode_Reward/action_rate: -0.0093
          Episode_Reward/joint_vel: -0.0105
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 19562496
                    Iteration time: 1.77s
                      Time elapsed: 00:06:51
                               ETA: 00:44:50

################################################################################
                     [1m Learning iteration 199/1500 [0m                      

                       Computation: 54308 steps/s (collection: 1.702s, learning 0.108s)
             Mean action noise std: 1.50
          Mean value_function loss: 49.7005
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 32.7593
                       Mean reward: 178.66
               Mean episode length: 237.70
    Episode_Reward/reaching_object: 0.5372
    Episode_Reward/rotating_object: 30.9406
        Episode_Reward/action_rate: -0.0093
          Episode_Reward/joint_vel: -0.0105
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 19660800
                    Iteration time: 1.81s
                      Time elapsed: 00:06:53
                               ETA: 00:44:46

################################################################################
                     [1m Learning iteration 200/1500 [0m                      

                       Computation: 55674 steps/s (collection: 1.662s, learning 0.104s)
             Mean action noise std: 1.51
          Mean value_function loss: 52.1655
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 32.7702
                       Mean reward: 168.98
               Mean episode length: 235.06
    Episode_Reward/reaching_object: 0.5485
    Episode_Reward/rotating_object: 30.0182
        Episode_Reward/action_rate: -0.0092
          Episode_Reward/joint_vel: -0.0104
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 19759104
                    Iteration time: 1.77s
                      Time elapsed: 00:06:54
                               ETA: 00:44:42

################################################################################
                     [1m Learning iteration 201/1500 [0m                      

                       Computation: 53124 steps/s (collection: 1.754s, learning 0.097s)
             Mean action noise std: 1.51
          Mean value_function loss: 51.9835
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 32.7847
                       Mean reward: 165.37
               Mean episode length: 235.06
    Episode_Reward/reaching_object: 0.5594
    Episode_Reward/rotating_object: 31.2235
        Episode_Reward/action_rate: -0.0094
          Episode_Reward/joint_vel: -0.0106
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 19857408
                    Iteration time: 1.85s
                      Time elapsed: 00:06:56
                               ETA: 00:44:39

################################################################################
                     [1m Learning iteration 202/1500 [0m                      

                       Computation: 55142 steps/s (collection: 1.692s, learning 0.091s)
             Mean action noise std: 1.51
          Mean value_function loss: 57.7363
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 32.7977
                       Mean reward: 159.43
               Mean episode length: 239.24
    Episode_Reward/reaching_object: 0.5634
    Episode_Reward/rotating_object: 29.9038
        Episode_Reward/action_rate: -0.0092
          Episode_Reward/joint_vel: -0.0102
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 19955712
                    Iteration time: 1.78s
                      Time elapsed: 00:06:58
                               ETA: 00:44:35

################################################################################
                     [1m Learning iteration 203/1500 [0m                      

                       Computation: 55485 steps/s (collection: 1.679s, learning 0.093s)
             Mean action noise std: 1.51
          Mean value_function loss: 55.1588
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 32.8081
                       Mean reward: 210.22
               Mean episode length: 241.30
    Episode_Reward/reaching_object: 0.5731
    Episode_Reward/rotating_object: 36.8746
        Episode_Reward/action_rate: -0.0094
          Episode_Reward/joint_vel: -0.0102
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 20054016
                    Iteration time: 1.77s
                      Time elapsed: 00:07:00
                               ETA: 00:44:31

################################################################################
                     [1m Learning iteration 204/1500 [0m                      

                       Computation: 53376 steps/s (collection: 1.742s, learning 0.100s)
             Mean action noise std: 1.51
          Mean value_function loss: 49.6163
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 32.8188
                       Mean reward: 172.87
               Mean episode length: 240.44
    Episode_Reward/reaching_object: 0.5807
    Episode_Reward/rotating_object: 30.8531
        Episode_Reward/action_rate: -0.0095
          Episode_Reward/joint_vel: -0.0103
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 20152320
                    Iteration time: 1.84s
                      Time elapsed: 00:07:02
                               ETA: 00:44:28

################################################################################
                     [1m Learning iteration 205/1500 [0m                      

                       Computation: 53227 steps/s (collection: 1.751s, learning 0.096s)
             Mean action noise std: 1.51
          Mean value_function loss: 55.2051
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 32.8322
                       Mean reward: 189.09
               Mean episode length: 242.94
    Episode_Reward/reaching_object: 0.5949
    Episode_Reward/rotating_object: 34.8330
        Episode_Reward/action_rate: -0.0095
          Episode_Reward/joint_vel: -0.0105
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 20250624
                    Iteration time: 1.85s
                      Time elapsed: 00:07:03
                               ETA: 00:44:24

################################################################################
                     [1m Learning iteration 206/1500 [0m                      

                       Computation: 54594 steps/s (collection: 1.707s, learning 0.094s)
             Mean action noise std: 1.51
          Mean value_function loss: 59.5314
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 32.8487
                       Mean reward: 171.89
               Mean episode length: 240.80
    Episode_Reward/reaching_object: 0.5744
    Episode_Reward/rotating_object: 33.2931
        Episode_Reward/action_rate: -0.0095
          Episode_Reward/joint_vel: -0.0103
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 20348928
                    Iteration time: 1.80s
                      Time elapsed: 00:07:05
                               ETA: 00:44:21

################################################################################
                     [1m Learning iteration 207/1500 [0m                      

                       Computation: 55889 steps/s (collection: 1.670s, learning 0.089s)
             Mean action noise std: 1.51
          Mean value_function loss: 56.4316
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 32.8713
                       Mean reward: 181.82
               Mean episode length: 243.99
    Episode_Reward/reaching_object: 0.5840
    Episode_Reward/rotating_object: 32.3646
        Episode_Reward/action_rate: -0.0095
          Episode_Reward/joint_vel: -0.0100
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 20447232
                    Iteration time: 1.76s
                      Time elapsed: 00:07:07
                               ETA: 00:44:17

################################################################################
                     [1m Learning iteration 208/1500 [0m                      

                       Computation: 55538 steps/s (collection: 1.672s, learning 0.099s)
             Mean action noise std: 1.52
          Mean value_function loss: 51.0438
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 32.8933
                       Mean reward: 196.72
               Mean episode length: 243.16
    Episode_Reward/reaching_object: 0.5874
    Episode_Reward/rotating_object: 35.4937
        Episode_Reward/action_rate: -0.0096
          Episode_Reward/joint_vel: -0.0105
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 20545536
                    Iteration time: 1.77s
                      Time elapsed: 00:07:09
                               ETA: 00:44:13

################################################################################
                     [1m Learning iteration 209/1500 [0m                      

                       Computation: 55802 steps/s (collection: 1.671s, learning 0.091s)
             Mean action noise std: 1.52
          Mean value_function loss: 47.1633
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 32.9184
                       Mean reward: 206.78
               Mean episode length: 238.81
    Episode_Reward/reaching_object: 0.5784
    Episode_Reward/rotating_object: 36.2440
        Episode_Reward/action_rate: -0.0096
          Episode_Reward/joint_vel: -0.0101
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 20643840
                    Iteration time: 1.76s
                      Time elapsed: 00:07:10
                               ETA: 00:44:09

################################################################################
                     [1m Learning iteration 210/1500 [0m                      

                       Computation: 56074 steps/s (collection: 1.660s, learning 0.093s)
             Mean action noise std: 1.52
          Mean value_function loss: 46.8844
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 32.9357
                       Mean reward: 188.20
               Mean episode length: 235.86
    Episode_Reward/reaching_object: 0.5710
    Episode_Reward/rotating_object: 33.8613
        Episode_Reward/action_rate: -0.0096
          Episode_Reward/joint_vel: -0.0103
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 20742144
                    Iteration time: 1.75s
                      Time elapsed: 00:07:12
                               ETA: 00:44:05

################################################################################
                     [1m Learning iteration 211/1500 [0m                      

                       Computation: 54128 steps/s (collection: 1.709s, learning 0.107s)
             Mean action noise std: 1.52
          Mean value_function loss: 52.2067
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 32.9535
                       Mean reward: 194.22
               Mean episode length: 242.31
    Episode_Reward/reaching_object: 0.5813
    Episode_Reward/rotating_object: 36.5013
        Episode_Reward/action_rate: -0.0097
          Episode_Reward/joint_vel: -0.0102
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 20840448
                    Iteration time: 1.82s
                      Time elapsed: 00:07:14
                               ETA: 00:44:02

################################################################################
                     [1m Learning iteration 212/1500 [0m                      

                       Computation: 55442 steps/s (collection: 1.664s, learning 0.110s)
             Mean action noise std: 1.52
          Mean value_function loss: 48.1605
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 32.9759
                       Mean reward: 222.65
               Mean episode length: 242.58
    Episode_Reward/reaching_object: 0.6014
    Episode_Reward/rotating_object: 39.4172
        Episode_Reward/action_rate: -0.0097
          Episode_Reward/joint_vel: -0.0099
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 20938752
                    Iteration time: 1.77s
                      Time elapsed: 00:07:16
                               ETA: 00:43:58

################################################################################
                     [1m Learning iteration 213/1500 [0m                      

                       Computation: 55815 steps/s (collection: 1.661s, learning 0.100s)
             Mean action noise std: 1.53
          Mean value_function loss: 47.9497
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 33.0022
                       Mean reward: 166.05
               Mean episode length: 232.45
    Episode_Reward/reaching_object: 0.5695
    Episode_Reward/rotating_object: 35.0893
        Episode_Reward/action_rate: -0.0096
          Episode_Reward/joint_vel: -0.0101
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 21037056
                    Iteration time: 1.76s
                      Time elapsed: 00:07:18
                               ETA: 00:43:54

################################################################################
                     [1m Learning iteration 214/1500 [0m                      

                       Computation: 55053 steps/s (collection: 1.676s, learning 0.110s)
             Mean action noise std: 1.53
          Mean value_function loss: 55.9045
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 33.0296
                       Mean reward: 246.18
               Mean episode length: 243.57
    Episode_Reward/reaching_object: 0.5825
    Episode_Reward/rotating_object: 42.2589
        Episode_Reward/action_rate: -0.0096
          Episode_Reward/joint_vel: -0.0096
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 21135360
                    Iteration time: 1.79s
                      Time elapsed: 00:07:19
                               ETA: 00:43:51

################################################################################
                     [1m Learning iteration 215/1500 [0m                      

                       Computation: 55616 steps/s (collection: 1.677s, learning 0.091s)
             Mean action noise std: 1.53
          Mean value_function loss: 48.0978
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 33.0529
                       Mean reward: 238.84
               Mean episode length: 242.55
    Episode_Reward/reaching_object: 0.5859
    Episode_Reward/rotating_object: 39.5506
        Episode_Reward/action_rate: -0.0098
          Episode_Reward/joint_vel: -0.0097
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 21233664
                    Iteration time: 1.77s
                      Time elapsed: 00:07:21
                               ETA: 00:43:47

################################################################################
                     [1m Learning iteration 216/1500 [0m                      

                       Computation: 55528 steps/s (collection: 1.675s, learning 0.096s)
             Mean action noise std: 1.53
          Mean value_function loss: 55.9142
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 33.0749
                       Mean reward: 199.29
               Mean episode length: 238.10
    Episode_Reward/reaching_object: 0.5833
    Episode_Reward/rotating_object: 39.0551
        Episode_Reward/action_rate: -0.0097
          Episode_Reward/joint_vel: -0.0098
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 21331968
                    Iteration time: 1.77s
                      Time elapsed: 00:07:23
                               ETA: 00:43:43

################################################################################
                     [1m Learning iteration 217/1500 [0m                      

                       Computation: 55893 steps/s (collection: 1.656s, learning 0.103s)
             Mean action noise std: 1.53
          Mean value_function loss: 55.2982
               Mean surrogate loss: 0.0005
                 Mean entropy loss: 33.0943
                       Mean reward: 214.88
               Mean episode length: 235.20
    Episode_Reward/reaching_object: 0.5656
    Episode_Reward/rotating_object: 37.5779
        Episode_Reward/action_rate: -0.0097
          Episode_Reward/joint_vel: -0.0098
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 21430272
                    Iteration time: 1.76s
                      Time elapsed: 00:07:25
                               ETA: 00:43:39

################################################################################
                     [1m Learning iteration 218/1500 [0m                      

                       Computation: 52823 steps/s (collection: 1.761s, learning 0.100s)
             Mean action noise std: 1.53
          Mean value_function loss: 48.7054
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 33.1040
                       Mean reward: 215.79
               Mean episode length: 239.73
    Episode_Reward/reaching_object: 0.5545
    Episode_Reward/rotating_object: 37.8779
        Episode_Reward/action_rate: -0.0097
          Episode_Reward/joint_vel: -0.0098
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 21528576
                    Iteration time: 1.86s
                      Time elapsed: 00:07:27
                               ETA: 00:43:36

################################################################################
                     [1m Learning iteration 219/1500 [0m                      

                       Computation: 54125 steps/s (collection: 1.699s, learning 0.117s)
             Mean action noise std: 1.54
          Mean value_function loss: 52.8765
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 33.1159
                       Mean reward: 204.57
               Mean episode length: 236.03
    Episode_Reward/reaching_object: 0.5847
    Episode_Reward/rotating_object: 40.1873
        Episode_Reward/action_rate: -0.0098
          Episode_Reward/joint_vel: -0.0098
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 21626880
                    Iteration time: 1.82s
                      Time elapsed: 00:07:28
                               ETA: 00:43:33

################################################################################
                     [1m Learning iteration 220/1500 [0m                      

                       Computation: 55377 steps/s (collection: 1.681s, learning 0.094s)
             Mean action noise std: 1.54
          Mean value_function loss: 47.8398
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 33.1287
                       Mean reward: 171.47
               Mean episode length: 236.90
    Episode_Reward/reaching_object: 0.5854
    Episode_Reward/rotating_object: 40.7446
        Episode_Reward/action_rate: -0.0097
          Episode_Reward/joint_vel: -0.0094
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 21725184
                    Iteration time: 1.78s
                      Time elapsed: 00:07:30
                               ETA: 00:43:29

################################################################################
                     [1m Learning iteration 221/1500 [0m                      

                       Computation: 53347 steps/s (collection: 1.749s, learning 0.094s)
             Mean action noise std: 1.54
          Mean value_function loss: 49.6959
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 33.1503
                       Mean reward: 218.79
               Mean episode length: 240.54
    Episode_Reward/reaching_object: 0.6004
    Episode_Reward/rotating_object: 40.6004
        Episode_Reward/action_rate: -0.0100
          Episode_Reward/joint_vel: -0.0099
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 21823488
                    Iteration time: 1.84s
                      Time elapsed: 00:07:32
                               ETA: 00:43:26

################################################################################
                     [1m Learning iteration 222/1500 [0m                      

                       Computation: 54957 steps/s (collection: 1.695s, learning 0.094s)
             Mean action noise std: 1.54
          Mean value_function loss: 54.0830
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 33.1735
                       Mean reward: 226.04
               Mean episode length: 243.68
    Episode_Reward/reaching_object: 0.6033
    Episode_Reward/rotating_object: 42.6483
        Episode_Reward/action_rate: -0.0100
          Episode_Reward/joint_vel: -0.0099
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 21921792
                    Iteration time: 1.79s
                      Time elapsed: 00:07:34
                               ETA: 00:43:23

################################################################################
                     [1m Learning iteration 223/1500 [0m                      

                       Computation: 55390 steps/s (collection: 1.671s, learning 0.104s)
             Mean action noise std: 1.54
          Mean value_function loss: 44.7931
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 33.1879
                       Mean reward: 226.94
               Mean episode length: 240.30
    Episode_Reward/reaching_object: 0.5927
    Episode_Reward/rotating_object: 41.9288
        Episode_Reward/action_rate: -0.0099
          Episode_Reward/joint_vel: -0.0095
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 22020096
                    Iteration time: 1.77s
                      Time elapsed: 00:07:36
                               ETA: 00:43:19

################################################################################
                     [1m Learning iteration 224/1500 [0m                      

                       Computation: 55023 steps/s (collection: 1.685s, learning 0.102s)
             Mean action noise std: 1.54
          Mean value_function loss: 46.8424
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 33.2071
                       Mean reward: 200.96
               Mean episode length: 232.75
    Episode_Reward/reaching_object: 0.6051
    Episode_Reward/rotating_object: 40.4919
        Episode_Reward/action_rate: -0.0099
          Episode_Reward/joint_vel: -0.0094
      Episode_Termination/time_out: 17.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 22118400
                    Iteration time: 1.79s
                      Time elapsed: 00:07:37
                               ETA: 00:43:16

################################################################################
                     [1m Learning iteration 225/1500 [0m                      

                       Computation: 54841 steps/s (collection: 1.702s, learning 0.090s)
             Mean action noise std: 1.54
          Mean value_function loss: 49.4219
               Mean surrogate loss: 0.0027
                 Mean entropy loss: 33.2252
                       Mean reward: 233.94
               Mean episode length: 241.14
    Episode_Reward/reaching_object: 0.6052
    Episode_Reward/rotating_object: 42.7191
        Episode_Reward/action_rate: -0.0099
          Episode_Reward/joint_vel: -0.0095
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 22216704
                    Iteration time: 1.79s
                      Time elapsed: 00:07:39
                               ETA: 00:43:12

################################################################################
                     [1m Learning iteration 226/1500 [0m                      

                       Computation: 54627 steps/s (collection: 1.706s, learning 0.094s)
             Mean action noise std: 1.55
          Mean value_function loss: 50.3643
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 33.2383
                       Mean reward: 185.14
               Mean episode length: 234.21
    Episode_Reward/reaching_object: 0.6011
    Episode_Reward/rotating_object: 44.7813
        Episode_Reward/action_rate: -0.0099
          Episode_Reward/joint_vel: -0.0092
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 22315008
                    Iteration time: 1.80s
                      Time elapsed: 00:07:41
                               ETA: 00:43:09

################################################################################
                     [1m Learning iteration 227/1500 [0m                      

                       Computation: 54944 steps/s (collection: 1.689s, learning 0.101s)
             Mean action noise std: 1.55
          Mean value_function loss: 54.8802
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 33.2629
                       Mean reward: 191.68
               Mean episode length: 237.52
    Episode_Reward/reaching_object: 0.6109
    Episode_Reward/rotating_object: 37.3973
        Episode_Reward/action_rate: -0.0100
          Episode_Reward/joint_vel: -0.0095
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 22413312
                    Iteration time: 1.79s
                      Time elapsed: 00:07:43
                               ETA: 00:43:06

################################################################################
                     [1m Learning iteration 228/1500 [0m                      

                       Computation: 54271 steps/s (collection: 1.693s, learning 0.118s)
             Mean action noise std: 1.55
          Mean value_function loss: 60.5373
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 33.2845
                       Mean reward: 209.04
               Mean episode length: 236.94
    Episode_Reward/reaching_object: 0.5954
    Episode_Reward/rotating_object: 38.8566
        Episode_Reward/action_rate: -0.0098
          Episode_Reward/joint_vel: -0.0093
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 22511616
                    Iteration time: 1.81s
                      Time elapsed: 00:07:45
                               ETA: 00:43:02

################################################################################
                     [1m Learning iteration 229/1500 [0m                      

                       Computation: 53537 steps/s (collection: 1.731s, learning 0.105s)
             Mean action noise std: 1.55
          Mean value_function loss: 56.8012
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 33.3052
                       Mean reward: 209.77
               Mean episode length: 237.35
    Episode_Reward/reaching_object: 0.6126
    Episode_Reward/rotating_object: 43.1012
        Episode_Reward/action_rate: -0.0100
          Episode_Reward/joint_vel: -0.0095
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 22609920
                    Iteration time: 1.84s
                      Time elapsed: 00:07:46
                               ETA: 00:42:59

################################################################################
                     [1m Learning iteration 230/1500 [0m                      

                       Computation: 54318 steps/s (collection: 1.697s, learning 0.113s)
             Mean action noise std: 1.55
          Mean value_function loss: 54.9007
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 33.3315
                       Mean reward: 198.84
               Mean episode length: 234.51
    Episode_Reward/reaching_object: 0.6154
    Episode_Reward/rotating_object: 39.5827
        Episode_Reward/action_rate: -0.0101
          Episode_Reward/joint_vel: -0.0096
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 22708224
                    Iteration time: 1.81s
                      Time elapsed: 00:07:48
                               ETA: 00:42:56

################################################################################
                     [1m Learning iteration 231/1500 [0m                      

                       Computation: 54535 steps/s (collection: 1.710s, learning 0.093s)
             Mean action noise std: 1.56
          Mean value_function loss: 59.0486
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 33.3481
                       Mean reward: 239.71
               Mean episode length: 236.97
    Episode_Reward/reaching_object: 0.6423
    Episode_Reward/rotating_object: 45.9817
        Episode_Reward/action_rate: -0.0101
          Episode_Reward/joint_vel: -0.0092
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 22806528
                    Iteration time: 1.80s
                      Time elapsed: 00:07:50
                               ETA: 00:42:53

################################################################################
                     [1m Learning iteration 232/1500 [0m                      

                       Computation: 54246 steps/s (collection: 1.714s, learning 0.098s)
             Mean action noise std: 1.56
          Mean value_function loss: 57.5218
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 33.3735
                       Mean reward: 214.50
               Mean episode length: 234.50
    Episode_Reward/reaching_object: 0.6460
    Episode_Reward/rotating_object: 44.0869
        Episode_Reward/action_rate: -0.0101
          Episode_Reward/joint_vel: -0.0094
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 22904832
                    Iteration time: 1.81s
                      Time elapsed: 00:07:52
                               ETA: 00:42:50

################################################################################
                     [1m Learning iteration 233/1500 [0m                      

                       Computation: 53572 steps/s (collection: 1.740s, learning 0.095s)
             Mean action noise std: 1.56
          Mean value_function loss: 53.1538
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 33.3977
                       Mean reward: 195.66
               Mean episode length: 239.62
    Episode_Reward/reaching_object: 0.6396
    Episode_Reward/rotating_object: 42.0417
        Episode_Reward/action_rate: -0.0101
          Episode_Reward/joint_vel: -0.0093
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 23003136
                    Iteration time: 1.83s
                      Time elapsed: 00:07:54
                               ETA: 00:42:47

################################################################################
                     [1m Learning iteration 234/1500 [0m                      

                       Computation: 52932 steps/s (collection: 1.753s, learning 0.104s)
             Mean action noise std: 1.56
          Mean value_function loss: 50.7471
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 33.4175
                       Mean reward: 201.11
               Mean episode length: 237.20
    Episode_Reward/reaching_object: 0.6622
    Episode_Reward/rotating_object: 42.4901
        Episode_Reward/action_rate: -0.0104
          Episode_Reward/joint_vel: -0.0097
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 23101440
                    Iteration time: 1.86s
                      Time elapsed: 00:07:55
                               ETA: 00:42:44

################################################################################
                     [1m Learning iteration 235/1500 [0m                      

                       Computation: 54019 steps/s (collection: 1.728s, learning 0.092s)
             Mean action noise std: 1.56
          Mean value_function loss: 58.4243
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 33.4418
                       Mean reward: 240.94
               Mean episode length: 232.76
    Episode_Reward/reaching_object: 0.6554
    Episode_Reward/rotating_object: 44.6722
        Episode_Reward/action_rate: -0.0102
          Episode_Reward/joint_vel: -0.0094
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 23199744
                    Iteration time: 1.82s
                      Time elapsed: 00:07:57
                               ETA: 00:42:40

################################################################################
                     [1m Learning iteration 236/1500 [0m                      

                       Computation: 52652 steps/s (collection: 1.775s, learning 0.092s)
             Mean action noise std: 1.57
          Mean value_function loss: 58.5078
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 33.4561
                       Mean reward: 267.83
               Mean episode length: 239.58
    Episode_Reward/reaching_object: 0.6589
    Episode_Reward/rotating_object: 49.0959
        Episode_Reward/action_rate: -0.0104
          Episode_Reward/joint_vel: -0.0094
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 23298048
                    Iteration time: 1.87s
                      Time elapsed: 00:07:59
                               ETA: 00:42:38

################################################################################
                     [1m Learning iteration 237/1500 [0m                      

                       Computation: 53179 steps/s (collection: 1.758s, learning 0.091s)
             Mean action noise std: 1.57
          Mean value_function loss: 53.8401
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 33.4719
                       Mean reward: 249.40
               Mean episode length: 238.98
    Episode_Reward/reaching_object: 0.6698
    Episode_Reward/rotating_object: 49.0116
        Episode_Reward/action_rate: -0.0105
          Episode_Reward/joint_vel: -0.0098
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 23396352
                    Iteration time: 1.85s
                      Time elapsed: 00:08:01
                               ETA: 00:42:35

################################################################################
                     [1m Learning iteration 238/1500 [0m                      

                       Computation: 53963 steps/s (collection: 1.729s, learning 0.093s)
             Mean action noise std: 1.57
          Mean value_function loss: 58.1549
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 33.4917
                       Mean reward: 250.39
               Mean episode length: 242.66
    Episode_Reward/reaching_object: 0.6651
    Episode_Reward/rotating_object: 46.0973
        Episode_Reward/action_rate: -0.0105
          Episode_Reward/joint_vel: -0.0095
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 23494656
                    Iteration time: 1.82s
                      Time elapsed: 00:08:03
                               ETA: 00:42:32

################################################################################
                     [1m Learning iteration 239/1500 [0m                      

                       Computation: 53761 steps/s (collection: 1.737s, learning 0.091s)
             Mean action noise std: 1.57
          Mean value_function loss: 50.6256
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 33.5080
                       Mean reward: 219.14
               Mean episode length: 237.46
    Episode_Reward/reaching_object: 0.6812
    Episode_Reward/rotating_object: 46.3402
        Episode_Reward/action_rate: -0.0107
          Episode_Reward/joint_vel: -0.0099
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 23592960
                    Iteration time: 1.83s
                      Time elapsed: 00:08:05
                               ETA: 00:42:29

################################################################################
                     [1m Learning iteration 240/1500 [0m                      

                       Computation: 54215 steps/s (collection: 1.716s, learning 0.098s)
             Mean action noise std: 1.57
          Mean value_function loss: 63.5063
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 33.5218
                       Mean reward: 264.47
               Mean episode length: 246.71
    Episode_Reward/reaching_object: 0.6797
    Episode_Reward/rotating_object: 48.8265
        Episode_Reward/action_rate: -0.0108
          Episode_Reward/joint_vel: -0.0099
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 23691264
                    Iteration time: 1.81s
                      Time elapsed: 00:08:06
                               ETA: 00:42:25

################################################################################
                     [1m Learning iteration 241/1500 [0m                      

                       Computation: 54010 steps/s (collection: 1.708s, learning 0.113s)
             Mean action noise std: 1.57
          Mean value_function loss: 59.0391
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 33.5343
                       Mean reward: 258.81
               Mean episode length: 243.60
    Episode_Reward/reaching_object: 0.6722
    Episode_Reward/rotating_object: 50.6004
        Episode_Reward/action_rate: -0.0107
          Episode_Reward/joint_vel: -0.0098
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 23789568
                    Iteration time: 1.82s
                      Time elapsed: 00:08:08
                               ETA: 00:42:22

################################################################################
                     [1m Learning iteration 242/1500 [0m                      

                       Computation: 53589 steps/s (collection: 1.741s, learning 0.093s)
             Mean action noise std: 1.57
          Mean value_function loss: 61.1863
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 33.5494
                       Mean reward: 269.29
               Mean episode length: 241.12
    Episode_Reward/reaching_object: 0.6800
    Episode_Reward/rotating_object: 52.0250
        Episode_Reward/action_rate: -0.0109
          Episode_Reward/joint_vel: -0.0100
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 23887872
                    Iteration time: 1.83s
                      Time elapsed: 00:08:10
                               ETA: 00:42:19

################################################################################
                     [1m Learning iteration 243/1500 [0m                      

                       Computation: 53596 steps/s (collection: 1.730s, learning 0.104s)
             Mean action noise std: 1.57
          Mean value_function loss: 60.6423
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 33.5602
                       Mean reward: 274.68
               Mean episode length: 245.62
    Episode_Reward/reaching_object: 0.6705
    Episode_Reward/rotating_object: 52.4088
        Episode_Reward/action_rate: -0.0108
          Episode_Reward/joint_vel: -0.0097
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 23986176
                    Iteration time: 1.83s
                      Time elapsed: 00:08:12
                               ETA: 00:42:16

################################################################################
                     [1m Learning iteration 244/1500 [0m                      

                       Computation: 53906 steps/s (collection: 1.728s, learning 0.096s)
             Mean action noise std: 1.58
          Mean value_function loss: 65.1838
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 33.5705
                       Mean reward: 282.88
               Mean episode length: 244.87
    Episode_Reward/reaching_object: 0.6683
    Episode_Reward/rotating_object: 51.7982
        Episode_Reward/action_rate: -0.0109
          Episode_Reward/joint_vel: -0.0100
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 24084480
                    Iteration time: 1.82s
                      Time elapsed: 00:08:14
                               ETA: 00:42:13

################################################################################
                     [1m Learning iteration 245/1500 [0m                      

                       Computation: 53538 steps/s (collection: 1.738s, learning 0.098s)
             Mean action noise std: 1.58
          Mean value_function loss: 63.6501
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 33.5874
                       Mean reward: 252.08
               Mean episode length: 242.81
    Episode_Reward/reaching_object: 0.6680
    Episode_Reward/rotating_object: 51.3791
        Episode_Reward/action_rate: -0.0110
          Episode_Reward/joint_vel: -0.0101
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 24182784
                    Iteration time: 1.84s
                      Time elapsed: 00:08:16
                               ETA: 00:42:10

################################################################################
                     [1m Learning iteration 246/1500 [0m                      

                       Computation: 50944 steps/s (collection: 1.810s, learning 0.120s)
             Mean action noise std: 1.58
          Mean value_function loss: 70.0144
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 33.6093
                       Mean reward: 256.43
               Mean episode length: 241.57
    Episode_Reward/reaching_object: 0.6495
    Episode_Reward/rotating_object: 49.0342
        Episode_Reward/action_rate: -0.0108
          Episode_Reward/joint_vel: -0.0100
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 24281088
                    Iteration time: 1.93s
                      Time elapsed: 00:08:18
                               ETA: 00:42:08

################################################################################
                     [1m Learning iteration 247/1500 [0m                      

                       Computation: 52992 steps/s (collection: 1.729s, learning 0.126s)
             Mean action noise std: 1.58
          Mean value_function loss: 70.4788
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 33.6253
                       Mean reward: 261.53
               Mean episode length: 238.87
    Episode_Reward/reaching_object: 0.6674
    Episode_Reward/rotating_object: 54.6525
        Episode_Reward/action_rate: -0.0110
          Episode_Reward/joint_vel: -0.0103
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 24379392
                    Iteration time: 1.86s
                      Time elapsed: 00:08:19
                               ETA: 00:42:05

################################################################################
                     [1m Learning iteration 248/1500 [0m                      

                       Computation: 53904 steps/s (collection: 1.734s, learning 0.090s)
             Mean action noise std: 1.58
          Mean value_function loss: 63.9668
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 33.6338
                       Mean reward: 253.58
               Mean episode length: 238.76
    Episode_Reward/reaching_object: 0.6594
    Episode_Reward/rotating_object: 51.7114
        Episode_Reward/action_rate: -0.0110
          Episode_Reward/joint_vel: -0.0102
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 24477696
                    Iteration time: 1.82s
                      Time elapsed: 00:08:21
                               ETA: 00:42:02

################################################################################
                     [1m Learning iteration 249/1500 [0m                      

                       Computation: 53503 steps/s (collection: 1.745s, learning 0.093s)
             Mean action noise std: 1.58
          Mean value_function loss: 57.6026
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 33.6421
                       Mean reward: 293.70
               Mean episode length: 242.34
    Episode_Reward/reaching_object: 0.6687
    Episode_Reward/rotating_object: 59.5589
        Episode_Reward/action_rate: -0.0111
          Episode_Reward/joint_vel: -0.0100
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 24576000
                    Iteration time: 1.84s
                      Time elapsed: 00:08:23
                               ETA: 00:41:59

################################################################################
                     [1m Learning iteration 250/1500 [0m                      

                       Computation: 54641 steps/s (collection: 1.707s, learning 0.092s)
             Mean action noise std: 1.58
          Mean value_function loss: 55.6972
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 33.6518
                       Mean reward: 287.47
               Mean episode length: 238.94
    Episode_Reward/reaching_object: 0.6646
    Episode_Reward/rotating_object: 58.5829
        Episode_Reward/action_rate: -0.0111
          Episode_Reward/joint_vel: -0.0100
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 24674304
                    Iteration time: 1.80s
                      Time elapsed: 00:08:25
                               ETA: 00:41:56

################################################################################
                     [1m Learning iteration 251/1500 [0m                      

                       Computation: 52255 steps/s (collection: 1.772s, learning 0.109s)
             Mean action noise std: 1.58
          Mean value_function loss: 59.9240
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 33.6629
                       Mean reward: 300.83
               Mean episode length: 246.15
    Episode_Reward/reaching_object: 0.6703
    Episode_Reward/rotating_object: 59.3054
        Episode_Reward/action_rate: -0.0112
          Episode_Reward/joint_vel: -0.0099
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 24772608
                    Iteration time: 1.88s
                      Time elapsed: 00:08:27
                               ETA: 00:41:54

################################################################################
                     [1m Learning iteration 252/1500 [0m                      

                       Computation: 55515 steps/s (collection: 1.673s, learning 0.098s)
             Mean action noise std: 1.59
          Mean value_function loss: 54.6402
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 33.6764
                       Mean reward: 331.83
               Mean episode length: 247.65
    Episode_Reward/reaching_object: 0.6663
    Episode_Reward/rotating_object: 61.9585
        Episode_Reward/action_rate: -0.0113
          Episode_Reward/joint_vel: -0.0100
      Episode_Termination/time_out: 17.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 24870912
                    Iteration time: 1.77s
                      Time elapsed: 00:08:29
                               ETA: 00:41:50

################################################################################
                     [1m Learning iteration 253/1500 [0m                      

                       Computation: 53457 steps/s (collection: 1.736s, learning 0.103s)
             Mean action noise std: 1.59
          Mean value_function loss: 61.8796
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 33.6910
                       Mean reward: 306.59
               Mean episode length: 244.97
    Episode_Reward/reaching_object: 0.6474
    Episode_Reward/rotating_object: 59.4782
        Episode_Reward/action_rate: -0.0111
          Episode_Reward/joint_vel: -0.0098
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 24969216
                    Iteration time: 1.84s
                      Time elapsed: 00:08:30
                               ETA: 00:41:47

################################################################################
                     [1m Learning iteration 254/1500 [0m                      

                       Computation: 54218 steps/s (collection: 1.720s, learning 0.093s)
             Mean action noise std: 1.59
          Mean value_function loss: 60.9802
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 33.7082
                       Mean reward: 277.54
               Mean episode length: 243.52
    Episode_Reward/reaching_object: 0.6532
    Episode_Reward/rotating_object: 57.6918
        Episode_Reward/action_rate: -0.0112
          Episode_Reward/joint_vel: -0.0100
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 25067520
                    Iteration time: 1.81s
                      Time elapsed: 00:08:32
                               ETA: 00:41:44

################################################################################
                     [1m Learning iteration 255/1500 [0m                      

                       Computation: 54965 steps/s (collection: 1.698s, learning 0.090s)
             Mean action noise std: 1.59
          Mean value_function loss: 58.4903
               Mean surrogate loss: -0.0007
                 Mean entropy loss: 33.7228
                       Mean reward: 297.97
               Mean episode length: 241.28
    Episode_Reward/reaching_object: 0.6397
    Episode_Reward/rotating_object: 57.9504
        Episode_Reward/action_rate: -0.0111
          Episode_Reward/joint_vel: -0.0099
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 25165824
                    Iteration time: 1.79s
                      Time elapsed: 00:08:34
                               ETA: 00:41:41

################################################################################
                     [1m Learning iteration 256/1500 [0m                      

                       Computation: 52810 steps/s (collection: 1.759s, learning 0.103s)
             Mean action noise std: 1.59
          Mean value_function loss: 62.5291
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 33.7312
                       Mean reward: 268.30
               Mean episode length: 239.82
    Episode_Reward/reaching_object: 0.6358
    Episode_Reward/rotating_object: 57.4381
        Episode_Reward/action_rate: -0.0112
          Episode_Reward/joint_vel: -0.0103
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 25264128
                    Iteration time: 1.86s
                      Time elapsed: 00:08:36
                               ETA: 00:41:39

################################################################################
                     [1m Learning iteration 257/1500 [0m                      

                       Computation: 53706 steps/s (collection: 1.731s, learning 0.100s)
             Mean action noise std: 1.59
          Mean value_function loss: 73.3963
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 33.7433
                       Mean reward: 270.23
               Mean episode length: 234.83
    Episode_Reward/reaching_object: 0.6295
    Episode_Reward/rotating_object: 57.1751
        Episode_Reward/action_rate: -0.0110
          Episode_Reward/joint_vel: -0.0100
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 25362432
                    Iteration time: 1.83s
                      Time elapsed: 00:08:38
                               ETA: 00:41:36

################################################################################
                     [1m Learning iteration 258/1500 [0m                      

                       Computation: 54683 steps/s (collection: 1.708s, learning 0.090s)
             Mean action noise std: 1.59
          Mean value_function loss: 63.7758
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 33.7602
                       Mean reward: 275.80
               Mean episode length: 239.26
    Episode_Reward/reaching_object: 0.6502
    Episode_Reward/rotating_object: 54.7587
        Episode_Reward/action_rate: -0.0113
          Episode_Reward/joint_vel: -0.0104
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 25460736
                    Iteration time: 1.80s
                      Time elapsed: 00:08:39
                               ETA: 00:41:33

################################################################################
                     [1m Learning iteration 259/1500 [0m                      

                       Computation: 53980 steps/s (collection: 1.732s, learning 0.089s)
             Mean action noise std: 1.59
          Mean value_function loss: 67.3935
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 33.7747
                       Mean reward: 318.45
               Mean episode length: 245.40
    Episode_Reward/reaching_object: 0.6436
    Episode_Reward/rotating_object: 59.1839
        Episode_Reward/action_rate: -0.0112
          Episode_Reward/joint_vel: -0.0101
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 25559040
                    Iteration time: 1.82s
                      Time elapsed: 00:08:41
                               ETA: 00:41:30

################################################################################
                     [1m Learning iteration 260/1500 [0m                      

                       Computation: 44070 steps/s (collection: 2.057s, learning 0.173s)
             Mean action noise std: 1.60
          Mean value_function loss: 65.6318
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 33.7877
                       Mean reward: 277.59
               Mean episode length: 240.86
    Episode_Reward/reaching_object: 0.6527
    Episode_Reward/rotating_object: 59.8435
        Episode_Reward/action_rate: -0.0112
          Episode_Reward/joint_vel: -0.0101
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 25657344
                    Iteration time: 2.23s
                      Time elapsed: 00:08:43
                               ETA: 00:41:29

################################################################################
                     [1m Learning iteration 261/1500 [0m                      

                       Computation: 53338 steps/s (collection: 1.748s, learning 0.095s)
             Mean action noise std: 1.60
          Mean value_function loss: 71.0745
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 33.8000
                       Mean reward: 287.11
               Mean episode length: 240.70
    Episode_Reward/reaching_object: 0.6552
    Episode_Reward/rotating_object: 56.7350
        Episode_Reward/action_rate: -0.0113
          Episode_Reward/joint_vel: -0.0104
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 25755648
                    Iteration time: 1.84s
                      Time elapsed: 00:08:45
                               ETA: 00:41:26

################################################################################
                     [1m Learning iteration 262/1500 [0m                      

                       Computation: 52964 steps/s (collection: 1.748s, learning 0.108s)
             Mean action noise std: 1.60
          Mean value_function loss: 69.9475
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 33.8139
                       Mean reward: 333.50
               Mean episode length: 245.83
    Episode_Reward/reaching_object: 0.6500
    Episode_Reward/rotating_object: 61.1032
        Episode_Reward/action_rate: -0.0112
          Episode_Reward/joint_vel: -0.0103
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 25853952
                    Iteration time: 1.86s
                      Time elapsed: 00:08:47
                               ETA: 00:41:23

################################################################################
                     [1m Learning iteration 263/1500 [0m                      

                       Computation: 51976 steps/s (collection: 1.788s, learning 0.104s)
             Mean action noise std: 1.60
          Mean value_function loss: 77.8934
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 33.8272
                       Mean reward: 300.79
               Mean episode length: 246.05
    Episode_Reward/reaching_object: 0.6620
    Episode_Reward/rotating_object: 55.6113
        Episode_Reward/action_rate: -0.0114
          Episode_Reward/joint_vel: -0.0106
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 25952256
                    Iteration time: 1.89s
                      Time elapsed: 00:08:49
                               ETA: 00:41:21

################################################################################
                     [1m Learning iteration 264/1500 [0m                      

                       Computation: 51858 steps/s (collection: 1.791s, learning 0.105s)
             Mean action noise std: 1.60
          Mean value_function loss: 75.2427
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 33.8360
                       Mean reward: 343.21
               Mean episode length: 244.46
    Episode_Reward/reaching_object: 0.6644
    Episode_Reward/rotating_object: 62.8233
        Episode_Reward/action_rate: -0.0114
          Episode_Reward/joint_vel: -0.0104
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 26050560
                    Iteration time: 1.90s
                      Time elapsed: 00:08:51
                               ETA: 00:41:18

################################################################################
                     [1m Learning iteration 265/1500 [0m                      

                       Computation: 51363 steps/s (collection: 1.779s, learning 0.135s)
             Mean action noise std: 1.60
          Mean value_function loss: 75.3856
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 33.8455
                       Mean reward: 310.65
               Mean episode length: 241.83
    Episode_Reward/reaching_object: 0.6687
    Episode_Reward/rotating_object: 61.0943
        Episode_Reward/action_rate: -0.0114
          Episode_Reward/joint_vel: -0.0102
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 26148864
                    Iteration time: 1.91s
                      Time elapsed: 00:08:53
                               ETA: 00:41:16

################################################################################
                     [1m Learning iteration 266/1500 [0m                      

                       Computation: 52025 steps/s (collection: 1.781s, learning 0.108s)
             Mean action noise std: 1.60
          Mean value_function loss: 87.7992
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 33.8619
                       Mean reward: 314.93
               Mean episode length: 242.09
    Episode_Reward/reaching_object: 0.6501
    Episode_Reward/rotating_object: 60.3639
        Episode_Reward/action_rate: -0.0111
          Episode_Reward/joint_vel: -0.0103
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 26247168
                    Iteration time: 1.89s
                      Time elapsed: 00:08:55
                               ETA: 00:41:13

################################################################################
                     [1m Learning iteration 267/1500 [0m                      

                       Computation: 52741 steps/s (collection: 1.760s, learning 0.104s)
             Mean action noise std: 1.60
          Mean value_function loss: 83.8450
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 33.8790
                       Mean reward: 275.58
               Mean episode length: 240.74
    Episode_Reward/reaching_object: 0.6760
    Episode_Reward/rotating_object: 61.7297
        Episode_Reward/action_rate: -0.0115
          Episode_Reward/joint_vel: -0.0102
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 26345472
                    Iteration time: 1.86s
                      Time elapsed: 00:08:57
                               ETA: 00:41:11

################################################################################
                     [1m Learning iteration 268/1500 [0m                      

                       Computation: 47607 steps/s (collection: 1.933s, learning 0.132s)
             Mean action noise std: 1.61
          Mean value_function loss: 75.9935
               Mean surrogate loss: -0.0001
                 Mean entropy loss: 33.8931
                       Mean reward: 324.87
               Mean episode length: 246.93
    Episode_Reward/reaching_object: 0.6767
    Episode_Reward/rotating_object: 65.9242
        Episode_Reward/action_rate: -0.0116
          Episode_Reward/joint_vel: -0.0106
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 26443776
                    Iteration time: 2.06s
                      Time elapsed: 00:08:59
                               ETA: 00:41:09

################################################################################
                     [1m Learning iteration 269/1500 [0m                      

                       Computation: 50962 steps/s (collection: 1.826s, learning 0.103s)
             Mean action noise std: 1.61
          Mean value_function loss: 84.9669
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 33.9068
                       Mean reward: 343.23
               Mean episode length: 248.62
    Episode_Reward/reaching_object: 0.6729
    Episode_Reward/rotating_object: 64.5293
        Episode_Reward/action_rate: -0.0116
          Episode_Reward/joint_vel: -0.0106
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 26542080
                    Iteration time: 1.93s
                      Time elapsed: 00:09:01
                               ETA: 00:41:07

################################################################################
                     [1m Learning iteration 270/1500 [0m                      

                       Computation: 47614 steps/s (collection: 1.884s, learning 0.181s)
             Mean action noise std: 1.61
          Mean value_function loss: 86.4595
               Mean surrogate loss: -0.0001
                 Mean entropy loss: 33.9210
                       Mean reward: 327.37
               Mean episode length: 242.90
    Episode_Reward/reaching_object: 0.6657
    Episode_Reward/rotating_object: 63.8110
        Episode_Reward/action_rate: -0.0116
          Episode_Reward/joint_vel: -0.0108
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 26640384
                    Iteration time: 2.06s
                      Time elapsed: 00:09:03
                               ETA: 00:41:05

################################################################################
                     [1m Learning iteration 271/1500 [0m                      

                       Computation: 52266 steps/s (collection: 1.785s, learning 0.096s)
             Mean action noise std: 1.61
          Mean value_function loss: 82.2270
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 33.9318
                       Mean reward: 278.18
               Mean episode length: 239.65
    Episode_Reward/reaching_object: 0.6624
    Episode_Reward/rotating_object: 61.3168
        Episode_Reward/action_rate: -0.0117
          Episode_Reward/joint_vel: -0.0107
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 26738688
                    Iteration time: 1.88s
                      Time elapsed: 00:09:05
                               ETA: 00:41:02

################################################################################
                     [1m Learning iteration 272/1500 [0m                      

                       Computation: 51451 steps/s (collection: 1.812s, learning 0.099s)
             Mean action noise std: 1.61
          Mean value_function loss: 93.0596
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 33.9444
                       Mean reward: 357.60
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6761
    Episode_Reward/rotating_object: 66.0278
        Episode_Reward/action_rate: -0.0117
          Episode_Reward/joint_vel: -0.0107
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 26836992
                    Iteration time: 1.91s
                      Time elapsed: 00:09:06
                               ETA: 00:41:00

################################################################################
                     [1m Learning iteration 273/1500 [0m                      

                       Computation: 52227 steps/s (collection: 1.787s, learning 0.095s)
             Mean action noise std: 1.61
          Mean value_function loss: 84.3868
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 33.9577
                       Mean reward: 340.56
               Mean episode length: 243.64
    Episode_Reward/reaching_object: 0.6777
    Episode_Reward/rotating_object: 69.3223
        Episode_Reward/action_rate: -0.0117
          Episode_Reward/joint_vel: -0.0106
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 26935296
                    Iteration time: 1.88s
                      Time elapsed: 00:09:08
                               ETA: 00:40:57

################################################################################
                     [1m Learning iteration 274/1500 [0m                      

                       Computation: 51430 steps/s (collection: 1.813s, learning 0.099s)
             Mean action noise std: 1.61
          Mean value_function loss: 72.9108
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 33.9652
                       Mean reward: 331.87
               Mean episode length: 245.59
    Episode_Reward/reaching_object: 0.6569
    Episode_Reward/rotating_object: 61.3538
        Episode_Reward/action_rate: -0.0117
          Episode_Reward/joint_vel: -0.0111
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 27033600
                    Iteration time: 1.91s
                      Time elapsed: 00:09:10
                               ETA: 00:40:55

################################################################################
                     [1m Learning iteration 275/1500 [0m                      

                       Computation: 48414 steps/s (collection: 1.846s, learning 0.185s)
             Mean action noise std: 1.61
          Mean value_function loss: 77.6430
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 33.9724
                       Mean reward: 370.19
               Mean episode length: 246.85
    Episode_Reward/reaching_object: 0.6648
    Episode_Reward/rotating_object: 71.3997
        Episode_Reward/action_rate: -0.0117
          Episode_Reward/joint_vel: -0.0105
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 27131904
                    Iteration time: 2.03s
                      Time elapsed: 00:09:12
                               ETA: 00:40:53

################################################################################
                     [1m Learning iteration 276/1500 [0m                      

                       Computation: 49381 steps/s (collection: 1.886s, learning 0.105s)
             Mean action noise std: 1.61
          Mean value_function loss: 74.4117
               Mean surrogate loss: 0.0008
                 Mean entropy loss: 33.9798
                       Mean reward: 347.00
               Mean episode length: 246.94
    Episode_Reward/reaching_object: 0.6834
    Episode_Reward/rotating_object: 69.1629
        Episode_Reward/action_rate: -0.0119
          Episode_Reward/joint_vel: -0.0106
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 27230208
                    Iteration time: 1.99s
                      Time elapsed: 00:09:14
                               ETA: 00:40:51

################################################################################
                     [1m Learning iteration 277/1500 [0m                      

                       Computation: 51678 steps/s (collection: 1.807s, learning 0.095s)
             Mean action noise std: 1.61
          Mean value_function loss: 87.8857
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 33.9848
                       Mean reward: 354.69
               Mean episode length: 238.73
    Episode_Reward/reaching_object: 0.6628
    Episode_Reward/rotating_object: 70.4549
        Episode_Reward/action_rate: -0.0117
          Episode_Reward/joint_vel: -0.0103
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 27328512
                    Iteration time: 1.90s
                      Time elapsed: 00:09:16
                               ETA: 00:40:49

################################################################################
                     [1m Learning iteration 278/1500 [0m                      

                       Computation: 51462 steps/s (collection: 1.814s, learning 0.097s)
             Mean action noise std: 1.62
          Mean value_function loss: 77.2188
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 33.9921
                       Mean reward: 346.41
               Mean episode length: 244.25
    Episode_Reward/reaching_object: 0.6666
    Episode_Reward/rotating_object: 70.7234
        Episode_Reward/action_rate: -0.0117
          Episode_Reward/joint_vel: -0.0107
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 27426816
                    Iteration time: 1.91s
                      Time elapsed: 00:09:18
                               ETA: 00:40:46

################################################################################
                     [1m Learning iteration 279/1500 [0m                      

                       Computation: 52588 steps/s (collection: 1.736s, learning 0.134s)
             Mean action noise std: 1.62
          Mean value_function loss: 80.8684
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 34.0024
                       Mean reward: 370.75
               Mean episode length: 248.24
    Episode_Reward/reaching_object: 0.6562
    Episode_Reward/rotating_object: 69.0494
        Episode_Reward/action_rate: -0.0119
          Episode_Reward/joint_vel: -0.0107
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 27525120
                    Iteration time: 1.87s
                      Time elapsed: 00:09:20
                               ETA: 00:40:44

################################################################################
                     [1m Learning iteration 280/1500 [0m                      

                       Computation: 52346 steps/s (collection: 1.732s, learning 0.146s)
             Mean action noise std: 1.62
          Mean value_function loss: 79.2891
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 34.0146
                       Mean reward: 359.21
               Mean episode length: 248.94
    Episode_Reward/reaching_object: 0.6748
    Episode_Reward/rotating_object: 70.5764
        Episode_Reward/action_rate: -0.0119
          Episode_Reward/joint_vel: -0.0110
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 27623424
                    Iteration time: 1.88s
                      Time elapsed: 00:09:22
                               ETA: 00:40:41

################################################################################
                     [1m Learning iteration 281/1500 [0m                      

                       Computation: 50154 steps/s (collection: 1.830s, learning 0.130s)
             Mean action noise std: 1.62
          Mean value_function loss: 84.1014
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 34.0237
                       Mean reward: 342.50
               Mean episode length: 248.41
    Episode_Reward/reaching_object: 0.6535
    Episode_Reward/rotating_object: 70.9960
        Episode_Reward/action_rate: -0.0120
          Episode_Reward/joint_vel: -0.0106
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 27721728
                    Iteration time: 1.96s
                      Time elapsed: 00:09:24
                               ETA: 00:40:39

################################################################################
                     [1m Learning iteration 282/1500 [0m                      

                       Computation: 52651 steps/s (collection: 1.762s, learning 0.105s)
             Mean action noise std: 1.62
          Mean value_function loss: 85.9663
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 34.0344
                       Mean reward: 362.53
               Mean episode length: 243.83
    Episode_Reward/reaching_object: 0.6435
    Episode_Reward/rotating_object: 69.0796
        Episode_Reward/action_rate: -0.0119
          Episode_Reward/joint_vel: -0.0106
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 27820032
                    Iteration time: 1.87s
                      Time elapsed: 00:09:26
                               ETA: 00:40:36

################################################################################
                     [1m Learning iteration 283/1500 [0m                      

                       Computation: 48989 steps/s (collection: 1.821s, learning 0.186s)
             Mean action noise std: 1.62
          Mean value_function loss: 77.7794
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 34.0442
                       Mean reward: 355.78
               Mean episode length: 241.25
    Episode_Reward/reaching_object: 0.6572
    Episode_Reward/rotating_object: 74.6111
        Episode_Reward/action_rate: -0.0120
          Episode_Reward/joint_vel: -0.0107
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 27918336
                    Iteration time: 2.01s
                      Time elapsed: 00:09:28
                               ETA: 00:40:34

################################################################################
                     [1m Learning iteration 284/1500 [0m                      

                       Computation: 51738 steps/s (collection: 1.804s, learning 0.096s)
             Mean action noise std: 1.62
          Mean value_function loss: 76.3859
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 34.0563
                       Mean reward: 370.04
               Mean episode length: 243.39
    Episode_Reward/reaching_object: 0.6489
    Episode_Reward/rotating_object: 70.4740
        Episode_Reward/action_rate: -0.0120
          Episode_Reward/joint_vel: -0.0105
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 28016640
                    Iteration time: 1.90s
                      Time elapsed: 00:09:30
                               ETA: 00:40:32

################################################################################
                     [1m Learning iteration 285/1500 [0m                      

                       Computation: 52520 steps/s (collection: 1.760s, learning 0.112s)
             Mean action noise std: 1.62
          Mean value_function loss: 68.1352
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 34.0718
                       Mean reward: 404.60
               Mean episode length: 244.18
    Episode_Reward/reaching_object: 0.6377
    Episode_Reward/rotating_object: 74.3026
        Episode_Reward/action_rate: -0.0120
          Episode_Reward/joint_vel: -0.0107
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 28114944
                    Iteration time: 1.87s
                      Time elapsed: 00:09:31
                               ETA: 00:40:29

################################################################################
                     [1m Learning iteration 286/1500 [0m                      

                       Computation: 53294 steps/s (collection: 1.752s, learning 0.093s)
             Mean action noise std: 1.62
          Mean value_function loss: 71.1131
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 34.0844
                       Mean reward: 377.74
               Mean episode length: 244.33
    Episode_Reward/reaching_object: 0.6471
    Episode_Reward/rotating_object: 75.9203
        Episode_Reward/action_rate: -0.0121
          Episode_Reward/joint_vel: -0.0108
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 28213248
                    Iteration time: 1.84s
                      Time elapsed: 00:09:33
                               ETA: 00:40:27

################################################################################
                     [1m Learning iteration 287/1500 [0m                      

                       Computation: 52202 steps/s (collection: 1.772s, learning 0.112s)
             Mean action noise std: 1.63
          Mean value_function loss: 82.3908
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 34.0961
                       Mean reward: 392.70
               Mean episode length: 244.50
    Episode_Reward/reaching_object: 0.6390
    Episode_Reward/rotating_object: 76.7068
        Episode_Reward/action_rate: -0.0121
          Episode_Reward/joint_vel: -0.0108
      Episode_Termination/time_out: 17.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 28311552
                    Iteration time: 1.88s
                      Time elapsed: 00:09:35
                               ETA: 00:40:24

################################################################################
                     [1m Learning iteration 288/1500 [0m                      

                       Computation: 51946 steps/s (collection: 1.774s, learning 0.119s)
             Mean action noise std: 1.63
          Mean value_function loss: 63.4912
               Mean surrogate loss: 0.0022
                 Mean entropy loss: 34.1040
                       Mean reward: 361.96
               Mean episode length: 247.74
    Episode_Reward/reaching_object: 0.6358
    Episode_Reward/rotating_object: 74.1744
        Episode_Reward/action_rate: -0.0123
          Episode_Reward/joint_vel: -0.0106
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 28409856
                    Iteration time: 1.89s
                      Time elapsed: 00:09:37
                               ETA: 00:40:22

################################################################################
                     [1m Learning iteration 289/1500 [0m                      

                       Computation: 52519 steps/s (collection: 1.761s, learning 0.111s)
             Mean action noise std: 1.63
          Mean value_function loss: 73.0269
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 34.1076
                       Mean reward: 350.03
               Mean episode length: 248.54
    Episode_Reward/reaching_object: 0.6290
    Episode_Reward/rotating_object: 71.9745
        Episode_Reward/action_rate: -0.0123
          Episode_Reward/joint_vel: -0.0109
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 28508160
                    Iteration time: 1.87s
                      Time elapsed: 00:09:39
                               ETA: 00:40:19

################################################################################
                     [1m Learning iteration 290/1500 [0m                      

                       Computation: 52689 steps/s (collection: 1.755s, learning 0.111s)
             Mean action noise std: 1.63
          Mean value_function loss: 74.7087
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 34.1144
                       Mean reward: 390.09
               Mean episode length: 248.08
    Episode_Reward/reaching_object: 0.6082
    Episode_Reward/rotating_object: 71.9874
        Episode_Reward/action_rate: -0.0122
          Episode_Reward/joint_vel: -0.0103
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 28606464
                    Iteration time: 1.87s
                      Time elapsed: 00:09:41
                               ETA: 00:40:17

################################################################################
                     [1m Learning iteration 291/1500 [0m                      

                       Computation: 50165 steps/s (collection: 1.836s, learning 0.124s)
             Mean action noise std: 1.63
          Mean value_function loss: 70.9722
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 34.1251
                       Mean reward: 389.85
               Mean episode length: 244.71
    Episode_Reward/reaching_object: 0.6175
    Episode_Reward/rotating_object: 71.7141
        Episode_Reward/action_rate: -0.0123
          Episode_Reward/joint_vel: -0.0105
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 28704768
                    Iteration time: 1.96s
                      Time elapsed: 00:09:43
                               ETA: 00:40:15

################################################################################
                     [1m Learning iteration 292/1500 [0m                      

                       Computation: 50959 steps/s (collection: 1.830s, learning 0.099s)
             Mean action noise std: 1.63
          Mean value_function loss: 80.4367
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 34.1375
                       Mean reward: 383.30
               Mean episode length: 240.78
    Episode_Reward/reaching_object: 0.6187
    Episode_Reward/rotating_object: 72.6885
        Episode_Reward/action_rate: -0.0122
          Episode_Reward/joint_vel: -0.0105
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 28803072
                    Iteration time: 1.93s
                      Time elapsed: 00:09:45
                               ETA: 00:40:12

################################################################################
                     [1m Learning iteration 293/1500 [0m                      

                       Computation: 50361 steps/s (collection: 1.826s, learning 0.126s)
             Mean action noise std: 1.63
          Mean value_function loss: 77.9093
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 34.1520
                       Mean reward: 375.40
               Mean episode length: 248.58
    Episode_Reward/reaching_object: 0.6335
    Episode_Reward/rotating_object: 72.3534
        Episode_Reward/action_rate: -0.0124
          Episode_Reward/joint_vel: -0.0106
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 28901376
                    Iteration time: 1.95s
                      Time elapsed: 00:09:47
                               ETA: 00:40:10

################################################################################
                     [1m Learning iteration 294/1500 [0m                      

                       Computation: 51648 steps/s (collection: 1.800s, learning 0.104s)
             Mean action noise std: 1.63
          Mean value_function loss: 81.6593
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 34.1650
                       Mean reward: 384.52
               Mean episode length: 249.52
    Episode_Reward/reaching_object: 0.6413
    Episode_Reward/rotating_object: 75.6663
        Episode_Reward/action_rate: -0.0124
          Episode_Reward/joint_vel: -0.0103
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 28999680
                    Iteration time: 1.90s
                      Time elapsed: 00:09:49
                               ETA: 00:40:08

################################################################################
                     [1m Learning iteration 295/1500 [0m                      

                       Computation: 52030 steps/s (collection: 1.775s, learning 0.114s)
             Mean action noise std: 1.63
          Mean value_function loss: 94.3398
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 34.1752
                       Mean reward: 377.06
               Mean episode length: 246.15
    Episode_Reward/reaching_object: 0.6278
    Episode_Reward/rotating_object: 71.4356
        Episode_Reward/action_rate: -0.0123
          Episode_Reward/joint_vel: -0.0103
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6667
--------------------------------------------------------------------------------
                   Total timesteps: 29097984
                    Iteration time: 1.89s
                      Time elapsed: 00:09:50
                               ETA: 00:40:05

################################################################################
                     [1m Learning iteration 296/1500 [0m                      

                       Computation: 52621 steps/s (collection: 1.771s, learning 0.097s)
             Mean action noise std: 1.63
          Mean value_function loss: 81.7978
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 34.1858
                       Mean reward: 380.75
               Mean episode length: 247.12
    Episode_Reward/reaching_object: 0.6524
    Episode_Reward/rotating_object: 76.5261
        Episode_Reward/action_rate: -0.0124
          Episode_Reward/joint_vel: -0.0104
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 29196288
                    Iteration time: 1.87s
                      Time elapsed: 00:09:52
                               ETA: 00:40:03

################################################################################
                     [1m Learning iteration 297/1500 [0m                      

                       Computation: 52540 steps/s (collection: 1.766s, learning 0.105s)
             Mean action noise std: 1.64
          Mean value_function loss: 83.9775
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 34.1969
                       Mean reward: 399.60
               Mean episode length: 241.64
    Episode_Reward/reaching_object: 0.6574
    Episode_Reward/rotating_object: 79.8679
        Episode_Reward/action_rate: -0.0124
          Episode_Reward/joint_vel: -0.0104
      Episode_Termination/time_out: 17.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 29294592
                    Iteration time: 1.87s
                      Time elapsed: 00:09:54
                               ETA: 00:40:00

################################################################################
                     [1m Learning iteration 298/1500 [0m                      

                       Computation: 52442 steps/s (collection: 1.765s, learning 0.109s)
             Mean action noise std: 1.64
          Mean value_function loss: 66.5428
               Mean surrogate loss: 0.0002
                 Mean entropy loss: 34.2086
                       Mean reward: 378.81
               Mean episode length: 244.17
    Episode_Reward/reaching_object: 0.6521
    Episode_Reward/rotating_object: 78.7472
        Episode_Reward/action_rate: -0.0125
          Episode_Reward/joint_vel: -0.0105
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 29392896
                    Iteration time: 1.87s
                      Time elapsed: 00:09:56
                               ETA: 00:39:58

################################################################################
                     [1m Learning iteration 299/1500 [0m                      

                       Computation: 48777 steps/s (collection: 1.844s, learning 0.171s)
             Mean action noise std: 1.64
          Mean value_function loss: 70.1272
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 34.2194
                       Mean reward: 392.44
               Mean episode length: 247.62
    Episode_Reward/reaching_object: 0.6584
    Episode_Reward/rotating_object: 78.0994
        Episode_Reward/action_rate: -0.0124
          Episode_Reward/joint_vel: -0.0105
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 29491200
                    Iteration time: 2.02s
                      Time elapsed: 00:09:58
                               ETA: 00:39:56

################################################################################
                     [1m Learning iteration 300/1500 [0m                      

                       Computation: 48711 steps/s (collection: 1.844s, learning 0.174s)
             Mean action noise std: 1.64
          Mean value_function loss: 68.7783
               Mean surrogate loss: -0.0001
                 Mean entropy loss: 34.2259
                       Mean reward: 427.74
               Mean episode length: 247.70
    Episode_Reward/reaching_object: 0.6488
    Episode_Reward/rotating_object: 83.9795
        Episode_Reward/action_rate: -0.0125
          Episode_Reward/joint_vel: -0.0101
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 29589504
                    Iteration time: 2.02s
                      Time elapsed: 00:10:00
                               ETA: 00:39:54

################################################################################
                     [1m Learning iteration 301/1500 [0m                      

                       Computation: 49904 steps/s (collection: 1.815s, learning 0.155s)
             Mean action noise std: 1.64
          Mean value_function loss: 77.8818
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 34.2313
                       Mean reward: 406.75
               Mean episode length: 240.18
    Episode_Reward/reaching_object: 0.6354
    Episode_Reward/rotating_object: 75.6964
        Episode_Reward/action_rate: -0.0124
          Episode_Reward/joint_vel: -0.0102
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 29687808
                    Iteration time: 1.97s
                      Time elapsed: 00:10:02
                               ETA: 00:39:52

################################################################################
                     [1m Learning iteration 302/1500 [0m                      

                       Computation: 51937 steps/s (collection: 1.781s, learning 0.112s)
             Mean action noise std: 1.64
          Mean value_function loss: 83.2626
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 34.2397
                       Mean reward: 424.14
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6468
    Episode_Reward/rotating_object: 79.8317
        Episode_Reward/action_rate: -0.0125
          Episode_Reward/joint_vel: -0.0104
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 29786112
                    Iteration time: 1.89s
                      Time elapsed: 00:10:04
                               ETA: 00:39:49

################################################################################
                     [1m Learning iteration 303/1500 [0m                      

                       Computation: 53297 steps/s (collection: 1.712s, learning 0.132s)
             Mean action noise std: 1.64
          Mean value_function loss: 77.6663
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 34.2477
                       Mean reward: 384.18
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6440
    Episode_Reward/rotating_object: 79.5609
        Episode_Reward/action_rate: -0.0125
          Episode_Reward/joint_vel: -0.0101
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 29884416
                    Iteration time: 1.84s
                      Time elapsed: 00:10:06
                               ETA: 00:39:47

################################################################################
                     [1m Learning iteration 304/1500 [0m                      

                       Computation: 53055 steps/s (collection: 1.735s, learning 0.118s)
             Mean action noise std: 1.64
          Mean value_function loss: 85.6049
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 34.2524
                       Mean reward: 409.72
               Mean episode length: 243.17
    Episode_Reward/reaching_object: 0.6408
    Episode_Reward/rotating_object: 78.0172
        Episode_Reward/action_rate: -0.0125
          Episode_Reward/joint_vel: -0.0101
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 29982720
                    Iteration time: 1.85s
                      Time elapsed: 00:10:08
                               ETA: 00:39:44

################################################################################
                     [1m Learning iteration 305/1500 [0m                      

                       Computation: 49933 steps/s (collection: 1.848s, learning 0.121s)
             Mean action noise std: 1.64
          Mean value_function loss: 86.8447
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 34.2571
                       Mean reward: 428.25
               Mean episode length: 246.93
    Episode_Reward/reaching_object: 0.6418
    Episode_Reward/rotating_object: 83.6082
        Episode_Reward/action_rate: -0.0125
          Episode_Reward/joint_vel: -0.0103
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 30081024
                    Iteration time: 1.97s
                      Time elapsed: 00:10:10
                               ETA: 00:39:42

################################################################################
                     [1m Learning iteration 306/1500 [0m                      

                       Computation: 52749 steps/s (collection: 1.758s, learning 0.106s)
             Mean action noise std: 1.64
          Mean value_function loss: 81.6329
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 34.2631
                       Mean reward: 434.50
               Mean episode length: 246.77
    Episode_Reward/reaching_object: 0.6575
    Episode_Reward/rotating_object: 84.1469
        Episode_Reward/action_rate: -0.0126
          Episode_Reward/joint_vel: -0.0104
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 30179328
                    Iteration time: 1.86s
                      Time elapsed: 00:10:11
                               ETA: 00:39:40

################################################################################
                     [1m Learning iteration 307/1500 [0m                      

                       Computation: 51479 steps/s (collection: 1.804s, learning 0.106s)
             Mean action noise std: 1.64
          Mean value_function loss: 75.5780
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 34.2716
                       Mean reward: 409.19
               Mean episode length: 243.87
    Episode_Reward/reaching_object: 0.6494
    Episode_Reward/rotating_object: 83.0136
        Episode_Reward/action_rate: -0.0126
          Episode_Reward/joint_vel: -0.0102
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 30277632
                    Iteration time: 1.91s
                      Time elapsed: 00:10:13
                               ETA: 00:39:37

################################################################################
                     [1m Learning iteration 308/1500 [0m                      

                       Computation: 51217 steps/s (collection: 1.820s, learning 0.099s)
             Mean action noise std: 1.64
          Mean value_function loss: 79.8044
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 34.2794
                       Mean reward: 427.09
               Mean episode length: 247.30
    Episode_Reward/reaching_object: 0.6526
    Episode_Reward/rotating_object: 82.6648
        Episode_Reward/action_rate: -0.0126
          Episode_Reward/joint_vel: -0.0103
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 30375936
                    Iteration time: 1.92s
                      Time elapsed: 00:10:15
                               ETA: 00:39:35

################################################################################
                     [1m Learning iteration 309/1500 [0m                      

                       Computation: 49090 steps/s (collection: 1.834s, learning 0.169s)
             Mean action noise std: 1.64
          Mean value_function loss: 76.4564
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 34.2861
                       Mean reward: 449.23
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6648
    Episode_Reward/rotating_object: 84.4877
        Episode_Reward/action_rate: -0.0128
          Episode_Reward/joint_vel: -0.0104
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 30474240
                    Iteration time: 2.00s
                      Time elapsed: 00:10:17
                               ETA: 00:39:33

################################################################################
                     [1m Learning iteration 310/1500 [0m                      

                       Computation: 49043 steps/s (collection: 1.835s, learning 0.170s)
             Mean action noise std: 1.64
          Mean value_function loss: 72.6298
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 34.2956
                       Mean reward: 411.07
               Mean episode length: 246.76
    Episode_Reward/reaching_object: 0.6475
    Episode_Reward/rotating_object: 85.6911
        Episode_Reward/action_rate: -0.0128
          Episode_Reward/joint_vel: -0.0102
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 30572544
                    Iteration time: 2.00s
                      Time elapsed: 00:10:19
                               ETA: 00:39:31

################################################################################
                     [1m Learning iteration 311/1500 [0m                      

                       Computation: 51178 steps/s (collection: 1.822s, learning 0.099s)
             Mean action noise std: 1.65
          Mean value_function loss: 75.3581
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 34.3047
                       Mean reward: 432.00
               Mean episode length: 246.85
    Episode_Reward/reaching_object: 0.6490
    Episode_Reward/rotating_object: 88.7458
        Episode_Reward/action_rate: -0.0128
          Episode_Reward/joint_vel: -0.0103
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 30670848
                    Iteration time: 1.92s
                      Time elapsed: 00:10:21
                               ETA: 00:39:29

################################################################################
                     [1m Learning iteration 312/1500 [0m                      

                       Computation: 51852 steps/s (collection: 1.768s, learning 0.128s)
             Mean action noise std: 1.65
          Mean value_function loss: 71.9688
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 34.3087
                       Mean reward: 431.60
               Mean episode length: 245.31
    Episode_Reward/reaching_object: 0.6454
    Episode_Reward/rotating_object: 86.7728
        Episode_Reward/action_rate: -0.0128
          Episode_Reward/joint_vel: -0.0102
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 30769152
                    Iteration time: 1.90s
                      Time elapsed: 00:10:23
                               ETA: 00:39:27

################################################################################
                     [1m Learning iteration 313/1500 [0m                      

                       Computation: 50941 steps/s (collection: 1.750s, learning 0.180s)
             Mean action noise std: 1.65
          Mean value_function loss: 78.4067
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 34.3099
                       Mean reward: 418.62
               Mean episode length: 249.36
    Episode_Reward/reaching_object: 0.6585
    Episode_Reward/rotating_object: 87.2313
        Episode_Reward/action_rate: -0.0130
          Episode_Reward/joint_vel: -0.0106
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 30867456
                    Iteration time: 1.93s
                      Time elapsed: 00:10:25
                               ETA: 00:39:24

################################################################################
                     [1m Learning iteration 314/1500 [0m                      

                       Computation: 51627 steps/s (collection: 1.760s, learning 0.144s)
             Mean action noise std: 1.65
          Mean value_function loss: 71.3095
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 34.3112
                       Mean reward: 469.71
               Mean episode length: 245.81
    Episode_Reward/reaching_object: 0.6392
    Episode_Reward/rotating_object: 87.8395
        Episode_Reward/action_rate: -0.0130
          Episode_Reward/joint_vel: -0.0104
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 30965760
                    Iteration time: 1.90s
                      Time elapsed: 00:10:27
                               ETA: 00:39:22

################################################################################
                     [1m Learning iteration 315/1500 [0m                      

                       Computation: 53019 steps/s (collection: 1.737s, learning 0.117s)
             Mean action noise std: 1.65
          Mean value_function loss: 64.8617
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 34.3147
                       Mean reward: 472.81
               Mean episode length: 247.80
    Episode_Reward/reaching_object: 0.6405
    Episode_Reward/rotating_object: 87.7636
        Episode_Reward/action_rate: -0.0129
          Episode_Reward/joint_vel: -0.0102
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 31064064
                    Iteration time: 1.85s
                      Time elapsed: 00:10:29
                               ETA: 00:39:20

################################################################################
                     [1m Learning iteration 316/1500 [0m                      

                       Computation: 53865 steps/s (collection: 1.730s, learning 0.095s)
             Mean action noise std: 1.65
          Mean value_function loss: 68.6355
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 34.3221
                       Mean reward: 465.22
               Mean episode length: 249.24
    Episode_Reward/reaching_object: 0.6371
    Episode_Reward/rotating_object: 87.5815
        Episode_Reward/action_rate: -0.0130
          Episode_Reward/joint_vel: -0.0104
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 31162368
                    Iteration time: 1.83s
                      Time elapsed: 00:10:31
                               ETA: 00:39:17

################################################################################
                     [1m Learning iteration 317/1500 [0m                      

                       Computation: 54456 steps/s (collection: 1.707s, learning 0.098s)
             Mean action noise std: 1.65
          Mean value_function loss: 63.8264
               Mean surrogate loss: 0.0007
                 Mean entropy loss: 34.3296
                       Mean reward: 469.23
               Mean episode length: 247.98
    Episode_Reward/reaching_object: 0.6438
    Episode_Reward/rotating_object: 92.9657
        Episode_Reward/action_rate: -0.0131
          Episode_Reward/joint_vel: -0.0106
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 31260672
                    Iteration time: 1.81s
                      Time elapsed: 00:10:32
                               ETA: 00:39:14

################################################################################
                     [1m Learning iteration 318/1500 [0m                      

                       Computation: 53999 steps/s (collection: 1.716s, learning 0.104s)
             Mean action noise std: 1.65
          Mean value_function loss: 65.3678
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 34.3328
                       Mean reward: 453.64
               Mean episode length: 248.84
    Episode_Reward/reaching_object: 0.6375
    Episode_Reward/rotating_object: 87.6955
        Episode_Reward/action_rate: -0.0131
          Episode_Reward/joint_vel: -0.0105
      Episode_Termination/time_out: 18.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 31358976
                    Iteration time: 1.82s
                      Time elapsed: 00:10:34
                               ETA: 00:39:12

################################################################################
                     [1m Learning iteration 319/1500 [0m                      

                       Computation: 53402 steps/s (collection: 1.711s, learning 0.130s)
             Mean action noise std: 1.65
          Mean value_function loss: 72.8435
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 34.3373
                       Mean reward: 466.84
               Mean episode length: 247.05
    Episode_Reward/reaching_object: 0.6273
    Episode_Reward/rotating_object: 90.7971
        Episode_Reward/action_rate: -0.0130
          Episode_Reward/joint_vel: -0.0103
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 31457280
                    Iteration time: 1.84s
                      Time elapsed: 00:10:36
                               ETA: 00:39:09

################################################################################
                     [1m Learning iteration 320/1500 [0m                      

                       Computation: 52359 steps/s (collection: 1.727s, learning 0.151s)
             Mean action noise std: 1.65
          Mean value_function loss: 65.0495
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 34.3416
                       Mean reward: 442.33
               Mean episode length: 245.62
    Episode_Reward/reaching_object: 0.6460
    Episode_Reward/rotating_object: 92.6146
        Episode_Reward/action_rate: -0.0132
          Episode_Reward/joint_vel: -0.0105
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 31555584
                    Iteration time: 1.88s
                      Time elapsed: 00:10:38
                               ETA: 00:39:07

################################################################################
                     [1m Learning iteration 321/1500 [0m                      

                       Computation: 53068 steps/s (collection: 1.721s, learning 0.132s)
             Mean action noise std: 1.65
          Mean value_function loss: 74.3638
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 34.3458
                       Mean reward: 412.46
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6330
    Episode_Reward/rotating_object: 88.9190
        Episode_Reward/action_rate: -0.0132
          Episode_Reward/joint_vel: -0.0105
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 31653888
                    Iteration time: 1.85s
                      Time elapsed: 00:10:40
                               ETA: 00:39:04

################################################################################
                     [1m Learning iteration 322/1500 [0m                      

                       Computation: 52617 steps/s (collection: 1.754s, learning 0.114s)
             Mean action noise std: 1.65
          Mean value_function loss: 79.2655
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 34.3485
                       Mean reward: 450.05
               Mean episode length: 246.30
    Episode_Reward/reaching_object: 0.6409
    Episode_Reward/rotating_object: 91.7888
        Episode_Reward/action_rate: -0.0132
          Episode_Reward/joint_vel: -0.0105
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 31752192
                    Iteration time: 1.87s
                      Time elapsed: 00:10:42
                               ETA: 00:39:02

################################################################################
                     [1m Learning iteration 323/1500 [0m                      

                       Computation: 51748 steps/s (collection: 1.799s, learning 0.101s)
             Mean action noise std: 1.65
          Mean value_function loss: 77.4247
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 34.3530
                       Mean reward: 466.06
               Mean episode length: 248.08
    Episode_Reward/reaching_object: 0.6422
    Episode_Reward/rotating_object: 91.3322
        Episode_Reward/action_rate: -0.0132
          Episode_Reward/joint_vel: -0.0103
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 31850496
                    Iteration time: 1.90s
                      Time elapsed: 00:10:44
                               ETA: 00:38:59

################################################################################
                     [1m Learning iteration 324/1500 [0m                      

                       Computation: 51867 steps/s (collection: 1.787s, learning 0.109s)
             Mean action noise std: 1.65
          Mean value_function loss: 67.7794
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 34.3614
                       Mean reward: 491.05
               Mean episode length: 248.17
    Episode_Reward/reaching_object: 0.6568
    Episode_Reward/rotating_object: 93.4248
        Episode_Reward/action_rate: -0.0133
          Episode_Reward/joint_vel: -0.0105
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 31948800
                    Iteration time: 1.90s
                      Time elapsed: 00:10:46
                               ETA: 00:38:57

################################################################################
                     [1m Learning iteration 325/1500 [0m                      

                       Computation: 51649 steps/s (collection: 1.807s, learning 0.097s)
             Mean action noise std: 1.65
          Mean value_function loss: 69.4421
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 34.3704
                       Mean reward: 487.74
               Mean episode length: 249.73
    Episode_Reward/reaching_object: 0.6591
    Episode_Reward/rotating_object: 96.0461
        Episode_Reward/action_rate: -0.0133
          Episode_Reward/joint_vel: -0.0104
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 32047104
                    Iteration time: 1.90s
                      Time elapsed: 00:10:47
                               ETA: 00:38:55

################################################################################
                     [1m Learning iteration 326/1500 [0m                      

                       Computation: 53619 steps/s (collection: 1.733s, learning 0.100s)
             Mean action noise std: 1.65
          Mean value_function loss: 64.8769
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 34.3769
                       Mean reward: 482.41
               Mean episode length: 247.76
    Episode_Reward/reaching_object: 0.6499
    Episode_Reward/rotating_object: 93.8593
        Episode_Reward/action_rate: -0.0133
          Episode_Reward/joint_vel: -0.0103
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 32145408
                    Iteration time: 1.83s
                      Time elapsed: 00:10:49
                               ETA: 00:38:52

################################################################################
                     [1m Learning iteration 327/1500 [0m                      

                       Computation: 51833 steps/s (collection: 1.797s, learning 0.099s)
             Mean action noise std: 1.65
          Mean value_function loss: 62.3599
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 34.3826
                       Mean reward: 478.10
               Mean episode length: 248.61
    Episode_Reward/reaching_object: 0.6464
    Episode_Reward/rotating_object: 93.0108
        Episode_Reward/action_rate: -0.0133
          Episode_Reward/joint_vel: -0.0103
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 32243712
                    Iteration time: 1.90s
                      Time elapsed: 00:10:51
                               ETA: 00:38:50

################################################################################
                     [1m Learning iteration 328/1500 [0m                      

                       Computation: 51619 steps/s (collection: 1.778s, learning 0.126s)
             Mean action noise std: 1.66
          Mean value_function loss: 62.9395
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 34.3893
                       Mean reward: 474.62
               Mean episode length: 245.81
    Episode_Reward/reaching_object: 0.6491
    Episode_Reward/rotating_object: 97.6798
        Episode_Reward/action_rate: -0.0132
          Episode_Reward/joint_vel: -0.0103
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 32342016
                    Iteration time: 1.90s
                      Time elapsed: 00:10:53
                               ETA: 00:38:48

################################################################################
                     [1m Learning iteration 329/1500 [0m                      

                       Computation: 54246 steps/s (collection: 1.716s, learning 0.096s)
             Mean action noise std: 1.66
          Mean value_function loss: 65.9282
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 34.3963
                       Mean reward: 468.54
               Mean episode length: 249.46
    Episode_Reward/reaching_object: 0.6499
    Episode_Reward/rotating_object: 94.2818
        Episode_Reward/action_rate: -0.0133
          Episode_Reward/joint_vel: -0.0103
      Episode_Termination/time_out: 17.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 32440320
                    Iteration time: 1.81s
                      Time elapsed: 00:10:55
                               ETA: 00:38:45

################################################################################
                     [1m Learning iteration 330/1500 [0m                      

                       Computation: 52334 steps/s (collection: 1.771s, learning 0.107s)
             Mean action noise std: 1.66
          Mean value_function loss: 70.4177
               Mean surrogate loss: 0.0014
                 Mean entropy loss: 34.4022
                       Mean reward: 475.87
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6423
    Episode_Reward/rotating_object: 95.4470
        Episode_Reward/action_rate: -0.0132
          Episode_Reward/joint_vel: -0.0102
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 32538624
                    Iteration time: 1.88s
                      Time elapsed: 00:10:57
                               ETA: 00:38:43

################################################################################
                     [1m Learning iteration 331/1500 [0m                      

                       Computation: 52088 steps/s (collection: 1.730s, learning 0.158s)
             Mean action noise std: 1.66
          Mean value_function loss: 71.7345
               Mean surrogate loss: 0.0016
                 Mean entropy loss: 34.4055
                       Mean reward: 472.50
               Mean episode length: 247.13
    Episode_Reward/reaching_object: 0.6407
    Episode_Reward/rotating_object: 94.9372
        Episode_Reward/action_rate: -0.0133
          Episode_Reward/joint_vel: -0.0103
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 32636928
                    Iteration time: 1.89s
                      Time elapsed: 00:10:59
                               ETA: 00:38:40

################################################################################
                     [1m Learning iteration 332/1500 [0m                      

                       Computation: 52567 steps/s (collection: 1.748s, learning 0.122s)
             Mean action noise std: 1.66
          Mean value_function loss: 72.7830
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 34.4088
                       Mean reward: 486.54
               Mean episode length: 248.43
    Episode_Reward/reaching_object: 0.6491
    Episode_Reward/rotating_object: 99.5677
        Episode_Reward/action_rate: -0.0133
          Episode_Reward/joint_vel: -0.0102
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 32735232
                    Iteration time: 1.87s
                      Time elapsed: 00:11:01
                               ETA: 00:38:38

################################################################################
                     [1m Learning iteration 333/1500 [0m                      

                       Computation: 19749 steps/s (collection: 4.769s, learning 0.209s)
             Mean action noise std: 1.66
          Mean value_function loss: 77.5372
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 34.4149
                       Mean reward: 462.29
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6501
    Episode_Reward/rotating_object: 93.6875
        Episode_Reward/action_rate: -0.0133
          Episode_Reward/joint_vel: -0.0103
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 32833536
                    Iteration time: 4.98s
                      Time elapsed: 00:11:05
                               ETA: 00:38:46

################################################################################
                     [1m Learning iteration 334/1500 [0m                      

                       Computation: 14836 steps/s (collection: 6.496s, learning 0.130s)
             Mean action noise std: 1.66
          Mean value_function loss: 84.6795
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 34.4238
                       Mean reward: 443.95
               Mean episode length: 243.60
    Episode_Reward/reaching_object: 0.6397
    Episode_Reward/rotating_object: 93.8288
        Episode_Reward/action_rate: -0.0132
          Episode_Reward/joint_vel: -0.0101
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 32931840
                    Iteration time: 6.63s
                      Time elapsed: 00:11:12
                               ETA: 00:39:01

################################################################################
                     [1m Learning iteration 335/1500 [0m                      

                       Computation: 15070 steps/s (collection: 6.357s, learning 0.167s)
             Mean action noise std: 1.66
          Mean value_function loss: 78.9607
               Mean surrogate loss: 0.0039
                 Mean entropy loss: 34.4311
                       Mean reward: 485.09
               Mean episode length: 248.08
    Episode_Reward/reaching_object: 0.6396
    Episode_Reward/rotating_object: 94.9991
        Episode_Reward/action_rate: -0.0132
          Episode_Reward/joint_vel: -0.0101
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 33030144
                    Iteration time: 6.52s
                      Time elapsed: 00:11:19
                               ETA: 00:39:14

################################################################################
                     [1m Learning iteration 336/1500 [0m                      

                       Computation: 14461 steps/s (collection: 6.670s, learning 0.128s)
             Mean action noise std: 1.66
          Mean value_function loss: 68.9707
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 34.4354
                       Mean reward: 489.01
               Mean episode length: 248.71
    Episode_Reward/reaching_object: 0.6386
    Episode_Reward/rotating_object: 93.1971
        Episode_Reward/action_rate: -0.0132
          Episode_Reward/joint_vel: -0.0100
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 33128448
                    Iteration time: 6.80s
                      Time elapsed: 00:11:25
                               ETA: 00:39:29

################################################################################
                     [1m Learning iteration 337/1500 [0m                      

                       Computation: 14724 steps/s (collection: 6.509s, learning 0.167s)
             Mean action noise std: 1.66
          Mean value_function loss: 61.3444
               Mean surrogate loss: -0.0004
                 Mean entropy loss: 34.4404
                       Mean reward: 515.38
               Mean episode length: 247.75
    Episode_Reward/reaching_object: 0.6414
    Episode_Reward/rotating_object: 98.6311
        Episode_Reward/action_rate: -0.0133
          Episode_Reward/joint_vel: -0.0100
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 33226752
                    Iteration time: 6.68s
                      Time elapsed: 00:11:32
                               ETA: 00:39:43

################################################################################
                     [1m Learning iteration 338/1500 [0m                      

                       Computation: 14746 steps/s (collection: 6.510s, learning 0.156s)
             Mean action noise std: 1.66
          Mean value_function loss: 60.6163
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 34.4435
                       Mean reward: 509.19
               Mean episode length: 248.91
    Episode_Reward/reaching_object: 0.6453
    Episode_Reward/rotating_object: 98.7992
        Episode_Reward/action_rate: -0.0132
          Episode_Reward/joint_vel: -0.0099
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 33325056
                    Iteration time: 6.67s
                      Time elapsed: 00:11:39
                               ETA: 00:39:56

################################################################################
                     [1m Learning iteration 339/1500 [0m                      

                       Computation: 15029 steps/s (collection: 6.376s, learning 0.165s)
             Mean action noise std: 1.66
          Mean value_function loss: 69.0846
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 34.4464
                       Mean reward: 459.70
               Mean episode length: 245.96
    Episode_Reward/reaching_object: 0.6250
    Episode_Reward/rotating_object: 93.5130
        Episode_Reward/action_rate: -0.0132
          Episode_Reward/joint_vel: -0.0099
      Episode_Termination/time_out: 18.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 33423360
                    Iteration time: 6.54s
                      Time elapsed: 00:11:45
                               ETA: 00:40:10

################################################################################
                     [1m Learning iteration 340/1500 [0m                      

                       Computation: 13850 steps/s (collection: 6.899s, learning 0.199s)
             Mean action noise std: 1.66
          Mean value_function loss: 66.1144
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 34.4516
                       Mean reward: 493.31
               Mean episode length: 246.70
    Episode_Reward/reaching_object: 0.6275
    Episode_Reward/rotating_object: 94.6316
        Episode_Reward/action_rate: -0.0132
          Episode_Reward/joint_vel: -0.0100
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 33521664
                    Iteration time: 7.10s
                      Time elapsed: 00:11:52
                               ETA: 00:40:25

################################################################################
                     [1m Learning iteration 341/1500 [0m                      

                       Computation: 13443 steps/s (collection: 7.184s, learning 0.129s)
             Mean action noise std: 1.66
          Mean value_function loss: 64.1108
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 34.4585
                       Mean reward: 467.76
               Mean episode length: 249.25
    Episode_Reward/reaching_object: 0.6233
    Episode_Reward/rotating_object: 96.1379
        Episode_Reward/action_rate: -0.0132
          Episode_Reward/joint_vel: -0.0096
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 33619968
                    Iteration time: 7.31s
                      Time elapsed: 00:12:00
                               ETA: 00:40:40

################################################################################
                     [1m Learning iteration 342/1500 [0m                      

                       Computation: 54836 steps/s (collection: 1.655s, learning 0.138s)
             Mean action noise std: 1.66
          Mean value_function loss: 63.7339
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 34.4632
                       Mean reward: 489.46
               Mean episode length: 244.46
    Episode_Reward/reaching_object: 0.6247
    Episode_Reward/rotating_object: 98.6890
        Episode_Reward/action_rate: -0.0133
          Episode_Reward/joint_vel: -0.0100
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 33718272
                    Iteration time: 1.79s
                      Time elapsed: 00:12:02
                               ETA: 00:40:37

################################################################################
                     [1m Learning iteration 343/1500 [0m                      

                       Computation: 54403 steps/s (collection: 1.707s, learning 0.100s)
             Mean action noise std: 1.66
          Mean value_function loss: 68.7351
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 34.4683
                       Mean reward: 507.32
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6256
    Episode_Reward/rotating_object: 95.5921
        Episode_Reward/action_rate: -0.0133
          Episode_Reward/joint_vel: -0.0099
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 33816576
                    Iteration time: 1.81s
                      Time elapsed: 00:12:03
                               ETA: 00:40:34

################################################################################
                     [1m Learning iteration 344/1500 [0m                      

                       Computation: 56853 steps/s (collection: 1.585s, learning 0.144s)
             Mean action noise std: 1.66
          Mean value_function loss: 77.3367
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 34.4697
                       Mean reward: 451.85
               Mean episode length: 247.19
    Episode_Reward/reaching_object: 0.6259
    Episode_Reward/rotating_object: 96.7137
        Episode_Reward/action_rate: -0.0133
          Episode_Reward/joint_vel: -0.0098
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 33914880
                    Iteration time: 1.73s
                      Time elapsed: 00:12:05
                               ETA: 00:40:31

################################################################################
                     [1m Learning iteration 345/1500 [0m                      

                       Computation: 56521 steps/s (collection: 1.637s, learning 0.102s)
             Mean action noise std: 1.66
          Mean value_function loss: 65.7249
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 34.4743
                       Mean reward: 515.52
               Mean episode length: 248.56
    Episode_Reward/reaching_object: 0.6272
    Episode_Reward/rotating_object: 97.7141
        Episode_Reward/action_rate: -0.0133
          Episode_Reward/joint_vel: -0.0098
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 34013184
                    Iteration time: 1.74s
                      Time elapsed: 00:12:07
                               ETA: 00:40:27

################################################################################
                     [1m Learning iteration 346/1500 [0m                      

                       Computation: 57682 steps/s (collection: 1.603s, learning 0.101s)
             Mean action noise std: 1.67
          Mean value_function loss: 56.2441
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 34.4786
                       Mean reward: 489.70
               Mean episode length: 246.04
    Episode_Reward/reaching_object: 0.6293
    Episode_Reward/rotating_object: 96.7814
        Episode_Reward/action_rate: -0.0133
          Episode_Reward/joint_vel: -0.0099
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 34111488
                    Iteration time: 1.70s
                      Time elapsed: 00:12:08
                               ETA: 00:40:24

################################################################################
                     [1m Learning iteration 347/1500 [0m                      

                       Computation: 56768 steps/s (collection: 1.594s, learning 0.138s)
             Mean action noise std: 1.67
          Mean value_function loss: 63.6537
               Mean surrogate loss: -0.0001
                 Mean entropy loss: 34.4871
                       Mean reward: 461.05
               Mean episode length: 244.92
    Episode_Reward/reaching_object: 0.6387
    Episode_Reward/rotating_object: 96.3941
        Episode_Reward/action_rate: -0.0134
          Episode_Reward/joint_vel: -0.0101
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 34209792
                    Iteration time: 1.73s
                      Time elapsed: 00:12:10
                               ETA: 00:40:21

################################################################################
                     [1m Learning iteration 348/1500 [0m                      

                       Computation: 54917 steps/s (collection: 1.635s, learning 0.155s)
             Mean action noise std: 1.67
          Mean value_function loss: 56.7470
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 34.4923
                       Mean reward: 507.87
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6314
    Episode_Reward/rotating_object: 101.2780
        Episode_Reward/action_rate: -0.0134
          Episode_Reward/joint_vel: -0.0098
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 34308096
                    Iteration time: 1.79s
                      Time elapsed: 00:12:12
                               ETA: 00:40:17

################################################################################
                     [1m Learning iteration 349/1500 [0m                      

                       Computation: 56295 steps/s (collection: 1.640s, learning 0.107s)
             Mean action noise std: 1.67
          Mean value_function loss: 60.0565
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 34.4948
                       Mean reward: 493.82
               Mean episode length: 247.90
    Episode_Reward/reaching_object: 0.6345
    Episode_Reward/rotating_object: 101.2422
        Episode_Reward/action_rate: -0.0134
          Episode_Reward/joint_vel: -0.0098
      Episode_Termination/time_out: 18.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 34406400
                    Iteration time: 1.75s
                      Time elapsed: 00:12:14
                               ETA: 00:40:14

################################################################################
                     [1m Learning iteration 350/1500 [0m                      

                       Computation: 56118 steps/s (collection: 1.660s, learning 0.092s)
             Mean action noise std: 1.67
          Mean value_function loss: 70.8759
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 34.5001
                       Mean reward: 526.65
               Mean episode length: 247.47
    Episode_Reward/reaching_object: 0.6350
    Episode_Reward/rotating_object: 99.7151
        Episode_Reward/action_rate: -0.0134
          Episode_Reward/joint_vel: -0.0098
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 34504704
                    Iteration time: 1.75s
                      Time elapsed: 00:12:16
                               ETA: 00:40:11

################################################################################
                     [1m Learning iteration 351/1500 [0m                      

                       Computation: 55307 steps/s (collection: 1.659s, learning 0.119s)
             Mean action noise std: 1.67
          Mean value_function loss: 76.6931
               Mean surrogate loss: 0.0010
                 Mean entropy loss: 34.5047
                       Mean reward: 488.16
               Mean episode length: 243.58
    Episode_Reward/reaching_object: 0.6232
    Episode_Reward/rotating_object: 97.2029
        Episode_Reward/action_rate: -0.0133
          Episode_Reward/joint_vel: -0.0097
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 34603008
                    Iteration time: 1.78s
                      Time elapsed: 00:12:17
                               ETA: 00:40:08

################################################################################
                     [1m Learning iteration 352/1500 [0m                      

                       Computation: 55518 steps/s (collection: 1.588s, learning 0.183s)
             Mean action noise std: 1.67
          Mean value_function loss: 69.3050
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 34.5070
                       Mean reward: 512.68
               Mean episode length: 246.96
    Episode_Reward/reaching_object: 0.6318
    Episode_Reward/rotating_object: 102.3422
        Episode_Reward/action_rate: -0.0133
          Episode_Reward/joint_vel: -0.0097
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 34701312
                    Iteration time: 1.77s
                      Time elapsed: 00:12:19
                               ETA: 00:40:05

################################################################################
                     [1m Learning iteration 353/1500 [0m                      

                       Computation: 60028 steps/s (collection: 1.548s, learning 0.090s)
             Mean action noise std: 1.67
          Mean value_function loss: 60.0206
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 34.5113
                       Mean reward: 480.45
               Mean episode length: 248.01
    Episode_Reward/reaching_object: 0.6342
    Episode_Reward/rotating_object: 99.2133
        Episode_Reward/action_rate: -0.0134
          Episode_Reward/joint_vel: -0.0098
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 34799616
                    Iteration time: 1.64s
                      Time elapsed: 00:12:21
                               ETA: 00:40:01

################################################################################
                     [1m Learning iteration 354/1500 [0m                      

                       Computation: 54050 steps/s (collection: 1.679s, learning 0.140s)
             Mean action noise std: 1.67
          Mean value_function loss: 62.1205
               Mean surrogate loss: -0.0005
                 Mean entropy loss: 34.5192
                       Mean reward: 506.13
               Mean episode length: 244.52
    Episode_Reward/reaching_object: 0.6443
    Episode_Reward/rotating_object: 106.1504
        Episode_Reward/action_rate: -0.0135
          Episode_Reward/joint_vel: -0.0096
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 34897920
                    Iteration time: 1.82s
                      Time elapsed: 00:12:23
                               ETA: 00:39:58

################################################################################
                     [1m Learning iteration 355/1500 [0m                      

                       Computation: 55969 steps/s (collection: 1.629s, learning 0.127s)
             Mean action noise std: 1.67
          Mean value_function loss: 59.6653
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 34.5255
                       Mean reward: 482.37
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6334
    Episode_Reward/rotating_object: 98.5227
        Episode_Reward/action_rate: -0.0136
          Episode_Reward/joint_vel: -0.0095
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 34996224
                    Iteration time: 1.76s
                      Time elapsed: 00:12:24
                               ETA: 00:39:55

################################################################################
                     [1m Learning iteration 356/1500 [0m                      

                       Computation: 55373 steps/s (collection: 1.635s, learning 0.141s)
             Mean action noise std: 1.67
          Mean value_function loss: 69.9380
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 34.5327
                       Mean reward: 536.04
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6289
    Episode_Reward/rotating_object: 101.3817
        Episode_Reward/action_rate: -0.0134
          Episode_Reward/joint_vel: -0.0095
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 35094528
                    Iteration time: 1.78s
                      Time elapsed: 00:12:26
                               ETA: 00:39:52

################################################################################
                     [1m Learning iteration 357/1500 [0m                      

                       Computation: 53104 steps/s (collection: 1.721s, learning 0.130s)
             Mean action noise std: 1.67
          Mean value_function loss: 70.8846
               Mean surrogate loss: 0.0001
                 Mean entropy loss: 34.5397
                       Mean reward: 464.63
               Mean episode length: 246.56
    Episode_Reward/reaching_object: 0.6357
    Episode_Reward/rotating_object: 99.5285
        Episode_Reward/action_rate: -0.0134
          Episode_Reward/joint_vel: -0.0096
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 35192832
                    Iteration time: 1.85s
                      Time elapsed: 00:12:28
                               ETA: 00:39:49

################################################################################
                     [1m Learning iteration 358/1500 [0m                      

                       Computation: 58959 steps/s (collection: 1.574s, learning 0.093s)
             Mean action noise std: 1.67
          Mean value_function loss: 68.0904
               Mean surrogate loss: 0.0018
                 Mean entropy loss: 34.5421
                       Mean reward: 512.86
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6420
    Episode_Reward/rotating_object: 101.3079
        Episode_Reward/action_rate: -0.0136
          Episode_Reward/joint_vel: -0.0095
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 35291136
                    Iteration time: 1.67s
                      Time elapsed: 00:12:30
                               ETA: 00:39:46

################################################################################
                     [1m Learning iteration 359/1500 [0m                      

                       Computation: 55552 steps/s (collection: 1.654s, learning 0.116s)
             Mean action noise std: 1.67
          Mean value_function loss: 77.3415
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 34.5441
                       Mean reward: 486.48
               Mean episode length: 240.70
    Episode_Reward/reaching_object: 0.6365
    Episode_Reward/rotating_object: 97.9650
        Episode_Reward/action_rate: -0.0135
          Episode_Reward/joint_vel: -0.0095
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 35389440
                    Iteration time: 1.77s
                      Time elapsed: 00:12:31
                               ETA: 00:39:42

################################################################################
                     [1m Learning iteration 360/1500 [0m                      

                       Computation: 55261 steps/s (collection: 1.673s, learning 0.106s)
             Mean action noise std: 1.67
          Mean value_function loss: 77.6389
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 34.5491
                       Mean reward: 521.64
               Mean episode length: 243.50
    Episode_Reward/reaching_object: 0.6344
    Episode_Reward/rotating_object: 99.7104
        Episode_Reward/action_rate: -0.0134
          Episode_Reward/joint_vel: -0.0092
      Episode_Termination/time_out: 18.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 35487744
                    Iteration time: 1.78s
                      Time elapsed: 00:12:33
                               ETA: 00:39:39

################################################################################
                     [1m Learning iteration 361/1500 [0m                      

                       Computation: 56757 steps/s (collection: 1.635s, learning 0.097s)
             Mean action noise std: 1.67
          Mean value_function loss: 75.3394
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 34.5537
                       Mean reward: 489.26
               Mean episode length: 243.09
    Episode_Reward/reaching_object: 0.6342
    Episode_Reward/rotating_object: 101.4053
        Episode_Reward/action_rate: -0.0134
          Episode_Reward/joint_vel: -0.0093
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 35586048
                    Iteration time: 1.73s
                      Time elapsed: 00:12:35
                               ETA: 00:39:36

################################################################################
                     [1m Learning iteration 362/1500 [0m                      

                       Computation: 56049 steps/s (collection: 1.651s, learning 0.103s)
             Mean action noise std: 1.67
          Mean value_function loss: 72.3537
               Mean surrogate loss: -0.0005
                 Mean entropy loss: 34.5561
                       Mean reward: 491.13
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6536
    Episode_Reward/rotating_object: 101.7549
        Episode_Reward/action_rate: -0.0137
          Episode_Reward/joint_vel: -0.0094
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 35684352
                    Iteration time: 1.75s
                      Time elapsed: 00:12:37
                               ETA: 00:39:33

################################################################################
                     [1m Learning iteration 363/1500 [0m                      

                       Computation: 57214 steps/s (collection: 1.627s, learning 0.091s)
             Mean action noise std: 1.67
          Mean value_function loss: 64.2965
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 34.5578
                       Mean reward: 463.50
               Mean episode length: 239.16
    Episode_Reward/reaching_object: 0.6430
    Episode_Reward/rotating_object: 100.6418
        Episode_Reward/action_rate: -0.0134
          Episode_Reward/joint_vel: -0.0093
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 35782656
                    Iteration time: 1.72s
                      Time elapsed: 00:12:38
                               ETA: 00:39:30

################################################################################
                     [1m Learning iteration 364/1500 [0m                      

                       Computation: 58474 steps/s (collection: 1.592s, learning 0.090s)
             Mean action noise std: 1.67
          Mean value_function loss: 59.2093
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 34.5626
                       Mean reward: 517.97
               Mean episode length: 243.20
    Episode_Reward/reaching_object: 0.6424
    Episode_Reward/rotating_object: 103.2227
        Episode_Reward/action_rate: -0.0135
          Episode_Reward/joint_vel: -0.0089
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 35880960
                    Iteration time: 1.68s
                      Time elapsed: 00:12:40
                               ETA: 00:39:26

################################################################################
                     [1m Learning iteration 365/1500 [0m                      

                       Computation: 55971 steps/s (collection: 1.611s, learning 0.146s)
             Mean action noise std: 1.68
          Mean value_function loss: 58.7090
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 34.5715
                       Mean reward: 552.58
               Mean episode length: 247.91
    Episode_Reward/reaching_object: 0.6431
    Episode_Reward/rotating_object: 105.3822
        Episode_Reward/action_rate: -0.0135
          Episode_Reward/joint_vel: -0.0093
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 35979264
                    Iteration time: 1.76s
                      Time elapsed: 00:12:42
                               ETA: 00:39:23

################################################################################
                     [1m Learning iteration 366/1500 [0m                      

                       Computation: 57447 steps/s (collection: 1.605s, learning 0.107s)
             Mean action noise std: 1.68
          Mean value_function loss: 57.3634
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 34.5803
                       Mean reward: 509.12
               Mean episode length: 246.23
    Episode_Reward/reaching_object: 0.6403
    Episode_Reward/rotating_object: 103.2003
        Episode_Reward/action_rate: -0.0136
          Episode_Reward/joint_vel: -0.0091
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 36077568
                    Iteration time: 1.71s
                      Time elapsed: 00:12:43
                               ETA: 00:39:20

################################################################################
                     [1m Learning iteration 367/1500 [0m                      

                       Computation: 56860 steps/s (collection: 1.595s, learning 0.134s)
             Mean action noise std: 1.68
          Mean value_function loss: 55.4597
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 34.5902
                       Mean reward: 538.21
               Mean episode length: 247.97
    Episode_Reward/reaching_object: 0.6352
    Episode_Reward/rotating_object: 102.8879
        Episode_Reward/action_rate: -0.0136
          Episode_Reward/joint_vel: -0.0089
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 36175872
                    Iteration time: 1.73s
                      Time elapsed: 00:12:45
                               ETA: 00:39:17

################################################################################
                     [1m Learning iteration 368/1500 [0m                      

                       Computation: 54323 steps/s (collection: 1.636s, learning 0.174s)
             Mean action noise std: 1.68
          Mean value_function loss: 66.0616
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 34.6001
                       Mean reward: 518.34
               Mean episode length: 246.17
    Episode_Reward/reaching_object: 0.6281
    Episode_Reward/rotating_object: 104.3944
        Episode_Reward/action_rate: -0.0134
          Episode_Reward/joint_vel: -0.0091
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 36274176
                    Iteration time: 1.81s
                      Time elapsed: 00:12:47
                               ETA: 00:39:14

################################################################################
                     [1m Learning iteration 369/1500 [0m                      

                       Computation: 57379 steps/s (collection: 1.624s, learning 0.089s)
             Mean action noise std: 1.68
          Mean value_function loss: 66.9541
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 34.6048
                       Mean reward: 499.78
               Mean episode length: 244.06
    Episode_Reward/reaching_object: 0.6285
    Episode_Reward/rotating_object: 102.3610
        Episode_Reward/action_rate: -0.0134
          Episode_Reward/joint_vel: -0.0089
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 36372480
                    Iteration time: 1.71s
                      Time elapsed: 00:12:49
                               ETA: 00:39:11

################################################################################
                     [1m Learning iteration 370/1500 [0m                      

                       Computation: 56700 steps/s (collection: 1.617s, learning 0.116s)
             Mean action noise std: 1.68
          Mean value_function loss: 57.5466
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 34.6101
                       Mean reward: 493.84
               Mean episode length: 241.46
    Episode_Reward/reaching_object: 0.6221
    Episode_Reward/rotating_object: 101.5435
        Episode_Reward/action_rate: -0.0134
          Episode_Reward/joint_vel: -0.0089
      Episode_Termination/time_out: 18.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 36470784
                    Iteration time: 1.73s
                      Time elapsed: 00:12:50
                               ETA: 00:39:08

################################################################################
                     [1m Learning iteration 371/1500 [0m                      

                       Computation: 58610 steps/s (collection: 1.591s, learning 0.087s)
             Mean action noise std: 1.68
          Mean value_function loss: 61.2858
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 34.6207
                       Mean reward: 502.50
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6299
    Episode_Reward/rotating_object: 105.0233
        Episode_Reward/action_rate: -0.0136
          Episode_Reward/joint_vel: -0.0089
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 36569088
                    Iteration time: 1.68s
                      Time elapsed: 00:12:52
                               ETA: 00:39:04

################################################################################
                     [1m Learning iteration 372/1500 [0m                      

                       Computation: 57292 steps/s (collection: 1.620s, learning 0.096s)
             Mean action noise std: 1.68
          Mean value_function loss: 60.4778
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 34.6313
                       Mean reward: 506.92
               Mean episode length: 242.13
    Episode_Reward/reaching_object: 0.6222
    Episode_Reward/rotating_object: 104.4432
        Episode_Reward/action_rate: -0.0135
          Episode_Reward/joint_vel: -0.0089
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 36667392
                    Iteration time: 1.72s
                      Time elapsed: 00:12:54
                               ETA: 00:39:01

################################################################################
                     [1m Learning iteration 373/1500 [0m                      

                       Computation: 57732 steps/s (collection: 1.610s, learning 0.093s)
             Mean action noise std: 1.68
          Mean value_function loss: 52.4212
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 34.6432
                       Mean reward: 537.77
               Mean episode length: 249.25
    Episode_Reward/reaching_object: 0.6309
    Episode_Reward/rotating_object: 105.2549
        Episode_Reward/action_rate: -0.0137
          Episode_Reward/joint_vel: -0.0089
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 36765696
                    Iteration time: 1.70s
                      Time elapsed: 00:12:56
                               ETA: 00:38:58

################################################################################
                     [1m Learning iteration 374/1500 [0m                      

                       Computation: 52467 steps/s (collection: 1.760s, learning 0.114s)
             Mean action noise std: 1.68
          Mean value_function loss: 62.0662
               Mean surrogate loss: 0.0012
                 Mean entropy loss: 34.6577
                       Mean reward: 552.39
               Mean episode length: 248.16
    Episode_Reward/reaching_object: 0.6287
    Episode_Reward/rotating_object: 105.1693
        Episode_Reward/action_rate: -0.0137
          Episode_Reward/joint_vel: -0.0093
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 36864000
                    Iteration time: 1.87s
                      Time elapsed: 00:12:57
                               ETA: 00:38:55

################################################################################
                     [1m Learning iteration 375/1500 [0m                      

                       Computation: 55867 steps/s (collection: 1.596s, learning 0.164s)
             Mean action noise std: 1.68
          Mean value_function loss: 58.1279
               Mean surrogate loss: -0.0007
                 Mean entropy loss: 34.6642
                       Mean reward: 533.02
               Mean episode length: 248.22
    Episode_Reward/reaching_object: 0.6272
    Episode_Reward/rotating_object: 105.1929
        Episode_Reward/action_rate: -0.0137
          Episode_Reward/joint_vel: -0.0088
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 36962304
                    Iteration time: 1.76s
                      Time elapsed: 00:12:59
                               ETA: 00:38:52

################################################################################
                     [1m Learning iteration 376/1500 [0m                      

                       Computation: 56117 steps/s (collection: 1.616s, learning 0.136s)
             Mean action noise std: 1.69
          Mean value_function loss: 55.3369
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 34.6687
                       Mean reward: 499.06
               Mean episode length: 245.49
    Episode_Reward/reaching_object: 0.6206
    Episode_Reward/rotating_object: 103.1764
        Episode_Reward/action_rate: -0.0137
          Episode_Reward/joint_vel: -0.0088
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 37060608
                    Iteration time: 1.75s
                      Time elapsed: 00:13:01
                               ETA: 00:38:49

################################################################################
                     [1m Learning iteration 377/1500 [0m                      

                       Computation: 53368 steps/s (collection: 1.732s, learning 0.110s)
             Mean action noise std: 1.69
          Mean value_function loss: 57.4721
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 34.6736
                       Mean reward: 514.59
               Mean episode length: 246.03
    Episode_Reward/reaching_object: 0.6286
    Episode_Reward/rotating_object: 106.9882
        Episode_Reward/action_rate: -0.0138
          Episode_Reward/joint_vel: -0.0091
      Episode_Termination/time_out: 17.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 37158912
                    Iteration time: 1.84s
                      Time elapsed: 00:13:03
                               ETA: 00:38:47

################################################################################
                     [1m Learning iteration 378/1500 [0m                      

                       Computation: 56266 steps/s (collection: 1.635s, learning 0.113s)
             Mean action noise std: 1.69
          Mean value_function loss: 55.6806
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 34.6855
                       Mean reward: 525.30
               Mean episode length: 248.00
    Episode_Reward/reaching_object: 0.6312
    Episode_Reward/rotating_object: 107.0979
        Episode_Reward/action_rate: -0.0138
          Episode_Reward/joint_vel: -0.0091
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 37257216
                    Iteration time: 1.75s
                      Time elapsed: 00:13:05
                               ETA: 00:38:44

################################################################################
                     [1m Learning iteration 379/1500 [0m                      

                       Computation: 58210 steps/s (collection: 1.580s, learning 0.109s)
             Mean action noise std: 1.69
          Mean value_function loss: 48.8176
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 34.6956
                       Mean reward: 491.28
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6277
    Episode_Reward/rotating_object: 104.0312
        Episode_Reward/action_rate: -0.0138
          Episode_Reward/joint_vel: -0.0090
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 37355520
                    Iteration time: 1.69s
                      Time elapsed: 00:13:06
                               ETA: 00:38:40

################################################################################
                     [1m Learning iteration 380/1500 [0m                      

                       Computation: 57729 steps/s (collection: 1.592s, learning 0.111s)
             Mean action noise std: 1.69
          Mean value_function loss: 47.9632
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 34.7038
                       Mean reward: 561.21
               Mean episode length: 247.89
    Episode_Reward/reaching_object: 0.6315
    Episode_Reward/rotating_object: 106.8964
        Episode_Reward/action_rate: -0.0138
          Episode_Reward/joint_vel: -0.0086
      Episode_Termination/time_out: 17.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 37453824
                    Iteration time: 1.70s
                      Time elapsed: 00:13:08
                               ETA: 00:38:37

################################################################################
                     [1m Learning iteration 381/1500 [0m                      

                       Computation: 58503 steps/s (collection: 1.578s, learning 0.103s)
             Mean action noise std: 1.69
          Mean value_function loss: 55.7308
               Mean surrogate loss: 0.0002
                 Mean entropy loss: 34.7113
                       Mean reward: 513.86
               Mean episode length: 245.14
    Episode_Reward/reaching_object: 0.6265
    Episode_Reward/rotating_object: 104.6327
        Episode_Reward/action_rate: -0.0139
          Episode_Reward/joint_vel: -0.0090
      Episode_Termination/time_out: 17.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 37552128
                    Iteration time: 1.68s
                      Time elapsed: 00:13:10
                               ETA: 00:38:34

################################################################################
                     [1m Learning iteration 382/1500 [0m                      

                       Computation: 57509 steps/s (collection: 1.603s, learning 0.106s)
             Mean action noise std: 1.69
          Mean value_function loss: 50.6790
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 34.7148
                       Mean reward: 553.31
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6265
    Episode_Reward/rotating_object: 109.2644
        Episode_Reward/action_rate: -0.0137
          Episode_Reward/joint_vel: -0.0086
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 37650432
                    Iteration time: 1.71s
                      Time elapsed: 00:13:11
                               ETA: 00:38:31

################################################################################
                     [1m Learning iteration 383/1500 [0m                      

                       Computation: 57493 steps/s (collection: 1.606s, learning 0.104s)
             Mean action noise std: 1.69
          Mean value_function loss: 60.5051
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 34.7195
                       Mean reward: 575.01
               Mean episode length: 247.97
    Episode_Reward/reaching_object: 0.6309
    Episode_Reward/rotating_object: 109.8329
        Episode_Reward/action_rate: -0.0139
          Episode_Reward/joint_vel: -0.0089
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 37748736
                    Iteration time: 1.71s
                      Time elapsed: 00:13:13
                               ETA: 00:38:28

################################################################################
                     [1m Learning iteration 384/1500 [0m                      

                       Computation: 57275 steps/s (collection: 1.601s, learning 0.116s)
             Mean action noise std: 1.69
          Mean value_function loss: 51.7644
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 34.7282
                       Mean reward: 550.76
               Mean episode length: 247.77
    Episode_Reward/reaching_object: 0.6336
    Episode_Reward/rotating_object: 112.1832
        Episode_Reward/action_rate: -0.0140
          Episode_Reward/joint_vel: -0.0087
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 37847040
                    Iteration time: 1.72s
                      Time elapsed: 00:13:15
                               ETA: 00:38:25

################################################################################
                     [1m Learning iteration 385/1500 [0m                      

                       Computation: 57021 steps/s (collection: 1.630s, learning 0.094s)
             Mean action noise std: 1.69
          Mean value_function loss: 52.8843
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 34.7348
                       Mean reward: 556.61
               Mean episode length: 248.72
    Episode_Reward/reaching_object: 0.6351
    Episode_Reward/rotating_object: 109.4610
        Episode_Reward/action_rate: -0.0140
          Episode_Reward/joint_vel: -0.0089
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 37945344
                    Iteration time: 1.72s
                      Time elapsed: 00:13:16
                               ETA: 00:38:22

################################################################################
                     [1m Learning iteration 386/1500 [0m                      

                       Computation: 57368 steps/s (collection: 1.612s, learning 0.102s)
             Mean action noise std: 1.69
          Mean value_function loss: 56.9073
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 34.7429
                       Mean reward: 551.30
               Mean episode length: 249.69
    Episode_Reward/reaching_object: 0.6380
    Episode_Reward/rotating_object: 110.9760
        Episode_Reward/action_rate: -0.0140
          Episode_Reward/joint_vel: -0.0088
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 38043648
                    Iteration time: 1.71s
                      Time elapsed: 00:13:18
                               ETA: 00:38:19

################################################################################
                     [1m Learning iteration 387/1500 [0m                      

                       Computation: 58061 steps/s (collection: 1.585s, learning 0.108s)
             Mean action noise std: 1.70
          Mean value_function loss: 57.8352
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 34.7541
                       Mean reward: 521.49
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6344
    Episode_Reward/rotating_object: 107.4110
        Episode_Reward/action_rate: -0.0139
          Episode_Reward/joint_vel: -0.0087
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 38141952
                    Iteration time: 1.69s
                      Time elapsed: 00:13:20
                               ETA: 00:38:15

################################################################################
                     [1m Learning iteration 388/1500 [0m                      

                       Computation: 57790 steps/s (collection: 1.586s, learning 0.115s)
             Mean action noise std: 1.70
          Mean value_function loss: 57.7329
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 34.7612
                       Mean reward: 549.24
               Mean episode length: 247.17
    Episode_Reward/reaching_object: 0.6348
    Episode_Reward/rotating_object: 108.2109
        Episode_Reward/action_rate: -0.0139
          Episode_Reward/joint_vel: -0.0088
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 38240256
                    Iteration time: 1.70s
                      Time elapsed: 00:13:22
                               ETA: 00:38:12

################################################################################
                     [1m Learning iteration 389/1500 [0m                      

                       Computation: 56586 steps/s (collection: 1.611s, learning 0.126s)
             Mean action noise std: 1.70
          Mean value_function loss: 64.4132
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 34.7673
                       Mean reward: 546.37
               Mean episode length: 240.11
    Episode_Reward/reaching_object: 0.6291
    Episode_Reward/rotating_object: 105.7380
        Episode_Reward/action_rate: -0.0137
          Episode_Reward/joint_vel: -0.0089
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 38338560
                    Iteration time: 1.74s
                      Time elapsed: 00:13:23
                               ETA: 00:38:09

################################################################################
                     [1m Learning iteration 390/1500 [0m                      

                       Computation: 57075 steps/s (collection: 1.616s, learning 0.106s)
             Mean action noise std: 1.70
          Mean value_function loss: 62.1845
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 34.7785
                       Mean reward: 559.74
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6528
    Episode_Reward/rotating_object: 114.7353
        Episode_Reward/action_rate: -0.0142
          Episode_Reward/joint_vel: -0.0087
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 38436864
                    Iteration time: 1.72s
                      Time elapsed: 00:13:25
                               ETA: 00:38:06

################################################################################
                     [1m Learning iteration 391/1500 [0m                      

                       Computation: 57477 steps/s (collection: 1.615s, learning 0.095s)
             Mean action noise std: 1.70
          Mean value_function loss: 69.8373
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 34.7880
                       Mean reward: 515.34
               Mean episode length: 243.14
    Episode_Reward/reaching_object: 0.6364
    Episode_Reward/rotating_object: 107.7712
        Episode_Reward/action_rate: -0.0140
          Episode_Reward/joint_vel: -0.0086
      Episode_Termination/time_out: 18.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 38535168
                    Iteration time: 1.71s
                      Time elapsed: 00:13:27
                               ETA: 00:38:03

################################################################################
                     [1m Learning iteration 392/1500 [0m                      

                       Computation: 57623 steps/s (collection: 1.607s, learning 0.099s)
             Mean action noise std: 1.70
          Mean value_function loss: 69.4558
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 34.7914
                       Mean reward: 558.82
               Mean episode length: 245.81
    Episode_Reward/reaching_object: 0.6412
    Episode_Reward/rotating_object: 110.2264
        Episode_Reward/action_rate: -0.0140
          Episode_Reward/joint_vel: -0.0088
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 38633472
                    Iteration time: 1.71s
                      Time elapsed: 00:13:28
                               ETA: 00:38:00

################################################################################
                     [1m Learning iteration 393/1500 [0m                      

                       Computation: 58688 steps/s (collection: 1.578s, learning 0.097s)
             Mean action noise std: 1.70
          Mean value_function loss: 62.5913
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 34.7958
                       Mean reward: 561.20
               Mean episode length: 245.81
    Episode_Reward/reaching_object: 0.6440
    Episode_Reward/rotating_object: 111.7060
        Episode_Reward/action_rate: -0.0141
          Episode_Reward/joint_vel: -0.0087
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 38731776
                    Iteration time: 1.68s
                      Time elapsed: 00:13:30
                               ETA: 00:37:57

################################################################################
                     [1m Learning iteration 394/1500 [0m                      

                       Computation: 56719 steps/s (collection: 1.636s, learning 0.097s)
             Mean action noise std: 1.70
          Mean value_function loss: 57.9172
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 34.7999
                       Mean reward: 534.27
               Mean episode length: 243.06
    Episode_Reward/reaching_object: 0.6383
    Episode_Reward/rotating_object: 104.4093
        Episode_Reward/action_rate: -0.0140
          Episode_Reward/joint_vel: -0.0087
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 38830080
                    Iteration time: 1.73s
                      Time elapsed: 00:13:32
                               ETA: 00:37:54

################################################################################
                     [1m Learning iteration 395/1500 [0m                      

                       Computation: 56998 steps/s (collection: 1.628s, learning 0.097s)
             Mean action noise std: 1.70
          Mean value_function loss: 51.5134
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 34.8052
                       Mean reward: 551.69
               Mean episode length: 247.35
    Episode_Reward/reaching_object: 0.6409
    Episode_Reward/rotating_object: 108.9469
        Episode_Reward/action_rate: -0.0141
          Episode_Reward/joint_vel: -0.0086
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 38928384
                    Iteration time: 1.72s
                      Time elapsed: 00:13:34
                               ETA: 00:37:51

################################################################################
                     [1m Learning iteration 396/1500 [0m                      

                       Computation: 55235 steps/s (collection: 1.643s, learning 0.137s)
             Mean action noise std: 1.70
          Mean value_function loss: 52.2260
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 34.8130
                       Mean reward: 573.83
               Mean episode length: 248.12
    Episode_Reward/reaching_object: 0.6408
    Episode_Reward/rotating_object: 109.9245
        Episode_Reward/action_rate: -0.0142
          Episode_Reward/joint_vel: -0.0088
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 39026688
                    Iteration time: 1.78s
                      Time elapsed: 00:13:35
                               ETA: 00:37:48

################################################################################
                     [1m Learning iteration 397/1500 [0m                      

                       Computation: 56788 steps/s (collection: 1.621s, learning 0.110s)
             Mean action noise std: 1.70
          Mean value_function loss: 54.4158
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 34.8174
                       Mean reward: 560.61
               Mean episode length: 247.22
    Episode_Reward/reaching_object: 0.6355
    Episode_Reward/rotating_object: 109.3779
        Episode_Reward/action_rate: -0.0141
          Episode_Reward/joint_vel: -0.0086
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 39124992
                    Iteration time: 1.73s
                      Time elapsed: 00:13:37
                               ETA: 00:37:45

################################################################################
                     [1m Learning iteration 398/1500 [0m                      

                       Computation: 55708 steps/s (collection: 1.664s, learning 0.100s)
             Mean action noise std: 1.70
          Mean value_function loss: 50.0647
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 34.8227
                       Mean reward: 583.78
               Mean episode length: 247.80
    Episode_Reward/reaching_object: 0.6343
    Episode_Reward/rotating_object: 110.2559
        Episode_Reward/action_rate: -0.0141
          Episode_Reward/joint_vel: -0.0085
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 39223296
                    Iteration time: 1.76s
                      Time elapsed: 00:13:39
                               ETA: 00:37:42

################################################################################
                     [1m Learning iteration 399/1500 [0m                      

                       Computation: 58602 steps/s (collection: 1.580s, learning 0.098s)
             Mean action noise std: 1.70
          Mean value_function loss: 57.5516
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 34.8353
                       Mean reward: 573.98
               Mean episode length: 248.08
    Episode_Reward/reaching_object: 0.6366
    Episode_Reward/rotating_object: 109.8001
        Episode_Reward/action_rate: -0.0142
          Episode_Reward/joint_vel: -0.0085
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 39321600
                    Iteration time: 1.68s
                      Time elapsed: 00:13:41
                               ETA: 00:37:39

################################################################################
                     [1m Learning iteration 400/1500 [0m                      

                       Computation: 54689 steps/s (collection: 1.684s, learning 0.114s)
             Mean action noise std: 1.71
          Mean value_function loss: 56.9317
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 34.8453
                       Mean reward: 553.22
               Mean episode length: 240.41
    Episode_Reward/reaching_object: 0.6366
    Episode_Reward/rotating_object: 114.5735
        Episode_Reward/action_rate: -0.0142
          Episode_Reward/joint_vel: -0.0086
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 39419904
                    Iteration time: 1.80s
                      Time elapsed: 00:13:42
                               ETA: 00:37:37

################################################################################
                     [1m Learning iteration 401/1500 [0m                      

                       Computation: 56603 steps/s (collection: 1.636s, learning 0.101s)
             Mean action noise std: 1.71
          Mean value_function loss: 53.6327
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 34.8559
                       Mean reward: 564.21
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6259
    Episode_Reward/rotating_object: 110.5357
        Episode_Reward/action_rate: -0.0140
          Episode_Reward/joint_vel: -0.0082
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 39518208
                    Iteration time: 1.74s
                      Time elapsed: 00:13:44
                               ETA: 00:37:34

################################################################################
                     [1m Learning iteration 402/1500 [0m                      

                       Computation: 57266 steps/s (collection: 1.622s, learning 0.094s)
             Mean action noise std: 1.71
          Mean value_function loss: 59.0991
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 34.8652
                       Mean reward: 546.82
               Mean episode length: 245.47
    Episode_Reward/reaching_object: 0.6316
    Episode_Reward/rotating_object: 111.5965
        Episode_Reward/action_rate: -0.0142
          Episode_Reward/joint_vel: -0.0086
      Episode_Termination/time_out: 18.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 39616512
                    Iteration time: 1.72s
                      Time elapsed: 00:13:46
                               ETA: 00:37:31

################################################################################
                     [1m Learning iteration 403/1500 [0m                      

                       Computation: 55189 steps/s (collection: 1.678s, learning 0.103s)
             Mean action noise std: 1.71
          Mean value_function loss: 55.5929
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 34.8716
                       Mean reward: 567.57
               Mean episode length: 243.86
    Episode_Reward/reaching_object: 0.6359
    Episode_Reward/rotating_object: 113.1488
        Episode_Reward/action_rate: -0.0143
          Episode_Reward/joint_vel: -0.0083
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 39714816
                    Iteration time: 1.78s
                      Time elapsed: 00:13:48
                               ETA: 00:37:28

################################################################################
                     [1m Learning iteration 404/1500 [0m                      

                       Computation: 57137 steps/s (collection: 1.630s, learning 0.090s)
             Mean action noise std: 1.71
          Mean value_function loss: 56.9096
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 34.8792
                       Mean reward: 545.78
               Mean episode length: 239.70
    Episode_Reward/reaching_object: 0.6367
    Episode_Reward/rotating_object: 113.2938
        Episode_Reward/action_rate: -0.0143
          Episode_Reward/joint_vel: -0.0083
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 39813120
                    Iteration time: 1.72s
                      Time elapsed: 00:13:49
                               ETA: 00:37:25

################################################################################
                     [1m Learning iteration 405/1500 [0m                      

                       Computation: 58648 steps/s (collection: 1.584s, learning 0.092s)
             Mean action noise std: 1.71
          Mean value_function loss: 48.4213
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 34.8882
                       Mean reward: 579.04
               Mean episode length: 243.92
    Episode_Reward/reaching_object: 0.6413
    Episode_Reward/rotating_object: 114.4822
        Episode_Reward/action_rate: -0.0143
          Episode_Reward/joint_vel: -0.0084
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 39911424
                    Iteration time: 1.68s
                      Time elapsed: 00:13:51
                               ETA: 00:37:22

################################################################################
                     [1m Learning iteration 406/1500 [0m                      

                       Computation: 57192 steps/s (collection: 1.629s, learning 0.090s)
             Mean action noise std: 1.71
          Mean value_function loss: 53.7248
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 34.8950
                       Mean reward: 586.58
               Mean episode length: 245.44
    Episode_Reward/reaching_object: 0.6367
    Episode_Reward/rotating_object: 114.0846
        Episode_Reward/action_rate: -0.0143
          Episode_Reward/joint_vel: -0.0082
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 40009728
                    Iteration time: 1.72s
                      Time elapsed: 00:13:53
                               ETA: 00:37:19

################################################################################
                     [1m Learning iteration 407/1500 [0m                      

                       Computation: 57707 steps/s (collection: 1.594s, learning 0.109s)
             Mean action noise std: 1.71
          Mean value_function loss: 56.3629
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 34.8997
                       Mean reward: 559.75
               Mean episode length: 244.18
    Episode_Reward/reaching_object: 0.6335
    Episode_Reward/rotating_object: 109.9265
        Episode_Reward/action_rate: -0.0142
          Episode_Reward/joint_vel: -0.0084
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 40108032
                    Iteration time: 1.70s
                      Time elapsed: 00:13:54
                               ETA: 00:37:16

################################################################################
                     [1m Learning iteration 408/1500 [0m                      

                       Computation: 56615 steps/s (collection: 1.637s, learning 0.099s)
             Mean action noise std: 1.71
          Mean value_function loss: 51.2165
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 34.9071
                       Mean reward: 537.44
               Mean episode length: 237.85
    Episode_Reward/reaching_object: 0.6343
    Episode_Reward/rotating_object: 111.1047
        Episode_Reward/action_rate: -0.0142
          Episode_Reward/joint_vel: -0.0082
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 40206336
                    Iteration time: 1.74s
                      Time elapsed: 00:13:56
                               ETA: 00:37:13

################################################################################
                     [1m Learning iteration 409/1500 [0m                      

                       Computation: 55878 steps/s (collection: 1.662s, learning 0.098s)
             Mean action noise std: 1.71
          Mean value_function loss: 48.8820
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 34.9193
                       Mean reward: 578.44
               Mean episode length: 248.36
    Episode_Reward/reaching_object: 0.6501
    Episode_Reward/rotating_object: 117.4665
        Episode_Reward/action_rate: -0.0145
          Episode_Reward/joint_vel: -0.0084
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 40304640
                    Iteration time: 1.76s
                      Time elapsed: 00:13:58
                               ETA: 00:37:10

################################################################################
                     [1m Learning iteration 410/1500 [0m                      

                       Computation: 57701 steps/s (collection: 1.616s, learning 0.088s)
             Mean action noise std: 1.72
          Mean value_function loss: 51.4543
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 34.9373
                       Mean reward: 581.72
               Mean episode length: 247.85
    Episode_Reward/reaching_object: 0.6387
    Episode_Reward/rotating_object: 111.9037
        Episode_Reward/action_rate: -0.0143
          Episode_Reward/joint_vel: -0.0085
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 40402944
                    Iteration time: 1.70s
                      Time elapsed: 00:14:00
                               ETA: 00:37:07

################################################################################
                     [1m Learning iteration 411/1500 [0m                      

                       Computation: 59076 steps/s (collection: 1.571s, learning 0.093s)
             Mean action noise std: 1.72
          Mean value_function loss: 54.4269
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 34.9482
                       Mean reward: 603.41
               Mean episode length: 248.67
    Episode_Reward/reaching_object: 0.6452
    Episode_Reward/rotating_object: 115.0723
        Episode_Reward/action_rate: -0.0144
          Episode_Reward/joint_vel: -0.0084
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 40501248
                    Iteration time: 1.66s
                      Time elapsed: 00:14:01
                               ETA: 00:37:04

################################################################################
                     [1m Learning iteration 412/1500 [0m                      

                       Computation: 57975 steps/s (collection: 1.599s, learning 0.097s)
             Mean action noise std: 1.72
          Mean value_function loss: 43.7182
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 34.9581
                       Mean reward: 531.95
               Mean episode length: 245.45
    Episode_Reward/reaching_object: 0.6362
    Episode_Reward/rotating_object: 113.6144
        Episode_Reward/action_rate: -0.0143
          Episode_Reward/joint_vel: -0.0083
      Episode_Termination/time_out: 18.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 40599552
                    Iteration time: 1.70s
                      Time elapsed: 00:14:03
                               ETA: 00:37:01

################################################################################
                     [1m Learning iteration 413/1500 [0m                      

                       Computation: 55005 steps/s (collection: 1.675s, learning 0.112s)
             Mean action noise std: 1.72
          Mean value_function loss: 55.9587
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 34.9685
                       Mean reward: 564.59
               Mean episode length: 242.51
    Episode_Reward/reaching_object: 0.6300
    Episode_Reward/rotating_object: 113.6906
        Episode_Reward/action_rate: -0.0142
          Episode_Reward/joint_vel: -0.0084
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 40697856
                    Iteration time: 1.79s
                      Time elapsed: 00:14:05
                               ETA: 00:36:59

################################################################################
                     [1m Learning iteration 414/1500 [0m                      

                       Computation: 56197 steps/s (collection: 1.638s, learning 0.111s)
             Mean action noise std: 1.72
          Mean value_function loss: 55.2517
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 34.9808
                       Mean reward: 591.18
               Mean episode length: 248.01
    Episode_Reward/reaching_object: 0.6337
    Episode_Reward/rotating_object: 114.5432
        Episode_Reward/action_rate: -0.0143
          Episode_Reward/joint_vel: -0.0080
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 40796160
                    Iteration time: 1.75s
                      Time elapsed: 00:14:06
                               ETA: 00:36:56

################################################################################
                     [1m Learning iteration 415/1500 [0m                      

                       Computation: 56601 steps/s (collection: 1.617s, learning 0.120s)
             Mean action noise std: 1.72
          Mean value_function loss: 49.8038
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 34.9923
                       Mean reward: 573.48
               Mean episode length: 247.74
    Episode_Reward/reaching_object: 0.6416
    Episode_Reward/rotating_object: 118.1107
        Episode_Reward/action_rate: -0.0144
          Episode_Reward/joint_vel: -0.0083
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 40894464
                    Iteration time: 1.74s
                      Time elapsed: 00:14:08
                               ETA: 00:36:53

################################################################################
                     [1m Learning iteration 416/1500 [0m                      

                       Computation: 55284 steps/s (collection: 1.686s, learning 0.092s)
             Mean action noise std: 1.72
          Mean value_function loss: 52.8682
               Mean surrogate loss: 0.0003
                 Mean entropy loss: 35.0037
                       Mean reward: 562.72
               Mean episode length: 248.33
    Episode_Reward/reaching_object: 0.6374
    Episode_Reward/rotating_object: 112.4922
        Episode_Reward/action_rate: -0.0144
          Episode_Reward/joint_vel: -0.0083
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 40992768
                    Iteration time: 1.78s
                      Time elapsed: 00:14:10
                               ETA: 00:36:50

################################################################################
                     [1m Learning iteration 417/1500 [0m                      

                       Computation: 56521 steps/s (collection: 1.646s, learning 0.093s)
             Mean action noise std: 1.72
          Mean value_function loss: 56.5316
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 35.0070
                       Mean reward: 552.27
               Mean episode length: 239.36
    Episode_Reward/reaching_object: 0.6335
    Episode_Reward/rotating_object: 115.0724
        Episode_Reward/action_rate: -0.0143
          Episode_Reward/joint_vel: -0.0083
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 41091072
                    Iteration time: 1.74s
                      Time elapsed: 00:14:12
                               ETA: 00:36:48

################################################################################
                     [1m Learning iteration 418/1500 [0m                      

                       Computation: 56824 steps/s (collection: 1.621s, learning 0.109s)
             Mean action noise std: 1.72
          Mean value_function loss: 54.0552
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 35.0148
                       Mean reward: 563.52
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6359
    Episode_Reward/rotating_object: 114.9112
        Episode_Reward/action_rate: -0.0144
          Episode_Reward/joint_vel: -0.0083
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 41189376
                    Iteration time: 1.73s
                      Time elapsed: 00:14:13
                               ETA: 00:36:45

################################################################################
                     [1m Learning iteration 419/1500 [0m                      

                       Computation: 57756 steps/s (collection: 1.608s, learning 0.094s)
             Mean action noise std: 1.73
          Mean value_function loss: 54.5639
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 35.0339
                       Mean reward: 563.67
               Mean episode length: 243.80
    Episode_Reward/reaching_object: 0.6422
    Episode_Reward/rotating_object: 116.0463
        Episode_Reward/action_rate: -0.0145
          Episode_Reward/joint_vel: -0.0082
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 41287680
                    Iteration time: 1.70s
                      Time elapsed: 00:14:15
                               ETA: 00:36:42

################################################################################
                     [1m Learning iteration 420/1500 [0m                      

                       Computation: 58544 steps/s (collection: 1.585s, learning 0.094s)
             Mean action noise std: 1.73
          Mean value_function loss: 48.9287
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 35.0507
                       Mean reward: 572.23
               Mean episode length: 245.80
    Episode_Reward/reaching_object: 0.6429
    Episode_Reward/rotating_object: 114.9209
        Episode_Reward/action_rate: -0.0144
          Episode_Reward/joint_vel: -0.0081
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 41385984
                    Iteration time: 1.68s
                      Time elapsed: 00:14:17
                               ETA: 00:36:39

################################################################################
                     [1m Learning iteration 421/1500 [0m                      

                       Computation: 58501 steps/s (collection: 1.582s, learning 0.099s)
             Mean action noise std: 1.73
          Mean value_function loss: 44.6423
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 35.0630
                       Mean reward: 598.03
               Mean episode length: 249.49
    Episode_Reward/reaching_object: 0.6469
    Episode_Reward/rotating_object: 116.5972
        Episode_Reward/action_rate: -0.0145
          Episode_Reward/joint_vel: -0.0081
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 41484288
                    Iteration time: 1.68s
                      Time elapsed: 00:14:19
                               ETA: 00:36:36

################################################################################
                     [1m Learning iteration 422/1500 [0m                      

                       Computation: 58475 steps/s (collection: 1.585s, learning 0.096s)
             Mean action noise std: 1.73
          Mean value_function loss: 41.2158
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 35.0768
                       Mean reward: 583.12
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6449
    Episode_Reward/rotating_object: 113.3309
        Episode_Reward/action_rate: -0.0145
          Episode_Reward/joint_vel: -0.0083
      Episode_Termination/time_out: 17.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 41582592
                    Iteration time: 1.68s
                      Time elapsed: 00:14:20
                               ETA: 00:36:33

################################################################################
                     [1m Learning iteration 423/1500 [0m                      

                       Computation: 59211 steps/s (collection: 1.572s, learning 0.088s)
             Mean action noise std: 1.73
          Mean value_function loss: 51.4114
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 35.0869
                       Mean reward: 600.57
               Mean episode length: 246.11
    Episode_Reward/reaching_object: 0.6330
    Episode_Reward/rotating_object: 112.9319
        Episode_Reward/action_rate: -0.0143
          Episode_Reward/joint_vel: -0.0080
      Episode_Termination/time_out: 17.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 41680896
                    Iteration time: 1.66s
                      Time elapsed: 00:14:22
                               ETA: 00:36:30

################################################################################
                     [1m Learning iteration 424/1500 [0m                      

                       Computation: 56043 steps/s (collection: 1.630s, learning 0.124s)
             Mean action noise std: 1.73
          Mean value_function loss: 49.3774
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 35.0932
                       Mean reward: 580.15
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6311
    Episode_Reward/rotating_object: 111.2613
        Episode_Reward/action_rate: -0.0144
          Episode_Reward/joint_vel: -0.0080
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 41779200
                    Iteration time: 1.75s
                      Time elapsed: 00:14:24
                               ETA: 00:36:27

################################################################################
                     [1m Learning iteration 425/1500 [0m                      

                       Computation: 58098 steps/s (collection: 1.593s, learning 0.099s)
             Mean action noise std: 1.73
          Mean value_function loss: 52.8321
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 35.1063
                       Mean reward: 566.82
               Mean episode length: 243.67
    Episode_Reward/reaching_object: 0.6360
    Episode_Reward/rotating_object: 116.8831
        Episode_Reward/action_rate: -0.0145
          Episode_Reward/joint_vel: -0.0080
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 41877504
                    Iteration time: 1.69s
                      Time elapsed: 00:14:25
                               ETA: 00:36:24

################################################################################
                     [1m Learning iteration 426/1500 [0m                      

                       Computation: 59502 steps/s (collection: 1.564s, learning 0.089s)
             Mean action noise std: 1.73
          Mean value_function loss: 43.8839
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 35.1211
                       Mean reward: 585.01
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6245
    Episode_Reward/rotating_object: 113.7458
        Episode_Reward/action_rate: -0.0143
          Episode_Reward/joint_vel: -0.0079
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 41975808
                    Iteration time: 1.65s
                      Time elapsed: 00:14:27
                               ETA: 00:36:21

################################################################################
                     [1m Learning iteration 427/1500 [0m                      

                       Computation: 57258 steps/s (collection: 1.621s, learning 0.096s)
             Mean action noise std: 1.74
          Mean value_function loss: 51.3793
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 35.1243
                       Mean reward: 590.84
               Mean episode length: 247.74
    Episode_Reward/reaching_object: 0.6277
    Episode_Reward/rotating_object: 114.9479
        Episode_Reward/action_rate: -0.0144
          Episode_Reward/joint_vel: -0.0079
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 42074112
                    Iteration time: 1.72s
                      Time elapsed: 00:14:29
                               ETA: 00:36:19

################################################################################
                     [1m Learning iteration 428/1500 [0m                      

                       Computation: 58968 steps/s (collection: 1.565s, learning 0.102s)
             Mean action noise std: 1.74
          Mean value_function loss: 46.2479
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 35.1378
                       Mean reward: 595.03
               Mean episode length: 248.62
    Episode_Reward/reaching_object: 0.6262
    Episode_Reward/rotating_object: 115.1276
        Episode_Reward/action_rate: -0.0145
          Episode_Reward/joint_vel: -0.0080
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 42172416
                    Iteration time: 1.67s
                      Time elapsed: 00:14:30
                               ETA: 00:36:16

################################################################################
                     [1m Learning iteration 429/1500 [0m                      

                       Computation: 58459 steps/s (collection: 1.582s, learning 0.100s)
             Mean action noise std: 1.74
          Mean value_function loss: 47.9528
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 35.1588
                       Mean reward: 597.28
               Mean episode length: 248.25
    Episode_Reward/reaching_object: 0.6263
    Episode_Reward/rotating_object: 115.1364
        Episode_Reward/action_rate: -0.0146
          Episode_Reward/joint_vel: -0.0083
      Episode_Termination/time_out: 17.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 42270720
                    Iteration time: 1.68s
                      Time elapsed: 00:14:32
                               ETA: 00:36:13

################################################################################
                     [1m Learning iteration 430/1500 [0m                      

                       Computation: 58867 steps/s (collection: 1.577s, learning 0.093s)
             Mean action noise std: 1.74
          Mean value_function loss: 57.6807
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 35.1755
                       Mean reward: 586.10
               Mean episode length: 243.38
    Episode_Reward/reaching_object: 0.6292
    Episode_Reward/rotating_object: 116.1956
        Episode_Reward/action_rate: -0.0145
          Episode_Reward/joint_vel: -0.0081
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 42369024
                    Iteration time: 1.67s
                      Time elapsed: 00:14:34
                               ETA: 00:36:10

################################################################################
                     [1m Learning iteration 431/1500 [0m                      

                       Computation: 58772 steps/s (collection: 1.568s, learning 0.105s)
             Mean action noise std: 1.74
          Mean value_function loss: 59.0188
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 35.1841
                       Mean reward: 611.22
               Mean episode length: 246.98
    Episode_Reward/reaching_object: 0.6431
    Episode_Reward/rotating_object: 118.2165
        Episode_Reward/action_rate: -0.0148
          Episode_Reward/joint_vel: -0.0085
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 42467328
                    Iteration time: 1.67s
                      Time elapsed: 00:14:35
                               ETA: 00:36:07

################################################################################
                     [1m Learning iteration 432/1500 [0m                      

                       Computation: 57500 steps/s (collection: 1.595s, learning 0.115s)
             Mean action noise std: 1.74
          Mean value_function loss: 49.0368
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 35.1973
                       Mean reward: 609.76
               Mean episode length: 247.86
    Episode_Reward/reaching_object: 0.6323
    Episode_Reward/rotating_object: 115.8880
        Episode_Reward/action_rate: -0.0145
          Episode_Reward/joint_vel: -0.0082
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 42565632
                    Iteration time: 1.71s
                      Time elapsed: 00:14:37
                               ETA: 00:36:04

################################################################################
                     [1m Learning iteration 433/1500 [0m                      

                       Computation: 58785 steps/s (collection: 1.577s, learning 0.095s)
             Mean action noise std: 1.74
          Mean value_function loss: 50.4899
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 35.2055
                       Mean reward: 587.68
               Mean episode length: 246.26
    Episode_Reward/reaching_object: 0.6357
    Episode_Reward/rotating_object: 117.2736
        Episode_Reward/action_rate: -0.0146
          Episode_Reward/joint_vel: -0.0083
      Episode_Termination/time_out: 17.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 42663936
                    Iteration time: 1.67s
                      Time elapsed: 00:14:39
                               ETA: 00:36:01

################################################################################
                     [1m Learning iteration 434/1500 [0m                      

                       Computation: 58084 steps/s (collection: 1.597s, learning 0.095s)
             Mean action noise std: 1.75
          Mean value_function loss: 51.9319
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 35.2137
                       Mean reward: 603.79
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6469
    Episode_Reward/rotating_object: 119.5012
        Episode_Reward/action_rate: -0.0148
          Episode_Reward/joint_vel: -0.0086
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 42762240
                    Iteration time: 1.69s
                      Time elapsed: 00:14:40
                               ETA: 00:35:58

################################################################################
                     [1m Learning iteration 435/1500 [0m                      

                       Computation: 57592 steps/s (collection: 1.600s, learning 0.107s)
             Mean action noise std: 1.75
          Mean value_function loss: 55.4111
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 35.2192
                       Mean reward: 597.28
               Mean episode length: 249.39
    Episode_Reward/reaching_object: 0.6432
    Episode_Reward/rotating_object: 119.6417
        Episode_Reward/action_rate: -0.0147
          Episode_Reward/joint_vel: -0.0083
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 42860544
                    Iteration time: 1.71s
                      Time elapsed: 00:14:42
                               ETA: 00:35:56

################################################################################
                     [1m Learning iteration 436/1500 [0m                      

                       Computation: 56521 steps/s (collection: 1.647s, learning 0.093s)
             Mean action noise std: 1.75
          Mean value_function loss: 51.1753
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 35.2231
                       Mean reward: 582.47
               Mean episode length: 246.82
    Episode_Reward/reaching_object: 0.6363
    Episode_Reward/rotating_object: 112.7268
        Episode_Reward/action_rate: -0.0146
          Episode_Reward/joint_vel: -0.0083
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 42958848
                    Iteration time: 1.74s
                      Time elapsed: 00:14:44
                               ETA: 00:35:53

################################################################################
                     [1m Learning iteration 437/1500 [0m                      

                       Computation: 56548 steps/s (collection: 1.628s, learning 0.110s)
             Mean action noise std: 1.75
          Mean value_function loss: 45.9134
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 35.2318
                       Mean reward: 599.07
               Mean episode length: 248.27
    Episode_Reward/reaching_object: 0.6461
    Episode_Reward/rotating_object: 118.6204
        Episode_Reward/action_rate: -0.0146
          Episode_Reward/joint_vel: -0.0081
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 43057152
                    Iteration time: 1.74s
                      Time elapsed: 00:14:46
                               ETA: 00:35:50

################################################################################
                     [1m Learning iteration 438/1500 [0m                      

                       Computation: 57919 steps/s (collection: 1.579s, learning 0.119s)
             Mean action noise std: 1.75
          Mean value_function loss: 56.5511
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 35.2405
                       Mean reward: 593.13
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6580
    Episode_Reward/rotating_object: 121.3559
        Episode_Reward/action_rate: -0.0149
          Episode_Reward/joint_vel: -0.0087
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 43155456
                    Iteration time: 1.70s
                      Time elapsed: 00:14:47
                               ETA: 00:35:47

################################################################################
                     [1m Learning iteration 439/1500 [0m                      

                       Computation: 58879 steps/s (collection: 1.575s, learning 0.095s)
             Mean action noise std: 1.75
          Mean value_function loss: 45.3842
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 35.2446
                       Mean reward: 594.09
               Mean episode length: 247.68
    Episode_Reward/reaching_object: 0.6426
    Episode_Reward/rotating_object: 115.4259
        Episode_Reward/action_rate: -0.0147
          Episode_Reward/joint_vel: -0.0083
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 43253760
                    Iteration time: 1.67s
                      Time elapsed: 00:14:49
                               ETA: 00:35:44

################################################################################
                     [1m Learning iteration 440/1500 [0m                      

                       Computation: 58536 steps/s (collection: 1.588s, learning 0.092s)
             Mean action noise std: 1.75
          Mean value_function loss: 41.2804
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 35.2439
                       Mean reward: 594.87
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6462
    Episode_Reward/rotating_object: 120.7483
        Episode_Reward/action_rate: -0.0147
          Episode_Reward/joint_vel: -0.0082
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 43352064
                    Iteration time: 1.68s
                      Time elapsed: 00:14:51
                               ETA: 00:35:42

################################################################################
                     [1m Learning iteration 441/1500 [0m                      

                       Computation: 54807 steps/s (collection: 1.674s, learning 0.120s)
             Mean action noise std: 1.75
          Mean value_function loss: 44.4591
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 35.2458
                       Mean reward: 620.53
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6411
    Episode_Reward/rotating_object: 121.2972
        Episode_Reward/action_rate: -0.0147
          Episode_Reward/joint_vel: -0.0080
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 43450368
                    Iteration time: 1.79s
                      Time elapsed: 00:14:52
                               ETA: 00:35:39

################################################################################
                     [1m Learning iteration 442/1500 [0m                      

                       Computation: 58034 steps/s (collection: 1.601s, learning 0.093s)
             Mean action noise std: 1.75
          Mean value_function loss: 39.2338
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 35.2564
                       Mean reward: 573.95
               Mean episode length: 245.80
    Episode_Reward/reaching_object: 0.6335
    Episode_Reward/rotating_object: 117.9667
        Episode_Reward/action_rate: -0.0148
          Episode_Reward/joint_vel: -0.0080
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 43548672
                    Iteration time: 1.69s
                      Time elapsed: 00:14:54
                               ETA: 00:35:36

################################################################################
                     [1m Learning iteration 443/1500 [0m                      

                       Computation: 56343 steps/s (collection: 1.637s, learning 0.108s)
             Mean action noise std: 1.75
          Mean value_function loss: 43.0717
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 35.2706
                       Mean reward: 608.35
               Mean episode length: 247.88
    Episode_Reward/reaching_object: 0.6271
    Episode_Reward/rotating_object: 117.2311
        Episode_Reward/action_rate: -0.0147
          Episode_Reward/joint_vel: -0.0082
      Episode_Termination/time_out: 17.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 43646976
                    Iteration time: 1.74s
                      Time elapsed: 00:14:56
                               ETA: 00:35:34

################################################################################
                     [1m Learning iteration 444/1500 [0m                      

                       Computation: 58276 steps/s (collection: 1.581s, learning 0.106s)
             Mean action noise std: 1.75
          Mean value_function loss: 47.0163
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 35.2781
                       Mean reward: 609.28
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6311
    Episode_Reward/rotating_object: 121.5565
        Episode_Reward/action_rate: -0.0148
          Episode_Reward/joint_vel: -0.0082
      Episode_Termination/time_out: 17.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 43745280
                    Iteration time: 1.69s
                      Time elapsed: 00:14:58
                               ETA: 00:35:31

################################################################################
                     [1m Learning iteration 445/1500 [0m                      

                       Computation: 59506 steps/s (collection: 1.562s, learning 0.090s)
             Mean action noise std: 1.75
          Mean value_function loss: 49.8609
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 35.2808
                       Mean reward: 597.17
               Mean episode length: 245.77
    Episode_Reward/reaching_object: 0.6173
    Episode_Reward/rotating_object: 114.5835
        Episode_Reward/action_rate: -0.0147
          Episode_Reward/joint_vel: -0.0080
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 43843584
                    Iteration time: 1.65s
                      Time elapsed: 00:14:59
                               ETA: 00:35:28

################################################################################
                     [1m Learning iteration 446/1500 [0m                      

                       Computation: 59071 steps/s (collection: 1.569s, learning 0.096s)
             Mean action noise std: 1.76
          Mean value_function loss: 46.0359
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 35.2873
                       Mean reward: 607.99
               Mean episode length: 247.90
    Episode_Reward/reaching_object: 0.6221
    Episode_Reward/rotating_object: 120.3703
        Episode_Reward/action_rate: -0.0149
          Episode_Reward/joint_vel: -0.0081
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 43941888
                    Iteration time: 1.66s
                      Time elapsed: 00:15:01
                               ETA: 00:35:25

################################################################################
                     [1m Learning iteration 447/1500 [0m                      

                       Computation: 57850 steps/s (collection: 1.567s, learning 0.132s)
             Mean action noise std: 1.76
          Mean value_function loss: 48.0386
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 35.2997
                       Mean reward: 596.07
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6280
    Episode_Reward/rotating_object: 117.8183
        Episode_Reward/action_rate: -0.0149
          Episode_Reward/joint_vel: -0.0082
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 44040192
                    Iteration time: 1.70s
                      Time elapsed: 00:15:03
                               ETA: 00:35:22

################################################################################
                     [1m Learning iteration 448/1500 [0m                      

                       Computation: 59112 steps/s (collection: 1.565s, learning 0.098s)
             Mean action noise std: 1.76
          Mean value_function loss: 50.3807
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 35.3092
                       Mean reward: 624.19
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6199
    Episode_Reward/rotating_object: 118.7383
        Episode_Reward/action_rate: -0.0149
          Episode_Reward/joint_vel: -0.0084
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 44138496
                    Iteration time: 1.66s
                      Time elapsed: 00:15:04
                               ETA: 00:35:19

################################################################################
                     [1m Learning iteration 449/1500 [0m                      

                       Computation: 59063 steps/s (collection: 1.555s, learning 0.110s)
             Mean action noise std: 1.76
          Mean value_function loss: 46.7013
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 35.3232
                       Mean reward: 622.80
               Mean episode length: 247.66
    Episode_Reward/reaching_object: 0.6313
    Episode_Reward/rotating_object: 122.8889
        Episode_Reward/action_rate: -0.0150
          Episode_Reward/joint_vel: -0.0085
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 44236800
                    Iteration time: 1.66s
                      Time elapsed: 00:15:06
                               ETA: 00:35:17

################################################################################
                     [1m Learning iteration 450/1500 [0m                      

                       Computation: 57882 steps/s (collection: 1.586s, learning 0.112s)
             Mean action noise std: 1.76
          Mean value_function loss: 50.4581
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 35.3414
                       Mean reward: 610.12
               Mean episode length: 248.00
    Episode_Reward/reaching_object: 0.6333
    Episode_Reward/rotating_object: 122.6451
        Episode_Reward/action_rate: -0.0150
          Episode_Reward/joint_vel: -0.0081
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 44335104
                    Iteration time: 1.70s
                      Time elapsed: 00:15:08
                               ETA: 00:35:14

################################################################################
                     [1m Learning iteration 451/1500 [0m                      

                       Computation: 55799 steps/s (collection: 1.646s, learning 0.116s)
             Mean action noise std: 1.76
          Mean value_function loss: 50.3421
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 35.3494
                       Mean reward: 599.02
               Mean episode length: 247.68
    Episode_Reward/reaching_object: 0.6290
    Episode_Reward/rotating_object: 118.6940
        Episode_Reward/action_rate: -0.0149
          Episode_Reward/joint_vel: -0.0080
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 44433408
                    Iteration time: 1.76s
                      Time elapsed: 00:15:09
                               ETA: 00:35:11

################################################################################
                     [1m Learning iteration 452/1500 [0m                      

                       Computation: 58871 steps/s (collection: 1.575s, learning 0.095s)
             Mean action noise std: 1.76
          Mean value_function loss: 46.1944
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 35.3557
                       Mean reward: 595.16
               Mean episode length: 245.56
    Episode_Reward/reaching_object: 0.6305
    Episode_Reward/rotating_object: 121.0397
        Episode_Reward/action_rate: -0.0149
          Episode_Reward/joint_vel: -0.0079
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 44531712
                    Iteration time: 1.67s
                      Time elapsed: 00:15:11
                               ETA: 00:35:08

################################################################################
                     [1m Learning iteration 453/1500 [0m                      

                       Computation: 55774 steps/s (collection: 1.656s, learning 0.107s)
             Mean action noise std: 1.76
          Mean value_function loss: 43.1540
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 35.3646
                       Mean reward: 593.54
               Mean episode length: 245.87
    Episode_Reward/reaching_object: 0.6342
    Episode_Reward/rotating_object: 120.0050
        Episode_Reward/action_rate: -0.0150
          Episode_Reward/joint_vel: -0.0080
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 44630016
                    Iteration time: 1.76s
                      Time elapsed: 00:15:13
                               ETA: 00:35:06

################################################################################
                     [1m Learning iteration 454/1500 [0m                      

                       Computation: 58280 steps/s (collection: 1.594s, learning 0.093s)
             Mean action noise std: 1.77
          Mean value_function loss: 39.2622
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 35.3808
                       Mean reward: 619.71
               Mean episode length: 248.43
    Episode_Reward/reaching_object: 0.6396
    Episode_Reward/rotating_object: 122.7870
        Episode_Reward/action_rate: -0.0151
          Episode_Reward/joint_vel: -0.0081
      Episode_Termination/time_out: 18.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 44728320
                    Iteration time: 1.69s
                      Time elapsed: 00:15:15
                               ETA: 00:35:03

################################################################################
                     [1m Learning iteration 455/1500 [0m                      

                       Computation: 59291 steps/s (collection: 1.565s, learning 0.093s)
             Mean action noise std: 1.77
          Mean value_function loss: 50.6475
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 35.3993
                       Mean reward: 595.95
               Mean episode length: 248.04
    Episode_Reward/reaching_object: 0.6392
    Episode_Reward/rotating_object: 122.8303
        Episode_Reward/action_rate: -0.0151
          Episode_Reward/joint_vel: -0.0080
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 44826624
                    Iteration time: 1.66s
                      Time elapsed: 00:15:16
                               ETA: 00:35:00

################################################################################
                     [1m Learning iteration 456/1500 [0m                      

                       Computation: 57699 steps/s (collection: 1.599s, learning 0.105s)
             Mean action noise std: 1.77
          Mean value_function loss: 46.7705
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 35.4180
                       Mean reward: 609.22
               Mean episode length: 248.04
    Episode_Reward/reaching_object: 0.6409
    Episode_Reward/rotating_object: 120.0000
        Episode_Reward/action_rate: -0.0151
          Episode_Reward/joint_vel: -0.0079
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 44924928
                    Iteration time: 1.70s
                      Time elapsed: 00:15:18
                               ETA: 00:34:57

################################################################################
                     [1m Learning iteration 457/1500 [0m                      

                       Computation: 58698 steps/s (collection: 1.577s, learning 0.098s)
             Mean action noise std: 1.77
          Mean value_function loss: 43.3041
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 35.4253
                       Mean reward: 595.01
               Mean episode length: 246.65
    Episode_Reward/reaching_object: 0.6400
    Episode_Reward/rotating_object: 122.4893
        Episode_Reward/action_rate: -0.0151
          Episode_Reward/joint_vel: -0.0079
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 45023232
                    Iteration time: 1.67s
                      Time elapsed: 00:15:20
                               ETA: 00:34:55

################################################################################
                     [1m Learning iteration 458/1500 [0m                      

                       Computation: 57763 steps/s (collection: 1.602s, learning 0.100s)
             Mean action noise std: 1.77
          Mean value_function loss: 45.8658
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 35.4326
                       Mean reward: 568.67
               Mean episode length: 242.53
    Episode_Reward/reaching_object: 0.6402
    Episode_Reward/rotating_object: 119.5463
        Episode_Reward/action_rate: -0.0152
          Episode_Reward/joint_vel: -0.0084
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 45121536
                    Iteration time: 1.70s
                      Time elapsed: 00:15:21
                               ETA: 00:34:52

################################################################################
                     [1m Learning iteration 459/1500 [0m                      

                       Computation: 58903 steps/s (collection: 1.576s, learning 0.093s)
             Mean action noise std: 1.77
          Mean value_function loss: 47.5258
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 35.4442
                       Mean reward: 610.43
               Mean episode length: 243.68
    Episode_Reward/reaching_object: 0.6414
    Episode_Reward/rotating_object: 123.0705
        Episode_Reward/action_rate: -0.0151
          Episode_Reward/joint_vel: -0.0081
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 45219840
                    Iteration time: 1.67s
                      Time elapsed: 00:15:23
                               ETA: 00:34:49

################################################################################
                     [1m Learning iteration 460/1500 [0m                      

                       Computation: 59443 steps/s (collection: 1.559s, learning 0.095s)
             Mean action noise std: 1.77
          Mean value_function loss: 46.4700
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 35.4592
                       Mean reward: 586.68
               Mean episode length: 245.57
    Episode_Reward/reaching_object: 0.6437
    Episode_Reward/rotating_object: 121.0925
        Episode_Reward/action_rate: -0.0152
          Episode_Reward/joint_vel: -0.0081
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 45318144
                    Iteration time: 1.65s
                      Time elapsed: 00:15:25
                               ETA: 00:34:46

################################################################################
                     [1m Learning iteration 461/1500 [0m                      

                       Computation: 58828 steps/s (collection: 1.570s, learning 0.101s)
             Mean action noise std: 1.78
          Mean value_function loss: 40.6808
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 35.4715
                       Mean reward: 586.12
               Mean episode length: 248.00
    Episode_Reward/reaching_object: 0.6451
    Episode_Reward/rotating_object: 118.0654
        Episode_Reward/action_rate: -0.0152
          Episode_Reward/joint_vel: -0.0080
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 45416448
                    Iteration time: 1.67s
                      Time elapsed: 00:15:26
                               ETA: 00:34:44

################################################################################
                     [1m Learning iteration 462/1500 [0m                      

                       Computation: 59120 steps/s (collection: 1.571s, learning 0.092s)
             Mean action noise std: 1.78
          Mean value_function loss: 42.2042
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 35.4829
                       Mean reward: 612.41
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6498
    Episode_Reward/rotating_object: 121.5555
        Episode_Reward/action_rate: -0.0153
          Episode_Reward/joint_vel: -0.0079
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 45514752
                    Iteration time: 1.66s
                      Time elapsed: 00:15:28
                               ETA: 00:34:41

################################################################################
                     [1m Learning iteration 463/1500 [0m                      

                       Computation: 58750 steps/s (collection: 1.585s, learning 0.089s)
             Mean action noise std: 1.78
          Mean value_function loss: 50.8803
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 35.4957
                       Mean reward: 636.02
               Mean episode length: 247.72
    Episode_Reward/reaching_object: 0.6533
    Episode_Reward/rotating_object: 123.9058
        Episode_Reward/action_rate: -0.0153
          Episode_Reward/joint_vel: -0.0079
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 45613056
                    Iteration time: 1.67s
                      Time elapsed: 00:15:30
                               ETA: 00:34:38

################################################################################
                     [1m Learning iteration 464/1500 [0m                      

                       Computation: 58759 steps/s (collection: 1.567s, learning 0.106s)
             Mean action noise std: 1.78
          Mean value_function loss: 48.3408
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 35.5058
                       Mean reward: 604.26
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6561
    Episode_Reward/rotating_object: 122.4814
        Episode_Reward/action_rate: -0.0153
          Episode_Reward/joint_vel: -0.0081
      Episode_Termination/time_out: 18.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 45711360
                    Iteration time: 1.67s
                      Time elapsed: 00:15:31
                               ETA: 00:34:35

################################################################################
                     [1m Learning iteration 465/1500 [0m                      

                       Computation: 58587 steps/s (collection: 1.584s, learning 0.094s)
             Mean action noise std: 1.78
          Mean value_function loss: 49.5772
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 35.5160
                       Mean reward: 585.96
               Mean episode length: 242.69
    Episode_Reward/reaching_object: 0.6457
    Episode_Reward/rotating_object: 117.8528
        Episode_Reward/action_rate: -0.0151
          Episode_Reward/joint_vel: -0.0076
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 45809664
                    Iteration time: 1.68s
                      Time elapsed: 00:15:33
                               ETA: 00:34:33

################################################################################
                     [1m Learning iteration 466/1500 [0m                      

                       Computation: 57061 steps/s (collection: 1.610s, learning 0.112s)
             Mean action noise std: 1.78
          Mean value_function loss: 50.2168
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 35.5237
                       Mean reward: 626.67
               Mean episode length: 244.80
    Episode_Reward/reaching_object: 0.6551
    Episode_Reward/rotating_object: 124.1108
        Episode_Reward/action_rate: -0.0152
          Episode_Reward/joint_vel: -0.0079
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 45907968
                    Iteration time: 1.72s
                      Time elapsed: 00:15:35
                               ETA: 00:34:30

################################################################################
                     [1m Learning iteration 467/1500 [0m                      

                       Computation: 59017 steps/s (collection: 1.562s, learning 0.104s)
             Mean action noise std: 1.78
          Mean value_function loss: 47.7377
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 35.5366
                       Mean reward: 636.70
               Mean episode length: 244.80
    Episode_Reward/reaching_object: 0.6501
    Episode_Reward/rotating_object: 121.6659
        Episode_Reward/action_rate: -0.0152
          Episode_Reward/joint_vel: -0.0081
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 46006272
                    Iteration time: 1.67s
                      Time elapsed: 00:15:36
                               ETA: 00:34:27

################################################################################
                     [1m Learning iteration 468/1500 [0m                      

                       Computation: 57525 steps/s (collection: 1.598s, learning 0.111s)
             Mean action noise std: 1.79
          Mean value_function loss: 48.3272
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 35.5525
                       Mean reward: 648.92
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6537
    Episode_Reward/rotating_object: 123.7704
        Episode_Reward/action_rate: -0.0153
          Episode_Reward/joint_vel: -0.0077
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 46104576
                    Iteration time: 1.71s
                      Time elapsed: 00:15:38
                               ETA: 00:34:25

################################################################################
                     [1m Learning iteration 469/1500 [0m                      

                       Computation: 57792 steps/s (collection: 1.578s, learning 0.123s)
             Mean action noise std: 1.79
          Mean value_function loss: 43.3110
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 35.5677
                       Mean reward: 641.80
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6536
    Episode_Reward/rotating_object: 124.7138
        Episode_Reward/action_rate: -0.0153
          Episode_Reward/joint_vel: -0.0080
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 46202880
                    Iteration time: 1.70s
                      Time elapsed: 00:15:40
                               ETA: 00:34:22

################################################################################
                     [1m Learning iteration 470/1500 [0m                      

                       Computation: 58460 steps/s (collection: 1.582s, learning 0.099s)
             Mean action noise std: 1.79
          Mean value_function loss: 44.5778
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 35.5799
                       Mean reward: 633.69
               Mean episode length: 248.03
    Episode_Reward/reaching_object: 0.6510
    Episode_Reward/rotating_object: 122.1463
        Episode_Reward/action_rate: -0.0153
          Episode_Reward/joint_vel: -0.0079
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 46301184
                    Iteration time: 1.68s
                      Time elapsed: 00:15:41
                               ETA: 00:34:19

################################################################################
                     [1m Learning iteration 471/1500 [0m                      

                       Computation: 58864 steps/s (collection: 1.571s, learning 0.099s)
             Mean action noise std: 1.79
          Mean value_function loss: 39.2006
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 35.5908
                       Mean reward: 635.27
               Mean episode length: 248.76
    Episode_Reward/reaching_object: 0.6564
    Episode_Reward/rotating_object: 123.9482
        Episode_Reward/action_rate: -0.0154
          Episode_Reward/joint_vel: -0.0078
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 46399488
                    Iteration time: 1.67s
                      Time elapsed: 00:15:43
                               ETA: 00:34:17

################################################################################
                     [1m Learning iteration 472/1500 [0m                      

                       Computation: 57578 steps/s (collection: 1.607s, learning 0.100s)
             Mean action noise std: 1.79
          Mean value_function loss: 40.3416
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 35.5937
                       Mean reward: 598.77
               Mean episode length: 247.99
    Episode_Reward/reaching_object: 0.6506
    Episode_Reward/rotating_object: 122.6238
        Episode_Reward/action_rate: -0.0154
          Episode_Reward/joint_vel: -0.0081
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 46497792
                    Iteration time: 1.71s
                      Time elapsed: 00:15:45
                               ETA: 00:34:14

################################################################################
                     [1m Learning iteration 473/1500 [0m                      

                       Computation: 58933 steps/s (collection: 1.561s, learning 0.107s)
             Mean action noise std: 1.79
          Mean value_function loss: 42.5705
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 35.6001
                       Mean reward: 598.61
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6431
    Episode_Reward/rotating_object: 118.7657
        Episode_Reward/action_rate: -0.0153
          Episode_Reward/joint_vel: -0.0078
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 46596096
                    Iteration time: 1.67s
                      Time elapsed: 00:15:46
                               ETA: 00:34:11

################################################################################
                     [1m Learning iteration 474/1500 [0m                      

                       Computation: 59450 steps/s (collection: 1.560s, learning 0.093s)
             Mean action noise std: 1.79
          Mean value_function loss: 34.9092
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 35.6143
                       Mean reward: 645.39
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6591
    Episode_Reward/rotating_object: 125.3193
        Episode_Reward/action_rate: -0.0156
          Episode_Reward/joint_vel: -0.0082
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 46694400
                    Iteration time: 1.65s
                      Time elapsed: 00:15:48
                               ETA: 00:34:09

################################################################################
                     [1m Learning iteration 475/1500 [0m                      

                       Computation: 57801 steps/s (collection: 1.601s, learning 0.100s)
             Mean action noise std: 1.79
          Mean value_function loss: 46.6436
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 35.6251
                       Mean reward: 604.87
               Mean episode length: 247.15
    Episode_Reward/reaching_object: 0.6460
    Episode_Reward/rotating_object: 123.9267
        Episode_Reward/action_rate: -0.0154
          Episode_Reward/joint_vel: -0.0082
      Episode_Termination/time_out: 17.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 46792704
                    Iteration time: 1.70s
                      Time elapsed: 00:15:50
                               ETA: 00:34:06

################################################################################
                     [1m Learning iteration 476/1500 [0m                      

                       Computation: 58901 steps/s (collection: 1.577s, learning 0.092s)
             Mean action noise std: 1.80
          Mean value_function loss: 47.9460
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 35.6381
                       Mean reward: 648.68
               Mean episode length: 248.38
    Episode_Reward/reaching_object: 0.6506
    Episode_Reward/rotating_object: 125.9946
        Episode_Reward/action_rate: -0.0155
          Episode_Reward/joint_vel: -0.0079
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 46891008
                    Iteration time: 1.67s
                      Time elapsed: 00:15:51
                               ETA: 00:34:03

################################################################################
                     [1m Learning iteration 477/1500 [0m                      

                       Computation: 59156 steps/s (collection: 1.565s, learning 0.097s)
             Mean action noise std: 1.80
          Mean value_function loss: 48.4790
               Mean surrogate loss: 0.0001
                 Mean entropy loss: 35.6483
                       Mean reward: 620.34
               Mean episode length: 245.51
    Episode_Reward/reaching_object: 0.6465
    Episode_Reward/rotating_object: 122.2741
        Episode_Reward/action_rate: -0.0155
          Episode_Reward/joint_vel: -0.0083
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 46989312
                    Iteration time: 1.66s
                      Time elapsed: 00:15:53
                               ETA: 00:34:00

################################################################################
                     [1m Learning iteration 478/1500 [0m                      

                       Computation: 58456 steps/s (collection: 1.583s, learning 0.099s)
             Mean action noise std: 1.80
          Mean value_function loss: 44.2548
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 35.6564
                       Mean reward: 604.78
               Mean episode length: 241.62
    Episode_Reward/reaching_object: 0.6497
    Episode_Reward/rotating_object: 122.7019
        Episode_Reward/action_rate: -0.0156
          Episode_Reward/joint_vel: -0.0082
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 47087616
                    Iteration time: 1.68s
                      Time elapsed: 00:15:55
                               ETA: 00:33:58

################################################################################
                     [1m Learning iteration 479/1500 [0m                      

                       Computation: 58721 steps/s (collection: 1.582s, learning 0.092s)
             Mean action noise std: 1.80
          Mean value_function loss: 44.0978
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 35.6756
                       Mean reward: 627.96
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6582
    Episode_Reward/rotating_object: 124.8363
        Episode_Reward/action_rate: -0.0157
          Episode_Reward/joint_vel: -0.0081
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 47185920
                    Iteration time: 1.67s
                      Time elapsed: 00:15:56
                               ETA: 00:33:55

################################################################################
                     [1m Learning iteration 480/1500 [0m                      

                       Computation: 57166 steps/s (collection: 1.618s, learning 0.102s)
             Mean action noise std: 1.80
          Mean value_function loss: 44.2572
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 35.6904
                       Mean reward: 593.49
               Mean episode length: 244.83
    Episode_Reward/reaching_object: 0.6498
    Episode_Reward/rotating_object: 123.8764
        Episode_Reward/action_rate: -0.0155
          Episode_Reward/joint_vel: -0.0081
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 47284224
                    Iteration time: 1.72s
                      Time elapsed: 00:15:58
                               ETA: 00:33:53

################################################################################
                     [1m Learning iteration 481/1500 [0m                      

                       Computation: 58168 steps/s (collection: 1.601s, learning 0.089s)
             Mean action noise std: 1.80
          Mean value_function loss: 45.7144
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 35.6973
                       Mean reward: 622.45
               Mean episode length: 248.71
    Episode_Reward/reaching_object: 0.6466
    Episode_Reward/rotating_object: 120.9853
        Episode_Reward/action_rate: -0.0155
          Episode_Reward/joint_vel: -0.0080
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 47382528
                    Iteration time: 1.69s
                      Time elapsed: 00:16:00
                               ETA: 00:33:50

################################################################################
                     [1m Learning iteration 482/1500 [0m                      

                       Computation: 56980 steps/s (collection: 1.620s, learning 0.106s)
             Mean action noise std: 1.80
          Mean value_function loss: 41.3513
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 35.7066
                       Mean reward: 598.05
               Mean episode length: 237.40
    Episode_Reward/reaching_object: 0.6503
    Episode_Reward/rotating_object: 124.5199
        Episode_Reward/action_rate: -0.0155
          Episode_Reward/joint_vel: -0.0083
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 47480832
                    Iteration time: 1.73s
                      Time elapsed: 00:16:02
                               ETA: 00:33:47

################################################################################
                     [1m Learning iteration 483/1500 [0m                      

                       Computation: 58173 steps/s (collection: 1.588s, learning 0.102s)
             Mean action noise std: 1.81
          Mean value_function loss: 38.4040
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 35.7189
                       Mean reward: 648.88
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6600
    Episode_Reward/rotating_object: 124.1930
        Episode_Reward/action_rate: -0.0157
          Episode_Reward/joint_vel: -0.0083
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 47579136
                    Iteration time: 1.69s
                      Time elapsed: 00:16:03
                               ETA: 00:33:45

################################################################################
                     [1m Learning iteration 484/1500 [0m                      

                       Computation: 57582 steps/s (collection: 1.596s, learning 0.112s)
             Mean action noise std: 1.81
          Mean value_function loss: 38.4547
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 35.7275
                       Mean reward: 625.71
               Mean episode length: 248.02
    Episode_Reward/reaching_object: 0.6613
    Episode_Reward/rotating_object: 124.3472
        Episode_Reward/action_rate: -0.0157
          Episode_Reward/joint_vel: -0.0083
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 47677440
                    Iteration time: 1.71s
                      Time elapsed: 00:16:05
                               ETA: 00:33:42

################################################################################
                     [1m Learning iteration 485/1500 [0m                      

                       Computation: 56585 steps/s (collection: 1.621s, learning 0.116s)
             Mean action noise std: 1.81
          Mean value_function loss: 44.7135
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 35.7378
                       Mean reward: 619.27
               Mean episode length: 246.19
    Episode_Reward/reaching_object: 0.6544
    Episode_Reward/rotating_object: 123.7347
        Episode_Reward/action_rate: -0.0157
          Episode_Reward/joint_vel: -0.0080
      Episode_Termination/time_out: 17.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 47775744
                    Iteration time: 1.74s
                      Time elapsed: 00:16:07
                               ETA: 00:33:40

################################################################################
                     [1m Learning iteration 486/1500 [0m                      

                       Computation: 58111 steps/s (collection: 1.588s, learning 0.104s)
             Mean action noise std: 1.81
          Mean value_function loss: 41.5435
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 35.7585
                       Mean reward: 624.59
               Mean episode length: 245.90
    Episode_Reward/reaching_object: 0.6516
    Episode_Reward/rotating_object: 122.4846
        Episode_Reward/action_rate: -0.0155
          Episode_Reward/joint_vel: -0.0078
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 47874048
                    Iteration time: 1.69s
                      Time elapsed: 00:16:08
                               ETA: 00:33:37

################################################################################
                     [1m Learning iteration 487/1500 [0m                      

                       Computation: 57716 steps/s (collection: 1.598s, learning 0.105s)
             Mean action noise std: 1.81
          Mean value_function loss: 53.6146
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 35.7764
                       Mean reward: 620.81
               Mean episode length: 245.95
    Episode_Reward/reaching_object: 0.6637
    Episode_Reward/rotating_object: 125.1594
        Episode_Reward/action_rate: -0.0157
          Episode_Reward/joint_vel: -0.0079
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 47972352
                    Iteration time: 1.70s
                      Time elapsed: 00:16:10
                               ETA: 00:33:34

################################################################################
                     [1m Learning iteration 488/1500 [0m                      

                       Computation: 58313 steps/s (collection: 1.577s, learning 0.109s)
             Mean action noise std: 1.81
          Mean value_function loss: 45.6168
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 35.7915
                       Mean reward: 585.36
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6658
    Episode_Reward/rotating_object: 124.6118
        Episode_Reward/action_rate: -0.0157
          Episode_Reward/joint_vel: -0.0080
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 48070656
                    Iteration time: 1.69s
                      Time elapsed: 00:16:12
                               ETA: 00:33:32

################################################################################
                     [1m Learning iteration 489/1500 [0m                      

                       Computation: 57502 steps/s (collection: 1.603s, learning 0.107s)
             Mean action noise std: 1.82
          Mean value_function loss: 43.7555
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 35.8076
                       Mean reward: 622.98
               Mean episode length: 247.74
    Episode_Reward/reaching_object: 0.6704
    Episode_Reward/rotating_object: 125.8568
        Episode_Reward/action_rate: -0.0158
          Episode_Reward/joint_vel: -0.0080
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 48168960
                    Iteration time: 1.71s
                      Time elapsed: 00:16:14
                               ETA: 00:33:29

################################################################################
                     [1m Learning iteration 490/1500 [0m                      

                       Computation: 58170 steps/s (collection: 1.598s, learning 0.092s)
             Mean action noise std: 1.82
          Mean value_function loss: 37.8476
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 35.8274
                       Mean reward: 671.34
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6768
    Episode_Reward/rotating_object: 129.3336
        Episode_Reward/action_rate: -0.0159
          Episode_Reward/joint_vel: -0.0081
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 48267264
                    Iteration time: 1.69s
                      Time elapsed: 00:16:15
                               ETA: 00:33:27

################################################################################
                     [1m Learning iteration 491/1500 [0m                      

                       Computation: 58940 steps/s (collection: 1.576s, learning 0.092s)
             Mean action noise std: 1.82
          Mean value_function loss: 36.7733
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 35.8481
                       Mean reward: 638.48
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6791
    Episode_Reward/rotating_object: 128.9124
        Episode_Reward/action_rate: -0.0160
          Episode_Reward/joint_vel: -0.0081
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 48365568
                    Iteration time: 1.67s
                      Time elapsed: 00:16:17
                               ETA: 00:33:24

################################################################################
                     [1m Learning iteration 492/1500 [0m                      

                       Computation: 59110 steps/s (collection: 1.558s, learning 0.105s)
             Mean action noise std: 1.82
          Mean value_function loss: 38.7848
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 35.8641
                       Mean reward: 662.27
               Mean episode length: 247.73
    Episode_Reward/reaching_object: 0.6791
    Episode_Reward/rotating_object: 130.3249
        Episode_Reward/action_rate: -0.0160
          Episode_Reward/joint_vel: -0.0081
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 48463872
                    Iteration time: 1.66s
                      Time elapsed: 00:16:19
                               ETA: 00:33:21

################################################################################
                     [1m Learning iteration 493/1500 [0m                      

                       Computation: 58054 steps/s (collection: 1.594s, learning 0.099s)
             Mean action noise std: 1.82
          Mean value_function loss: 39.7289
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 35.8819
                       Mean reward: 632.11
               Mean episode length: 248.25
    Episode_Reward/reaching_object: 0.6749
    Episode_Reward/rotating_object: 128.7308
        Episode_Reward/action_rate: -0.0160
          Episode_Reward/joint_vel: -0.0081
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 48562176
                    Iteration time: 1.69s
                      Time elapsed: 00:16:20
                               ETA: 00:33:19

################################################################################
                     [1m Learning iteration 494/1500 [0m                      

                       Computation: 58158 steps/s (collection: 1.598s, learning 0.092s)
             Mean action noise std: 1.83
          Mean value_function loss: 42.2986
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 35.8984
                       Mean reward: 618.43
               Mean episode length: 244.18
    Episode_Reward/reaching_object: 0.6692
    Episode_Reward/rotating_object: 125.3335
        Episode_Reward/action_rate: -0.0159
          Episode_Reward/joint_vel: -0.0082
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 48660480
                    Iteration time: 1.69s
                      Time elapsed: 00:16:22
                               ETA: 00:33:16

################################################################################
                     [1m Learning iteration 495/1500 [0m                      

                       Computation: 57361 steps/s (collection: 1.611s, learning 0.103s)
             Mean action noise std: 1.83
          Mean value_function loss: 32.1112
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 35.9098
                       Mean reward: 632.88
               Mean episode length: 248.16
    Episode_Reward/reaching_object: 0.6683
    Episode_Reward/rotating_object: 126.8865
        Episode_Reward/action_rate: -0.0159
          Episode_Reward/joint_vel: -0.0080
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 48758784
                    Iteration time: 1.71s
                      Time elapsed: 00:16:24
                               ETA: 00:33:14

################################################################################
                     [1m Learning iteration 496/1500 [0m                      

                       Computation: 59750 steps/s (collection: 1.552s, learning 0.094s)
             Mean action noise std: 1.83
          Mean value_function loss: 39.1502
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 35.9172
                       Mean reward: 652.06
               Mean episode length: 245.63
    Episode_Reward/reaching_object: 0.6652
    Episode_Reward/rotating_object: 125.3032
        Episode_Reward/action_rate: -0.0160
          Episode_Reward/joint_vel: -0.0080
      Episode_Termination/time_out: 17.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 48857088
                    Iteration time: 1.65s
                      Time elapsed: 00:16:25
                               ETA: 00:33:11

################################################################################
                     [1m Learning iteration 497/1500 [0m                      

                       Computation: 58338 steps/s (collection: 1.592s, learning 0.093s)
             Mean action noise std: 1.83
          Mean value_function loss: 44.0097
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 35.9276
                       Mean reward: 629.81
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6711
    Episode_Reward/rotating_object: 127.1725
        Episode_Reward/action_rate: -0.0161
          Episode_Reward/joint_vel: -0.0079
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 48955392
                    Iteration time: 1.69s
                      Time elapsed: 00:16:27
                               ETA: 00:33:08

################################################################################
                     [1m Learning iteration 498/1500 [0m                      

                       Computation: 57907 steps/s (collection: 1.594s, learning 0.104s)
             Mean action noise std: 1.83
          Mean value_function loss: 40.1209
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 35.9416
                       Mean reward: 648.39
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6689
    Episode_Reward/rotating_object: 127.7089
        Episode_Reward/action_rate: -0.0161
          Episode_Reward/joint_vel: -0.0078
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 49053696
                    Iteration time: 1.70s
                      Time elapsed: 00:16:29
                               ETA: 00:33:06

################################################################################
                     [1m Learning iteration 499/1500 [0m                      

                       Computation: 58307 steps/s (collection: 1.593s, learning 0.093s)
             Mean action noise std: 1.83
          Mean value_function loss: 44.5765
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 35.9536
                       Mean reward: 633.45
               Mean episode length: 246.16
    Episode_Reward/reaching_object: 0.6718
    Episode_Reward/rotating_object: 129.0467
        Episode_Reward/action_rate: -0.0161
          Episode_Reward/joint_vel: -0.0083
      Episode_Termination/time_out: 17.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 49152000
                    Iteration time: 1.69s
                      Time elapsed: 00:16:30
                               ETA: 00:33:03

################################################################################
                     [1m Learning iteration 500/1500 [0m                      

                       Computation: 58749 steps/s (collection: 1.585s, learning 0.088s)
             Mean action noise std: 1.83
          Mean value_function loss: 41.9360
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 35.9675
                       Mean reward: 626.97
               Mean episode length: 246.06
    Episode_Reward/reaching_object: 0.6668
    Episode_Reward/rotating_object: 125.3061
        Episode_Reward/action_rate: -0.0161
          Episode_Reward/joint_vel: -0.0079
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 49250304
                    Iteration time: 1.67s
                      Time elapsed: 00:16:32
                               ETA: 00:33:01

################################################################################
                     [1m Learning iteration 501/1500 [0m                      

                       Computation: 56449 steps/s (collection: 1.628s, learning 0.113s)
             Mean action noise std: 1.83
          Mean value_function loss: 46.8448
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 35.9781
                       Mean reward: 637.31
               Mean episode length: 242.96
    Episode_Reward/reaching_object: 0.6692
    Episode_Reward/rotating_object: 127.5276
        Episode_Reward/action_rate: -0.0162
          Episode_Reward/joint_vel: -0.0080
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 49348608
                    Iteration time: 1.74s
                      Time elapsed: 00:16:34
                               ETA: 00:32:58

################################################################################
                     [1m Learning iteration 502/1500 [0m                      

                       Computation: 57702 steps/s (collection: 1.597s, learning 0.107s)
             Mean action noise std: 1.84
          Mean value_function loss: 41.1298
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 35.9948
                       Mean reward: 622.99
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6731
    Episode_Reward/rotating_object: 126.2212
        Episode_Reward/action_rate: -0.0163
          Episode_Reward/joint_vel: -0.0082
      Episode_Termination/time_out: 17.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 49446912
                    Iteration time: 1.70s
                      Time elapsed: 00:16:36
                               ETA: 00:32:56

################################################################################
                     [1m Learning iteration 503/1500 [0m                      

                       Computation: 58380 steps/s (collection: 1.579s, learning 0.105s)
             Mean action noise std: 1.84
          Mean value_function loss: 35.2043
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 36.0132
                       Mean reward: 632.78
               Mean episode length: 246.48
    Episode_Reward/reaching_object: 0.6648
    Episode_Reward/rotating_object: 124.0701
        Episode_Reward/action_rate: -0.0163
          Episode_Reward/joint_vel: -0.0080
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 49545216
                    Iteration time: 1.68s
                      Time elapsed: 00:16:37
                               ETA: 00:32:53

################################################################################
                     [1m Learning iteration 504/1500 [0m                      

                       Computation: 59036 steps/s (collection: 1.549s, learning 0.116s)
             Mean action noise std: 1.84
          Mean value_function loss: 36.2114
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 36.0271
                       Mean reward: 626.14
               Mean episode length: 247.79
    Episode_Reward/reaching_object: 0.6670
    Episode_Reward/rotating_object: 126.1084
        Episode_Reward/action_rate: -0.0164
          Episode_Reward/joint_vel: -0.0080
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 49643520
                    Iteration time: 1.67s
                      Time elapsed: 00:16:39
                               ETA: 00:32:51

################################################################################
                     [1m Learning iteration 505/1500 [0m                      

                       Computation: 58315 steps/s (collection: 1.581s, learning 0.105s)
             Mean action noise std: 1.84
          Mean value_function loss: 31.9197
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 36.0402
                       Mean reward: 659.76
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6696
    Episode_Reward/rotating_object: 128.2106
        Episode_Reward/action_rate: -0.0164
          Episode_Reward/joint_vel: -0.0081
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 49741824
                    Iteration time: 1.69s
                      Time elapsed: 00:16:41
                               ETA: 00:32:48

################################################################################
                     [1m Learning iteration 506/1500 [0m                      

                       Computation: 57682 steps/s (collection: 1.612s, learning 0.092s)
             Mean action noise std: 1.84
          Mean value_function loss: 34.9825
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 36.0527
                       Mean reward: 631.18
               Mean episode length: 245.60
    Episode_Reward/reaching_object: 0.6713
    Episode_Reward/rotating_object: 128.6898
        Episode_Reward/action_rate: -0.0165
          Episode_Reward/joint_vel: -0.0082
      Episode_Termination/time_out: 17.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 49840128
                    Iteration time: 1.70s
                      Time elapsed: 00:16:42
                               ETA: 00:32:45

################################################################################
                     [1m Learning iteration 507/1500 [0m                      

                       Computation: 57194 steps/s (collection: 1.602s, learning 0.117s)
             Mean action noise std: 1.84
          Mean value_function loss: 41.5114
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 36.0625
                       Mean reward: 645.97
               Mean episode length: 245.62
    Episode_Reward/reaching_object: 0.6697
    Episode_Reward/rotating_object: 128.1163
        Episode_Reward/action_rate: -0.0165
          Episode_Reward/joint_vel: -0.0081
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 49938432
                    Iteration time: 1.72s
                      Time elapsed: 00:16:44
                               ETA: 00:32:43

################################################################################
                     [1m Learning iteration 508/1500 [0m                      

                       Computation: 58262 steps/s (collection: 1.595s, learning 0.093s)
             Mean action noise std: 1.85
          Mean value_function loss: 40.2679
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 36.0783
                       Mean reward: 630.76
               Mean episode length: 247.74
    Episode_Reward/reaching_object: 0.6695
    Episode_Reward/rotating_object: 123.5571
        Episode_Reward/action_rate: -0.0166
          Episode_Reward/joint_vel: -0.0081
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 50036736
                    Iteration time: 1.69s
                      Time elapsed: 00:16:46
                               ETA: 00:32:40

################################################################################
                     [1m Learning iteration 509/1500 [0m                      

                       Computation: 57935 steps/s (collection: 1.601s, learning 0.096s)
             Mean action noise std: 1.85
          Mean value_function loss: 40.2976
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 36.1012
                       Mean reward: 618.74
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6746
    Episode_Reward/rotating_object: 129.5195
        Episode_Reward/action_rate: -0.0167
          Episode_Reward/joint_vel: -0.0082
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 50135040
                    Iteration time: 1.70s
                      Time elapsed: 00:16:47
                               ETA: 00:32:38

################################################################################
                     [1m Learning iteration 510/1500 [0m                      

                       Computation: 58588 steps/s (collection: 1.571s, learning 0.107s)
             Mean action noise std: 1.85
          Mean value_function loss: 42.3434
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 36.1183
                       Mean reward: 639.27
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6711
    Episode_Reward/rotating_object: 128.6115
        Episode_Reward/action_rate: -0.0167
          Episode_Reward/joint_vel: -0.0079
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 50233344
                    Iteration time: 1.68s
                      Time elapsed: 00:16:49
                               ETA: 00:32:35

################################################################################
                     [1m Learning iteration 511/1500 [0m                      

                       Computation: 58910 steps/s (collection: 1.577s, learning 0.092s)
             Mean action noise std: 1.85
          Mean value_function loss: 41.8331
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 36.1330
                       Mean reward: 643.95
               Mean episode length: 246.51
    Episode_Reward/reaching_object: 0.6687
    Episode_Reward/rotating_object: 127.2678
        Episode_Reward/action_rate: -0.0166
          Episode_Reward/joint_vel: -0.0081
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 50331648
                    Iteration time: 1.67s
                      Time elapsed: 00:16:51
                               ETA: 00:32:33

################################################################################
                     [1m Learning iteration 512/1500 [0m                      

                       Computation: 57278 steps/s (collection: 1.601s, learning 0.116s)
             Mean action noise std: 1.85
          Mean value_function loss: 41.9924
               Mean surrogate loss: 0.0001
                 Mean entropy loss: 36.1435
                       Mean reward: 635.47
               Mean episode length: 245.79
    Episode_Reward/reaching_object: 0.6737
    Episode_Reward/rotating_object: 126.6042
        Episode_Reward/action_rate: -0.0168
          Episode_Reward/joint_vel: -0.0084
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 50429952
                    Iteration time: 1.72s
                      Time elapsed: 00:16:52
                               ETA: 00:32:30

################################################################################
                     [1m Learning iteration 513/1500 [0m                      

                       Computation: 59566 steps/s (collection: 1.556s, learning 0.095s)
             Mean action noise std: 1.86
          Mean value_function loss: 34.8228
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 36.1513
                       Mean reward: 641.63
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6714
    Episode_Reward/rotating_object: 129.5050
        Episode_Reward/action_rate: -0.0168
          Episode_Reward/joint_vel: -0.0081
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 50528256
                    Iteration time: 1.65s
                      Time elapsed: 00:16:54
                               ETA: 00:32:28

################################################################################
                     [1m Learning iteration 514/1500 [0m                      

                       Computation: 58570 steps/s (collection: 1.579s, learning 0.099s)
             Mean action noise std: 1.86
          Mean value_function loss: 37.8865
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 36.1656
                       Mean reward: 650.43
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6756
    Episode_Reward/rotating_object: 127.7880
        Episode_Reward/action_rate: -0.0170
          Episode_Reward/joint_vel: -0.0080
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 50626560
                    Iteration time: 1.68s
                      Time elapsed: 00:16:56
                               ETA: 00:32:25

################################################################################
                     [1m Learning iteration 515/1500 [0m                      

                       Computation: 58334 steps/s (collection: 1.594s, learning 0.092s)
             Mean action noise std: 1.86
          Mean value_function loss: 36.1255
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 36.1787
                       Mean reward: 637.52
               Mean episode length: 245.67
    Episode_Reward/reaching_object: 0.6779
    Episode_Reward/rotating_object: 131.3546
        Episode_Reward/action_rate: -0.0169
          Episode_Reward/joint_vel: -0.0082
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 50724864
                    Iteration time: 1.69s
                      Time elapsed: 00:16:57
                               ETA: 00:32:23

################################################################################
                     [1m Learning iteration 516/1500 [0m                      

                       Computation: 57901 steps/s (collection: 1.589s, learning 0.109s)
             Mean action noise std: 1.86
          Mean value_function loss: 39.2220
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 36.1926
                       Mean reward: 655.65
               Mean episode length: 247.98
    Episode_Reward/reaching_object: 0.6702
    Episode_Reward/rotating_object: 127.5558
        Episode_Reward/action_rate: -0.0169
          Episode_Reward/joint_vel: -0.0082
      Episode_Termination/time_out: 17.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 50823168
                    Iteration time: 1.70s
                      Time elapsed: 00:16:59
                               ETA: 00:32:20

################################################################################
                     [1m Learning iteration 517/1500 [0m                      

                       Computation: 58594 steps/s (collection: 1.580s, learning 0.098s)
             Mean action noise std: 1.86
          Mean value_function loss: 41.9573
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 36.2128
                       Mean reward: 653.42
               Mean episode length: 245.68
    Episode_Reward/reaching_object: 0.6754
    Episode_Reward/rotating_object: 129.0318
        Episode_Reward/action_rate: -0.0170
          Episode_Reward/joint_vel: -0.0082
      Episode_Termination/time_out: 18.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 50921472
                    Iteration time: 1.68s
                      Time elapsed: 00:17:01
                               ETA: 00:32:18

################################################################################
                     [1m Learning iteration 518/1500 [0m                      

                       Computation: 58297 steps/s (collection: 1.586s, learning 0.101s)
             Mean action noise std: 1.87
          Mean value_function loss: 57.5135
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 36.2380
                       Mean reward: 655.57
               Mean episode length: 245.66
    Episode_Reward/reaching_object: 0.6796
    Episode_Reward/rotating_object: 129.7406
        Episode_Reward/action_rate: -0.0171
          Episode_Reward/joint_vel: -0.0080
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 51019776
                    Iteration time: 1.69s
                      Time elapsed: 00:17:02
                               ETA: 00:32:15

################################################################################
                     [1m Learning iteration 519/1500 [0m                      

                       Computation: 56069 steps/s (collection: 1.659s, learning 0.094s)
             Mean action noise std: 1.87
          Mean value_function loss: 42.2280
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 36.2545
                       Mean reward: 620.35
               Mean episode length: 244.45
    Episode_Reward/reaching_object: 0.6739
    Episode_Reward/rotating_object: 128.4354
        Episode_Reward/action_rate: -0.0170
          Episode_Reward/joint_vel: -0.0080
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 51118080
                    Iteration time: 1.75s
                      Time elapsed: 00:17:04
                               ETA: 00:32:13

################################################################################
                     [1m Learning iteration 520/1500 [0m                      

                       Computation: 53853 steps/s (collection: 1.628s, learning 0.198s)
             Mean action noise std: 1.87
          Mean value_function loss: 43.6624
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 36.2658
                       Mean reward: 637.40
               Mean episode length: 246.21
    Episode_Reward/reaching_object: 0.6781
    Episode_Reward/rotating_object: 128.2215
        Episode_Reward/action_rate: -0.0171
          Episode_Reward/joint_vel: -0.0082
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 51216384
                    Iteration time: 1.83s
                      Time elapsed: 00:17:06
                               ETA: 00:32:10

################################################################################
                     [1m Learning iteration 521/1500 [0m                      

                       Computation: 57129 steps/s (collection: 1.586s, learning 0.135s)
             Mean action noise std: 1.87
          Mean value_function loss: 35.7315
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 36.2845
                       Mean reward: 657.09
               Mean episode length: 247.70
    Episode_Reward/reaching_object: 0.6842
    Episode_Reward/rotating_object: 132.6862
        Episode_Reward/action_rate: -0.0172
          Episode_Reward/joint_vel: -0.0080
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 51314688
                    Iteration time: 1.72s
                      Time elapsed: 00:17:08
                               ETA: 00:32:08

################################################################################
                     [1m Learning iteration 522/1500 [0m                      

                       Computation: 57271 steps/s (collection: 1.620s, learning 0.097s)
             Mean action noise std: 1.87
          Mean value_function loss: 39.8930
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 36.2967
                       Mean reward: 650.83
               Mean episode length: 247.80
    Episode_Reward/reaching_object: 0.6738
    Episode_Reward/rotating_object: 130.0401
        Episode_Reward/action_rate: -0.0169
          Episode_Reward/joint_vel: -0.0078
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 51412992
                    Iteration time: 1.72s
                      Time elapsed: 00:17:10
                               ETA: 00:32:06

################################################################################
                     [1m Learning iteration 523/1500 [0m                      

                       Computation: 56182 steps/s (collection: 1.631s, learning 0.119s)
             Mean action noise std: 1.87
          Mean value_function loss: 37.7970
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 36.3026
                       Mean reward: 668.30
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6824
    Episode_Reward/rotating_object: 131.5895
        Episode_Reward/action_rate: -0.0173
          Episode_Reward/joint_vel: -0.0082
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 51511296
                    Iteration time: 1.75s
                      Time elapsed: 00:17:11
                               ETA: 00:32:03

################################################################################
                     [1m Learning iteration 524/1500 [0m                      

                       Computation: 53856 steps/s (collection: 1.670s, learning 0.155s)
             Mean action noise std: 1.87
          Mean value_function loss: 40.7972
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 36.3122
                       Mean reward: 675.75
               Mean episode length: 246.56
    Episode_Reward/reaching_object: 0.6743
    Episode_Reward/rotating_object: 128.8013
        Episode_Reward/action_rate: -0.0171
          Episode_Reward/joint_vel: -0.0078
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 51609600
                    Iteration time: 1.83s
                      Time elapsed: 00:17:13
                               ETA: 00:32:01

################################################################################
                     [1m Learning iteration 525/1500 [0m                      

                       Computation: 56304 steps/s (collection: 1.642s, learning 0.104s)
             Mean action noise std: 1.88
          Mean value_function loss: 32.9474
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 36.3238
                       Mean reward: 634.00
               Mean episode length: 247.39
    Episode_Reward/reaching_object: 0.6716
    Episode_Reward/rotating_object: 126.7008
        Episode_Reward/action_rate: -0.0172
          Episode_Reward/joint_vel: -0.0082
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 51707904
                    Iteration time: 1.75s
                      Time elapsed: 00:17:15
                               ETA: 00:31:59

################################################################################
                     [1m Learning iteration 526/1500 [0m                      

                       Computation: 54201 steps/s (collection: 1.725s, learning 0.089s)
             Mean action noise std: 1.88
          Mean value_function loss: 32.3662
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 36.3492
                       Mean reward: 649.28
               Mean episode length: 248.23
    Episode_Reward/reaching_object: 0.6731
    Episode_Reward/rotating_object: 127.7018
        Episode_Reward/action_rate: -0.0172
          Episode_Reward/joint_vel: -0.0078
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 51806208
                    Iteration time: 1.81s
                      Time elapsed: 00:17:17
                               ETA: 00:31:56

################################################################################
                     [1m Learning iteration 527/1500 [0m                      

                       Computation: 57821 steps/s (collection: 1.599s, learning 0.101s)
             Mean action noise std: 1.88
          Mean value_function loss: 40.3981
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 36.3687
                       Mean reward: 661.68
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6758
    Episode_Reward/rotating_object: 129.2649
        Episode_Reward/action_rate: -0.0173
          Episode_Reward/joint_vel: -0.0079
      Episode_Termination/time_out: 18.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 51904512
                    Iteration time: 1.70s
                      Time elapsed: 00:17:18
                               ETA: 00:31:54

################################################################################
                     [1m Learning iteration 528/1500 [0m                      

                       Computation: 56660 steps/s (collection: 1.579s, learning 0.156s)
             Mean action noise std: 1.88
          Mean value_function loss: 39.3094
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 36.3755
                       Mean reward: 658.34
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6758
    Episode_Reward/rotating_object: 129.3337
        Episode_Reward/action_rate: -0.0173
          Episode_Reward/joint_vel: -0.0078
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 52002816
                    Iteration time: 1.73s
                      Time elapsed: 00:17:20
                               ETA: 00:31:51

################################################################################
                     [1m Learning iteration 529/1500 [0m                      

                       Computation: 57278 steps/s (collection: 1.593s, learning 0.123s)
             Mean action noise std: 1.88
          Mean value_function loss: 34.8733
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 36.3911
                       Mean reward: 659.55
               Mean episode length: 248.68
    Episode_Reward/reaching_object: 0.6750
    Episode_Reward/rotating_object: 130.7843
        Episode_Reward/action_rate: -0.0173
          Episode_Reward/joint_vel: -0.0081
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 52101120
                    Iteration time: 1.72s
                      Time elapsed: 00:17:22
                               ETA: 00:31:49

################################################################################
                     [1m Learning iteration 530/1500 [0m                      

                       Computation: 56018 steps/s (collection: 1.641s, learning 0.114s)
             Mean action noise std: 1.89
          Mean value_function loss: 37.8503
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 36.4069
                       Mean reward: 634.52
               Mean episode length: 247.85
    Episode_Reward/reaching_object: 0.6714
    Episode_Reward/rotating_object: 129.7643
        Episode_Reward/action_rate: -0.0173
          Episode_Reward/joint_vel: -0.0080
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 52199424
                    Iteration time: 1.75s
                      Time elapsed: 00:17:24
                               ETA: 00:31:47

################################################################################
                     [1m Learning iteration 531/1500 [0m                      

                       Computation: 51306 steps/s (collection: 1.797s, learning 0.119s)
             Mean action noise std: 1.89
          Mean value_function loss: 41.1940
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 36.4219
                       Mean reward: 666.36
               Mean episode length: 248.15
    Episode_Reward/reaching_object: 0.6705
    Episode_Reward/rotating_object: 131.1716
        Episode_Reward/action_rate: -0.0174
          Episode_Reward/joint_vel: -0.0084
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 52297728
                    Iteration time: 1.92s
                      Time elapsed: 00:17:25
                               ETA: 00:31:45

################################################################################
                     [1m Learning iteration 532/1500 [0m                      

                       Computation: 56081 steps/s (collection: 1.656s, learning 0.097s)
             Mean action noise std: 1.89
          Mean value_function loss: 32.7505
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 36.4299
                       Mean reward: 661.95
               Mean episode length: 248.03
    Episode_Reward/reaching_object: 0.6660
    Episode_Reward/rotating_object: 129.9643
        Episode_Reward/action_rate: -0.0173
          Episode_Reward/joint_vel: -0.0079
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 52396032
                    Iteration time: 1.75s
                      Time elapsed: 00:17:27
                               ETA: 00:31:42

################################################################################
                     [1m Learning iteration 533/1500 [0m                      

                       Computation: 58033 steps/s (collection: 1.580s, learning 0.114s)
             Mean action noise std: 1.89
          Mean value_function loss: 38.3792
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 36.4408
                       Mean reward: 668.00
               Mean episode length: 247.88
    Episode_Reward/reaching_object: 0.6809
    Episode_Reward/rotating_object: 134.9355
        Episode_Reward/action_rate: -0.0177
          Episode_Reward/joint_vel: -0.0083
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 52494336
                    Iteration time: 1.69s
                      Time elapsed: 00:17:29
                               ETA: 00:31:40

################################################################################
                     [1m Learning iteration 534/1500 [0m                      

                       Computation: 55737 steps/s (collection: 1.655s, learning 0.109s)
             Mean action noise std: 1.89
          Mean value_function loss: 34.6901
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 36.4548
                       Mean reward: 706.94
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6732
    Episode_Reward/rotating_object: 130.9485
        Episode_Reward/action_rate: -0.0177
          Episode_Reward/joint_vel: -0.0083
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 52592640
                    Iteration time: 1.76s
                      Time elapsed: 00:17:31
                               ETA: 00:31:38

################################################################################
                     [1m Learning iteration 535/1500 [0m                      

                       Computation: 56716 steps/s (collection: 1.621s, learning 0.112s)
             Mean action noise std: 1.90
          Mean value_function loss: 32.8231
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 36.4725
                       Mean reward: 676.51
               Mean episode length: 247.70
    Episode_Reward/reaching_object: 0.6654
    Episode_Reward/rotating_object: 130.2766
        Episode_Reward/action_rate: -0.0174
          Episode_Reward/joint_vel: -0.0080
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 52690944
                    Iteration time: 1.73s
                      Time elapsed: 00:17:32
                               ETA: 00:31:35

################################################################################
                     [1m Learning iteration 536/1500 [0m                      

                       Computation: 56391 steps/s (collection: 1.628s, learning 0.115s)
             Mean action noise std: 1.90
          Mean value_function loss: 32.7691
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 36.4990
                       Mean reward: 666.19
               Mean episode length: 246.43
    Episode_Reward/reaching_object: 0.6692
    Episode_Reward/rotating_object: 130.7361
        Episode_Reward/action_rate: -0.0176
          Episode_Reward/joint_vel: -0.0084
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 52789248
                    Iteration time: 1.74s
                      Time elapsed: 00:17:34
                               ETA: 00:31:33

################################################################################
                     [1m Learning iteration 537/1500 [0m                      

                       Computation: 55622 steps/s (collection: 1.650s, learning 0.118s)
             Mean action noise std: 1.90
          Mean value_function loss: 33.0870
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 36.5141
                       Mean reward: 684.40
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6761
    Episode_Reward/rotating_object: 132.7925
        Episode_Reward/action_rate: -0.0179
          Episode_Reward/joint_vel: -0.0086
      Episode_Termination/time_out: 18.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 52887552
                    Iteration time: 1.77s
                      Time elapsed: 00:17:36
                               ETA: 00:31:30

################################################################################
                     [1m Learning iteration 538/1500 [0m                      

                       Computation: 57611 steps/s (collection: 1.589s, learning 0.117s)
             Mean action noise std: 1.90
          Mean value_function loss: 36.6146
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 36.5334
                       Mean reward: 666.10
               Mean episode length: 247.76
    Episode_Reward/reaching_object: 0.6700
    Episode_Reward/rotating_object: 131.3899
        Episode_Reward/action_rate: -0.0177
          Episode_Reward/joint_vel: -0.0084
      Episode_Termination/time_out: 17.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 52985856
                    Iteration time: 1.71s
                      Time elapsed: 00:17:38
                               ETA: 00:31:28

################################################################################
                     [1m Learning iteration 539/1500 [0m                      

                       Computation: 57288 steps/s (collection: 1.589s, learning 0.127s)
             Mean action noise std: 1.90
          Mean value_function loss: 37.5947
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 36.5516
                       Mean reward: 648.90
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6779
    Episode_Reward/rotating_object: 130.9650
        Episode_Reward/action_rate: -0.0179
          Episode_Reward/joint_vel: -0.0084
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 53084160
                    Iteration time: 1.72s
                      Time elapsed: 00:17:39
                               ETA: 00:31:26

################################################################################
                     [1m Learning iteration 540/1500 [0m                      

                       Computation: 55574 steps/s (collection: 1.643s, learning 0.126s)
             Mean action noise std: 1.91
          Mean value_function loss: 40.1669
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 36.5629
                       Mean reward: 669.88
               Mean episode length: 248.03
    Episode_Reward/reaching_object: 0.6748
    Episode_Reward/rotating_object: 130.8170
        Episode_Reward/action_rate: -0.0178
          Episode_Reward/joint_vel: -0.0089
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 53182464
                    Iteration time: 1.77s
                      Time elapsed: 00:17:41
                               ETA: 00:31:23

################################################################################
                     [1m Learning iteration 541/1500 [0m                      

                       Computation: 55567 steps/s (collection: 1.626s, learning 0.143s)
             Mean action noise std: 1.91
          Mean value_function loss: 39.0665
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 36.5832
                       Mean reward: 650.86
               Mean episode length: 248.36
    Episode_Reward/reaching_object: 0.6768
    Episode_Reward/rotating_object: 131.4836
        Episode_Reward/action_rate: -0.0179
          Episode_Reward/joint_vel: -0.0085
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 53280768
                    Iteration time: 1.77s
                      Time elapsed: 00:17:43
                               ETA: 00:31:21

################################################################################
                     [1m Learning iteration 542/1500 [0m                      

                       Computation: 54223 steps/s (collection: 1.631s, learning 0.182s)
             Mean action noise std: 1.91
          Mean value_function loss: 33.8601
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 36.6062
                       Mean reward: 655.09
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6783
    Episode_Reward/rotating_object: 131.2773
        Episode_Reward/action_rate: -0.0180
          Episode_Reward/joint_vel: -0.0088
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 53379072
                    Iteration time: 1.81s
                      Time elapsed: 00:17:45
                               ETA: 00:31:19

################################################################################
                     [1m Learning iteration 543/1500 [0m                      

                       Computation: 55347 steps/s (collection: 1.684s, learning 0.092s)
             Mean action noise std: 1.91
          Mean value_function loss: 41.9714
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 36.6183
                       Mean reward: 682.32
               Mean episode length: 249.28
    Episode_Reward/reaching_object: 0.6845
    Episode_Reward/rotating_object: 134.9765
        Episode_Reward/action_rate: -0.0183
          Episode_Reward/joint_vel: -0.0092
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 53477376
                    Iteration time: 1.78s
                      Time elapsed: 00:17:46
                               ETA: 00:31:16

################################################################################
                     [1m Learning iteration 544/1500 [0m                      

                       Computation: 55192 steps/s (collection: 1.629s, learning 0.152s)
             Mean action noise std: 1.91
          Mean value_function loss: 36.0375
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 36.6283
                       Mean reward: 649.30
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6814
    Episode_Reward/rotating_object: 131.1640
        Episode_Reward/action_rate: -0.0182
          Episode_Reward/joint_vel: -0.0087
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 53575680
                    Iteration time: 1.78s
                      Time elapsed: 00:17:48
                               ETA: 00:31:14

################################################################################
                     [1m Learning iteration 545/1500 [0m                      

                       Computation: 54232 steps/s (collection: 1.664s, learning 0.149s)
             Mean action noise std: 1.92
          Mean value_function loss: 30.0360
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 36.6526
                       Mean reward: 660.56
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6791
    Episode_Reward/rotating_object: 132.3814
        Episode_Reward/action_rate: -0.0181
          Episode_Reward/joint_vel: -0.0086
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 53673984
                    Iteration time: 1.81s
                      Time elapsed: 00:17:50
                               ETA: 00:31:12

################################################################################
                     [1m Learning iteration 546/1500 [0m                      

                       Computation: 56167 steps/s (collection: 1.651s, learning 0.100s)
             Mean action noise std: 1.92
          Mean value_function loss: 30.0589
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 36.6789
                       Mean reward: 666.92
               Mean episode length: 248.75
    Episode_Reward/reaching_object: 0.6816
    Episode_Reward/rotating_object: 132.4980
        Episode_Reward/action_rate: -0.0183
          Episode_Reward/joint_vel: -0.0088
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 53772288
                    Iteration time: 1.75s
                      Time elapsed: 00:17:52
                               ETA: 00:31:10

################################################################################
                     [1m Learning iteration 547/1500 [0m                      

                       Computation: 56146 steps/s (collection: 1.633s, learning 0.118s)
             Mean action noise std: 1.92
          Mean value_function loss: 35.6805
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 36.7007
                       Mean reward: 675.22
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6797
    Episode_Reward/rotating_object: 132.5192
        Episode_Reward/action_rate: -0.0183
          Episode_Reward/joint_vel: -0.0087
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 53870592
                    Iteration time: 1.75s
                      Time elapsed: 00:17:54
                               ETA: 00:31:07

################################################################################
                     [1m Learning iteration 548/1500 [0m                      

                       Computation: 55340 steps/s (collection: 1.634s, learning 0.143s)
             Mean action noise std: 1.93
          Mean value_function loss: 35.1593
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 36.7225
                       Mean reward: 661.45
               Mean episode length: 246.86
    Episode_Reward/reaching_object: 0.6761
    Episode_Reward/rotating_object: 130.7206
        Episode_Reward/action_rate: -0.0182
          Episode_Reward/joint_vel: -0.0088
      Episode_Termination/time_out: 18.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 53968896
                    Iteration time: 1.78s
                      Time elapsed: 00:17:55
                               ETA: 00:31:05

################################################################################
                     [1m Learning iteration 549/1500 [0m                      

                       Computation: 55887 steps/s (collection: 1.611s, learning 0.148s)
             Mean action noise std: 1.93
          Mean value_function loss: 35.6787
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 36.7444
                       Mean reward: 661.82
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6823
    Episode_Reward/rotating_object: 132.7446
        Episode_Reward/action_rate: -0.0184
          Episode_Reward/joint_vel: -0.0088
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 54067200
                    Iteration time: 1.76s
                      Time elapsed: 00:17:57
                               ETA: 00:31:03

################################################################################
                     [1m Learning iteration 550/1500 [0m                      

                       Computation: 55906 steps/s (collection: 1.640s, learning 0.119s)
             Mean action noise std: 1.93
          Mean value_function loss: 33.7899
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 36.7646
                       Mean reward: 652.66
               Mean episode length: 246.33
    Episode_Reward/reaching_object: 0.6740
    Episode_Reward/rotating_object: 130.7478
        Episode_Reward/action_rate: -0.0182
          Episode_Reward/joint_vel: -0.0090
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 54165504
                    Iteration time: 1.76s
                      Time elapsed: 00:17:59
                               ETA: 00:31:00

################################################################################
                     [1m Learning iteration 551/1500 [0m                      

                       Computation: 53334 steps/s (collection: 1.724s, learning 0.120s)
             Mean action noise std: 1.93
          Mean value_function loss: 31.7938
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 36.7739
                       Mean reward: 679.24
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6841
    Episode_Reward/rotating_object: 133.5621
        Episode_Reward/action_rate: -0.0185
          Episode_Reward/joint_vel: -0.0089
      Episode_Termination/time_out: 17.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 54263808
                    Iteration time: 1.84s
                      Time elapsed: 00:18:01
                               ETA: 00:30:58

################################################################################
                     [1m Learning iteration 552/1500 [0m                      

                       Computation: 57377 steps/s (collection: 1.617s, learning 0.096s)
             Mean action noise std: 1.93
          Mean value_function loss: 35.4257
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 36.7836
                       Mean reward: 673.91
               Mean episode length: 247.71
    Episode_Reward/reaching_object: 0.6800
    Episode_Reward/rotating_object: 130.7155
        Episode_Reward/action_rate: -0.0184
          Episode_Reward/joint_vel: -0.0089
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 54362112
                    Iteration time: 1.71s
                      Time elapsed: 00:18:02
                               ETA: 00:30:56

################################################################################
                     [1m Learning iteration 553/1500 [0m                      

                       Computation: 56181 steps/s (collection: 1.617s, learning 0.133s)
             Mean action noise std: 1.93
          Mean value_function loss: 40.0353
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 36.7948
                       Mean reward: 702.62
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6833
    Episode_Reward/rotating_object: 132.7815
        Episode_Reward/action_rate: -0.0186
          Episode_Reward/joint_vel: -0.0089
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 54460416
                    Iteration time: 1.75s
                      Time elapsed: 00:18:04
                               ETA: 00:30:54

################################################################################
                     [1m Learning iteration 554/1500 [0m                      

                       Computation: 57530 steps/s (collection: 1.587s, learning 0.122s)
             Mean action noise std: 1.94
          Mean value_function loss: 33.0571
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 36.8105
                       Mean reward: 688.47
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6862
    Episode_Reward/rotating_object: 133.5723
        Episode_Reward/action_rate: -0.0186
          Episode_Reward/joint_vel: -0.0088
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 54558720
                    Iteration time: 1.71s
                      Time elapsed: 00:18:06
                               ETA: 00:30:51

################################################################################
                     [1m Learning iteration 555/1500 [0m                      

                       Computation: 56645 steps/s (collection: 1.640s, learning 0.096s)
             Mean action noise std: 1.94
          Mean value_function loss: 36.0480
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 36.8272
                       Mean reward: 651.71
               Mean episode length: 245.98
    Episode_Reward/reaching_object: 0.6820
    Episode_Reward/rotating_object: 133.1612
        Episode_Reward/action_rate: -0.0185
          Episode_Reward/joint_vel: -0.0089
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 54657024
                    Iteration time: 1.74s
                      Time elapsed: 00:18:08
                               ETA: 00:30:49

################################################################################
                     [1m Learning iteration 556/1500 [0m                      

                       Computation: 57929 steps/s (collection: 1.592s, learning 0.105s)
             Mean action noise std: 1.94
          Mean value_function loss: 39.9143
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 36.8417
                       Mean reward: 657.63
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6828
    Episode_Reward/rotating_object: 131.8596
        Episode_Reward/action_rate: -0.0185
          Episode_Reward/joint_vel: -0.0089
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 54755328
                    Iteration time: 1.70s
                      Time elapsed: 00:18:09
                               ETA: 00:30:46

################################################################################
                     [1m Learning iteration 557/1500 [0m                      

                       Computation: 56419 steps/s (collection: 1.594s, learning 0.148s)
             Mean action noise std: 1.94
          Mean value_function loss: 29.7912
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 36.8565
                       Mean reward: 662.59
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6819
    Episode_Reward/rotating_object: 131.8866
        Episode_Reward/action_rate: -0.0185
          Episode_Reward/joint_vel: -0.0087
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 54853632
                    Iteration time: 1.74s
                      Time elapsed: 00:18:11
                               ETA: 00:30:44

################################################################################
                     [1m Learning iteration 558/1500 [0m                      

                       Computation: 58884 steps/s (collection: 1.575s, learning 0.094s)
             Mean action noise std: 1.94
          Mean value_function loss: 40.2360
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 36.8691
                       Mean reward: 687.91
               Mean episode length: 247.99
    Episode_Reward/reaching_object: 0.6853
    Episode_Reward/rotating_object: 132.8663
        Episode_Reward/action_rate: -0.0186
          Episode_Reward/joint_vel: -0.0087
      Episode_Termination/time_out: 17.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 54951936
                    Iteration time: 1.67s
                      Time elapsed: 00:18:13
                               ETA: 00:30:42

################################################################################
                     [1m Learning iteration 559/1500 [0m                      

                       Computation: 58991 steps/s (collection: 1.573s, learning 0.093s)
             Mean action noise std: 1.95
          Mean value_function loss: 40.6395
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 36.8916
                       Mean reward: 682.13
               Mean episode length: 248.26
    Episode_Reward/reaching_object: 0.6889
    Episode_Reward/rotating_object: 134.5288
        Episode_Reward/action_rate: -0.0187
          Episode_Reward/joint_vel: -0.0089
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 55050240
                    Iteration time: 1.67s
                      Time elapsed: 00:18:14
                               ETA: 00:30:39

################################################################################
                     [1m Learning iteration 560/1500 [0m                      

                       Computation: 56707 steps/s (collection: 1.620s, learning 0.113s)
             Mean action noise std: 1.95
          Mean value_function loss: 33.5812
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 36.9150
                       Mean reward: 685.64
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6832
    Episode_Reward/rotating_object: 131.8866
        Episode_Reward/action_rate: -0.0187
          Episode_Reward/joint_vel: -0.0088
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 55148544
                    Iteration time: 1.73s
                      Time elapsed: 00:18:16
                               ETA: 00:30:37

################################################################################
                     [1m Learning iteration 561/1500 [0m                      

                       Computation: 57122 steps/s (collection: 1.612s, learning 0.109s)
             Mean action noise std: 1.95
          Mean value_function loss: 32.3939
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 36.9284
                       Mean reward: 635.72
               Mean episode length: 248.30
    Episode_Reward/reaching_object: 0.6875
    Episode_Reward/rotating_object: 132.6152
        Episode_Reward/action_rate: -0.0188
          Episode_Reward/joint_vel: -0.0090
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 55246848
                    Iteration time: 1.72s
                      Time elapsed: 00:18:18
                               ETA: 00:30:35

################################################################################
                     [1m Learning iteration 562/1500 [0m                      

                       Computation: 57421 steps/s (collection: 1.617s, learning 0.095s)
             Mean action noise std: 1.95
          Mean value_function loss: 37.0841
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 36.9472
                       Mean reward: 661.08
               Mean episode length: 248.06
    Episode_Reward/reaching_object: 0.6848
    Episode_Reward/rotating_object: 133.1052
        Episode_Reward/action_rate: -0.0187
          Episode_Reward/joint_vel: -0.0085
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 55345152
                    Iteration time: 1.71s
                      Time elapsed: 00:18:20
                               ETA: 00:30:32

################################################################################
                     [1m Learning iteration 563/1500 [0m                      

                       Computation: 57926 steps/s (collection: 1.581s, learning 0.117s)
             Mean action noise std: 1.96
          Mean value_function loss: 36.7107
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 36.9608
                       Mean reward: 662.36
               Mean episode length: 248.45
    Episode_Reward/reaching_object: 0.6843
    Episode_Reward/rotating_object: 131.0312
        Episode_Reward/action_rate: -0.0188
          Episode_Reward/joint_vel: -0.0088
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 55443456
                    Iteration time: 1.70s
                      Time elapsed: 00:18:21
                               ETA: 00:30:30

################################################################################
                     [1m Learning iteration 564/1500 [0m                      

                       Computation: 58074 steps/s (collection: 1.593s, learning 0.100s)
             Mean action noise std: 1.96
          Mean value_function loss: 39.1045
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 36.9733
                       Mean reward: 648.82
               Mean episode length: 245.68
    Episode_Reward/reaching_object: 0.6849
    Episode_Reward/rotating_object: 132.6810
        Episode_Reward/action_rate: -0.0188
          Episode_Reward/joint_vel: -0.0091
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 55541760
                    Iteration time: 1.69s
                      Time elapsed: 00:18:23
                               ETA: 00:30:27

################################################################################
                     [1m Learning iteration 565/1500 [0m                      

                       Computation: 58288 steps/s (collection: 1.590s, learning 0.096s)
             Mean action noise std: 1.96
          Mean value_function loss: 38.0575
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 36.9788
                       Mean reward: 668.10
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6909
    Episode_Reward/rotating_object: 133.2437
        Episode_Reward/action_rate: -0.0189
          Episode_Reward/joint_vel: -0.0087
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 55640064
                    Iteration time: 1.69s
                      Time elapsed: 00:18:25
                               ETA: 00:30:25

################################################################################
                     [1m Learning iteration 566/1500 [0m                      

                       Computation: 57518 steps/s (collection: 1.598s, learning 0.111s)
             Mean action noise std: 1.96
          Mean value_function loss: 43.7699
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 36.9898
                       Mean reward: 656.65
               Mean episode length: 247.71
    Episode_Reward/reaching_object: 0.6874
    Episode_Reward/rotating_object: 132.4491
        Episode_Reward/action_rate: -0.0188
          Episode_Reward/joint_vel: -0.0085
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 55738368
                    Iteration time: 1.71s
                      Time elapsed: 00:18:26
                               ETA: 00:30:23

################################################################################
                     [1m Learning iteration 567/1500 [0m                      

                       Computation: 58596 steps/s (collection: 1.584s, learning 0.094s)
             Mean action noise std: 1.96
          Mean value_function loss: 30.7752
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 37.0072
                       Mean reward: 672.92
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6921
    Episode_Reward/rotating_object: 133.1534
        Episode_Reward/action_rate: -0.0190
          Episode_Reward/joint_vel: -0.0087
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 55836672
                    Iteration time: 1.68s
                      Time elapsed: 00:18:28
                               ETA: 00:30:20

################################################################################
                     [1m Learning iteration 568/1500 [0m                      

                       Computation: 57929 steps/s (collection: 1.603s, learning 0.094s)
             Mean action noise std: 1.96
          Mean value_function loss: 37.0758
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 37.0148
                       Mean reward: 671.20
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6898
    Episode_Reward/rotating_object: 131.9873
        Episode_Reward/action_rate: -0.0190
          Episode_Reward/joint_vel: -0.0086
      Episode_Termination/time_out: 17.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 55934976
                    Iteration time: 1.70s
                      Time elapsed: 00:18:30
                               ETA: 00:30:18

################################################################################
                     [1m Learning iteration 569/1500 [0m                      

                       Computation: 57955 steps/s (collection: 1.604s, learning 0.092s)
             Mean action noise std: 1.97
          Mean value_function loss: 39.8776
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 37.0326
                       Mean reward: 668.56
               Mean episode length: 247.78
    Episode_Reward/reaching_object: 0.6959
    Episode_Reward/rotating_object: 134.2778
        Episode_Reward/action_rate: -0.0190
          Episode_Reward/joint_vel: -0.0086
      Episode_Termination/time_out: 18.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 56033280
                    Iteration time: 1.70s
                      Time elapsed: 00:18:31
                               ETA: 00:30:16

################################################################################
                     [1m Learning iteration 570/1500 [0m                      

                       Computation: 56704 steps/s (collection: 1.614s, learning 0.119s)
             Mean action noise std: 1.97
          Mean value_function loss: 37.3235
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 37.0542
                       Mean reward: 634.14
               Mean episode length: 245.54
    Episode_Reward/reaching_object: 0.6931
    Episode_Reward/rotating_object: 132.9874
        Episode_Reward/action_rate: -0.0189
          Episode_Reward/joint_vel: -0.0085
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 56131584
                    Iteration time: 1.73s
                      Time elapsed: 00:18:33
                               ETA: 00:30:13

################################################################################
                     [1m Learning iteration 571/1500 [0m                      

                       Computation: 58157 steps/s (collection: 1.595s, learning 0.095s)
             Mean action noise std: 1.97
          Mean value_function loss: 27.5163
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 37.0707
                       Mean reward: 660.83
               Mean episode length: 246.24
    Episode_Reward/reaching_object: 0.6875
    Episode_Reward/rotating_object: 130.9362
        Episode_Reward/action_rate: -0.0188
          Episode_Reward/joint_vel: -0.0086
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 56229888
                    Iteration time: 1.69s
                      Time elapsed: 00:18:35
                               ETA: 00:30:11

################################################################################
                     [1m Learning iteration 572/1500 [0m                      

                       Computation: 57248 steps/s (collection: 1.622s, learning 0.095s)
             Mean action noise std: 1.97
          Mean value_function loss: 39.8256
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 37.0811
                       Mean reward: 636.59
               Mean episode length: 244.61
    Episode_Reward/reaching_object: 0.6886
    Episode_Reward/rotating_object: 129.4253
        Episode_Reward/action_rate: -0.0189
          Episode_Reward/joint_vel: -0.0089
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 56328192
                    Iteration time: 1.72s
                      Time elapsed: 00:18:37
                               ETA: 00:30:09

################################################################################
                     [1m Learning iteration 573/1500 [0m                      

                       Computation: 58076 steps/s (collection: 1.596s, learning 0.097s)
             Mean action noise std: 1.97
          Mean value_function loss: 37.2061
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 37.0959
                       Mean reward: 659.40
               Mean episode length: 248.17
    Episode_Reward/reaching_object: 0.6912
    Episode_Reward/rotating_object: 129.7063
        Episode_Reward/action_rate: -0.0191
          Episode_Reward/joint_vel: -0.0087
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 56426496
                    Iteration time: 1.69s
                      Time elapsed: 00:18:38
                               ETA: 00:30:06

################################################################################
                     [1m Learning iteration 574/1500 [0m                      

                       Computation: 56415 steps/s (collection: 1.635s, learning 0.108s)
             Mean action noise std: 1.98
          Mean value_function loss: 36.1992
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 37.1227
                       Mean reward: 669.35
               Mean episode length: 245.98
    Episode_Reward/reaching_object: 0.6990
    Episode_Reward/rotating_object: 132.4422
        Episode_Reward/action_rate: -0.0191
          Episode_Reward/joint_vel: -0.0084
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 56524800
                    Iteration time: 1.74s
                      Time elapsed: 00:18:40
                               ETA: 00:30:04

################################################################################
                     [1m Learning iteration 575/1500 [0m                      

                       Computation: 56961 steps/s (collection: 1.635s, learning 0.091s)
             Mean action noise std: 1.98
          Mean value_function loss: 39.6572
               Mean surrogate loss: 0.0025
                 Mean entropy loss: 37.1407
                       Mean reward: 660.14
               Mean episode length: 245.60
    Episode_Reward/reaching_object: 0.6934
    Episode_Reward/rotating_object: 130.0542
        Episode_Reward/action_rate: -0.0190
          Episode_Reward/joint_vel: -0.0083
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 56623104
                    Iteration time: 1.73s
                      Time elapsed: 00:18:42
                               ETA: 00:30:02

################################################################################
                     [1m Learning iteration 576/1500 [0m                      

                       Computation: 58095 steps/s (collection: 1.597s, learning 0.095s)
             Mean action noise std: 1.98
          Mean value_function loss: 36.6098
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 37.1461
                       Mean reward: 669.31
               Mean episode length: 248.18
    Episode_Reward/reaching_object: 0.6999
    Episode_Reward/rotating_object: 132.7853
        Episode_Reward/action_rate: -0.0191
          Episode_Reward/joint_vel: -0.0085
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 56721408
                    Iteration time: 1.69s
                      Time elapsed: 00:18:43
                               ETA: 00:29:59

################################################################################
                     [1m Learning iteration 577/1500 [0m                      

                       Computation: 56548 steps/s (collection: 1.620s, learning 0.118s)
             Mean action noise std: 1.98
          Mean value_function loss: 32.5350
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 37.1578
                       Mean reward: 659.00
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7012
    Episode_Reward/rotating_object: 132.1931
        Episode_Reward/action_rate: -0.0192
          Episode_Reward/joint_vel: -0.0081
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 56819712
                    Iteration time: 1.74s
                      Time elapsed: 00:18:45
                               ETA: 00:29:57

################################################################################
                     [1m Learning iteration 578/1500 [0m                      

                       Computation: 56691 steps/s (collection: 1.632s, learning 0.102s)
             Mean action noise std: 1.98
          Mean value_function loss: 28.5708
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 37.1692
                       Mean reward: 660.34
               Mean episode length: 243.45
    Episode_Reward/reaching_object: 0.7072
    Episode_Reward/rotating_object: 132.5411
        Episode_Reward/action_rate: -0.0193
          Episode_Reward/joint_vel: -0.0086
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 56918016
                    Iteration time: 1.73s
                      Time elapsed: 00:18:47
                               ETA: 00:29:55

################################################################################
                     [1m Learning iteration 579/1500 [0m                      

                       Computation: 56874 steps/s (collection: 1.633s, learning 0.095s)
             Mean action noise std: 1.98
          Mean value_function loss: 31.4981
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 37.1802
                       Mean reward: 672.75
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7070
    Episode_Reward/rotating_object: 132.4632
        Episode_Reward/action_rate: -0.0194
          Episode_Reward/joint_vel: -0.0087
      Episode_Termination/time_out: 18.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 57016320
                    Iteration time: 1.73s
                      Time elapsed: 00:18:49
                               ETA: 00:29:52

################################################################################
                     [1m Learning iteration 580/1500 [0m                      

                       Computation: 56700 steps/s (collection: 1.628s, learning 0.106s)
             Mean action noise std: 1.99
          Mean value_function loss: 36.7961
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 37.1936
                       Mean reward: 678.64
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7081
    Episode_Reward/rotating_object: 131.1967
        Episode_Reward/action_rate: -0.0194
          Episode_Reward/joint_vel: -0.0086
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 57114624
                    Iteration time: 1.73s
                      Time elapsed: 00:18:50
                               ETA: 00:29:50

################################################################################
                     [1m Learning iteration 581/1500 [0m                      

                       Computation: 57261 steps/s (collection: 1.600s, learning 0.117s)
             Mean action noise std: 1.99
          Mean value_function loss: 28.4431
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 37.2107
                       Mean reward: 650.77
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7104
    Episode_Reward/rotating_object: 132.3403
        Episode_Reward/action_rate: -0.0195
          Episode_Reward/joint_vel: -0.0089
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 57212928
                    Iteration time: 1.72s
                      Time elapsed: 00:18:52
                               ETA: 00:29:48

################################################################################
                     [1m Learning iteration 582/1500 [0m                      

                       Computation: 56505 steps/s (collection: 1.633s, learning 0.106s)
             Mean action noise std: 1.99
          Mean value_function loss: 29.8096
               Mean surrogate loss: 0.0022
                 Mean entropy loss: 37.2208
                       Mean reward: 697.73
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7204
    Episode_Reward/rotating_object: 136.8287
        Episode_Reward/action_rate: -0.0196
          Episode_Reward/joint_vel: -0.0087
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 57311232
                    Iteration time: 1.74s
                      Time elapsed: 00:18:54
                               ETA: 00:29:46

################################################################################
                     [1m Learning iteration 583/1500 [0m                      

                       Computation: 56345 steps/s (collection: 1.649s, learning 0.096s)
             Mean action noise std: 1.99
          Mean value_function loss: 37.8027
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 37.2280
                       Mean reward: 665.84
               Mean episode length: 248.13
    Episode_Reward/reaching_object: 0.7077
    Episode_Reward/rotating_object: 131.7818
        Episode_Reward/action_rate: -0.0195
          Episode_Reward/joint_vel: -0.0090
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 57409536
                    Iteration time: 1.74s
                      Time elapsed: 00:18:56
                               ETA: 00:29:43

################################################################################
                     [1m Learning iteration 584/1500 [0m                      

                       Computation: 57082 steps/s (collection: 1.628s, learning 0.094s)
             Mean action noise std: 1.99
          Mean value_function loss: 37.4779
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 37.2377
                       Mean reward: 639.18
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7120
    Episode_Reward/rotating_object: 130.9623
        Episode_Reward/action_rate: -0.0195
          Episode_Reward/joint_vel: -0.0082
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 57507840
                    Iteration time: 1.72s
                      Time elapsed: 00:18:57
                               ETA: 00:29:41

################################################################################
                     [1m Learning iteration 585/1500 [0m                      

                       Computation: 53803 steps/s (collection: 1.673s, learning 0.154s)
             Mean action noise std: 1.99
          Mean value_function loss: 33.4936
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 37.2460
                       Mean reward: 663.40
               Mean episode length: 245.08
    Episode_Reward/reaching_object: 0.7079
    Episode_Reward/rotating_object: 131.6084
        Episode_Reward/action_rate: -0.0194
          Episode_Reward/joint_vel: -0.0085
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 57606144
                    Iteration time: 1.83s
                      Time elapsed: 00:18:59
                               ETA: 00:29:39

################################################################################
                     [1m Learning iteration 586/1500 [0m                      

                       Computation: 56997 steps/s (collection: 1.634s, learning 0.091s)
             Mean action noise std: 1.99
          Mean value_function loss: 38.1282
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 37.2630
                       Mean reward: 656.98
               Mean episode length: 247.12
    Episode_Reward/reaching_object: 0.7100
    Episode_Reward/rotating_object: 132.7607
        Episode_Reward/action_rate: -0.0194
          Episode_Reward/joint_vel: -0.0084
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 57704448
                    Iteration time: 1.72s
                      Time elapsed: 00:19:01
                               ETA: 00:29:37

################################################################################
                     [1m Learning iteration 587/1500 [0m                      

                       Computation: 56659 steps/s (collection: 1.636s, learning 0.099s)
             Mean action noise std: 2.00
          Mean value_function loss: 36.4208
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 37.2779
                       Mean reward: 656.97
               Mean episode length: 245.76
    Episode_Reward/reaching_object: 0.7144
    Episode_Reward/rotating_object: 134.3843
        Episode_Reward/action_rate: -0.0196
          Episode_Reward/joint_vel: -0.0085
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 57802752
                    Iteration time: 1.73s
                      Time elapsed: 00:19:03
                               ETA: 00:29:34

################################################################################
                     [1m Learning iteration 588/1500 [0m                      

                       Computation: 55537 steps/s (collection: 1.650s, learning 0.120s)
             Mean action noise std: 2.00
          Mean value_function loss: 30.7716
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 37.2945
                       Mean reward: 691.62
               Mean episode length: 248.23
    Episode_Reward/reaching_object: 0.7179
    Episode_Reward/rotating_object: 135.2238
        Episode_Reward/action_rate: -0.0197
          Episode_Reward/joint_vel: -0.0084
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 57901056
                    Iteration time: 1.77s
                      Time elapsed: 00:19:04
                               ETA: 00:29:32

################################################################################
                     [1m Learning iteration 589/1500 [0m                      

                       Computation: 52862 steps/s (collection: 1.693s, learning 0.167s)
             Mean action noise std: 2.00
          Mean value_function loss: 32.9364
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 37.3115
                       Mean reward: 693.81
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7123
    Episode_Reward/rotating_object: 132.7710
        Episode_Reward/action_rate: -0.0196
          Episode_Reward/joint_vel: -0.0087
      Episode_Termination/time_out: 18.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 57999360
                    Iteration time: 1.86s
                      Time elapsed: 00:19:06
                               ETA: 00:29:30

################################################################################
                     [1m Learning iteration 590/1500 [0m                      

                       Computation: 55173 steps/s (collection: 1.683s, learning 0.098s)
             Mean action noise std: 2.00
          Mean value_function loss: 44.4508
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 37.3288
                       Mean reward: 694.23
               Mean episode length: 247.71
    Episode_Reward/reaching_object: 0.7180
    Episode_Reward/rotating_object: 135.8648
        Episode_Reward/action_rate: -0.0196
          Episode_Reward/joint_vel: -0.0085
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 58097664
                    Iteration time: 1.78s
                      Time elapsed: 00:19:08
                               ETA: 00:29:28

################################################################################
                     [1m Learning iteration 591/1500 [0m                      

                       Computation: 52523 steps/s (collection: 1.716s, learning 0.156s)
             Mean action noise std: 2.00
          Mean value_function loss: 41.9597
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 37.3322
                       Mean reward: 684.20
               Mean episode length: 249.48
    Episode_Reward/reaching_object: 0.7163
    Episode_Reward/rotating_object: 132.8944
        Episode_Reward/action_rate: -0.0198
          Episode_Reward/joint_vel: -0.0085
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 58195968
                    Iteration time: 1.87s
                      Time elapsed: 00:19:10
                               ETA: 00:29:26

################################################################################
                     [1m Learning iteration 592/1500 [0m                      

                       Computation: 43669 steps/s (collection: 2.094s, learning 0.157s)
             Mean action noise std: 2.00
          Mean value_function loss: 37.1061
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 37.3379
                       Mean reward: 653.92
               Mean episode length: 244.41
    Episode_Reward/reaching_object: 0.7136
    Episode_Reward/rotating_object: 132.1671
        Episode_Reward/action_rate: -0.0197
          Episode_Reward/joint_vel: -0.0087
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 58294272
                    Iteration time: 2.25s
                      Time elapsed: 00:19:12
                               ETA: 00:29:24

################################################################################
                     [1m Learning iteration 593/1500 [0m                      

                       Computation: 54009 steps/s (collection: 1.705s, learning 0.116s)
             Mean action noise std: 2.01
          Mean value_function loss: 35.6306
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 37.3421
                       Mean reward: 674.85
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7216
    Episode_Reward/rotating_object: 134.4357
        Episode_Reward/action_rate: -0.0197
          Episode_Reward/joint_vel: -0.0085
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 58392576
                    Iteration time: 1.82s
                      Time elapsed: 00:19:14
                               ETA: 00:29:22

################################################################################
                     [1m Learning iteration 594/1500 [0m                      

                       Computation: 53491 steps/s (collection: 1.741s, learning 0.097s)
             Mean action noise std: 2.01
          Mean value_function loss: 34.9326
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 37.3577
                       Mean reward: 694.01
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7164
    Episode_Reward/rotating_object: 134.0736
        Episode_Reward/action_rate: -0.0196
          Episode_Reward/joint_vel: -0.0083
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 58490880
                    Iteration time: 1.84s
                      Time elapsed: 00:19:16
                               ETA: 00:29:20

################################################################################
                     [1m Learning iteration 595/1500 [0m                      

                       Computation: 50323 steps/s (collection: 1.758s, learning 0.195s)
             Mean action noise std: 2.01
          Mean value_function loss: 37.4715
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 37.3748
                       Mean reward: 647.97
               Mean episode length: 247.50
    Episode_Reward/reaching_object: 0.7217
    Episode_Reward/rotating_object: 134.1066
        Episode_Reward/action_rate: -0.0198
          Episode_Reward/joint_vel: -0.0091
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 58589184
                    Iteration time: 1.95s
                      Time elapsed: 00:19:18
                               ETA: 00:29:18

################################################################################
                     [1m Learning iteration 596/1500 [0m                      

                       Computation: 52250 steps/s (collection: 1.762s, learning 0.120s)
             Mean action noise std: 2.01
          Mean value_function loss: 34.5156
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 37.3852
                       Mean reward: 659.05
               Mean episode length: 246.31
    Episode_Reward/reaching_object: 0.7196
    Episode_Reward/rotating_object: 134.8918
        Episode_Reward/action_rate: -0.0196
          Episode_Reward/joint_vel: -0.0082
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 58687488
                    Iteration time: 1.88s
                      Time elapsed: 00:19:20
                               ETA: 00:29:16

################################################################################
                     [1m Learning iteration 597/1500 [0m                      

                       Computation: 51784 steps/s (collection: 1.786s, learning 0.112s)
             Mean action noise std: 2.01
          Mean value_function loss: 32.7925
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 37.3949
                       Mean reward: 663.17
               Mean episode length: 248.07
    Episode_Reward/reaching_object: 0.7176
    Episode_Reward/rotating_object: 132.0704
        Episode_Reward/action_rate: -0.0196
          Episode_Reward/joint_vel: -0.0082
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 58785792
                    Iteration time: 1.90s
                      Time elapsed: 00:19:21
                               ETA: 00:29:14

################################################################################
                     [1m Learning iteration 598/1500 [0m                      

                       Computation: 53584 steps/s (collection: 1.698s, learning 0.137s)
             Mean action noise std: 2.01
          Mean value_function loss: 30.1568
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 37.4046
                       Mean reward: 674.03
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7177
    Episode_Reward/rotating_object: 135.3682
        Episode_Reward/action_rate: -0.0197
          Episode_Reward/joint_vel: -0.0082
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 58884096
                    Iteration time: 1.83s
                      Time elapsed: 00:19:23
                               ETA: 00:29:12

################################################################################
                     [1m Learning iteration 599/1500 [0m                      

                       Computation: 56313 steps/s (collection: 1.649s, learning 0.097s)
             Mean action noise std: 2.02
          Mean value_function loss: 35.8342
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 37.4214
                       Mean reward: 660.33
               Mean episode length: 247.71
    Episode_Reward/reaching_object: 0.7159
    Episode_Reward/rotating_object: 133.1635
        Episode_Reward/action_rate: -0.0196
          Episode_Reward/joint_vel: -0.0079
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 58982400
                    Iteration time: 1.75s
                      Time elapsed: 00:19:25
                               ETA: 00:29:10

################################################################################
                     [1m Learning iteration 600/1500 [0m                      

                       Computation: 55428 steps/s (collection: 1.673s, learning 0.100s)
             Mean action noise std: 2.02
          Mean value_function loss: 32.3434
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 37.4301
                       Mean reward: 648.18
               Mean episode length: 247.87
    Episode_Reward/reaching_object: 0.7110
    Episode_Reward/rotating_object: 130.3848
        Episode_Reward/action_rate: -0.0196
          Episode_Reward/joint_vel: -0.0079
      Episode_Termination/time_out: 17.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 59080704
                    Iteration time: 1.77s
                      Time elapsed: 00:19:27
                               ETA: 00:29:08

################################################################################
                     [1m Learning iteration 601/1500 [0m                      

                       Computation: 52273 steps/s (collection: 1.778s, learning 0.103s)
             Mean action noise std: 2.02
          Mean value_function loss: 33.8253
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 37.4366
                       Mean reward: 646.86
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7123
    Episode_Reward/rotating_object: 133.9963
        Episode_Reward/action_rate: -0.0196
          Episode_Reward/joint_vel: -0.0078
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 59179008
                    Iteration time: 1.88s
                      Time elapsed: 00:19:29
                               ETA: 00:29:06

################################################################################
                     [1m Learning iteration 602/1500 [0m                      

                       Computation: 54951 steps/s (collection: 1.686s, learning 0.103s)
             Mean action noise std: 2.02
          Mean value_function loss: 32.3072
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 37.4418
                       Mean reward: 652.29
               Mean episode length: 247.78
    Episode_Reward/reaching_object: 0.7127
    Episode_Reward/rotating_object: 133.1057
        Episode_Reward/action_rate: -0.0197
          Episode_Reward/joint_vel: -0.0080
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 59277312
                    Iteration time: 1.79s
                      Time elapsed: 00:19:30
                               ETA: 00:29:03

################################################################################
                     [1m Learning iteration 603/1500 [0m                      

                       Computation: 53660 steps/s (collection: 1.713s, learning 0.119s)
             Mean action noise std: 2.02
          Mean value_function loss: 31.6613
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 37.4554
                       Mean reward: 681.91
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7140
    Episode_Reward/rotating_object: 134.6271
        Episode_Reward/action_rate: -0.0198
          Episode_Reward/joint_vel: -0.0080
      Episode_Termination/time_out: 17.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 59375616
                    Iteration time: 1.83s
                      Time elapsed: 00:19:32
                               ETA: 00:29:01

################################################################################
                     [1m Learning iteration 604/1500 [0m                      

                       Computation: 54497 steps/s (collection: 1.668s, learning 0.136s)
             Mean action noise std: 2.02
          Mean value_function loss: 31.5932
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 37.4694
                       Mean reward: 671.02
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7101
    Episode_Reward/rotating_object: 133.9276
        Episode_Reward/action_rate: -0.0198
          Episode_Reward/joint_vel: -0.0080
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 59473920
                    Iteration time: 1.80s
                      Time elapsed: 00:19:34
                               ETA: 00:28:59

################################################################################
                     [1m Learning iteration 605/1500 [0m                      

                       Computation: 55382 steps/s (collection: 1.670s, learning 0.105s)
             Mean action noise std: 2.03
          Mean value_function loss: 37.8136
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 37.4851
                       Mean reward: 697.78
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7127
    Episode_Reward/rotating_object: 134.0440
        Episode_Reward/action_rate: -0.0199
          Episode_Reward/joint_vel: -0.0083
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 59572224
                    Iteration time: 1.77s
                      Time elapsed: 00:19:36
                               ETA: 00:28:57

################################################################################
                     [1m Learning iteration 606/1500 [0m                      

                       Computation: 54466 steps/s (collection: 1.693s, learning 0.112s)
             Mean action noise std: 2.03
          Mean value_function loss: 34.8210
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 37.5145
                       Mean reward: 658.05
               Mean episode length: 244.76
    Episode_Reward/reaching_object: 0.7074
    Episode_Reward/rotating_object: 133.2375
        Episode_Reward/action_rate: -0.0197
          Episode_Reward/joint_vel: -0.0079
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 59670528
                    Iteration time: 1.80s
                      Time elapsed: 00:19:38
                               ETA: 00:28:55

################################################################################
                     [1m Learning iteration 607/1500 [0m                      

                       Computation: 51220 steps/s (collection: 1.756s, learning 0.164s)
             Mean action noise std: 2.03
          Mean value_function loss: 34.0935
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 37.5314
                       Mean reward: 672.99
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7171
    Episode_Reward/rotating_object: 135.9805
        Episode_Reward/action_rate: -0.0200
          Episode_Reward/joint_vel: -0.0078
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 59768832
                    Iteration time: 1.92s
                      Time elapsed: 00:19:40
                               ETA: 00:28:53

################################################################################
                     [1m Learning iteration 608/1500 [0m                      

                       Computation: 54163 steps/s (collection: 1.711s, learning 0.104s)
             Mean action noise std: 2.03
          Mean value_function loss: 32.7040
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 37.5458
                       Mean reward: 662.67
               Mean episode length: 247.77
    Episode_Reward/reaching_object: 0.7145
    Episode_Reward/rotating_object: 135.6577
        Episode_Reward/action_rate: -0.0199
          Episode_Reward/joint_vel: -0.0080
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 59867136
                    Iteration time: 1.81s
                      Time elapsed: 00:19:41
                               ETA: 00:28:51

################################################################################
                     [1m Learning iteration 609/1500 [0m                      

                       Computation: 55410 steps/s (collection: 1.633s, learning 0.142s)
             Mean action noise std: 2.04
          Mean value_function loss: 33.2031
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 37.5662
                       Mean reward: 673.45
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7203
    Episode_Reward/rotating_object: 135.7119
        Episode_Reward/action_rate: -0.0200
          Episode_Reward/joint_vel: -0.0080
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 59965440
                    Iteration time: 1.77s
                      Time elapsed: 00:19:43
                               ETA: 00:28:48

################################################################################
                     [1m Learning iteration 610/1500 [0m                      

                       Computation: 54647 steps/s (collection: 1.674s, learning 0.125s)
             Mean action noise std: 2.04
          Mean value_function loss: 30.2166
               Mean surrogate loss: 0.0003
                 Mean entropy loss: 37.5798
                       Mean reward: 688.21
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7159
    Episode_Reward/rotating_object: 135.7230
        Episode_Reward/action_rate: -0.0199
          Episode_Reward/joint_vel: -0.0076
      Episode_Termination/time_out: 17.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 60063744
                    Iteration time: 1.80s
                      Time elapsed: 00:19:45
                               ETA: 00:28:46

################################################################################
                     [1m Learning iteration 611/1500 [0m                      

                       Computation: 54503 steps/s (collection: 1.687s, learning 0.116s)
             Mean action noise std: 2.04
          Mean value_function loss: 32.3290
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 37.5852
                       Mean reward: 692.12
               Mean episode length: 247.84
    Episode_Reward/reaching_object: 0.7107
    Episode_Reward/rotating_object: 134.5034
        Episode_Reward/action_rate: -0.0198
          Episode_Reward/joint_vel: -0.0078
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 60162048
                    Iteration time: 1.80s
                      Time elapsed: 00:19:47
                               ETA: 00:28:44

################################################################################
                     [1m Learning iteration 612/1500 [0m                      

                       Computation: 54647 steps/s (collection: 1.696s, learning 0.103s)
             Mean action noise std: 2.04
          Mean value_function loss: 34.0266
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 37.5922
                       Mean reward: 685.79
               Mean episode length: 247.97
    Episode_Reward/reaching_object: 0.7208
    Episode_Reward/rotating_object: 134.9062
        Episode_Reward/action_rate: -0.0201
          Episode_Reward/joint_vel: -0.0079
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 60260352
                    Iteration time: 1.80s
                      Time elapsed: 00:19:49
                               ETA: 00:28:42

################################################################################
                     [1m Learning iteration 613/1500 [0m                      

                       Computation: 53804 steps/s (collection: 1.707s, learning 0.121s)
             Mean action noise std: 2.04
          Mean value_function loss: 33.3676
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 37.5961
                       Mean reward: 666.11
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7185
    Episode_Reward/rotating_object: 134.4518
        Episode_Reward/action_rate: -0.0200
          Episode_Reward/joint_vel: -0.0078
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 60358656
                    Iteration time: 1.83s
                      Time elapsed: 00:19:50
                               ETA: 00:28:40

################################################################################
                     [1m Learning iteration 614/1500 [0m                      

                       Computation: 54042 steps/s (collection: 1.714s, learning 0.105s)
             Mean action noise std: 2.04
          Mean value_function loss: 32.7244
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 37.6080
                       Mean reward: 680.80
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7197
    Episode_Reward/rotating_object: 135.0049
        Episode_Reward/action_rate: -0.0201
          Episode_Reward/joint_vel: -0.0077
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 60456960
                    Iteration time: 1.82s
                      Time elapsed: 00:19:52
                               ETA: 00:28:38

################################################################################
                     [1m Learning iteration 615/1500 [0m                      

                       Computation: 54387 steps/s (collection: 1.669s, learning 0.139s)
             Mean action noise std: 2.04
          Mean value_function loss: 35.9341
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 37.6228
                       Mean reward: 658.81
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7224
    Episode_Reward/rotating_object: 134.0030
        Episode_Reward/action_rate: -0.0202
          Episode_Reward/joint_vel: -0.0086
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 60555264
                    Iteration time: 1.81s
                      Time elapsed: 00:19:54
                               ETA: 00:28:36

################################################################################
                     [1m Learning iteration 616/1500 [0m                      

                       Computation: 51516 steps/s (collection: 1.811s, learning 0.097s)
             Mean action noise std: 2.04
          Mean value_function loss: 40.4122
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 37.6342
                       Mean reward: 678.98
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7153
    Episode_Reward/rotating_object: 134.4072
        Episode_Reward/action_rate: -0.0199
          Episode_Reward/joint_vel: -0.0076
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 60653568
                    Iteration time: 1.91s
                      Time elapsed: 00:19:56
                               ETA: 00:28:34

################################################################################
                     [1m Learning iteration 617/1500 [0m                      

                       Computation: 54763 steps/s (collection: 1.684s, learning 0.111s)
             Mean action noise std: 2.05
          Mean value_function loss: 36.6784
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 37.6430
                       Mean reward: 670.63
               Mean episode length: 247.79
    Episode_Reward/reaching_object: 0.7191
    Episode_Reward/rotating_object: 132.2470
        Episode_Reward/action_rate: -0.0202
          Episode_Reward/joint_vel: -0.0079
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 60751872
                    Iteration time: 1.80s
                      Time elapsed: 00:19:58
                               ETA: 00:28:32

################################################################################
                     [1m Learning iteration 618/1500 [0m                      

                       Computation: 49817 steps/s (collection: 1.816s, learning 0.157s)
             Mean action noise std: 2.05
          Mean value_function loss: 36.1982
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 37.6534
                       Mean reward: 637.85
               Mean episode length: 247.87
    Episode_Reward/reaching_object: 0.7154
    Episode_Reward/rotating_object: 132.9165
        Episode_Reward/action_rate: -0.0201
          Episode_Reward/joint_vel: -0.0078
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 60850176
                    Iteration time: 1.97s
                      Time elapsed: 00:20:00
                               ETA: 00:28:30

################################################################################
                     [1m Learning iteration 619/1500 [0m                      

                       Computation: 52821 steps/s (collection: 1.756s, learning 0.105s)
             Mean action noise std: 2.05
          Mean value_function loss: 30.2479
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 37.6621
                       Mean reward: 661.00
               Mean episode length: 247.86
    Episode_Reward/reaching_object: 0.7200
    Episode_Reward/rotating_object: 134.0030
        Episode_Reward/action_rate: -0.0202
          Episode_Reward/joint_vel: -0.0078
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 60948480
                    Iteration time: 1.86s
                      Time elapsed: 00:20:02
                               ETA: 00:28:28

################################################################################
                     [1m Learning iteration 620/1500 [0m                      

                       Computation: 52671 steps/s (collection: 1.771s, learning 0.096s)
             Mean action noise std: 2.05
          Mean value_function loss: 32.2726
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 37.6783
                       Mean reward: 655.79
               Mean episode length: 248.01
    Episode_Reward/reaching_object: 0.7237
    Episode_Reward/rotating_object: 136.9159
        Episode_Reward/action_rate: -0.0203
          Episode_Reward/joint_vel: -0.0077
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 61046784
                    Iteration time: 1.87s
                      Time elapsed: 00:20:03
                               ETA: 00:28:26

################################################################################
                     [1m Learning iteration 621/1500 [0m                      

                       Computation: 55009 steps/s (collection: 1.683s, learning 0.104s)
             Mean action noise std: 2.05
          Mean value_function loss: 39.3276
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 37.6967
                       Mean reward: 673.37
               Mean episode length: 243.40
    Episode_Reward/reaching_object: 0.7180
    Episode_Reward/rotating_object: 136.3459
        Episode_Reward/action_rate: -0.0202
          Episode_Reward/joint_vel: -0.0077
      Episode_Termination/time_out: 17.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 61145088
                    Iteration time: 1.79s
                      Time elapsed: 00:20:05
                               ETA: 00:28:23

################################################################################
                     [1m Learning iteration 622/1500 [0m                      

                       Computation: 53901 steps/s (collection: 1.711s, learning 0.113s)
             Mean action noise std: 2.06
          Mean value_function loss: 31.8554
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 37.7126
                       Mean reward: 686.28
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7211
    Episode_Reward/rotating_object: 135.5995
        Episode_Reward/action_rate: -0.0204
          Episode_Reward/joint_vel: -0.0077
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 61243392
                    Iteration time: 1.82s
                      Time elapsed: 00:20:07
                               ETA: 00:28:21

################################################################################
                     [1m Learning iteration 623/1500 [0m                      

                       Computation: 53727 steps/s (collection: 1.728s, learning 0.102s)
             Mean action noise std: 2.06
          Mean value_function loss: 28.6670
               Mean surrogate loss: -0.0005
                 Mean entropy loss: 37.7244
                       Mean reward: 706.66
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7217
    Episode_Reward/rotating_object: 135.6255
        Episode_Reward/action_rate: -0.0206
          Episode_Reward/joint_vel: -0.0078
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 61341696
                    Iteration time: 1.83s
                      Time elapsed: 00:20:09
                               ETA: 00:28:19

################################################################################
                     [1m Learning iteration 624/1500 [0m                      

                       Computation: 53734 steps/s (collection: 1.713s, learning 0.116s)
             Mean action noise std: 2.06
          Mean value_function loss: 28.3376
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 37.7344
                       Mean reward: 679.14
               Mean episode length: 248.16
    Episode_Reward/reaching_object: 0.7184
    Episode_Reward/rotating_object: 134.8664
        Episode_Reward/action_rate: -0.0205
          Episode_Reward/joint_vel: -0.0081
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 61440000
                    Iteration time: 1.83s
                      Time elapsed: 00:20:11
                               ETA: 00:28:17

################################################################################
                     [1m Learning iteration 625/1500 [0m                      

                       Computation: 53189 steps/s (collection: 1.743s, learning 0.106s)
             Mean action noise std: 2.06
          Mean value_function loss: 32.4203
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 37.7528
                       Mean reward: 693.97
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7175
    Episode_Reward/rotating_object: 136.0095
        Episode_Reward/action_rate: -0.0205
          Episode_Reward/joint_vel: -0.0083
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 61538304
                    Iteration time: 1.85s
                      Time elapsed: 00:20:13
                               ETA: 00:28:15

################################################################################
                     [1m Learning iteration 626/1500 [0m                      

                       Computation: 52502 steps/s (collection: 1.747s, learning 0.125s)
             Mean action noise std: 2.06
          Mean value_function loss: 34.0922
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 37.7714
                       Mean reward: 689.65
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7128
    Episode_Reward/rotating_object: 134.7358
        Episode_Reward/action_rate: -0.0205
          Episode_Reward/joint_vel: -0.0080
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 61636608
                    Iteration time: 1.87s
                      Time elapsed: 00:20:14
                               ETA: 00:28:13

################################################################################
                     [1m Learning iteration 627/1500 [0m                      

                       Computation: 53364 steps/s (collection: 1.702s, learning 0.140s)
             Mean action noise std: 2.07
          Mean value_function loss: 28.9003
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 37.7840
                       Mean reward: 705.90
               Mean episode length: 247.84
    Episode_Reward/reaching_object: 0.7155
    Episode_Reward/rotating_object: 134.7181
        Episode_Reward/action_rate: -0.0206
          Episode_Reward/joint_vel: -0.0084
      Episode_Termination/time_out: 17.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 61734912
                    Iteration time: 1.84s
                      Time elapsed: 00:20:16
                               ETA: 00:28:11

################################################################################
                     [1m Learning iteration 628/1500 [0m                      

                       Computation: 49640 steps/s (collection: 1.797s, learning 0.183s)
             Mean action noise std: 2.07
          Mean value_function loss: 31.8943
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 37.7970
                       Mean reward: 665.51
               Mean episode length: 246.05
    Episode_Reward/reaching_object: 0.7099
    Episode_Reward/rotating_object: 134.2507
        Episode_Reward/action_rate: -0.0204
          Episode_Reward/joint_vel: -0.0077
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 61833216
                    Iteration time: 1.98s
                      Time elapsed: 00:20:18
                               ETA: 00:28:09

################################################################################
                     [1m Learning iteration 629/1500 [0m                      

                       Computation: 51490 steps/s (collection: 1.776s, learning 0.134s)
             Mean action noise std: 2.07
          Mean value_function loss: 33.3735
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 37.8087
                       Mean reward: 704.33
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7151
    Episode_Reward/rotating_object: 134.6012
        Episode_Reward/action_rate: -0.0206
          Episode_Reward/joint_vel: -0.0078
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 61931520
                    Iteration time: 1.91s
                      Time elapsed: 00:20:20
                               ETA: 00:28:07

################################################################################
                     [1m Learning iteration 630/1500 [0m                      

                       Computation: 55197 steps/s (collection: 1.683s, learning 0.097s)
             Mean action noise std: 2.07
          Mean value_function loss: 34.1241
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 37.8147
                       Mean reward: 660.92
               Mean episode length: 248.84
    Episode_Reward/reaching_object: 0.7100
    Episode_Reward/rotating_object: 133.4006
        Episode_Reward/action_rate: -0.0206
          Episode_Reward/joint_vel: -0.0079
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 62029824
                    Iteration time: 1.78s
                      Time elapsed: 00:20:22
                               ETA: 00:28:05

################################################################################
                     [1m Learning iteration 631/1500 [0m                      

                       Computation: 52249 steps/s (collection: 1.688s, learning 0.193s)
             Mean action noise std: 2.07
          Mean value_function loss: 35.4084
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 37.8188
                       Mean reward: 680.88
               Mean episode length: 247.76
    Episode_Reward/reaching_object: 0.7182
    Episode_Reward/rotating_object: 137.8265
        Episode_Reward/action_rate: -0.0208
          Episode_Reward/joint_vel: -0.0078
      Episode_Termination/time_out: 17.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 62128128
                    Iteration time: 1.88s
                      Time elapsed: 00:20:24
                               ETA: 00:28:03

################################################################################
                     [1m Learning iteration 632/1500 [0m                      

                       Computation: 49972 steps/s (collection: 1.843s, learning 0.124s)
             Mean action noise std: 2.07
          Mean value_function loss: 30.6234
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 37.8291
                       Mean reward: 701.17
               Mean episode length: 246.72
    Episode_Reward/reaching_object: 0.7194
    Episode_Reward/rotating_object: 140.2220
        Episode_Reward/action_rate: -0.0209
          Episode_Reward/joint_vel: -0.0078
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 62226432
                    Iteration time: 1.97s
                      Time elapsed: 00:20:26
                               ETA: 00:28:01

################################################################################
                     [1m Learning iteration 633/1500 [0m                      

                       Computation: 55625 steps/s (collection: 1.651s, learning 0.117s)
             Mean action noise std: 2.08
          Mean value_function loss: 33.5676
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 37.8460
                       Mean reward: 673.17
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7184
    Episode_Reward/rotating_object: 136.2939
        Episode_Reward/action_rate: -0.0208
          Episode_Reward/joint_vel: -0.0079
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 62324736
                    Iteration time: 1.77s
                      Time elapsed: 00:20:28
                               ETA: 00:27:59

################################################################################
                     [1m Learning iteration 634/1500 [0m                      

                       Computation: 54635 steps/s (collection: 1.703s, learning 0.097s)
             Mean action noise std: 2.08
          Mean value_function loss: 29.3450
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 37.8611
                       Mean reward: 671.28
               Mean episode length: 249.13
    Episode_Reward/reaching_object: 0.7212
    Episode_Reward/rotating_object: 137.4655
        Episode_Reward/action_rate: -0.0210
          Episode_Reward/joint_vel: -0.0079
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 62423040
                    Iteration time: 1.80s
                      Time elapsed: 00:20:29
                               ETA: 00:27:57

################################################################################
                     [1m Learning iteration 635/1500 [0m                      

                       Computation: 56276 steps/s (collection: 1.649s, learning 0.098s)
             Mean action noise std: 2.08
          Mean value_function loss: 35.0561
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 37.8781
                       Mean reward: 681.42
               Mean episode length: 245.55
    Episode_Reward/reaching_object: 0.7147
    Episode_Reward/rotating_object: 135.7248
        Episode_Reward/action_rate: -0.0208
          Episode_Reward/joint_vel: -0.0077
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 62521344
                    Iteration time: 1.75s
                      Time elapsed: 00:20:31
                               ETA: 00:27:55

################################################################################
                     [1m Learning iteration 636/1500 [0m                      

                       Computation: 56462 steps/s (collection: 1.641s, learning 0.101s)
             Mean action noise std: 2.08
          Mean value_function loss: 32.5775
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 37.8919
                       Mean reward: 667.46
               Mean episode length: 247.00
    Episode_Reward/reaching_object: 0.7185
    Episode_Reward/rotating_object: 137.0532
        Episode_Reward/action_rate: -0.0210
          Episode_Reward/joint_vel: -0.0082
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 62619648
                    Iteration time: 1.74s
                      Time elapsed: 00:20:33
                               ETA: 00:27:52

################################################################################
                     [1m Learning iteration 637/1500 [0m                      

                       Computation: 55363 steps/s (collection: 1.674s, learning 0.102s)
             Mean action noise std: 2.08
          Mean value_function loss: 32.7731
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 37.9071
                       Mean reward: 695.68
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7156
    Episode_Reward/rotating_object: 136.8345
        Episode_Reward/action_rate: -0.0209
          Episode_Reward/joint_vel: -0.0076
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 62717952
                    Iteration time: 1.78s
                      Time elapsed: 00:20:35
                               ETA: 00:27:50

################################################################################
                     [1m Learning iteration 638/1500 [0m                      

                       Computation: 54717 steps/s (collection: 1.689s, learning 0.107s)
             Mean action noise std: 2.09
          Mean value_function loss: 30.8551
               Mean surrogate loss: -0.0002
                 Mean entropy loss: 37.9217
                       Mean reward: 684.05
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7145
    Episode_Reward/rotating_object: 135.0428
        Episode_Reward/action_rate: -0.0211
          Episode_Reward/joint_vel: -0.0078
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 62816256
                    Iteration time: 1.80s
                      Time elapsed: 00:20:36
                               ETA: 00:27:48

################################################################################
                     [1m Learning iteration 639/1500 [0m                      

                       Computation: 53155 steps/s (collection: 1.684s, learning 0.166s)
             Mean action noise std: 2.09
          Mean value_function loss: 36.9758
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 37.9318
                       Mean reward: 678.60
               Mean episode length: 247.67
    Episode_Reward/reaching_object: 0.7011
    Episode_Reward/rotating_object: 133.5791
        Episode_Reward/action_rate: -0.0207
          Episode_Reward/joint_vel: -0.0077
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 62914560
                    Iteration time: 1.85s
                      Time elapsed: 00:20:38
                               ETA: 00:27:46

################################################################################
                     [1m Learning iteration 640/1500 [0m                      

                       Computation: 50803 steps/s (collection: 1.793s, learning 0.142s)
             Mean action noise std: 2.09
          Mean value_function loss: 40.2245
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 37.9490
                       Mean reward: 686.22
               Mean episode length: 248.25
    Episode_Reward/reaching_object: 0.7124
    Episode_Reward/rotating_object: 135.1362
        Episode_Reward/action_rate: -0.0209
          Episode_Reward/joint_vel: -0.0076
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 63012864
                    Iteration time: 1.93s
                      Time elapsed: 00:20:40
                               ETA: 00:27:44

################################################################################
                     [1m Learning iteration 641/1500 [0m                      

                       Computation: 54441 steps/s (collection: 1.704s, learning 0.102s)
             Mean action noise std: 2.09
          Mean value_function loss: 36.5790
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 37.9640
                       Mean reward: 690.95
               Mean episode length: 245.22
    Episode_Reward/reaching_object: 0.7207
    Episode_Reward/rotating_object: 138.4223
        Episode_Reward/action_rate: -0.0211
          Episode_Reward/joint_vel: -0.0078
      Episode_Termination/time_out: 17.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 63111168
                    Iteration time: 1.81s
                      Time elapsed: 00:20:42
                               ETA: 00:27:42

################################################################################
                     [1m Learning iteration 642/1500 [0m                      

                       Computation: 50495 steps/s (collection: 1.791s, learning 0.156s)
             Mean action noise std: 2.09
          Mean value_function loss: 36.7048
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 37.9772
                       Mean reward: 668.43
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7193
    Episode_Reward/rotating_object: 134.7568
        Episode_Reward/action_rate: -0.0211
          Episode_Reward/joint_vel: -0.0077
      Episode_Termination/time_out: 18.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 63209472
                    Iteration time: 1.95s
                      Time elapsed: 00:20:44
                               ETA: 00:27:40

################################################################################
                     [1m Learning iteration 643/1500 [0m                      

                       Computation: 53127 steps/s (collection: 1.738s, learning 0.112s)
             Mean action noise std: 2.10
          Mean value_function loss: 36.5527
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 37.9960
                       Mean reward: 682.00
               Mean episode length: 247.73
    Episode_Reward/reaching_object: 0.7256
    Episode_Reward/rotating_object: 137.3651
        Episode_Reward/action_rate: -0.0212
          Episode_Reward/joint_vel: -0.0075
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 63307776
                    Iteration time: 1.85s
                      Time elapsed: 00:20:46
                               ETA: 00:27:38

################################################################################
                     [1m Learning iteration 644/1500 [0m                      

                       Computation: 54756 steps/s (collection: 1.661s, learning 0.135s)
             Mean action noise std: 2.10
          Mean value_function loss: 29.8516
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 38.0093
                       Mean reward: 674.43
               Mean episode length: 249.03
    Episode_Reward/reaching_object: 0.7219
    Episode_Reward/rotating_object: 134.8205
        Episode_Reward/action_rate: -0.0212
          Episode_Reward/joint_vel: -0.0079
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 63406080
                    Iteration time: 1.80s
                      Time elapsed: 00:20:48
                               ETA: 00:27:36

################################################################################
                     [1m Learning iteration 645/1500 [0m                      

                       Computation: 46621 steps/s (collection: 1.924s, learning 0.185s)
             Mean action noise std: 2.10
          Mean value_function loss: 30.9464
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 38.0230
                       Mean reward: 710.56
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7215
    Episode_Reward/rotating_object: 136.2151
        Episode_Reward/action_rate: -0.0212
          Episode_Reward/joint_vel: -0.0072
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 63504384
                    Iteration time: 2.11s
                      Time elapsed: 00:20:50
                               ETA: 00:27:34

################################################################################
                     [1m Learning iteration 646/1500 [0m                      

                       Computation: 50492 steps/s (collection: 1.805s, learning 0.142s)
             Mean action noise std: 2.10
          Mean value_function loss: 35.1527
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 38.0322
                       Mean reward: 645.88
               Mean episode length: 241.34
    Episode_Reward/reaching_object: 0.7212
    Episode_Reward/rotating_object: 135.9463
        Episode_Reward/action_rate: -0.0211
          Episode_Reward/joint_vel: -0.0075
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 63602688
                    Iteration time: 1.95s
                      Time elapsed: 00:20:52
                               ETA: 00:27:32

################################################################################
                     [1m Learning iteration 647/1500 [0m                      

                       Computation: 52636 steps/s (collection: 1.712s, learning 0.156s)
             Mean action noise std: 2.10
          Mean value_function loss: 36.3117
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 38.0386
                       Mean reward: 717.05
               Mean episode length: 247.72
    Episode_Reward/reaching_object: 0.7292
    Episode_Reward/rotating_object: 139.1738
        Episode_Reward/action_rate: -0.0213
          Episode_Reward/joint_vel: -0.0076
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 63700992
                    Iteration time: 1.87s
                      Time elapsed: 00:20:54
                               ETA: 00:27:30

################################################################################
                     [1m Learning iteration 648/1500 [0m                      

                       Computation: 50608 steps/s (collection: 1.834s, learning 0.108s)
             Mean action noise std: 2.10
          Mean value_function loss: 29.4159
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 38.0483
                       Mean reward: 656.85
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7193
    Episode_Reward/rotating_object: 133.5950
        Episode_Reward/action_rate: -0.0214
          Episode_Reward/joint_vel: -0.0076
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 63799296
                    Iteration time: 1.94s
                      Time elapsed: 00:20:55
                               ETA: 00:27:28

################################################################################
                     [1m Learning iteration 649/1500 [0m                      

                       Computation: 50340 steps/s (collection: 1.752s, learning 0.201s)
             Mean action noise std: 2.11
          Mean value_function loss: 31.9194
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 38.0650
                       Mean reward: 664.07
               Mean episode length: 247.48
    Episode_Reward/reaching_object: 0.7182
    Episode_Reward/rotating_object: 133.5494
        Episode_Reward/action_rate: -0.0214
          Episode_Reward/joint_vel: -0.0078
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 63897600
                    Iteration time: 1.95s
                      Time elapsed: 00:20:57
                               ETA: 00:27:26

################################################################################
                     [1m Learning iteration 650/1500 [0m                      

                       Computation: 47903 steps/s (collection: 1.825s, learning 0.227s)
             Mean action noise std: 2.11
          Mean value_function loss: 32.3233
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 38.0849
                       Mean reward: 702.25
               Mean episode length: 245.95
    Episode_Reward/reaching_object: 0.7113
    Episode_Reward/rotating_object: 133.1617
        Episode_Reward/action_rate: -0.0213
          Episode_Reward/joint_vel: -0.0080
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 63995904
                    Iteration time: 2.05s
                      Time elapsed: 00:21:00
                               ETA: 00:27:25

################################################################################
                     [1m Learning iteration 651/1500 [0m                      

                       Computation: 49006 steps/s (collection: 1.834s, learning 0.172s)
             Mean action noise std: 2.11
          Mean value_function loss: 31.0595
               Mean surrogate loss: -0.0000
                 Mean entropy loss: 38.1030
                       Mean reward: 671.99
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7064
    Episode_Reward/rotating_object: 129.9077
        Episode_Reward/action_rate: -0.0213
          Episode_Reward/joint_vel: -0.0081
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 64094208
                    Iteration time: 2.01s
                      Time elapsed: 00:21:02
                               ETA: 00:27:23

################################################################################
                     [1m Learning iteration 652/1500 [0m                      

                       Computation: 52443 steps/s (collection: 1.703s, learning 0.171s)
             Mean action noise std: 2.11
          Mean value_function loss: 32.9867
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 38.1071
                       Mean reward: 669.07
               Mean episode length: 246.57
    Episode_Reward/reaching_object: 0.7164
    Episode_Reward/rotating_object: 136.9178
        Episode_Reward/action_rate: -0.0214
          Episode_Reward/joint_vel: -0.0079
      Episode_Termination/time_out: 18.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 64192512
                    Iteration time: 1.87s
                      Time elapsed: 00:21:03
                               ETA: 00:27:21

################################################################################
                     [1m Learning iteration 653/1500 [0m                      

                       Computation: 54327 steps/s (collection: 1.699s, learning 0.111s)
             Mean action noise std: 2.11
          Mean value_function loss: 38.9549
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 38.1086
                       Mean reward: 689.34
               Mean episode length: 243.15
    Episode_Reward/reaching_object: 0.7153
    Episode_Reward/rotating_object: 138.4409
        Episode_Reward/action_rate: -0.0214
          Episode_Reward/joint_vel: -0.0075
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 64290816
                    Iteration time: 1.81s
                      Time elapsed: 00:21:05
                               ETA: 00:27:19

################################################################################
                     [1m Learning iteration 654/1500 [0m                      

                       Computation: 54325 steps/s (collection: 1.707s, learning 0.102s)
             Mean action noise std: 2.11
          Mean value_function loss: 35.2754
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 38.1143
                       Mean reward: 690.36
               Mean episode length: 246.30
    Episode_Reward/reaching_object: 0.7167
    Episode_Reward/rotating_object: 136.5171
        Episode_Reward/action_rate: -0.0216
          Episode_Reward/joint_vel: -0.0079
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 64389120
                    Iteration time: 1.81s
                      Time elapsed: 00:21:07
                               ETA: 00:27:17

################################################################################
                     [1m Learning iteration 655/1500 [0m                      

                       Computation: 49573 steps/s (collection: 1.799s, learning 0.184s)
             Mean action noise std: 2.12
          Mean value_function loss: 29.5466
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 38.1351
                       Mean reward: 669.72
               Mean episode length: 249.82
    Episode_Reward/reaching_object: 0.7083
    Episode_Reward/rotating_object: 132.5302
        Episode_Reward/action_rate: -0.0215
          Episode_Reward/joint_vel: -0.0080
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 64487424
                    Iteration time: 1.98s
                      Time elapsed: 00:21:09
                               ETA: 00:27:15

################################################################################
                     [1m Learning iteration 656/1500 [0m                      

                       Computation: 51893 steps/s (collection: 1.771s, learning 0.123s)
             Mean action noise std: 2.12
          Mean value_function loss: 37.1175
               Mean surrogate loss: 0.0007
                 Mean entropy loss: 38.1527
                       Mean reward: 691.99
               Mean episode length: 247.90
    Episode_Reward/reaching_object: 0.7212
    Episode_Reward/rotating_object: 135.9135
        Episode_Reward/action_rate: -0.0218
          Episode_Reward/joint_vel: -0.0078
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 64585728
                    Iteration time: 1.89s
                      Time elapsed: 00:21:11
                               ETA: 00:27:13

################################################################################
                     [1m Learning iteration 657/1500 [0m                      

                       Computation: 53205 steps/s (collection: 1.701s, learning 0.146s)
             Mean action noise std: 2.12
          Mean value_function loss: 36.3339
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 38.1589
                       Mean reward: 673.31
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7244
    Episode_Reward/rotating_object: 135.8354
        Episode_Reward/action_rate: -0.0217
          Episode_Reward/joint_vel: -0.0079
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 64684032
                    Iteration time: 1.85s
                      Time elapsed: 00:21:13
                               ETA: 00:27:11

################################################################################
                     [1m Learning iteration 658/1500 [0m                      

                       Computation: 52679 steps/s (collection: 1.763s, learning 0.103s)
             Mean action noise std: 2.12
          Mean value_function loss: 30.8155
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 38.1748
                       Mean reward: 676.90
               Mean episode length: 245.84
    Episode_Reward/reaching_object: 0.7250
    Episode_Reward/rotating_object: 136.0681
        Episode_Reward/action_rate: -0.0218
          Episode_Reward/joint_vel: -0.0078
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 64782336
                    Iteration time: 1.87s
                      Time elapsed: 00:21:15
                               ETA: 00:27:09

################################################################################
                     [1m Learning iteration 659/1500 [0m                      

                       Computation: 52487 steps/s (collection: 1.686s, learning 0.187s)
             Mean action noise std: 2.12
          Mean value_function loss: 35.0765
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 38.1957
                       Mean reward: 684.35
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7286
    Episode_Reward/rotating_object: 136.9035
        Episode_Reward/action_rate: -0.0218
          Episode_Reward/joint_vel: -0.0080
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 64880640
                    Iteration time: 1.87s
                      Time elapsed: 00:21:16
                               ETA: 00:27:07

################################################################################
                     [1m Learning iteration 660/1500 [0m                      

                       Computation: 53460 steps/s (collection: 1.729s, learning 0.110s)
             Mean action noise std: 2.13
          Mean value_function loss: 30.6793
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 38.2137
                       Mean reward: 684.69
               Mean episode length: 245.11
    Episode_Reward/reaching_object: 0.7226
    Episode_Reward/rotating_object: 135.3380
        Episode_Reward/action_rate: -0.0218
          Episode_Reward/joint_vel: -0.0085
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 64978944
                    Iteration time: 1.84s
                      Time elapsed: 00:21:18
                               ETA: 00:27:05

################################################################################
                     [1m Learning iteration 661/1500 [0m                      

                       Computation: 54474 steps/s (collection: 1.702s, learning 0.102s)
             Mean action noise std: 2.13
          Mean value_function loss: 31.1394
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 38.2260
                       Mean reward: 662.12
               Mean episode length: 247.93
    Episode_Reward/reaching_object: 0.7303
    Episode_Reward/rotating_object: 136.3871
        Episode_Reward/action_rate: -0.0220
          Episode_Reward/joint_vel: -0.0083
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 65077248
                    Iteration time: 1.80s
                      Time elapsed: 00:21:20
                               ETA: 00:27:03

################################################################################
                     [1m Learning iteration 662/1500 [0m                      

                       Computation: 55274 steps/s (collection: 1.666s, learning 0.113s)
             Mean action noise std: 2.13
          Mean value_function loss: 28.7448
               Mean surrogate loss: -0.0005
                 Mean entropy loss: 38.2394
                       Mean reward: 695.14
               Mean episode length: 246.55
    Episode_Reward/reaching_object: 0.7286
    Episode_Reward/rotating_object: 136.3547
        Episode_Reward/action_rate: -0.0219
          Episode_Reward/joint_vel: -0.0084
      Episode_Termination/time_out: 17.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 65175552
                    Iteration time: 1.78s
                      Time elapsed: 00:21:22
                               ETA: 00:27:00

################################################################################
                     [1m Learning iteration 663/1500 [0m                      

                       Computation: 54743 steps/s (collection: 1.692s, learning 0.104s)
             Mean action noise std: 2.13
          Mean value_function loss: 35.9548
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 38.2467
                       Mean reward: 683.02
               Mean episode length: 247.72
    Episode_Reward/reaching_object: 0.7210
    Episode_Reward/rotating_object: 136.2894
        Episode_Reward/action_rate: -0.0217
          Episode_Reward/joint_vel: -0.0079
      Episode_Termination/time_out: 17.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 65273856
                    Iteration time: 1.80s
                      Time elapsed: 00:21:24
                               ETA: 00:26:58

################################################################################
                     [1m Learning iteration 664/1500 [0m                      

                       Computation: 53180 steps/s (collection: 1.679s, learning 0.170s)
             Mean action noise std: 2.13
          Mean value_function loss: 34.9282
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 38.2581
                       Mean reward: 685.17
               Mean episode length: 246.40
    Episode_Reward/reaching_object: 0.7249
    Episode_Reward/rotating_object: 136.5411
        Episode_Reward/action_rate: -0.0219
          Episode_Reward/joint_vel: -0.0081
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 65372160
                    Iteration time: 1.85s
                      Time elapsed: 00:21:26
                               ETA: 00:26:56

################################################################################
                     [1m Learning iteration 665/1500 [0m                      

                       Computation: 53318 steps/s (collection: 1.691s, learning 0.153s)
             Mean action noise std: 2.14
          Mean value_function loss: 35.5864
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 38.2754
                       Mean reward: 700.50
               Mean episode length: 248.01
    Episode_Reward/reaching_object: 0.7316
    Episode_Reward/rotating_object: 139.6881
        Episode_Reward/action_rate: -0.0220
          Episode_Reward/joint_vel: -0.0078
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 65470464
                    Iteration time: 1.84s
                      Time elapsed: 00:21:27
                               ETA: 00:26:54

################################################################################
                     [1m Learning iteration 666/1500 [0m                      

                       Computation: 29564 steps/s (collection: 3.189s, learning 0.136s)
             Mean action noise std: 2.14
          Mean value_function loss: 29.3742
               Mean surrogate loss: -0.0005
                 Mean entropy loss: 38.2904
                       Mean reward: 691.19
               Mean episode length: 247.82
    Episode_Reward/reaching_object: 0.7279
    Episode_Reward/rotating_object: 137.3485
        Episode_Reward/action_rate: -0.0221
          Episode_Reward/joint_vel: -0.0080
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 65568768
                    Iteration time: 3.33s
                      Time elapsed: 00:21:31
                               ETA: 00:26:54

################################################################################
                     [1m Learning iteration 667/1500 [0m                      

                       Computation: 15098 steps/s (collection: 6.376s, learning 0.135s)
             Mean action noise std: 2.14
          Mean value_function loss: 33.0903
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 38.2967
                       Mean reward: 685.60
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7286
    Episode_Reward/rotating_object: 137.4097
        Episode_Reward/action_rate: -0.0221
          Episode_Reward/joint_vel: -0.0078
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 65667072
                    Iteration time: 6.51s
                      Time elapsed: 00:21:37
                               ETA: 00:26:58

################################################################################
                     [1m Learning iteration 668/1500 [0m                      

                       Computation: 15008 steps/s (collection: 6.389s, learning 0.161s)
             Mean action noise std: 2.14
          Mean value_function loss: 32.6920
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 38.3058
                       Mean reward: 687.80
               Mean episode length: 247.83
    Episode_Reward/reaching_object: 0.7171
    Episode_Reward/rotating_object: 134.6876
        Episode_Reward/action_rate: -0.0220
          Episode_Reward/joint_vel: -0.0078
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 65765376
                    Iteration time: 6.55s
                      Time elapsed: 00:21:44
                               ETA: 00:27:02

################################################################################
                     [1m Learning iteration 669/1500 [0m                      

                       Computation: 14909 steps/s (collection: 6.459s, learning 0.134s)
             Mean action noise std: 2.14
          Mean value_function loss: 28.9242
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 38.3159
                       Mean reward: 697.71
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7341
    Episode_Reward/rotating_object: 141.4325
        Episode_Reward/action_rate: -0.0222
          Episode_Reward/joint_vel: -0.0079
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 65863680
                    Iteration time: 6.59s
                      Time elapsed: 00:21:50
                               ETA: 00:27:05

################################################################################
                     [1m Learning iteration 670/1500 [0m                      

                       Computation: 14174 steps/s (collection: 6.811s, learning 0.124s)
             Mean action noise std: 2.14
          Mean value_function loss: 31.2452
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 38.3303
                       Mean reward: 705.55
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7322
    Episode_Reward/rotating_object: 138.7259
        Episode_Reward/action_rate: -0.0223
          Episode_Reward/joint_vel: -0.0078
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 65961984
                    Iteration time: 6.94s
                      Time elapsed: 00:21:57
                               ETA: 00:27:10

################################################################################
                     [1m Learning iteration 671/1500 [0m                      

                       Computation: 14897 steps/s (collection: 6.422s, learning 0.177s)
             Mean action noise std: 2.14
          Mean value_function loss: 33.0838
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 38.3449
                       Mean reward: 698.76
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7280
    Episode_Reward/rotating_object: 138.8997
        Episode_Reward/action_rate: -0.0222
          Episode_Reward/joint_vel: -0.0078
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 66060288
                    Iteration time: 6.60s
                      Time elapsed: 00:22:04
                               ETA: 00:27:13

################################################################################
                     [1m Learning iteration 672/1500 [0m                      

                       Computation: 15135 steps/s (collection: 6.357s, learning 0.138s)
             Mean action noise std: 2.15
          Mean value_function loss: 29.5588
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 38.3555
                       Mean reward: 724.91
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7287
    Episode_Reward/rotating_object: 139.4692
        Episode_Reward/action_rate: -0.0223
          Episode_Reward/joint_vel: -0.0079
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 66158592
                    Iteration time: 6.50s
                      Time elapsed: 00:22:10
                               ETA: 00:27:17

################################################################################
                     [1m Learning iteration 673/1500 [0m                      

                       Computation: 15109 steps/s (collection: 6.333s, learning 0.173s)
             Mean action noise std: 2.15
          Mean value_function loss: 34.4346
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 38.3607
                       Mean reward: 686.78
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7244
    Episode_Reward/rotating_object: 137.3461
        Episode_Reward/action_rate: -0.0223
          Episode_Reward/joint_vel: -0.0079
      Episode_Termination/time_out: 18.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 66256896
                    Iteration time: 6.51s
                      Time elapsed: 00:22:17
                               ETA: 00:27:20

################################################################################
                     [1m Learning iteration 674/1500 [0m                      

                       Computation: 14981 steps/s (collection: 6.378s, learning 0.184s)
             Mean action noise std: 2.15
          Mean value_function loss: 35.8590
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 38.3706
                       Mean reward: 714.93
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7288
    Episode_Reward/rotating_object: 138.5271
        Episode_Reward/action_rate: -0.0224
          Episode_Reward/joint_vel: -0.0080
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 66355200
                    Iteration time: 6.56s
                      Time elapsed: 00:22:23
                               ETA: 00:27:24

################################################################################
                     [1m Learning iteration 675/1500 [0m                      

                       Computation: 24620 steps/s (collection: 3.893s, learning 0.100s)
             Mean action noise std: 2.15
          Mean value_function loss: 29.1604
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 38.3813
                       Mean reward: 702.75
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7277
    Episode_Reward/rotating_object: 137.7938
        Episode_Reward/action_rate: -0.0223
          Episode_Reward/joint_vel: -0.0077
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 66453504
                    Iteration time: 3.99s
                      Time elapsed: 00:22:27
                               ETA: 00:27:25

################################################################################
                     [1m Learning iteration 676/1500 [0m                      

                       Computation: 57197 steps/s (collection: 1.613s, learning 0.106s)
             Mean action noise std: 2.15
          Mean value_function loss: 28.6610
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 38.3939
                       Mean reward: 685.49
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7295
    Episode_Reward/rotating_object: 138.2827
        Episode_Reward/action_rate: -0.0224
          Episode_Reward/joint_vel: -0.0080
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 66551808
                    Iteration time: 1.72s
                      Time elapsed: 00:22:29
                               ETA: 00:27:22

################################################################################
                     [1m Learning iteration 677/1500 [0m                      

                       Computation: 56299 steps/s (collection: 1.587s, learning 0.159s)
             Mean action noise std: 2.15
          Mean value_function loss: 28.8468
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 38.4021
                       Mean reward: 725.98
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7308
    Episode_Reward/rotating_object: 140.1176
        Episode_Reward/action_rate: -0.0224
          Episode_Reward/joint_vel: -0.0077
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 66650112
                    Iteration time: 1.75s
                      Time elapsed: 00:22:31
                               ETA: 00:27:20

################################################################################
                     [1m Learning iteration 678/1500 [0m                      

                       Computation: 59473 steps/s (collection: 1.557s, learning 0.096s)
             Mean action noise std: 2.16
          Mean value_function loss: 31.5656
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 38.4119
                       Mean reward: 702.70
               Mean episode length: 247.95
    Episode_Reward/reaching_object: 0.7216
    Episode_Reward/rotating_object: 136.2017
        Episode_Reward/action_rate: -0.0223
          Episode_Reward/joint_vel: -0.0077
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 66748416
                    Iteration time: 1.65s
                      Time elapsed: 00:22:33
                               ETA: 00:27:18

################################################################################
                     [1m Learning iteration 679/1500 [0m                      

                       Computation: 57469 steps/s (collection: 1.586s, learning 0.124s)
             Mean action noise std: 2.16
          Mean value_function loss: 33.0830
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 38.4223
                       Mean reward: 711.59
               Mean episode length: 246.21
    Episode_Reward/reaching_object: 0.7263
    Episode_Reward/rotating_object: 136.9070
        Episode_Reward/action_rate: -0.0224
          Episode_Reward/joint_vel: -0.0076
      Episode_Termination/time_out: 17.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 66846720
                    Iteration time: 1.71s
                      Time elapsed: 00:22:34
                               ETA: 00:27:15

################################################################################
                     [1m Learning iteration 680/1500 [0m                      

                       Computation: 55389 steps/s (collection: 1.603s, learning 0.172s)
             Mean action noise std: 2.16
          Mean value_function loss: 32.0217
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 38.4284
                       Mean reward: 691.01
               Mean episode length: 248.21
    Episode_Reward/reaching_object: 0.7266
    Episode_Reward/rotating_object: 139.4018
        Episode_Reward/action_rate: -0.0223
          Episode_Reward/joint_vel: -0.0074
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 66945024
                    Iteration time: 1.77s
                      Time elapsed: 00:22:36
                               ETA: 00:27:13

################################################################################
                     [1m Learning iteration 681/1500 [0m                      

                       Computation: 59554 steps/s (collection: 1.557s, learning 0.094s)
             Mean action noise std: 2.16
          Mean value_function loss: 30.9042
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 38.4443
                       Mean reward: 711.25
               Mean episode length: 247.78
    Episode_Reward/reaching_object: 0.7305
    Episode_Reward/rotating_object: 139.6670
        Episode_Reward/action_rate: -0.0224
          Episode_Reward/joint_vel: -0.0081
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 67043328
                    Iteration time: 1.65s
                      Time elapsed: 00:22:38
                               ETA: 00:27:11

################################################################################
                     [1m Learning iteration 682/1500 [0m                      

                       Computation: 57810 steps/s (collection: 1.594s, learning 0.106s)
             Mean action noise std: 2.16
          Mean value_function loss: 29.3276
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 38.4664
                       Mean reward: 686.29
               Mean episode length: 247.87
    Episode_Reward/reaching_object: 0.7247
    Episode_Reward/rotating_object: 137.6628
        Episode_Reward/action_rate: -0.0223
          Episode_Reward/joint_vel: -0.0074
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 67141632
                    Iteration time: 1.70s
                      Time elapsed: 00:22:39
                               ETA: 00:27:08

################################################################################
                     [1m Learning iteration 683/1500 [0m                      

                       Computation: 55824 steps/s (collection: 1.647s, learning 0.114s)
             Mean action noise std: 2.16
          Mean value_function loss: 38.7682
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 38.4788
                       Mean reward: 662.15
               Mean episode length: 246.10
    Episode_Reward/reaching_object: 0.7134
    Episode_Reward/rotating_object: 133.1695
        Episode_Reward/action_rate: -0.0222
          Episode_Reward/joint_vel: -0.0077
      Episode_Termination/time_out: 17.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 67239936
                    Iteration time: 1.76s
                      Time elapsed: 00:22:41
                               ETA: 00:27:06

################################################################################
                     [1m Learning iteration 684/1500 [0m                      

                       Computation: 60416 steps/s (collection: 1.534s, learning 0.094s)
             Mean action noise std: 2.17
          Mean value_function loss: 36.7430
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 38.4894
                       Mean reward: 717.83
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7281
    Episode_Reward/rotating_object: 140.1505
        Episode_Reward/action_rate: -0.0225
          Episode_Reward/joint_vel: -0.0077
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 67338240
                    Iteration time: 1.63s
                      Time elapsed: 00:22:43
                               ETA: 00:27:04

################################################################################
                     [1m Learning iteration 685/1500 [0m                      

                       Computation: 56339 steps/s (collection: 1.650s, learning 0.095s)
             Mean action noise std: 2.17
          Mean value_function loss: 33.2337
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 38.5023
                       Mean reward: 700.64
               Mean episode length: 247.90
    Episode_Reward/reaching_object: 0.7324
    Episode_Reward/rotating_object: 140.4897
        Episode_Reward/action_rate: -0.0226
          Episode_Reward/joint_vel: -0.0079
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 67436544
                    Iteration time: 1.74s
                      Time elapsed: 00:22:45
                               ETA: 00:27:01

################################################################################
                     [1m Learning iteration 686/1500 [0m                      

                       Computation: 58837 steps/s (collection: 1.562s, learning 0.109s)
             Mean action noise std: 2.17
          Mean value_function loss: 35.3474
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 38.5197
                       Mean reward: 694.49
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7323
    Episode_Reward/rotating_object: 138.9871
        Episode_Reward/action_rate: -0.0226
          Episode_Reward/joint_vel: -0.0076
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 67534848
                    Iteration time: 1.67s
                      Time elapsed: 00:22:46
                               ETA: 00:26:59

################################################################################
                     [1m Learning iteration 687/1500 [0m                      

                       Computation: 59030 steps/s (collection: 1.561s, learning 0.105s)
             Mean action noise std: 2.17
          Mean value_function loss: 41.2068
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 38.5303
                       Mean reward: 668.19
               Mean episode length: 247.86
    Episode_Reward/reaching_object: 0.7279
    Episode_Reward/rotating_object: 137.1172
        Episode_Reward/action_rate: -0.0226
          Episode_Reward/joint_vel: -0.0076
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 67633152
                    Iteration time: 1.67s
                      Time elapsed: 00:22:48
                               ETA: 00:26:56

################################################################################
                     [1m Learning iteration 688/1500 [0m                      

                       Computation: 56165 steps/s (collection: 1.661s, learning 0.090s)
             Mean action noise std: 2.17
          Mean value_function loss: 37.7819
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 38.5371
                       Mean reward: 687.45
               Mean episode length: 244.22
    Episode_Reward/reaching_object: 0.7231
    Episode_Reward/rotating_object: 135.0454
        Episode_Reward/action_rate: -0.0225
          Episode_Reward/joint_vel: -0.0076
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 67731456
                    Iteration time: 1.75s
                      Time elapsed: 00:22:50
                               ETA: 00:26:54

################################################################################
                     [1m Learning iteration 689/1500 [0m                      

                       Computation: 55937 steps/s (collection: 1.619s, learning 0.139s)
             Mean action noise std: 2.18
          Mean value_function loss: 33.5085
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 38.5484
                       Mean reward: 673.99
               Mean episode length: 247.64
    Episode_Reward/reaching_object: 0.7358
    Episode_Reward/rotating_object: 139.6059
        Episode_Reward/action_rate: -0.0227
          Episode_Reward/joint_vel: -0.0080
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 67829760
                    Iteration time: 1.76s
                      Time elapsed: 00:22:51
                               ETA: 00:26:52

################################################################################
                     [1m Learning iteration 690/1500 [0m                      

                       Computation: 59463 steps/s (collection: 1.549s, learning 0.105s)
             Mean action noise std: 2.18
          Mean value_function loss: 35.4709
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 38.5632
                       Mean reward: 700.19
               Mean episode length: 247.89
    Episode_Reward/reaching_object: 0.7327
    Episode_Reward/rotating_object: 137.7293
        Episode_Reward/action_rate: -0.0225
          Episode_Reward/joint_vel: -0.0073
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 67928064
                    Iteration time: 1.65s
                      Time elapsed: 00:22:53
                               ETA: 00:26:50

################################################################################
                     [1m Learning iteration 691/1500 [0m                      

                       Computation: 58422 steps/s (collection: 1.595s, learning 0.088s)
             Mean action noise std: 2.18
          Mean value_function loss: 34.1416
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 38.5733
                       Mean reward: 672.12
               Mean episode length: 247.72
    Episode_Reward/reaching_object: 0.7464
    Episode_Reward/rotating_object: 141.4488
        Episode_Reward/action_rate: -0.0229
          Episode_Reward/joint_vel: -0.0077
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 68026368
                    Iteration time: 1.68s
                      Time elapsed: 00:22:55
                               ETA: 00:26:47

################################################################################
                     [1m Learning iteration 692/1500 [0m                      

                       Computation: 57735 steps/s (collection: 1.613s, learning 0.090s)
             Mean action noise std: 2.18
          Mean value_function loss: 34.0532
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 38.5822
                       Mean reward: 719.20
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7395
    Episode_Reward/rotating_object: 138.5146
        Episode_Reward/action_rate: -0.0227
          Episode_Reward/joint_vel: -0.0075
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 68124672
                    Iteration time: 1.70s
                      Time elapsed: 00:22:56
                               ETA: 00:26:45

################################################################################
                     [1m Learning iteration 693/1500 [0m                      

                       Computation: 57396 steps/s (collection: 1.573s, learning 0.140s)
             Mean action noise std: 2.18
          Mean value_function loss: 27.3389
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 38.5934
                       Mean reward: 696.68
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7412
    Episode_Reward/rotating_object: 137.4671
        Episode_Reward/action_rate: -0.0229
          Episode_Reward/joint_vel: -0.0074
      Episode_Termination/time_out: 17.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 68222976
                    Iteration time: 1.71s
                      Time elapsed: 00:22:58
                               ETA: 00:26:43

################################################################################
                     [1m Learning iteration 694/1500 [0m                      

                       Computation: 57550 steps/s (collection: 1.555s, learning 0.154s)
             Mean action noise std: 2.18
          Mean value_function loss: 36.8773
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 38.6024
                       Mean reward: 682.81
               Mean episode length: 241.84
    Episode_Reward/reaching_object: 0.7403
    Episode_Reward/rotating_object: 138.5252
        Episode_Reward/action_rate: -0.0227
          Episode_Reward/joint_vel: -0.0074
      Episode_Termination/time_out: 18.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 68321280
                    Iteration time: 1.71s
                      Time elapsed: 00:23:00
                               ETA: 00:26:40

################################################################################
                     [1m Learning iteration 695/1500 [0m                      

                       Computation: 55766 steps/s (collection: 1.661s, learning 0.102s)
             Mean action noise std: 2.18
          Mean value_function loss: 32.5788
               Mean surrogate loss: -0.0003
                 Mean entropy loss: 38.6082
                       Mean reward: 674.57
               Mean episode length: 247.82
    Episode_Reward/reaching_object: 0.7376
    Episode_Reward/rotating_object: 136.4110
        Episode_Reward/action_rate: -0.0228
          Episode_Reward/joint_vel: -0.0074
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 68419584
                    Iteration time: 1.76s
                      Time elapsed: 00:23:02
                               ETA: 00:26:38

################################################################################
                     [1m Learning iteration 696/1500 [0m                      

                       Computation: 57953 steps/s (collection: 1.606s, learning 0.091s)
             Mean action noise std: 2.19
          Mean value_function loss: 35.4344
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 38.6121
                       Mean reward: 701.45
               Mean episode length: 248.10
    Episode_Reward/reaching_object: 0.7328
    Episode_Reward/rotating_object: 135.5374
        Episode_Reward/action_rate: -0.0228
          Episode_Reward/joint_vel: -0.0074
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 68517888
                    Iteration time: 1.70s
                      Time elapsed: 00:23:03
                               ETA: 00:26:36

################################################################################
                     [1m Learning iteration 697/1500 [0m                      

                       Computation: 57301 steps/s (collection: 1.570s, learning 0.145s)
             Mean action noise std: 2.19
          Mean value_function loss: 28.2804
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 38.6236
                       Mean reward: 683.75
               Mean episode length: 247.72
    Episode_Reward/reaching_object: 0.7322
    Episode_Reward/rotating_object: 135.5347
        Episode_Reward/action_rate: -0.0229
          Episode_Reward/joint_vel: -0.0072
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 68616192
                    Iteration time: 1.72s
                      Time elapsed: 00:23:05
                               ETA: 00:26:33

################################################################################
                     [1m Learning iteration 698/1500 [0m                      

                       Computation: 56799 steps/s (collection: 1.626s, learning 0.105s)
             Mean action noise std: 2.19
          Mean value_function loss: 29.8624
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 38.6396
                       Mean reward: 698.66
               Mean episode length: 245.74
    Episode_Reward/reaching_object: 0.7365
    Episode_Reward/rotating_object: 140.5516
        Episode_Reward/action_rate: -0.0228
          Episode_Reward/joint_vel: -0.0071
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 68714496
                    Iteration time: 1.73s
                      Time elapsed: 00:23:07
                               ETA: 00:26:31

################################################################################
                     [1m Learning iteration 699/1500 [0m                      

                       Computation: 58891 steps/s (collection: 1.557s, learning 0.113s)
             Mean action noise std: 2.19
          Mean value_function loss: 31.9745
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 38.6567
                       Mean reward: 671.34
               Mean episode length: 244.70
    Episode_Reward/reaching_object: 0.7246
    Episode_Reward/rotating_object: 134.0135
        Episode_Reward/action_rate: -0.0229
          Episode_Reward/joint_vel: -0.0076
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 68812800
                    Iteration time: 1.67s
                      Time elapsed: 00:23:08
                               ETA: 00:26:29

################################################################################
                     [1m Learning iteration 700/1500 [0m                      

                       Computation: 58421 steps/s (collection: 1.590s, learning 0.093s)
             Mean action noise std: 2.19
          Mean value_function loss: 35.5849
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 38.6642
                       Mean reward: 681.11
               Mean episode length: 245.41
    Episode_Reward/reaching_object: 0.7248
    Episode_Reward/rotating_object: 135.2893
        Episode_Reward/action_rate: -0.0229
          Episode_Reward/joint_vel: -0.0073
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 68911104
                    Iteration time: 1.68s
                      Time elapsed: 00:23:10
                               ETA: 00:26:26

################################################################################
                     [1m Learning iteration 701/1500 [0m                      

                       Computation: 55330 steps/s (collection: 1.631s, learning 0.146s)
             Mean action noise std: 2.19
          Mean value_function loss: 28.6125
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 38.6743
                       Mean reward: 695.32
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7320
    Episode_Reward/rotating_object: 138.2650
        Episode_Reward/action_rate: -0.0229
          Episode_Reward/joint_vel: -0.0072
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 69009408
                    Iteration time: 1.78s
                      Time elapsed: 00:23:12
                               ETA: 00:26:24

################################################################################
                     [1m Learning iteration 702/1500 [0m                      

                       Computation: 56503 steps/s (collection: 1.634s, learning 0.106s)
             Mean action noise std: 2.20
          Mean value_function loss: 30.0095
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 38.6917
                       Mean reward: 703.79
               Mean episode length: 245.43
    Episode_Reward/reaching_object: 0.7347
    Episode_Reward/rotating_object: 140.2731
        Episode_Reward/action_rate: -0.0230
          Episode_Reward/joint_vel: -0.0072
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 69107712
                    Iteration time: 1.74s
                      Time elapsed: 00:23:14
                               ETA: 00:26:22

################################################################################
                     [1m Learning iteration 703/1500 [0m                      

                       Computation: 56976 steps/s (collection: 1.615s, learning 0.111s)
             Mean action noise std: 2.20
          Mean value_function loss: 28.2423
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 38.7040
                       Mean reward: 690.87
               Mean episode length: 246.25
    Episode_Reward/reaching_object: 0.7350
    Episode_Reward/rotating_object: 138.7920
        Episode_Reward/action_rate: -0.0232
          Episode_Reward/joint_vel: -0.0075
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 69206016
                    Iteration time: 1.73s
                      Time elapsed: 00:23:15
                               ETA: 00:26:20

################################################################################
                     [1m Learning iteration 704/1500 [0m                      

                       Computation: 52956 steps/s (collection: 1.707s, learning 0.149s)
             Mean action noise std: 2.20
          Mean value_function loss: 33.5190
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 38.7110
                       Mean reward: 719.92
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7329
    Episode_Reward/rotating_object: 139.1202
        Episode_Reward/action_rate: -0.0232
          Episode_Reward/joint_vel: -0.0071
      Episode_Termination/time_out: 18.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 69304320
                    Iteration time: 1.86s
                      Time elapsed: 00:23:17
                               ETA: 00:26:18

################################################################################
                     [1m Learning iteration 705/1500 [0m                      

                       Computation: 56355 steps/s (collection: 1.562s, learning 0.182s)
             Mean action noise std: 2.20
          Mean value_function loss: 37.0678
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 38.7158
                       Mean reward: 676.08
               Mean episode length: 243.38
    Episode_Reward/reaching_object: 0.7334
    Episode_Reward/rotating_object: 138.2460
        Episode_Reward/action_rate: -0.0232
          Episode_Reward/joint_vel: -0.0072
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 69402624
                    Iteration time: 1.74s
                      Time elapsed: 00:23:19
                               ETA: 00:26:15

################################################################################
                     [1m Learning iteration 706/1500 [0m                      

                       Computation: 58060 steps/s (collection: 1.604s, learning 0.090s)
             Mean action noise std: 2.20
          Mean value_function loss: 40.6245
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 38.7274
                       Mean reward: 692.32
               Mean episode length: 243.79
    Episode_Reward/reaching_object: 0.7339
    Episode_Reward/rotating_object: 139.4811
        Episode_Reward/action_rate: -0.0233
          Episode_Reward/joint_vel: -0.0073
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 69500928
                    Iteration time: 1.69s
                      Time elapsed: 00:23:21
                               ETA: 00:26:13

################################################################################
                     [1m Learning iteration 707/1500 [0m                      

                       Computation: 54687 steps/s (collection: 1.671s, learning 0.127s)
             Mean action noise std: 2.20
          Mean value_function loss: 33.4760
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 38.7371
                       Mean reward: 701.56
               Mean episode length: 247.76
    Episode_Reward/reaching_object: 0.7390
    Episode_Reward/rotating_object: 140.0049
        Episode_Reward/action_rate: -0.0233
          Episode_Reward/joint_vel: -0.0072
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 69599232
                    Iteration time: 1.80s
                      Time elapsed: 00:23:22
                               ETA: 00:26:11

################################################################################
                     [1m Learning iteration 708/1500 [0m                      

                       Computation: 57717 steps/s (collection: 1.549s, learning 0.154s)
             Mean action noise std: 2.21
          Mean value_function loss: 38.9585
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 38.7472
                       Mean reward: 686.09
               Mean episode length: 244.04
    Episode_Reward/reaching_object: 0.7395
    Episode_Reward/rotating_object: 140.5945
        Episode_Reward/action_rate: -0.0233
          Episode_Reward/joint_vel: -0.0073
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 69697536
                    Iteration time: 1.70s
                      Time elapsed: 00:23:24
                               ETA: 00:26:09

################################################################################
                     [1m Learning iteration 709/1500 [0m                      

                       Computation: 59605 steps/s (collection: 1.554s, learning 0.095s)
             Mean action noise std: 2.21
          Mean value_function loss: 33.0651
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 38.7774
                       Mean reward: 699.27
               Mean episode length: 248.99
    Episode_Reward/reaching_object: 0.7353
    Episode_Reward/rotating_object: 139.5364
        Episode_Reward/action_rate: -0.0233
          Episode_Reward/joint_vel: -0.0071
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 69795840
                    Iteration time: 1.65s
                      Time elapsed: 00:23:26
                               ETA: 00:26:06

################################################################################
                     [1m Learning iteration 710/1500 [0m                      

                       Computation: 57580 steps/s (collection: 1.602s, learning 0.105s)
             Mean action noise std: 2.21
          Mean value_function loss: 32.3747
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 38.8056
                       Mean reward: 699.21
               Mean episode length: 248.04
    Episode_Reward/reaching_object: 0.7382
    Episode_Reward/rotating_object: 139.2654
        Episode_Reward/action_rate: -0.0234
          Episode_Reward/joint_vel: -0.0072
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 69894144
                    Iteration time: 1.71s
                      Time elapsed: 00:23:27
                               ETA: 00:26:04

################################################################################
                     [1m Learning iteration 711/1500 [0m                      

                       Computation: 58138 steps/s (collection: 1.576s, learning 0.115s)
             Mean action noise std: 2.21
          Mean value_function loss: 34.5974
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 38.8222
                       Mean reward: 689.34
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7363
    Episode_Reward/rotating_object: 138.7743
        Episode_Reward/action_rate: -0.0233
          Episode_Reward/joint_vel: -0.0070
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 69992448
                    Iteration time: 1.69s
                      Time elapsed: 00:23:29
                               ETA: 00:26:02

################################################################################
                     [1m Learning iteration 712/1500 [0m                      

                       Computation: 56827 steps/s (collection: 1.576s, learning 0.154s)
             Mean action noise std: 2.22
          Mean value_function loss: 30.8822
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 38.8358
                       Mean reward: 721.98
               Mean episode length: 246.01
    Episode_Reward/reaching_object: 0.7340
    Episode_Reward/rotating_object: 138.9353
        Episode_Reward/action_rate: -0.0232
          Episode_Reward/joint_vel: -0.0069
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 70090752
                    Iteration time: 1.73s
                      Time elapsed: 00:23:31
                               ETA: 00:25:59

################################################################################
                     [1m Learning iteration 713/1500 [0m                      

                       Computation: 58430 steps/s (collection: 1.576s, learning 0.106s)
             Mean action noise std: 2.22
          Mean value_function loss: 28.2292
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 38.8528
                       Mean reward: 692.56
               Mean episode length: 247.98
    Episode_Reward/reaching_object: 0.7389
    Episode_Reward/rotating_object: 139.0049
        Episode_Reward/action_rate: -0.0235
          Episode_Reward/joint_vel: -0.0075
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 70189056
                    Iteration time: 1.68s
                      Time elapsed: 00:23:33
                               ETA: 00:25:57

################################################################################
                     [1m Learning iteration 714/1500 [0m                      

                       Computation: 58053 steps/s (collection: 1.604s, learning 0.089s)
             Mean action noise std: 2.22
          Mean value_function loss: 29.4236
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 38.8608
                       Mean reward: 700.76
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7389
    Episode_Reward/rotating_object: 137.8609
        Episode_Reward/action_rate: -0.0236
          Episode_Reward/joint_vel: -0.0067
      Episode_Termination/time_out: 17.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 70287360
                    Iteration time: 1.69s
                      Time elapsed: 00:23:34
                               ETA: 00:25:55

################################################################################
                     [1m Learning iteration 715/1500 [0m                      

                       Computation: 57178 steps/s (collection: 1.612s, learning 0.108s)
             Mean action noise std: 2.22
          Mean value_function loss: 39.7798
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 38.8806
                       Mean reward: 661.59
               Mean episode length: 241.11
    Episode_Reward/reaching_object: 0.7312
    Episode_Reward/rotating_object: 135.4431
        Episode_Reward/action_rate: -0.0234
          Episode_Reward/joint_vel: -0.0070
      Episode_Termination/time_out: 17.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 70385664
                    Iteration time: 1.72s
                      Time elapsed: 00:23:36
                               ETA: 00:25:53

################################################################################
                     [1m Learning iteration 716/1500 [0m                      

                       Computation: 56500 steps/s (collection: 1.628s, learning 0.112s)
             Mean action noise std: 2.23
          Mean value_function loss: 35.6945
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 38.9036
                       Mean reward: 688.58
               Mean episode length: 245.35
    Episode_Reward/reaching_object: 0.7379
    Episode_Reward/rotating_object: 138.1006
        Episode_Reward/action_rate: -0.0234
          Episode_Reward/joint_vel: -0.0065
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 70483968
                    Iteration time: 1.74s
                      Time elapsed: 00:23:38
                               ETA: 00:25:50

################################################################################
                     [1m Learning iteration 717/1500 [0m                      

                       Computation: 56944 steps/s (collection: 1.613s, learning 0.113s)
             Mean action noise std: 2.23
          Mean value_function loss: 32.3285
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 38.9149
                       Mean reward: 681.12
               Mean episode length: 247.73
    Episode_Reward/reaching_object: 0.7363
    Episode_Reward/rotating_object: 136.1943
        Episode_Reward/action_rate: -0.0235
          Episode_Reward/joint_vel: -0.0070
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 70582272
                    Iteration time: 1.73s
                      Time elapsed: 00:23:39
                               ETA: 00:25:48

################################################################################
                     [1m Learning iteration 718/1500 [0m                      

                       Computation: 59131 steps/s (collection: 1.570s, learning 0.093s)
             Mean action noise std: 2.23
          Mean value_function loss: 35.1373
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 38.9252
                       Mean reward: 703.07
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7467
    Episode_Reward/rotating_object: 139.9673
        Episode_Reward/action_rate: -0.0237
          Episode_Reward/joint_vel: -0.0066
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 70680576
                    Iteration time: 1.66s
                      Time elapsed: 00:23:41
                               ETA: 00:25:46

################################################################################
                     [1m Learning iteration 719/1500 [0m                      

                       Computation: 53571 steps/s (collection: 1.714s, learning 0.121s)
             Mean action noise std: 2.23
          Mean value_function loss: 32.2434
               Mean surrogate loss: -0.0002
                 Mean entropy loss: 38.9401
                       Mean reward: 697.63
               Mean episode length: 247.64
    Episode_Reward/reaching_object: 0.7464
    Episode_Reward/rotating_object: 140.2183
        Episode_Reward/action_rate: -0.0237
          Episode_Reward/joint_vel: -0.0067
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 70778880
                    Iteration time: 1.84s
                      Time elapsed: 00:23:43
                               ETA: 00:25:44

################################################################################
                     [1m Learning iteration 720/1500 [0m                      

                       Computation: 57366 steps/s (collection: 1.592s, learning 0.121s)
             Mean action noise std: 2.23
          Mean value_function loss: 32.8144
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 38.9503
                       Mean reward: 681.85
               Mean episode length: 245.47
    Episode_Reward/reaching_object: 0.7368
    Episode_Reward/rotating_object: 137.6591
        Episode_Reward/action_rate: -0.0236
          Episode_Reward/joint_vel: -0.0069
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 70877184
                    Iteration time: 1.71s
                      Time elapsed: 00:23:45
                               ETA: 00:25:41

################################################################################
                     [1m Learning iteration 721/1500 [0m                      

                       Computation: 58372 steps/s (collection: 1.588s, learning 0.097s)
             Mean action noise std: 2.23
          Mean value_function loss: 36.1866
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 38.9597
                       Mean reward: 658.14
               Mean episode length: 241.07
    Episode_Reward/reaching_object: 0.7316
    Episode_Reward/rotating_object: 136.0110
        Episode_Reward/action_rate: -0.0235
          Episode_Reward/joint_vel: -0.0066
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 70975488
                    Iteration time: 1.68s
                      Time elapsed: 00:23:46
                               ETA: 00:25:39

################################################################################
                     [1m Learning iteration 722/1500 [0m                      

                       Computation: 53909 steps/s (collection: 1.685s, learning 0.138s)
             Mean action noise std: 2.24
          Mean value_function loss: 32.5533
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 38.9721
                       Mean reward: 690.41
               Mean episode length: 243.60
    Episode_Reward/reaching_object: 0.7441
    Episode_Reward/rotating_object: 138.6978
        Episode_Reward/action_rate: -0.0237
          Episode_Reward/joint_vel: -0.0068
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 71073792
                    Iteration time: 1.82s
                      Time elapsed: 00:23:48
                               ETA: 00:25:37

################################################################################
                     [1m Learning iteration 723/1500 [0m                      

                       Computation: 57113 steps/s (collection: 1.622s, learning 0.100s)
             Mean action noise std: 2.24
          Mean value_function loss: 31.7505
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 38.9818
                       Mean reward: 701.00
               Mean episode length: 247.72
    Episode_Reward/reaching_object: 0.7430
    Episode_Reward/rotating_object: 139.9154
        Episode_Reward/action_rate: -0.0237
          Episode_Reward/joint_vel: -0.0067
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 71172096
                    Iteration time: 1.72s
                      Time elapsed: 00:23:50
                               ETA: 00:25:35

################################################################################
                     [1m Learning iteration 724/1500 [0m                      

                       Computation: 55963 steps/s (collection: 1.648s, learning 0.109s)
             Mean action noise std: 2.24
          Mean value_function loss: 30.1759
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 38.9943
                       Mean reward: 669.96
               Mean episode length: 243.34
    Episode_Reward/reaching_object: 0.7386
    Episode_Reward/rotating_object: 137.4967
        Episode_Reward/action_rate: -0.0238
          Episode_Reward/joint_vel: -0.0068
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 71270400
                    Iteration time: 1.76s
                      Time elapsed: 00:23:52
                               ETA: 00:25:32

################################################################################
                     [1m Learning iteration 725/1500 [0m                      

                       Computation: 54549 steps/s (collection: 1.677s, learning 0.126s)
             Mean action noise std: 2.24
          Mean value_function loss: 33.1362
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 39.0091
                       Mean reward: 676.74
               Mean episode length: 247.94
    Episode_Reward/reaching_object: 0.7382
    Episode_Reward/rotating_object: 136.8820
        Episode_Reward/action_rate: -0.0239
          Episode_Reward/joint_vel: -0.0072
      Episode_Termination/time_out: 18.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 71368704
                    Iteration time: 1.80s
                      Time elapsed: 00:23:53
                               ETA: 00:25:30

################################################################################
                     [1m Learning iteration 726/1500 [0m                      

                       Computation: 52116 steps/s (collection: 1.722s, learning 0.164s)
             Mean action noise std: 2.24
          Mean value_function loss: 34.1458
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 39.0195
                       Mean reward: 680.13
               Mean episode length: 247.99
    Episode_Reward/reaching_object: 0.7432
    Episode_Reward/rotating_object: 137.8586
        Episode_Reward/action_rate: -0.0239
          Episode_Reward/joint_vel: -0.0070
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 71467008
                    Iteration time: 1.89s
                      Time elapsed: 00:23:55
                               ETA: 00:25:28

################################################################################
                     [1m Learning iteration 727/1500 [0m                      

                       Computation: 58619 steps/s (collection: 1.562s, learning 0.115s)
             Mean action noise std: 2.24
          Mean value_function loss: 34.3698
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 39.0285
                       Mean reward: 715.16
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7367
    Episode_Reward/rotating_object: 137.3392
        Episode_Reward/action_rate: -0.0238
          Episode_Reward/joint_vel: -0.0068
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 71565312
                    Iteration time: 1.68s
                      Time elapsed: 00:23:57
                               ETA: 00:25:26

################################################################################
                     [1m Learning iteration 728/1500 [0m                      

                       Computation: 56742 steps/s (collection: 1.623s, learning 0.110s)
             Mean action noise std: 2.25
          Mean value_function loss: 28.8893
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 39.0338
                       Mean reward: 696.63
               Mean episode length: 247.97
    Episode_Reward/reaching_object: 0.7484
    Episode_Reward/rotating_object: 139.8905
        Episode_Reward/action_rate: -0.0241
          Episode_Reward/joint_vel: -0.0067
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 71663616
                    Iteration time: 1.73s
                      Time elapsed: 00:23:59
                               ETA: 00:25:24

################################################################################
                     [1m Learning iteration 729/1500 [0m                      

                       Computation: 56879 steps/s (collection: 1.620s, learning 0.108s)
             Mean action noise std: 2.25
          Mean value_function loss: 27.7578
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 39.0330
                       Mean reward: 690.17
               Mean episode length: 247.97
    Episode_Reward/reaching_object: 0.7391
    Episode_Reward/rotating_object: 138.2713
        Episode_Reward/action_rate: -0.0239
          Episode_Reward/joint_vel: -0.0067
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 71761920
                    Iteration time: 1.73s
                      Time elapsed: 00:24:00
                               ETA: 00:25:21

################################################################################
                     [1m Learning iteration 730/1500 [0m                      

                       Computation: 54806 steps/s (collection: 1.649s, learning 0.145s)
             Mean action noise std: 2.25
          Mean value_function loss: 28.6775
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 39.0393
                       Mean reward: 727.69
               Mean episode length: 247.92
    Episode_Reward/reaching_object: 0.7452
    Episode_Reward/rotating_object: 140.5472
        Episode_Reward/action_rate: -0.0241
          Episode_Reward/joint_vel: -0.0072
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 71860224
                    Iteration time: 1.79s
                      Time elapsed: 00:24:02
                               ETA: 00:25:19

################################################################################
                     [1m Learning iteration 731/1500 [0m                      

                       Computation: 56686 steps/s (collection: 1.596s, learning 0.139s)
             Mean action noise std: 2.25
          Mean value_function loss: 30.9631
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 39.0516
                       Mean reward: 715.88
               Mean episode length: 245.69
    Episode_Reward/reaching_object: 0.7449
    Episode_Reward/rotating_object: 137.9258
        Episode_Reward/action_rate: -0.0241
          Episode_Reward/joint_vel: -0.0069
      Episode_Termination/time_out: 17.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 71958528
                    Iteration time: 1.73s
                      Time elapsed: 00:24:04
                               ETA: 00:25:17

################################################################################
                     [1m Learning iteration 732/1500 [0m                      

                       Computation: 56932 steps/s (collection: 1.628s, learning 0.099s)
             Mean action noise std: 2.25
          Mean value_function loss: 30.5499
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 39.0644
                       Mean reward: 676.19
               Mean episode length: 243.44
    Episode_Reward/reaching_object: 0.7412
    Episode_Reward/rotating_object: 138.8665
        Episode_Reward/action_rate: -0.0241
          Episode_Reward/joint_vel: -0.0068
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 72056832
                    Iteration time: 1.73s
                      Time elapsed: 00:24:06
                               ETA: 00:25:15

################################################################################
                     [1m Learning iteration 733/1500 [0m                      

                       Computation: 57905 steps/s (collection: 1.599s, learning 0.099s)
             Mean action noise std: 2.25
          Mean value_function loss: 33.3608
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 39.0759
                       Mean reward: 702.67
               Mean episode length: 243.91
    Episode_Reward/reaching_object: 0.7422
    Episode_Reward/rotating_object: 139.9287
        Episode_Reward/action_rate: -0.0241
          Episode_Reward/joint_vel: -0.0069
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 72155136
                    Iteration time: 1.70s
                      Time elapsed: 00:24:07
                               ETA: 00:25:13

################################################################################
                     [1m Learning iteration 734/1500 [0m                      

                       Computation: 56053 steps/s (collection: 1.597s, learning 0.157s)
             Mean action noise std: 2.25
          Mean value_function loss: 32.2714
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 39.0816
                       Mean reward: 701.84
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7467
    Episode_Reward/rotating_object: 139.3578
        Episode_Reward/action_rate: -0.0244
          Episode_Reward/joint_vel: -0.0067
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 72253440
                    Iteration time: 1.75s
                      Time elapsed: 00:24:09
                               ETA: 00:25:10

################################################################################
                     [1m Learning iteration 735/1500 [0m                      

                       Computation: 57717 steps/s (collection: 1.611s, learning 0.092s)
             Mean action noise std: 2.26
          Mean value_function loss: 28.8219
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 39.0910
                       Mean reward: 739.38
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7492
    Episode_Reward/rotating_object: 141.3423
        Episode_Reward/action_rate: -0.0244
          Episode_Reward/joint_vel: -0.0069
      Episode_Termination/time_out: 17.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 72351744
                    Iteration time: 1.70s
                      Time elapsed: 00:24:11
                               ETA: 00:25:08

################################################################################
                     [1m Learning iteration 736/1500 [0m                      

                       Computation: 55961 steps/s (collection: 1.642s, learning 0.115s)
             Mean action noise std: 2.26
          Mean value_function loss: 34.0962
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 39.1083
                       Mean reward: 706.71
               Mean episode length: 245.52
    Episode_Reward/reaching_object: 0.7506
    Episode_Reward/rotating_object: 141.6100
        Episode_Reward/action_rate: -0.0244
          Episode_Reward/joint_vel: -0.0068
      Episode_Termination/time_out: 17.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 72450048
                    Iteration time: 1.76s
                      Time elapsed: 00:24:13
                               ETA: 00:25:06

################################################################################
                     [1m Learning iteration 737/1500 [0m                      

                       Computation: 55891 steps/s (collection: 1.650s, learning 0.109s)
             Mean action noise std: 2.26
          Mean value_function loss: 32.9744
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 39.1253
                       Mean reward: 702.26
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7452
    Episode_Reward/rotating_object: 141.1704
        Episode_Reward/action_rate: -0.0243
          Episode_Reward/joint_vel: -0.0070
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 72548352
                    Iteration time: 1.76s
                      Time elapsed: 00:24:14
                               ETA: 00:25:04

################################################################################
                     [1m Learning iteration 738/1500 [0m                      

                       Computation: 58022 steps/s (collection: 1.600s, learning 0.095s)
             Mean action noise std: 2.26
          Mean value_function loss: 32.8738
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 39.1363
                       Mean reward: 708.35
               Mean episode length: 248.08
    Episode_Reward/reaching_object: 0.7425
    Episode_Reward/rotating_object: 139.3257
        Episode_Reward/action_rate: -0.0243
          Episode_Reward/joint_vel: -0.0068
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 72646656
                    Iteration time: 1.69s
                      Time elapsed: 00:24:16
                               ETA: 00:25:01

################################################################################
                     [1m Learning iteration 739/1500 [0m                      

                       Computation: 54440 steps/s (collection: 1.672s, learning 0.134s)
             Mean action noise std: 2.27
          Mean value_function loss: 34.9436
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 39.1533
                       Mean reward: 689.33
               Mean episode length: 243.09
    Episode_Reward/reaching_object: 0.7430
    Episode_Reward/rotating_object: 141.6510
        Episode_Reward/action_rate: -0.0242
          Episode_Reward/joint_vel: -0.0070
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 72744960
                    Iteration time: 1.81s
                      Time elapsed: 00:24:18
                               ETA: 00:24:59

################################################################################
                     [1m Learning iteration 740/1500 [0m                      

                       Computation: 56407 steps/s (collection: 1.640s, learning 0.103s)
             Mean action noise std: 2.27
          Mean value_function loss: 25.4303
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 39.1708
                       Mean reward: 733.08
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7519
    Episode_Reward/rotating_object: 143.4365
        Episode_Reward/action_rate: -0.0245
          Episode_Reward/joint_vel: -0.0070
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 72843264
                    Iteration time: 1.74s
                      Time elapsed: 00:24:20
                               ETA: 00:24:57

################################################################################
                     [1m Learning iteration 741/1500 [0m                      

                       Computation: 57969 steps/s (collection: 1.591s, learning 0.105s)
             Mean action noise std: 2.27
          Mean value_function loss: 29.6374
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 39.1810
                       Mean reward: 708.41
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7480
    Episode_Reward/rotating_object: 141.0824
        Episode_Reward/action_rate: -0.0246
          Episode_Reward/joint_vel: -0.0069
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 72941568
                    Iteration time: 1.70s
                      Time elapsed: 00:24:21
                               ETA: 00:24:55

################################################################################
                     [1m Learning iteration 742/1500 [0m                      

                       Computation: 57029 steps/s (collection: 1.578s, learning 0.146s)
             Mean action noise std: 2.27
          Mean value_function loss: 24.7371
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 39.1853
                       Mean reward: 701.78
               Mean episode length: 245.90
    Episode_Reward/reaching_object: 0.7411
    Episode_Reward/rotating_object: 138.9670
        Episode_Reward/action_rate: -0.0245
          Episode_Reward/joint_vel: -0.0071
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 73039872
                    Iteration time: 1.72s
                      Time elapsed: 00:24:23
                               ETA: 00:24:53

################################################################################
                     [1m Learning iteration 743/1500 [0m                      

                       Computation: 58488 steps/s (collection: 1.592s, learning 0.088s)
             Mean action noise std: 2.27
          Mean value_function loss: 33.3024
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 39.1984
                       Mean reward: 718.45
               Mean episode length: 247.87
    Episode_Reward/reaching_object: 0.7453
    Episode_Reward/rotating_object: 140.0305
        Episode_Reward/action_rate: -0.0246
          Episode_Reward/joint_vel: -0.0073
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 73138176
                    Iteration time: 1.68s
                      Time elapsed: 00:24:25
                               ETA: 00:24:50

################################################################################
                     [1m Learning iteration 744/1500 [0m                      

                       Computation: 57197 steps/s (collection: 1.608s, learning 0.111s)
             Mean action noise std: 2.27
          Mean value_function loss: 26.4065
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 39.2133
                       Mean reward: 707.18
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7469
    Episode_Reward/rotating_object: 141.5612
        Episode_Reward/action_rate: -0.0246
          Episode_Reward/joint_vel: -0.0066
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 73236480
                    Iteration time: 1.72s
                      Time elapsed: 00:24:26
                               ETA: 00:24:48

################################################################################
                     [1m Learning iteration 745/1500 [0m                      

                       Computation: 58725 steps/s (collection: 1.547s, learning 0.127s)
             Mean action noise std: 2.28
          Mean value_function loss: 26.8124
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 39.2251
                       Mean reward: 698.90
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7436
    Episode_Reward/rotating_object: 140.6897
        Episode_Reward/action_rate: -0.0246
          Episode_Reward/joint_vel: -0.0070
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 73334784
                    Iteration time: 1.67s
                      Time elapsed: 00:24:28
                               ETA: 00:24:46

################################################################################
                     [1m Learning iteration 746/1500 [0m                      

                       Computation: 58280 steps/s (collection: 1.588s, learning 0.099s)
             Mean action noise std: 2.28
          Mean value_function loss: 30.3963
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 39.2439
                       Mean reward: 718.20
               Mean episode length: 247.89
    Episode_Reward/reaching_object: 0.7448
    Episode_Reward/rotating_object: 141.8793
        Episode_Reward/action_rate: -0.0247
          Episode_Reward/joint_vel: -0.0068
      Episode_Termination/time_out: 18.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 73433088
                    Iteration time: 1.69s
                      Time elapsed: 00:24:30
                               ETA: 00:24:44

################################################################################
                     [1m Learning iteration 747/1500 [0m                      

                       Computation: 57678 steps/s (collection: 1.615s, learning 0.090s)
             Mean action noise std: 2.28
          Mean value_function loss: 33.7383
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 39.2678
                       Mean reward: 689.41
               Mean episode length: 243.61
    Episode_Reward/reaching_object: 0.7388
    Episode_Reward/rotating_object: 138.9568
        Episode_Reward/action_rate: -0.0246
          Episode_Reward/joint_vel: -0.0069
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 73531392
                    Iteration time: 1.70s
                      Time elapsed: 00:24:32
                               ETA: 00:24:41

################################################################################
                     [1m Learning iteration 748/1500 [0m                      

                       Computation: 56241 steps/s (collection: 1.632s, learning 0.116s)
             Mean action noise std: 2.29
          Mean value_function loss: 36.4721
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 39.2847
                       Mean reward: 655.60
               Mean episode length: 241.28
    Episode_Reward/reaching_object: 0.7343
    Episode_Reward/rotating_object: 136.8942
        Episode_Reward/action_rate: -0.0245
          Episode_Reward/joint_vel: -0.0068
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 73629696
                    Iteration time: 1.75s
                      Time elapsed: 00:24:33
                               ETA: 00:24:39

################################################################################
                     [1m Learning iteration 749/1500 [0m                      

                       Computation: 57043 steps/s (collection: 1.619s, learning 0.104s)
             Mean action noise std: 2.29
          Mean value_function loss: 28.9735
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 39.3025
                       Mean reward: 668.17
               Mean episode length: 247.71
    Episode_Reward/reaching_object: 0.7434
    Episode_Reward/rotating_object: 139.3701
        Episode_Reward/action_rate: -0.0246
          Episode_Reward/joint_vel: -0.0068
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 73728000
                    Iteration time: 1.72s
                      Time elapsed: 00:24:35
                               ETA: 00:24:37

################################################################################
                     [1m Learning iteration 750/1500 [0m                      

                       Computation: 57329 steps/s (collection: 1.619s, learning 0.096s)
             Mean action noise std: 2.29
          Mean value_function loss: 28.7421
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 39.3189
                       Mean reward: 710.62
               Mean episode length: 247.74
    Episode_Reward/reaching_object: 0.7506
    Episode_Reward/rotating_object: 141.5952
        Episode_Reward/action_rate: -0.0249
          Episode_Reward/joint_vel: -0.0072
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 73826304
                    Iteration time: 1.71s
                      Time elapsed: 00:24:37
                               ETA: 00:24:35

################################################################################
                     [1m Learning iteration 751/1500 [0m                      

                       Computation: 54382 steps/s (collection: 1.704s, learning 0.104s)
             Mean action noise std: 2.29
          Mean value_function loss: 29.5358
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 39.3374
                       Mean reward: 702.61
               Mean episode length: 247.76
    Episode_Reward/reaching_object: 0.7440
    Episode_Reward/rotating_object: 140.8157
        Episode_Reward/action_rate: -0.0247
          Episode_Reward/joint_vel: -0.0070
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 73924608
                    Iteration time: 1.81s
                      Time elapsed: 00:24:39
                               ETA: 00:24:33

################################################################################
                     [1m Learning iteration 752/1500 [0m                      

                       Computation: 58337 steps/s (collection: 1.595s, learning 0.090s)
             Mean action noise std: 2.29
          Mean value_function loss: 27.1256
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 39.3474
                       Mean reward: 715.38
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7435
    Episode_Reward/rotating_object: 139.0142
        Episode_Reward/action_rate: -0.0250
          Episode_Reward/joint_vel: -0.0072
      Episode_Termination/time_out: 17.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 74022912
                    Iteration time: 1.69s
                      Time elapsed: 00:24:40
                               ETA: 00:24:30

################################################################################
                     [1m Learning iteration 753/1500 [0m                      

                       Computation: 58210 steps/s (collection: 1.598s, learning 0.091s)
             Mean action noise std: 2.30
          Mean value_function loss: 32.5955
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 39.3575
                       Mean reward: 722.93
               Mean episode length: 247.83
    Episode_Reward/reaching_object: 0.7383
    Episode_Reward/rotating_object: 138.9015
        Episode_Reward/action_rate: -0.0249
          Episode_Reward/joint_vel: -0.0069
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 74121216
                    Iteration time: 1.69s
                      Time elapsed: 00:24:42
                               ETA: 00:24:28

################################################################################
                     [1m Learning iteration 754/1500 [0m                      

                       Computation: 57721 steps/s (collection: 1.614s, learning 0.090s)
             Mean action noise std: 2.30
          Mean value_function loss: 31.6132
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 39.3677
                       Mean reward: 711.36
               Mean episode length: 248.04
    Episode_Reward/reaching_object: 0.7486
    Episode_Reward/rotating_object: 141.7251
        Episode_Reward/action_rate: -0.0251
          Episode_Reward/joint_vel: -0.0069
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 74219520
                    Iteration time: 1.70s
                      Time elapsed: 00:24:44
                               ETA: 00:24:26

################################################################################
                     [1m Learning iteration 755/1500 [0m                      

                       Computation: 56427 steps/s (collection: 1.617s, learning 0.125s)
             Mean action noise std: 2.30
          Mean value_function loss: 25.9123
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 39.3813
                       Mean reward: 734.33
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7481
    Episode_Reward/rotating_object: 141.6486
        Episode_Reward/action_rate: -0.0252
          Episode_Reward/joint_vel: -0.0072
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 74317824
                    Iteration time: 1.74s
                      Time elapsed: 00:24:45
                               ETA: 00:24:24

################################################################################
                     [1m Learning iteration 756/1500 [0m                      

                       Computation: 56341 steps/s (collection: 1.590s, learning 0.155s)
             Mean action noise std: 2.30
          Mean value_function loss: 27.1395
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 39.3925
                       Mean reward: 715.42
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7482
    Episode_Reward/rotating_object: 140.5400
        Episode_Reward/action_rate: -0.0252
          Episode_Reward/joint_vel: -0.0069
      Episode_Termination/time_out: 17.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 74416128
                    Iteration time: 1.74s
                      Time elapsed: 00:24:47
                               ETA: 00:24:22

################################################################################
                     [1m Learning iteration 757/1500 [0m                      

                       Computation: 55977 steps/s (collection: 1.650s, learning 0.106s)
             Mean action noise std: 2.30
          Mean value_function loss: 28.3565
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 39.3962
                       Mean reward: 700.89
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7478
    Episode_Reward/rotating_object: 139.9806
        Episode_Reward/action_rate: -0.0251
          Episode_Reward/joint_vel: -0.0070
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 74514432
                    Iteration time: 1.76s
                      Time elapsed: 00:24:49
                               ETA: 00:24:19

################################################################################
                     [1m Learning iteration 758/1500 [0m                      

                       Computation: 58338 steps/s (collection: 1.596s, learning 0.089s)
             Mean action noise std: 2.31
          Mean value_function loss: 32.7361
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 39.4100
                       Mean reward: 721.53
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7528
    Episode_Reward/rotating_object: 140.7330
        Episode_Reward/action_rate: -0.0254
          Episode_Reward/joint_vel: -0.0073
      Episode_Termination/time_out: 17.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 74612736
                    Iteration time: 1.69s
                      Time elapsed: 00:24:51
                               ETA: 00:24:17

################################################################################
                     [1m Learning iteration 759/1500 [0m                      

                       Computation: 57669 steps/s (collection: 1.609s, learning 0.096s)
             Mean action noise std: 2.31
          Mean value_function loss: 33.2448
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 39.4308
                       Mean reward: 708.50
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7472
    Episode_Reward/rotating_object: 140.2150
        Episode_Reward/action_rate: -0.0253
          Episode_Reward/joint_vel: -0.0072
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 74711040
                    Iteration time: 1.70s
                      Time elapsed: 00:24:52
                               ETA: 00:24:15

################################################################################
                     [1m Learning iteration 760/1500 [0m                      

                       Computation: 58171 steps/s (collection: 1.584s, learning 0.105s)
             Mean action noise std: 2.31
          Mean value_function loss: 33.2651
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 39.4397
                       Mean reward: 713.29
               Mean episode length: 247.70
    Episode_Reward/reaching_object: 0.7450
    Episode_Reward/rotating_object: 140.1783
        Episode_Reward/action_rate: -0.0252
          Episode_Reward/joint_vel: -0.0070
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 74809344
                    Iteration time: 1.69s
                      Time elapsed: 00:24:54
                               ETA: 00:24:13

################################################################################
                     [1m Learning iteration 761/1500 [0m                      

                       Computation: 56191 steps/s (collection: 1.633s, learning 0.116s)
             Mean action noise std: 2.31
          Mean value_function loss: 34.3194
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 39.4522
                       Mean reward: 711.57
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7502
    Episode_Reward/rotating_object: 142.2585
        Episode_Reward/action_rate: -0.0254
          Episode_Reward/joint_vel: -0.0069
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 74907648
                    Iteration time: 1.75s
                      Time elapsed: 00:24:56
                               ETA: 00:24:11

################################################################################
                     [1m Learning iteration 762/1500 [0m                      

                       Computation: 56648 steps/s (collection: 1.634s, learning 0.102s)
             Mean action noise std: 2.31
          Mean value_function loss: 30.4833
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 39.4640
                       Mean reward: 709.14
               Mean episode length: 247.75
    Episode_Reward/reaching_object: 0.7523
    Episode_Reward/rotating_object: 143.0611
        Episode_Reward/action_rate: -0.0254
          Episode_Reward/joint_vel: -0.0070
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 75005952
                    Iteration time: 1.74s
                      Time elapsed: 00:24:57
                               ETA: 00:24:08

################################################################################
                     [1m Learning iteration 763/1500 [0m                      

                       Computation: 56532 steps/s (collection: 1.595s, learning 0.144s)
             Mean action noise std: 2.32
          Mean value_function loss: 30.6744
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 39.4757
                       Mean reward: 696.38
               Mean episode length: 247.71
    Episode_Reward/reaching_object: 0.7439
    Episode_Reward/rotating_object: 140.1251
        Episode_Reward/action_rate: -0.0252
          Episode_Reward/joint_vel: -0.0068
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 75104256
                    Iteration time: 1.74s
                      Time elapsed: 00:24:59
                               ETA: 00:24:06

################################################################################
                     [1m Learning iteration 764/1500 [0m                      

                       Computation: 57732 steps/s (collection: 1.600s, learning 0.103s)
             Mean action noise std: 2.32
          Mean value_function loss: 33.3626
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 39.4904
                       Mean reward: 689.49
               Mean episode length: 243.41
    Episode_Reward/reaching_object: 0.7395
    Episode_Reward/rotating_object: 140.4046
        Episode_Reward/action_rate: -0.0251
          Episode_Reward/joint_vel: -0.0068
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 75202560
                    Iteration time: 1.70s
                      Time elapsed: 00:25:01
                               ETA: 00:24:04

################################################################################
                     [1m Learning iteration 765/1500 [0m                      

                       Computation: 54126 steps/s (collection: 1.642s, learning 0.175s)
             Mean action noise std: 2.32
          Mean value_function loss: 31.0415
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 39.5006
                       Mean reward: 728.48
               Mean episode length: 248.16
    Episode_Reward/reaching_object: 0.7458
    Episode_Reward/rotating_object: 141.2903
        Episode_Reward/action_rate: -0.0255
          Episode_Reward/joint_vel: -0.0071
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 75300864
                    Iteration time: 1.82s
                      Time elapsed: 00:25:03
                               ETA: 00:24:02

################################################################################
                     [1m Learning iteration 766/1500 [0m                      

                       Computation: 56412 steps/s (collection: 1.644s, learning 0.099s)
             Mean action noise std: 2.32
          Mean value_function loss: 35.7856
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 39.5064
                       Mean reward: 711.87
               Mean episode length: 245.61
    Episode_Reward/reaching_object: 0.7467
    Episode_Reward/rotating_object: 142.4699
        Episode_Reward/action_rate: -0.0254
          Episode_Reward/joint_vel: -0.0069
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 75399168
                    Iteration time: 1.74s
                      Time elapsed: 00:25:04
                               ETA: 00:24:00

################################################################################
                     [1m Learning iteration 767/1500 [0m                      

                       Computation: 57895 steps/s (collection: 1.590s, learning 0.107s)
             Mean action noise std: 2.32
          Mean value_function loss: 31.6820
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 39.5134
                       Mean reward: 722.16
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7410
    Episode_Reward/rotating_object: 139.3579
        Episode_Reward/action_rate: -0.0256
          Episode_Reward/joint_vel: -0.0071
      Episode_Termination/time_out: 18.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 75497472
                    Iteration time: 1.70s
                      Time elapsed: 00:25:06
                               ETA: 00:23:57

################################################################################
                     [1m Learning iteration 768/1500 [0m                      

                       Computation: 58282 steps/s (collection: 1.597s, learning 0.090s)
             Mean action noise std: 2.32
          Mean value_function loss: 43.2485
               Mean surrogate loss: -0.0002
                 Mean entropy loss: 39.5181
                       Mean reward: 705.20
               Mean episode length: 245.40
    Episode_Reward/reaching_object: 0.7415
    Episode_Reward/rotating_object: 140.2881
        Episode_Reward/action_rate: -0.0255
          Episode_Reward/joint_vel: -0.0070
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 75595776
                    Iteration time: 1.69s
                      Time elapsed: 00:25:08
                               ETA: 00:23:55

################################################################################
                     [1m Learning iteration 769/1500 [0m                      

                       Computation: 53914 steps/s (collection: 1.713s, learning 0.110s)
             Mean action noise std: 2.32
          Mean value_function loss: 35.1413
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 39.5269
                       Mean reward: 692.28
               Mean episode length: 248.11
    Episode_Reward/reaching_object: 0.7412
    Episode_Reward/rotating_object: 138.3238
        Episode_Reward/action_rate: -0.0257
          Episode_Reward/joint_vel: -0.0070
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 75694080
                    Iteration time: 1.82s
                      Time elapsed: 00:25:10
                               ETA: 00:23:53

################################################################################
                     [1m Learning iteration 770/1500 [0m                      

                       Computation: 56228 steps/s (collection: 1.608s, learning 0.140s)
             Mean action noise std: 2.33
          Mean value_function loss: 32.5075
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 39.5411
                       Mean reward: 687.05
               Mean episode length: 245.55
    Episode_Reward/reaching_object: 0.7412
    Episode_Reward/rotating_object: 139.9885
        Episode_Reward/action_rate: -0.0258
          Episode_Reward/joint_vel: -0.0071
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 75792384
                    Iteration time: 1.75s
                      Time elapsed: 00:25:11
                               ETA: 00:23:51

################################################################################
                     [1m Learning iteration 771/1500 [0m                      

                       Computation: 55079 steps/s (collection: 1.638s, learning 0.147s)
             Mean action noise std: 2.33
          Mean value_function loss: 30.7922
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 39.5537
                       Mean reward: 703.61
               Mean episode length: 248.18
    Episode_Reward/reaching_object: 0.7446
    Episode_Reward/rotating_object: 141.8254
        Episode_Reward/action_rate: -0.0257
          Episode_Reward/joint_vel: -0.0067
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 75890688
                    Iteration time: 1.78s
                      Time elapsed: 00:25:13
                               ETA: 00:23:49

################################################################################
                     [1m Learning iteration 772/1500 [0m                      

                       Computation: 57349 steps/s (collection: 1.620s, learning 0.094s)
             Mean action noise std: 2.33
          Mean value_function loss: 36.1855
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 39.5664
                       Mean reward: 690.48
               Mean episode length: 245.80
    Episode_Reward/reaching_object: 0.7386
    Episode_Reward/rotating_object: 139.9425
        Episode_Reward/action_rate: -0.0255
          Episode_Reward/joint_vel: -0.0068
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 75988992
                    Iteration time: 1.71s
                      Time elapsed: 00:25:15
                               ETA: 00:23:47

################################################################################
                     [1m Learning iteration 773/1500 [0m                      

                       Computation: 57851 steps/s (collection: 1.601s, learning 0.099s)
             Mean action noise std: 2.33
          Mean value_function loss: 36.6876
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 39.5786
                       Mean reward: 669.79
               Mean episode length: 244.63
    Episode_Reward/reaching_object: 0.7356
    Episode_Reward/rotating_object: 138.6343
        Episode_Reward/action_rate: -0.0256
          Episode_Reward/joint_vel: -0.0070
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 76087296
                    Iteration time: 1.70s
                      Time elapsed: 00:25:17
                               ETA: 00:23:44

################################################################################
                     [1m Learning iteration 774/1500 [0m                      

                       Computation: 52448 steps/s (collection: 1.720s, learning 0.155s)
             Mean action noise std: 2.33
          Mean value_function loss: 38.8964
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 39.5937
                       Mean reward: 715.70
               Mean episode length: 247.74
    Episode_Reward/reaching_object: 0.7373
    Episode_Reward/rotating_object: 138.4004
        Episode_Reward/action_rate: -0.0256
          Episode_Reward/joint_vel: -0.0068
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 76185600
                    Iteration time: 1.87s
                      Time elapsed: 00:25:18
                               ETA: 00:23:42

################################################################################
                     [1m Learning iteration 775/1500 [0m                      

                       Computation: 55499 steps/s (collection: 1.623s, learning 0.148s)
             Mean action noise std: 2.33
          Mean value_function loss: 26.4056
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 39.6048
                       Mean reward: 660.06
               Mean episode length: 248.05
    Episode_Reward/reaching_object: 0.7378
    Episode_Reward/rotating_object: 136.1429
        Episode_Reward/action_rate: -0.0260
          Episode_Reward/joint_vel: -0.0073
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 76283904
                    Iteration time: 1.77s
                      Time elapsed: 00:25:20
                               ETA: 00:23:40

################################################################################
                     [1m Learning iteration 776/1500 [0m                      

                       Computation: 55299 steps/s (collection: 1.672s, learning 0.106s)
             Mean action noise std: 2.34
          Mean value_function loss: 29.3387
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 39.6204
                       Mean reward: 667.07
               Mean episode length: 245.31
    Episode_Reward/reaching_object: 0.7406
    Episode_Reward/rotating_object: 137.0553
        Episode_Reward/action_rate: -0.0259
          Episode_Reward/joint_vel: -0.0074
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 76382208
                    Iteration time: 1.78s
                      Time elapsed: 00:25:22
                               ETA: 00:23:38

################################################################################
                     [1m Learning iteration 777/1500 [0m                      

                       Computation: 57054 steps/s (collection: 1.621s, learning 0.102s)
             Mean action noise std: 2.34
          Mean value_function loss: 25.7960
               Mean surrogate loss: -0.0002
                 Mean entropy loss: 39.6355
                       Mean reward: 674.87
               Mean episode length: 248.05
    Episode_Reward/reaching_object: 0.7409
    Episode_Reward/rotating_object: 138.8740
        Episode_Reward/action_rate: -0.0259
          Episode_Reward/joint_vel: -0.0067
      Episode_Termination/time_out: 18.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 76480512
                    Iteration time: 1.72s
                      Time elapsed: 00:25:24
                               ETA: 00:23:36

################################################################################
                     [1m Learning iteration 778/1500 [0m                      

                       Computation: 56644 steps/s (collection: 1.636s, learning 0.099s)
             Mean action noise std: 2.34
          Mean value_function loss: 28.5949
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 39.6456
                       Mean reward: 679.83
               Mean episode length: 245.45
    Episode_Reward/reaching_object: 0.7402
    Episode_Reward/rotating_object: 138.8841
        Episode_Reward/action_rate: -0.0259
          Episode_Reward/joint_vel: -0.0064
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 76578816
                    Iteration time: 1.74s
                      Time elapsed: 00:25:25
                               ETA: 00:23:34

################################################################################
                     [1m Learning iteration 779/1500 [0m                      

                       Computation: 57244 steps/s (collection: 1.618s, learning 0.099s)
             Mean action noise std: 2.34
          Mean value_function loss: 36.6711
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 39.6656
                       Mean reward: 708.78
               Mean episode length: 248.19
    Episode_Reward/reaching_object: 0.7415
    Episode_Reward/rotating_object: 140.3352
        Episode_Reward/action_rate: -0.0260
          Episode_Reward/joint_vel: -0.0065
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 76677120
                    Iteration time: 1.72s
                      Time elapsed: 00:25:27
                               ETA: 00:23:32

################################################################################
                     [1m Learning iteration 780/1500 [0m                      

                       Computation: 55869 steps/s (collection: 1.648s, learning 0.111s)
             Mean action noise std: 2.35
          Mean value_function loss: 31.1036
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 39.6849
                       Mean reward: 680.61
               Mean episode length: 246.00
    Episode_Reward/reaching_object: 0.7320
    Episode_Reward/rotating_object: 135.8294
        Episode_Reward/action_rate: -0.0258
          Episode_Reward/joint_vel: -0.0064
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 76775424
                    Iteration time: 1.76s
                      Time elapsed: 00:25:29
                               ETA: 00:23:29

################################################################################
                     [1m Learning iteration 781/1500 [0m                      

                       Computation: 55556 steps/s (collection: 1.658s, learning 0.112s)
             Mean action noise std: 2.35
          Mean value_function loss: 31.2836
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 39.6923
                       Mean reward: 690.71
               Mean episode length: 243.14
    Episode_Reward/reaching_object: 0.7369
    Episode_Reward/rotating_object: 139.5660
        Episode_Reward/action_rate: -0.0259
          Episode_Reward/joint_vel: -0.0065
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 76873728
                    Iteration time: 1.77s
                      Time elapsed: 00:25:31
                               ETA: 00:23:27

################################################################################
                     [1m Learning iteration 782/1500 [0m                      

                       Computation: 55523 steps/s (collection: 1.642s, learning 0.128s)
             Mean action noise std: 2.35
          Mean value_function loss: 28.8875
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 39.7129
                       Mean reward: 686.23
               Mean episode length: 246.93
    Episode_Reward/reaching_object: 0.7391
    Episode_Reward/rotating_object: 138.9414
        Episode_Reward/action_rate: -0.0261
          Episode_Reward/joint_vel: -0.0064
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 76972032
                    Iteration time: 1.77s
                      Time elapsed: 00:25:32
                               ETA: 00:23:25

################################################################################
                     [1m Learning iteration 783/1500 [0m                      

                       Computation: 56286 steps/s (collection: 1.652s, learning 0.095s)
             Mean action noise std: 2.35
          Mean value_function loss: 31.5123
               Mean surrogate loss: 0.0000
                 Mean entropy loss: 39.7328
                       Mean reward: 712.57
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7392
    Episode_Reward/rotating_object: 139.4286
        Episode_Reward/action_rate: -0.0261
          Episode_Reward/joint_vel: -0.0065
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 77070336
                    Iteration time: 1.75s
                      Time elapsed: 00:25:34
                               ETA: 00:23:23

################################################################################
                     [1m Learning iteration 784/1500 [0m                      

                       Computation: 55935 steps/s (collection: 1.625s, learning 0.133s)
             Mean action noise std: 2.35
          Mean value_function loss: 28.3267
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 39.7428
                       Mean reward: 718.18
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7444
    Episode_Reward/rotating_object: 141.4628
        Episode_Reward/action_rate: -0.0261
          Episode_Reward/joint_vel: -0.0061
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 77168640
                    Iteration time: 1.76s
                      Time elapsed: 00:25:36
                               ETA: 00:23:21

################################################################################
                     [1m Learning iteration 785/1500 [0m                      

                       Computation: 55543 steps/s (collection: 1.619s, learning 0.151s)
             Mean action noise std: 2.36
          Mean value_function loss: 29.3693
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 39.7626
                       Mean reward: 709.97
               Mean episode length: 245.94
    Episode_Reward/reaching_object: 0.7448
    Episode_Reward/rotating_object: 142.0967
        Episode_Reward/action_rate: -0.0260
          Episode_Reward/joint_vel: -0.0062
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 77266944
                    Iteration time: 1.77s
                      Time elapsed: 00:25:38
                               ETA: 00:23:19

################################################################################
                     [1m Learning iteration 786/1500 [0m                      

                       Computation: 54746 steps/s (collection: 1.685s, learning 0.111s)
             Mean action noise std: 2.36
          Mean value_function loss: 25.9698
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 39.7901
                       Mean reward: 688.79
               Mean episode length: 245.91
    Episode_Reward/reaching_object: 0.7476
    Episode_Reward/rotating_object: 141.7966
        Episode_Reward/action_rate: -0.0261
          Episode_Reward/joint_vel: -0.0064
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 77365248
                    Iteration time: 1.80s
                      Time elapsed: 00:25:40
                               ETA: 00:23:17

################################################################################
                     [1m Learning iteration 787/1500 [0m                      

                       Computation: 55576 steps/s (collection: 1.674s, learning 0.095s)
             Mean action noise std: 2.36
          Mean value_function loss: 32.9056
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 39.8042
                       Mean reward: 708.86
               Mean episode length: 247.69
    Episode_Reward/reaching_object: 0.7487
    Episode_Reward/rotating_object: 141.4903
        Episode_Reward/action_rate: -0.0262
          Episode_Reward/joint_vel: -0.0064
      Episode_Termination/time_out: 17.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 77463552
                    Iteration time: 1.77s
                      Time elapsed: 00:25:41
                               ETA: 00:23:15

################################################################################
                     [1m Learning iteration 788/1500 [0m                      

                       Computation: 55408 steps/s (collection: 1.664s, learning 0.110s)
             Mean action noise std: 2.36
          Mean value_function loss: 33.2447
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 39.8151
                       Mean reward: 715.65
               Mean episode length: 247.80
    Episode_Reward/reaching_object: 0.7541
    Episode_Reward/rotating_object: 140.8790
        Episode_Reward/action_rate: -0.0263
          Episode_Reward/joint_vel: -0.0063
      Episode_Termination/time_out: 17.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 77561856
                    Iteration time: 1.77s
                      Time elapsed: 00:25:43
                               ETA: 00:23:12

################################################################################
                     [1m Learning iteration 789/1500 [0m                      

                       Computation: 55599 steps/s (collection: 1.660s, learning 0.109s)
             Mean action noise std: 2.37
          Mean value_function loss: 41.7007
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 39.8184
                       Mean reward: 713.98
               Mean episode length: 247.82
    Episode_Reward/reaching_object: 0.7479
    Episode_Reward/rotating_object: 139.9611
        Episode_Reward/action_rate: -0.0263
          Episode_Reward/joint_vel: -0.0067
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 77660160
                    Iteration time: 1.77s
                      Time elapsed: 00:25:45
                               ETA: 00:23:10

################################################################################
                     [1m Learning iteration 790/1500 [0m                      

                       Computation: 55613 steps/s (collection: 1.648s, learning 0.120s)
             Mean action noise std: 2.37
          Mean value_function loss: 36.7706
               Mean surrogate loss: 0.0018
                 Mean entropy loss: 39.8186
                       Mean reward: 677.98
               Mean episode length: 245.52
    Episode_Reward/reaching_object: 0.7418
    Episode_Reward/rotating_object: 137.4851
        Episode_Reward/action_rate: -0.0261
          Episode_Reward/joint_vel: -0.0064
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 77758464
                    Iteration time: 1.77s
                      Time elapsed: 00:25:47
                               ETA: 00:23:08

################################################################################
                     [1m Learning iteration 791/1500 [0m                      

                       Computation: 55962 steps/s (collection: 1.622s, learning 0.134s)
             Mean action noise std: 2.37
          Mean value_function loss: 25.5028
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 39.8206
                       Mean reward: 715.98
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7554
    Episode_Reward/rotating_object: 141.6181
        Episode_Reward/action_rate: -0.0265
          Episode_Reward/joint_vel: -0.0062
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 77856768
                    Iteration time: 1.76s
                      Time elapsed: 00:25:48
                               ETA: 00:23:06

################################################################################
                     [1m Learning iteration 792/1500 [0m                      

                       Computation: 57911 steps/s (collection: 1.605s, learning 0.093s)
             Mean action noise std: 2.37
          Mean value_function loss: 28.8183
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 39.8244
                       Mean reward: 683.93
               Mean episode length: 245.55
    Episode_Reward/reaching_object: 0.7506
    Episode_Reward/rotating_object: 140.7872
        Episode_Reward/action_rate: -0.0265
          Episode_Reward/joint_vel: -0.0064
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 77955072
                    Iteration time: 1.70s
                      Time elapsed: 00:25:50
                               ETA: 00:23:04

################################################################################
                     [1m Learning iteration 793/1500 [0m                      

                       Computation: 57106 steps/s (collection: 1.632s, learning 0.089s)
             Mean action noise std: 2.37
          Mean value_function loss: 28.8917
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 39.8269
                       Mean reward: 710.18
               Mean episode length: 248.00
    Episode_Reward/reaching_object: 0.7506
    Episode_Reward/rotating_object: 140.4969
        Episode_Reward/action_rate: -0.0266
          Episode_Reward/joint_vel: -0.0064
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 78053376
                    Iteration time: 1.72s
                      Time elapsed: 00:25:52
                               ETA: 00:23:02

################################################################################
                     [1m Learning iteration 794/1500 [0m                      

                       Computation: 57950 steps/s (collection: 1.599s, learning 0.097s)
             Mean action noise std: 2.37
          Mean value_function loss: 33.5572
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 39.8304
                       Mean reward: 701.65
               Mean episode length: 247.83
    Episode_Reward/reaching_object: 0.7446
    Episode_Reward/rotating_object: 140.4418
        Episode_Reward/action_rate: -0.0264
          Episode_Reward/joint_vel: -0.0064
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 78151680
                    Iteration time: 1.70s
                      Time elapsed: 00:25:53
                               ETA: 00:23:00

################################################################################
                     [1m Learning iteration 795/1500 [0m                      

                       Computation: 57893 steps/s (collection: 1.596s, learning 0.102s)
             Mean action noise std: 2.37
          Mean value_function loss: 29.3809
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 39.8392
                       Mean reward: 725.16
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7521
    Episode_Reward/rotating_object: 144.1172
        Episode_Reward/action_rate: -0.0266
          Episode_Reward/joint_vel: -0.0066
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 78249984
                    Iteration time: 1.70s
                      Time elapsed: 00:25:55
                               ETA: 00:22:57

################################################################################
                     [1m Learning iteration 796/1500 [0m                      

                       Computation: 56570 steps/s (collection: 1.649s, learning 0.089s)
             Mean action noise std: 2.37
          Mean value_function loss: 28.5230
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 39.8477
                       Mean reward: 701.88
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7432
    Episode_Reward/rotating_object: 139.8269
        Episode_Reward/action_rate: -0.0268
          Episode_Reward/joint_vel: -0.0065
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 78348288
                    Iteration time: 1.74s
                      Time elapsed: 00:25:57
                               ETA: 00:22:55

################################################################################
                     [1m Learning iteration 797/1500 [0m                      

                       Computation: 57687 steps/s (collection: 1.614s, learning 0.091s)
             Mean action noise std: 2.37
          Mean value_function loss: 31.3194
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 39.8543
                       Mean reward: 662.22
               Mean episode length: 243.46
    Episode_Reward/reaching_object: 0.7331
    Episode_Reward/rotating_object: 137.1369
        Episode_Reward/action_rate: -0.0264
          Episode_Reward/joint_vel: -0.0065
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 78446592
                    Iteration time: 1.70s
                      Time elapsed: 00:25:59
                               ETA: 00:22:53

################################################################################
                     [1m Learning iteration 798/1500 [0m                      

                       Computation: 57408 steps/s (collection: 1.588s, learning 0.125s)
             Mean action noise std: 2.38
          Mean value_function loss: 26.2358
               Mean surrogate loss: 0.0003
                 Mean entropy loss: 39.8607
                       Mean reward: 715.23
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7406
    Episode_Reward/rotating_object: 140.6537
        Episode_Reward/action_rate: -0.0268
          Episode_Reward/joint_vel: -0.0064
      Episode_Termination/time_out: 18.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 78544896
                    Iteration time: 1.71s
                      Time elapsed: 00:26:00
                               ETA: 00:22:51

################################################################################
                     [1m Learning iteration 799/1500 [0m                      

                       Computation: 56610 steps/s (collection: 1.632s, learning 0.104s)
             Mean action noise std: 2.38
          Mean value_function loss: 30.8636
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 39.8682
                       Mean reward: 718.53
               Mean episode length: 247.87
    Episode_Reward/reaching_object: 0.7478
    Episode_Reward/rotating_object: 142.9611
        Episode_Reward/action_rate: -0.0268
          Episode_Reward/joint_vel: -0.0064
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 78643200
                    Iteration time: 1.74s
                      Time elapsed: 00:26:02
                               ETA: 00:22:49

################################################################################
                     [1m Learning iteration 800/1500 [0m                      

                       Computation: 58333 steps/s (collection: 1.595s, learning 0.091s)
             Mean action noise std: 2.38
          Mean value_function loss: 33.6537
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 39.8712
                       Mean reward: 694.85
               Mean episode length: 245.63
    Episode_Reward/reaching_object: 0.7412
    Episode_Reward/rotating_object: 142.5646
        Episode_Reward/action_rate: -0.0268
          Episode_Reward/joint_vel: -0.0065
      Episode_Termination/time_out: 17.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 78741504
                    Iteration time: 1.69s
                      Time elapsed: 00:26:04
                               ETA: 00:22:47

################################################################################
                     [1m Learning iteration 801/1500 [0m                      

                       Computation: 56219 steps/s (collection: 1.637s, learning 0.112s)
             Mean action noise std: 2.38
          Mean value_function loss: 40.7492
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 39.8751
                       Mean reward: 722.36
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7353
    Episode_Reward/rotating_object: 140.6964
        Episode_Reward/action_rate: -0.0268
          Episode_Reward/joint_vel: -0.0064
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 78839808
                    Iteration time: 1.75s
                      Time elapsed: 00:26:06
                               ETA: 00:22:44

################################################################################
                     [1m Learning iteration 802/1500 [0m                      

                       Computation: 57445 steps/s (collection: 1.614s, learning 0.097s)
             Mean action noise std: 2.38
          Mean value_function loss: 28.0989
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 39.8850
                       Mean reward: 701.09
               Mean episode length: 247.81
    Episode_Reward/reaching_object: 0.7371
    Episode_Reward/rotating_object: 141.2611
        Episode_Reward/action_rate: -0.0268
          Episode_Reward/joint_vel: -0.0064
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 78938112
                    Iteration time: 1.71s
                      Time elapsed: 00:26:07
                               ETA: 00:22:42

################################################################################
                     [1m Learning iteration 803/1500 [0m                      

                       Computation: 56822 steps/s (collection: 1.627s, learning 0.103s)
             Mean action noise std: 2.38
          Mean value_function loss: 27.6399
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 39.8978
                       Mean reward: 726.12
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7460
    Episode_Reward/rotating_object: 144.6572
        Episode_Reward/action_rate: -0.0270
          Episode_Reward/joint_vel: -0.0066
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 79036416
                    Iteration time: 1.73s
                      Time elapsed: 00:26:09
                               ETA: 00:22:40

################################################################################
                     [1m Learning iteration 804/1500 [0m                      

                       Computation: 56440 steps/s (collection: 1.644s, learning 0.098s)
             Mean action noise std: 2.39
          Mean value_function loss: 23.4316
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 39.9150
                       Mean reward: 705.21
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7362
    Episode_Reward/rotating_object: 140.7965
        Episode_Reward/action_rate: -0.0270
          Episode_Reward/joint_vel: -0.0067
      Episode_Termination/time_out: 17.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 79134720
                    Iteration time: 1.74s
                      Time elapsed: 00:26:11
                               ETA: 00:22:38

################################################################################
                     [1m Learning iteration 805/1500 [0m                      

                       Computation: 55514 steps/s (collection: 1.611s, learning 0.160s)
             Mean action noise std: 2.39
          Mean value_function loss: 31.0753
               Mean surrogate loss: 0.0018
                 Mean entropy loss: 39.9231
                       Mean reward: 690.09
               Mean episode length: 243.57
    Episode_Reward/reaching_object: 0.7342
    Episode_Reward/rotating_object: 140.9788
        Episode_Reward/action_rate: -0.0269
          Episode_Reward/joint_vel: -0.0066
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 79233024
                    Iteration time: 1.77s
                      Time elapsed: 00:26:12
                               ETA: 00:22:36

################################################################################
                     [1m Learning iteration 806/1500 [0m                      

                       Computation: 56643 steps/s (collection: 1.644s, learning 0.092s)
             Mean action noise std: 2.39
          Mean value_function loss: 28.5790
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 39.9256
                       Mean reward: 704.46
               Mean episode length: 248.17
    Episode_Reward/reaching_object: 0.7341
    Episode_Reward/rotating_object: 139.8000
        Episode_Reward/action_rate: -0.0271
          Episode_Reward/joint_vel: -0.0070
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 79331328
                    Iteration time: 1.74s
                      Time elapsed: 00:26:14
                               ETA: 00:22:34

################################################################################
                     [1m Learning iteration 807/1500 [0m                      

                       Computation: 57570 steps/s (collection: 1.607s, learning 0.101s)
             Mean action noise std: 2.39
          Mean value_function loss: 28.8381
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 39.9383
                       Mean reward: 707.64
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7371
    Episode_Reward/rotating_object: 141.2306
        Episode_Reward/action_rate: -0.0272
          Episode_Reward/joint_vel: -0.0070
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 79429632
                    Iteration time: 1.71s
                      Time elapsed: 00:26:16
                               ETA: 00:22:32

################################################################################
                     [1m Learning iteration 808/1500 [0m                      

                       Computation: 59057 steps/s (collection: 1.571s, learning 0.093s)
             Mean action noise std: 2.39
          Mean value_function loss: 28.6118
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 39.9567
                       Mean reward: 672.99
               Mean episode length: 247.95
    Episode_Reward/reaching_object: 0.7322
    Episode_Reward/rotating_object: 139.6519
        Episode_Reward/action_rate: -0.0271
          Episode_Reward/joint_vel: -0.0068
      Episode_Termination/time_out: 17.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 79527936
                    Iteration time: 1.66s
                      Time elapsed: 00:26:18
                               ETA: 00:22:29

################################################################################
                     [1m Learning iteration 809/1500 [0m                      

                       Computation: 57965 steps/s (collection: 1.593s, learning 0.103s)
             Mean action noise std: 2.39
          Mean value_function loss: 30.4630
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 39.9719
                       Mean reward: 703.91
               Mean episode length: 247.72
    Episode_Reward/reaching_object: 0.7398
    Episode_Reward/rotating_object: 143.4123
        Episode_Reward/action_rate: -0.0272
          Episode_Reward/joint_vel: -0.0067
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 79626240
                    Iteration time: 1.70s
                      Time elapsed: 00:26:19
                               ETA: 00:22:27

################################################################################
                     [1m Learning iteration 810/1500 [0m                      

                       Computation: 57560 steps/s (collection: 1.608s, learning 0.100s)
             Mean action noise std: 2.39
          Mean value_function loss: 30.9493
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 39.9761
                       Mean reward: 729.15
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7259
    Episode_Reward/rotating_object: 138.2545
        Episode_Reward/action_rate: -0.0273
          Episode_Reward/joint_vel: -0.0070
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 79724544
                    Iteration time: 1.71s
                      Time elapsed: 00:26:21
                               ETA: 00:22:25

################################################################################
                     [1m Learning iteration 811/1500 [0m                      

                       Computation: 57401 steps/s (collection: 1.613s, learning 0.100s)
             Mean action noise std: 2.40
          Mean value_function loss: 30.7618
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 39.9876
                       Mean reward: 742.89
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7359
    Episode_Reward/rotating_object: 142.9113
        Episode_Reward/action_rate: -0.0274
          Episode_Reward/joint_vel: -0.0067
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 79822848
                    Iteration time: 1.71s
                      Time elapsed: 00:26:23
                               ETA: 00:22:23

################################################################################
                     [1m Learning iteration 812/1500 [0m                      

                       Computation: 57129 steps/s (collection: 1.596s, learning 0.125s)
             Mean action noise std: 2.40
          Mean value_function loss: 41.7022
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 40.0006
                       Mean reward: 720.40
               Mean episode length: 245.54
    Episode_Reward/reaching_object: 0.7265
    Episode_Reward/rotating_object: 140.4613
        Episode_Reward/action_rate: -0.0271
          Episode_Reward/joint_vel: -0.0066
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 79921152
                    Iteration time: 1.72s
                      Time elapsed: 00:26:24
                               ETA: 00:22:21

################################################################################
                     [1m Learning iteration 813/1500 [0m                      

                       Computation: 57396 steps/s (collection: 1.602s, learning 0.111s)
             Mean action noise std: 2.40
          Mean value_function loss: 28.0122
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 40.0097
                       Mean reward: 707.21
               Mean episode length: 244.42
    Episode_Reward/reaching_object: 0.7316
    Episode_Reward/rotating_object: 141.8811
        Episode_Reward/action_rate: -0.0273
          Episode_Reward/joint_vel: -0.0067
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 80019456
                    Iteration time: 1.71s
                      Time elapsed: 00:26:26
                               ETA: 00:22:19

################################################################################
                     [1m Learning iteration 814/1500 [0m                      

                       Computation: 57216 steps/s (collection: 1.618s, learning 0.101s)
             Mean action noise std: 2.40
          Mean value_function loss: 30.1120
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 40.0169
                       Mean reward: 716.73
               Mean episode length: 247.87
    Episode_Reward/reaching_object: 0.7319
    Episode_Reward/rotating_object: 141.5385
        Episode_Reward/action_rate: -0.0274
          Episode_Reward/joint_vel: -0.0068
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 80117760
                    Iteration time: 1.72s
                      Time elapsed: 00:26:28
                               ETA: 00:22:16

################################################################################
                     [1m Learning iteration 815/1500 [0m                      

                       Computation: 56727 steps/s (collection: 1.638s, learning 0.095s)
             Mean action noise std: 2.40
          Mean value_function loss: 29.1154
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 40.0311
                       Mean reward: 719.72
               Mean episode length: 248.85
    Episode_Reward/reaching_object: 0.7329
    Episode_Reward/rotating_object: 141.9409
        Episode_Reward/action_rate: -0.0277
          Episode_Reward/joint_vel: -0.0069
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 80216064
                    Iteration time: 1.73s
                      Time elapsed: 00:26:30
                               ETA: 00:22:14

################################################################################
                     [1m Learning iteration 816/1500 [0m                      

                       Computation: 58163 steps/s (collection: 1.590s, learning 0.100s)
             Mean action noise std: 2.40
          Mean value_function loss: 28.8162
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 40.0392
                       Mean reward: 734.83
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7355
    Episode_Reward/rotating_object: 145.3553
        Episode_Reward/action_rate: -0.0275
          Episode_Reward/joint_vel: -0.0066
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 80314368
                    Iteration time: 1.69s
                      Time elapsed: 00:26:31
                               ETA: 00:22:12

################################################################################
                     [1m Learning iteration 817/1500 [0m                      

                       Computation: 57691 steps/s (collection: 1.616s, learning 0.088s)
             Mean action noise std: 2.41
          Mean value_function loss: 30.2197
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 40.0531
                       Mean reward: 732.25
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7319
    Episode_Reward/rotating_object: 143.4287
        Episode_Reward/action_rate: -0.0276
          Episode_Reward/joint_vel: -0.0067
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 80412672
                    Iteration time: 1.70s
                      Time elapsed: 00:26:33
                               ETA: 00:22:10

################################################################################
                     [1m Learning iteration 818/1500 [0m                      

                       Computation: 56100 steps/s (collection: 1.614s, learning 0.138s)
             Mean action noise std: 2.41
          Mean value_function loss: 27.4665
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 40.0680
                       Mean reward: 739.30
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7299
    Episode_Reward/rotating_object: 143.6902
        Episode_Reward/action_rate: -0.0274
          Episode_Reward/joint_vel: -0.0063
      Episode_Termination/time_out: 17.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 80510976
                    Iteration time: 1.75s
                      Time elapsed: 00:26:35
                               ETA: 00:22:08

################################################################################
                     [1m Learning iteration 819/1500 [0m                      

                       Computation: 57238 steps/s (collection: 1.600s, learning 0.117s)
             Mean action noise std: 2.41
          Mean value_function loss: 28.6068
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 40.0845
                       Mean reward: 718.78
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7295
    Episode_Reward/rotating_object: 141.4385
        Episode_Reward/action_rate: -0.0277
          Episode_Reward/joint_vel: -0.0065
      Episode_Termination/time_out: 18.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 80609280
                    Iteration time: 1.72s
                      Time elapsed: 00:26:36
                               ETA: 00:22:06

################################################################################
                     [1m Learning iteration 820/1500 [0m                      

                       Computation: 57843 steps/s (collection: 1.608s, learning 0.091s)
             Mean action noise std: 2.41
          Mean value_function loss: 35.6035
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 40.1018
                       Mean reward: 711.21
               Mean episode length: 247.68
    Episode_Reward/reaching_object: 0.7284
    Episode_Reward/rotating_object: 143.7396
        Episode_Reward/action_rate: -0.0275
          Episode_Reward/joint_vel: -0.0063
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 80707584
                    Iteration time: 1.70s
                      Time elapsed: 00:26:38
                               ETA: 00:22:04

################################################################################
                     [1m Learning iteration 821/1500 [0m                      

                       Computation: 58381 steps/s (collection: 1.587s, learning 0.097s)
             Mean action noise std: 2.42
          Mean value_function loss: 32.4919
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 40.1131
                       Mean reward: 690.39
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7203
    Episode_Reward/rotating_object: 137.7268
        Episode_Reward/action_rate: -0.0276
          Episode_Reward/joint_vel: -0.0063
      Episode_Termination/time_out: 17.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 80805888
                    Iteration time: 1.68s
                      Time elapsed: 00:26:40
                               ETA: 00:22:01

################################################################################
                     [1m Learning iteration 822/1500 [0m                      

                       Computation: 58225 steps/s (collection: 1.598s, learning 0.090s)
             Mean action noise std: 2.42
          Mean value_function loss: 37.4417
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 40.1253
                       Mean reward: 715.06
               Mean episode length: 243.73
    Episode_Reward/reaching_object: 0.7247
    Episode_Reward/rotating_object: 141.4046
        Episode_Reward/action_rate: -0.0274
          Episode_Reward/joint_vel: -0.0064
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 80904192
                    Iteration time: 1.69s
                      Time elapsed: 00:26:42
                               ETA: 00:21:59

################################################################################
                     [1m Learning iteration 823/1500 [0m                      

                       Computation: 58252 steps/s (collection: 1.595s, learning 0.093s)
             Mean action noise std: 2.42
          Mean value_function loss: 33.9575
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 40.1392
                       Mean reward: 655.66
               Mean episode length: 241.07
    Episode_Reward/reaching_object: 0.7226
    Episode_Reward/rotating_object: 139.6136
        Episode_Reward/action_rate: -0.0275
          Episode_Reward/joint_vel: -0.0061
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 81002496
                    Iteration time: 1.69s
                      Time elapsed: 00:26:43
                               ETA: 00:21:57

################################################################################
                     [1m Learning iteration 824/1500 [0m                      

                       Computation: 57580 steps/s (collection: 1.602s, learning 0.105s)
             Mean action noise std: 2.42
          Mean value_function loss: 35.5130
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 40.1505
                       Mean reward: 684.39
               Mean episode length: 245.46
    Episode_Reward/reaching_object: 0.7209
    Episode_Reward/rotating_object: 138.6347
        Episode_Reward/action_rate: -0.0277
          Episode_Reward/joint_vel: -0.0061
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 81100800
                    Iteration time: 1.71s
                      Time elapsed: 00:26:45
                               ETA: 00:21:55

################################################################################
                     [1m Learning iteration 825/1500 [0m                      

                       Computation: 57624 steps/s (collection: 1.605s, learning 0.101s)
             Mean action noise std: 2.42
          Mean value_function loss: 32.7476
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 40.1589
                       Mean reward: 745.26
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7402
    Episode_Reward/rotating_object: 145.1918
        Episode_Reward/action_rate: -0.0280
          Episode_Reward/joint_vel: -0.0062
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 81199104
                    Iteration time: 1.71s
                      Time elapsed: 00:26:47
                               ETA: 00:21:53

################################################################################
                     [1m Learning iteration 826/1500 [0m                      

                       Computation: 53121 steps/s (collection: 1.742s, learning 0.108s)
             Mean action noise std: 2.42
          Mean value_function loss: 36.8287
               Mean surrogate loss: 0.0025
                 Mean entropy loss: 40.1673
                       Mean reward: 705.06
               Mean episode length: 247.89
    Episode_Reward/reaching_object: 0.7264
    Episode_Reward/rotating_object: 139.6104
        Episode_Reward/action_rate: -0.0278
          Episode_Reward/joint_vel: -0.0060
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 81297408
                    Iteration time: 1.85s
                      Time elapsed: 00:26:48
                               ETA: 00:21:51

################################################################################
                     [1m Learning iteration 827/1500 [0m                      

                       Computation: 56198 steps/s (collection: 1.640s, learning 0.110s)
             Mean action noise std: 2.42
          Mean value_function loss: 30.6696
               Mean surrogate loss: -0.0001
                 Mean entropy loss: 40.1695
                       Mean reward: 717.03
               Mean episode length: 247.80
    Episode_Reward/reaching_object: 0.7359
    Episode_Reward/rotating_object: 143.6450
        Episode_Reward/action_rate: -0.0279
          Episode_Reward/joint_vel: -0.0061
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 81395712
                    Iteration time: 1.75s
                      Time elapsed: 00:26:50
                               ETA: 00:21:49

################################################################################
                     [1m Learning iteration 828/1500 [0m                      

                       Computation: 58113 steps/s (collection: 1.600s, learning 0.092s)
             Mean action noise std: 2.42
          Mean value_function loss: 27.9670
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 40.1731
                       Mean reward: 695.90
               Mean episode length: 245.60
    Episode_Reward/reaching_object: 0.7297
    Episode_Reward/rotating_object: 142.5790
        Episode_Reward/action_rate: -0.0280
          Episode_Reward/joint_vel: -0.0061
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 81494016
                    Iteration time: 1.69s
                      Time elapsed: 00:26:52
                               ETA: 00:21:47

################################################################################
                     [1m Learning iteration 829/1500 [0m                      

                       Computation: 58085 steps/s (collection: 1.593s, learning 0.100s)
             Mean action noise std: 2.43
          Mean value_function loss: 29.0815
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 40.1806
                       Mean reward: 676.16
               Mean episode length: 246.26
    Episode_Reward/reaching_object: 0.7223
    Episode_Reward/rotating_object: 138.7613
        Episode_Reward/action_rate: -0.0279
          Episode_Reward/joint_vel: -0.0059
      Episode_Termination/time_out: 18.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 81592320
                    Iteration time: 1.69s
                      Time elapsed: 00:26:54
                               ETA: 00:21:44

################################################################################
                     [1m Learning iteration 830/1500 [0m                      

                       Computation: 55851 steps/s (collection: 1.616s, learning 0.144s)
             Mean action noise std: 2.43
          Mean value_function loss: 33.0718
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 40.1873
                       Mean reward: 729.00
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7303
    Episode_Reward/rotating_object: 141.2945
        Episode_Reward/action_rate: -0.0281
          Episode_Reward/joint_vel: -0.0061
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 81690624
                    Iteration time: 1.76s
                      Time elapsed: 00:26:55
                               ETA: 00:21:42

################################################################################
                     [1m Learning iteration 831/1500 [0m                      

                       Computation: 55571 steps/s (collection: 1.664s, learning 0.105s)
             Mean action noise std: 2.43
          Mean value_function loss: 31.6856
               Mean surrogate loss: 0.0031
                 Mean entropy loss: 40.1900
                       Mean reward: 715.65
               Mean episode length: 248.64
    Episode_Reward/reaching_object: 0.7312
    Episode_Reward/rotating_object: 141.8118
        Episode_Reward/action_rate: -0.0282
          Episode_Reward/joint_vel: -0.0061
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 81788928
                    Iteration time: 1.77s
                      Time elapsed: 00:26:57
                               ETA: 00:21:40

################################################################################
                     [1m Learning iteration 832/1500 [0m                      

                       Computation: 56895 steps/s (collection: 1.596s, learning 0.132s)
             Mean action noise std: 2.43
          Mean value_function loss: 30.1515
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 40.1915
                       Mean reward: 716.05
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7300
    Episode_Reward/rotating_object: 142.7705
        Episode_Reward/action_rate: -0.0282
          Episode_Reward/joint_vel: -0.0060
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 81887232
                    Iteration time: 1.73s
                      Time elapsed: 00:26:59
                               ETA: 00:21:38

################################################################################
                     [1m Learning iteration 833/1500 [0m                      

                       Computation: 56527 steps/s (collection: 1.610s, learning 0.129s)
             Mean action noise std: 2.43
          Mean value_function loss: 27.5092
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 40.1971
                       Mean reward: 735.02
               Mean episode length: 247.81
    Episode_Reward/reaching_object: 0.7291
    Episode_Reward/rotating_object: 143.5586
        Episode_Reward/action_rate: -0.0282
          Episode_Reward/joint_vel: -0.0060
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 81985536
                    Iteration time: 1.74s
                      Time elapsed: 00:27:01
                               ETA: 00:21:36

################################################################################
                     [1m Learning iteration 834/1500 [0m                      

                       Computation: 57046 steps/s (collection: 1.627s, learning 0.096s)
             Mean action noise std: 2.43
          Mean value_function loss: 28.6157
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 40.2054
                       Mean reward: 683.97
               Mean episode length: 247.75
    Episode_Reward/reaching_object: 0.7118
    Episode_Reward/rotating_object: 137.6080
        Episode_Reward/action_rate: -0.0280
          Episode_Reward/joint_vel: -0.0059
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 82083840
                    Iteration time: 1.72s
                      Time elapsed: 00:27:02
                               ETA: 00:21:34

################################################################################
                     [1m Learning iteration 835/1500 [0m                      

                       Computation: 56678 steps/s (collection: 1.619s, learning 0.116s)
             Mean action noise std: 2.43
          Mean value_function loss: 28.1724
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 40.2181
                       Mean reward: 685.32
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7218
    Episode_Reward/rotating_object: 140.2004
        Episode_Reward/action_rate: -0.0282
          Episode_Reward/joint_vel: -0.0060
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 82182144
                    Iteration time: 1.73s
                      Time elapsed: 00:27:04
                               ETA: 00:21:32

################################################################################
                     [1m Learning iteration 836/1500 [0m                      

                       Computation: 53471 steps/s (collection: 1.668s, learning 0.171s)
             Mean action noise std: 2.44
          Mean value_function loss: 29.2768
               Mean surrogate loss: -0.0007
                 Mean entropy loss: 40.2276
                       Mean reward: 716.54
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7252
    Episode_Reward/rotating_object: 141.5178
        Episode_Reward/action_rate: -0.0284
          Episode_Reward/joint_vel: -0.0059
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 82280448
                    Iteration time: 1.84s
                      Time elapsed: 00:27:06
                               ETA: 00:21:30

################################################################################
                     [1m Learning iteration 837/1500 [0m                      

                       Computation: 57930 steps/s (collection: 1.582s, learning 0.115s)
             Mean action noise std: 2.44
          Mean value_function loss: 33.0004
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 40.2336
                       Mean reward: 706.68
               Mean episode length: 241.59
    Episode_Reward/reaching_object: 0.7164
    Episode_Reward/rotating_object: 140.1707
        Episode_Reward/action_rate: -0.0281
          Episode_Reward/joint_vel: -0.0060
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 82378752
                    Iteration time: 1.70s
                      Time elapsed: 00:27:08
                               ETA: 00:21:28

################################################################################
                     [1m Learning iteration 838/1500 [0m                      

                       Computation: 56653 steps/s (collection: 1.643s, learning 0.093s)
             Mean action noise std: 2.44
          Mean value_function loss: 31.5353
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 40.2387
                       Mean reward: 712.17
               Mean episode length: 247.77
    Episode_Reward/reaching_object: 0.7242
    Episode_Reward/rotating_object: 142.8480
        Episode_Reward/action_rate: -0.0282
          Episode_Reward/joint_vel: -0.0060
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 82477056
                    Iteration time: 1.74s
                      Time elapsed: 00:27:09
                               ETA: 00:21:25

################################################################################
                     [1m Learning iteration 839/1500 [0m                      

                       Computation: 56899 steps/s (collection: 1.630s, learning 0.098s)
             Mean action noise std: 2.44
          Mean value_function loss: 29.3195
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 40.2448
                       Mean reward: 715.29
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7240
    Episode_Reward/rotating_object: 142.5622
        Episode_Reward/action_rate: -0.0283
          Episode_Reward/joint_vel: -0.0060
      Episode_Termination/time_out: 17.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 82575360
                    Iteration time: 1.73s
                      Time elapsed: 00:27:11
                               ETA: 00:21:23

################################################################################
                     [1m Learning iteration 840/1500 [0m                      

                       Computation: 56038 steps/s (collection: 1.641s, learning 0.114s)
             Mean action noise std: 2.44
          Mean value_function loss: 29.8999
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 40.2542
                       Mean reward: 704.57
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7184
    Episode_Reward/rotating_object: 139.9419
        Episode_Reward/action_rate: -0.0283
          Episode_Reward/joint_vel: -0.0060
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 82673664
                    Iteration time: 1.75s
                      Time elapsed: 00:27:13
                               ETA: 00:21:21

################################################################################
                     [1m Learning iteration 841/1500 [0m                      

                       Computation: 57040 steps/s (collection: 1.604s, learning 0.120s)
             Mean action noise std: 2.44
          Mean value_function loss: 32.5025
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 40.2613
                       Mean reward: 719.02
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7286
    Episode_Reward/rotating_object: 143.7798
        Episode_Reward/action_rate: -0.0285
          Episode_Reward/joint_vel: -0.0059
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 82771968
                    Iteration time: 1.72s
                      Time elapsed: 00:27:15
                               ETA: 00:21:19

################################################################################
                     [1m Learning iteration 842/1500 [0m                      

                       Computation: 56463 steps/s (collection: 1.627s, learning 0.114s)
             Mean action noise std: 2.44
          Mean value_function loss: 28.3626
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 40.2684
                       Mean reward: 728.93
               Mean episode length: 245.46
    Episode_Reward/reaching_object: 0.7275
    Episode_Reward/rotating_object: 143.3633
        Episode_Reward/action_rate: -0.0284
          Episode_Reward/joint_vel: -0.0060
      Episode_Termination/time_out: 17.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 82870272
                    Iteration time: 1.74s
                      Time elapsed: 00:27:16
                               ETA: 00:21:17

################################################################################
                     [1m Learning iteration 843/1500 [0m                      

                       Computation: 57040 steps/s (collection: 1.627s, learning 0.096s)
             Mean action noise std: 2.45
          Mean value_function loss: 25.6321
               Mean surrogate loss: 0.0005
                 Mean entropy loss: 40.2767
                       Mean reward: 714.14
               Mean episode length: 247.73
    Episode_Reward/reaching_object: 0.7247
    Episode_Reward/rotating_object: 142.7242
        Episode_Reward/action_rate: -0.0285
          Episode_Reward/joint_vel: -0.0060
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 82968576
                    Iteration time: 1.72s
                      Time elapsed: 00:27:18
                               ETA: 00:21:15

################################################################################
                     [1m Learning iteration 844/1500 [0m                      

                       Computation: 57791 steps/s (collection: 1.600s, learning 0.101s)
             Mean action noise std: 2.45
          Mean value_function loss: 26.9583
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 40.2839
                       Mean reward: 714.10
               Mean episode length: 247.95
    Episode_Reward/reaching_object: 0.7260
    Episode_Reward/rotating_object: 142.4451
        Episode_Reward/action_rate: -0.0286
          Episode_Reward/joint_vel: -0.0061
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 83066880
                    Iteration time: 1.70s
                      Time elapsed: 00:27:20
                               ETA: 00:21:13

################################################################################
                     [1m Learning iteration 845/1500 [0m                      

                       Computation: 51499 steps/s (collection: 1.796s, learning 0.113s)
             Mean action noise std: 2.45
          Mean value_function loss: 29.9551
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 40.2889
                       Mean reward: 686.81
               Mean episode length: 247.69
    Episode_Reward/reaching_object: 0.7163
    Episode_Reward/rotating_object: 140.1290
        Episode_Reward/action_rate: -0.0285
          Episode_Reward/joint_vel: -0.0061
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 83165184
                    Iteration time: 1.91s
                      Time elapsed: 00:27:22
                               ETA: 00:21:11

################################################################################
                     [1m Learning iteration 846/1500 [0m                      

                       Computation: 56931 steps/s (collection: 1.623s, learning 0.104s)
             Mean action noise std: 2.45
          Mean value_function loss: 25.8130
               Mean surrogate loss: -0.0006
                 Mean entropy loss: 40.2981
                       Mean reward: 728.40
               Mean episode length: 248.06
    Episode_Reward/reaching_object: 0.7220
    Episode_Reward/rotating_object: 143.3345
        Episode_Reward/action_rate: -0.0286
          Episode_Reward/joint_vel: -0.0059
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 83263488
                    Iteration time: 1.73s
                      Time elapsed: 00:27:23
                               ETA: 00:21:09

################################################################################
                     [1m Learning iteration 847/1500 [0m                      

                       Computation: 57561 steps/s (collection: 1.614s, learning 0.093s)
             Mean action noise std: 2.45
          Mean value_function loss: 25.6285
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 40.3045
                       Mean reward: 720.66
               Mean episode length: 245.53
    Episode_Reward/reaching_object: 0.7211
    Episode_Reward/rotating_object: 143.0546
        Episode_Reward/action_rate: -0.0286
          Episode_Reward/joint_vel: -0.0061
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 83361792
                    Iteration time: 1.71s
                      Time elapsed: 00:27:25
                               ETA: 00:21:07

################################################################################
                     [1m Learning iteration 848/1500 [0m                      

                       Computation: 56748 steps/s (collection: 1.583s, learning 0.149s)
             Mean action noise std: 2.45
          Mean value_function loss: 28.9016
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 40.3115
                       Mean reward: 730.02
               Mean episode length: 247.68
    Episode_Reward/reaching_object: 0.7220
    Episode_Reward/rotating_object: 142.8971
        Episode_Reward/action_rate: -0.0287
          Episode_Reward/joint_vel: -0.0063
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 83460096
                    Iteration time: 1.73s
                      Time elapsed: 00:27:27
                               ETA: 00:21:05

################################################################################
                     [1m Learning iteration 849/1500 [0m                      

                       Computation: 57182 steps/s (collection: 1.615s, learning 0.104s)
             Mean action noise std: 2.46
          Mean value_function loss: 27.5990
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 40.3267
                       Mean reward: 723.22
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7315
    Episode_Reward/rotating_object: 145.5012
        Episode_Reward/action_rate: -0.0289
          Episode_Reward/joint_vel: -0.0062
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 83558400
                    Iteration time: 1.72s
                      Time elapsed: 00:27:28
                               ETA: 00:21:02

################################################################################
                     [1m Learning iteration 850/1500 [0m                      

                       Computation: 57696 steps/s (collection: 1.613s, learning 0.091s)
             Mean action noise std: 2.46
          Mean value_function loss: 28.8361
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 40.3413
                       Mean reward: 721.53
               Mean episode length: 247.72
    Episode_Reward/reaching_object: 0.7214
    Episode_Reward/rotating_object: 142.6720
        Episode_Reward/action_rate: -0.0287
          Episode_Reward/joint_vel: -0.0062
      Episode_Termination/time_out: 18.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 83656704
                    Iteration time: 1.70s
                      Time elapsed: 00:27:30
                               ETA: 00:21:00

################################################################################
                     [1m Learning iteration 851/1500 [0m                      

                       Computation: 52425 steps/s (collection: 1.781s, learning 0.095s)
             Mean action noise std: 2.46
          Mean value_function loss: 31.5806
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 40.3484
                       Mean reward: 722.25
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7236
    Episode_Reward/rotating_object: 142.9730
        Episode_Reward/action_rate: -0.0289
          Episode_Reward/joint_vel: -0.0059
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 83755008
                    Iteration time: 1.88s
                      Time elapsed: 00:27:32
                               ETA: 00:20:58

################################################################################
                     [1m Learning iteration 852/1500 [0m                      

                       Computation: 55332 steps/s (collection: 1.622s, learning 0.155s)
             Mean action noise std: 2.46
          Mean value_function loss: 29.2291
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 40.3580
                       Mean reward: 698.77
               Mean episode length: 245.90
    Episode_Reward/reaching_object: 0.7196
    Episode_Reward/rotating_object: 142.0905
        Episode_Reward/action_rate: -0.0288
          Episode_Reward/joint_vel: -0.0059
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 83853312
                    Iteration time: 1.78s
                      Time elapsed: 00:27:34
                               ETA: 00:20:56

################################################################################
                     [1m Learning iteration 853/1500 [0m                      

                       Computation: 57992 steps/s (collection: 1.593s, learning 0.103s)
             Mean action noise std: 2.46
          Mean value_function loss: 32.1604
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 40.3673
                       Mean reward: 697.56
               Mean episode length: 245.90
    Episode_Reward/reaching_object: 0.7247
    Episode_Reward/rotating_object: 144.5762
        Episode_Reward/action_rate: -0.0288
          Episode_Reward/joint_vel: -0.0059
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 83951616
                    Iteration time: 1.70s
                      Time elapsed: 00:27:36
                               ETA: 00:20:54

################################################################################
                     [1m Learning iteration 854/1500 [0m                      

                       Computation: 56642 steps/s (collection: 1.631s, learning 0.104s)
             Mean action noise std: 2.46
          Mean value_function loss: 32.0607
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 40.3791
                       Mean reward: 697.13
               Mean episode length: 245.97
    Episode_Reward/reaching_object: 0.7186
    Episode_Reward/rotating_object: 142.3026
        Episode_Reward/action_rate: -0.0288
          Episode_Reward/joint_vel: -0.0059
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 84049920
                    Iteration time: 1.74s
                      Time elapsed: 00:27:37
                               ETA: 00:20:52

################################################################################
                     [1m Learning iteration 855/1500 [0m                      

                       Computation: 56592 steps/s (collection: 1.626s, learning 0.112s)
             Mean action noise std: 2.47
          Mean value_function loss: 31.2408
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 40.3966
                       Mean reward: 711.54
               Mean episode length: 246.33
    Episode_Reward/reaching_object: 0.7192
    Episode_Reward/rotating_object: 143.3401
        Episode_Reward/action_rate: -0.0287
          Episode_Reward/joint_vel: -0.0057
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 84148224
                    Iteration time: 1.74s
                      Time elapsed: 00:27:39
                               ETA: 00:20:50

################################################################################
                     [1m Learning iteration 856/1500 [0m                      

                       Computation: 56489 steps/s (collection: 1.641s, learning 0.100s)
             Mean action noise std: 2.47
          Mean value_function loss: 25.4926
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 40.4085
                       Mean reward: 705.82
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7223
    Episode_Reward/rotating_object: 142.9327
        Episode_Reward/action_rate: -0.0290
          Episode_Reward/joint_vel: -0.0058
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 84246528
                    Iteration time: 1.74s
                      Time elapsed: 00:27:41
                               ETA: 00:20:48

################################################################################
                     [1m Learning iteration 857/1500 [0m                      

                       Computation: 58299 steps/s (collection: 1.589s, learning 0.098s)
             Mean action noise std: 2.47
          Mean value_function loss: 23.1508
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 40.4138
                       Mean reward: 703.36
               Mean episode length: 247.69
    Episode_Reward/reaching_object: 0.7188
    Episode_Reward/rotating_object: 142.1988
        Episode_Reward/action_rate: -0.0291
          Episode_Reward/joint_vel: -0.0059
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 84344832
                    Iteration time: 1.69s
                      Time elapsed: 00:27:42
                               ETA: 00:20:46

################################################################################
                     [1m Learning iteration 858/1500 [0m                      

                       Computation: 57988 steps/s (collection: 1.597s, learning 0.098s)
             Mean action noise std: 2.47
          Mean value_function loss: 24.7732
               Mean surrogate loss: 0.0017
                 Mean entropy loss: 40.4193
                       Mean reward: 697.69
               Mean episode length: 246.80
    Episode_Reward/reaching_object: 0.7178
    Episode_Reward/rotating_object: 142.5173
        Episode_Reward/action_rate: -0.0290
          Episode_Reward/joint_vel: -0.0059
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 84443136
                    Iteration time: 1.70s
                      Time elapsed: 00:27:44
                               ETA: 00:20:44

################################################################################
                     [1m Learning iteration 859/1500 [0m                      

                       Computation: 55406 steps/s (collection: 1.602s, learning 0.173s)
             Mean action noise std: 2.47
          Mean value_function loss: 30.0844
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 40.4226
                       Mean reward: 738.02
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7226
    Episode_Reward/rotating_object: 143.7633
        Episode_Reward/action_rate: -0.0292
          Episode_Reward/joint_vel: -0.0058
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 84541440
                    Iteration time: 1.77s
                      Time elapsed: 00:27:46
                               ETA: 00:20:42

################################################################################
                     [1m Learning iteration 860/1500 [0m                      

                       Computation: 54399 steps/s (collection: 1.684s, learning 0.123s)
             Mean action noise std: 2.47
          Mean value_function loss: 26.6399
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 40.4287
                       Mean reward: 706.28
               Mean episode length: 245.73
    Episode_Reward/reaching_object: 0.7168
    Episode_Reward/rotating_object: 141.8843
        Episode_Reward/action_rate: -0.0289
          Episode_Reward/joint_vel: -0.0062
      Episode_Termination/time_out: 17.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 84639744
                    Iteration time: 1.81s
                      Time elapsed: 00:27:48
                               ETA: 00:20:40

################################################################################
                     [1m Learning iteration 861/1500 [0m                      

                       Computation: 56620 steps/s (collection: 1.644s, learning 0.092s)
             Mean action noise std: 2.48
          Mean value_function loss: 34.0718
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 40.4409
                       Mean reward: 728.78
               Mean episode length: 247.78
    Episode_Reward/reaching_object: 0.7243
    Episode_Reward/rotating_object: 144.4284
        Episode_Reward/action_rate: -0.0291
          Episode_Reward/joint_vel: -0.0059
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 84738048
                    Iteration time: 1.74s
                      Time elapsed: 00:27:49
                               ETA: 00:20:37

################################################################################
                     [1m Learning iteration 862/1500 [0m                      

                       Computation: 57394 steps/s (collection: 1.605s, learning 0.108s)
             Mean action noise std: 2.48
          Mean value_function loss: 32.1134
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 40.4543
                       Mean reward: 731.30
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7345
    Episode_Reward/rotating_object: 148.1722
        Episode_Reward/action_rate: -0.0293
          Episode_Reward/joint_vel: -0.0060
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 84836352
                    Iteration time: 1.71s
                      Time elapsed: 00:27:51
                               ETA: 00:20:35

################################################################################
                     [1m Learning iteration 863/1500 [0m                      

                       Computation: 56672 steps/s (collection: 1.605s, learning 0.130s)
             Mean action noise std: 2.48
          Mean value_function loss: 31.0851
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 40.4635
                       Mean reward: 725.08
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7243
    Episode_Reward/rotating_object: 144.0918
        Episode_Reward/action_rate: -0.0293
          Episode_Reward/joint_vel: -0.0060
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 84934656
                    Iteration time: 1.73s
                      Time elapsed: 00:27:53
                               ETA: 00:20:33

################################################################################
                     [1m Learning iteration 864/1500 [0m                      

                       Computation: 56112 steps/s (collection: 1.652s, learning 0.100s)
             Mean action noise std: 2.48
          Mean value_function loss: 24.2608
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 40.4693
                       Mean reward: 746.09
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7274
    Episode_Reward/rotating_object: 145.1636
        Episode_Reward/action_rate: -0.0294
          Episode_Reward/joint_vel: -0.0060
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 85032960
                    Iteration time: 1.75s
                      Time elapsed: 00:27:55
                               ETA: 00:20:31

################################################################################
                     [1m Learning iteration 865/1500 [0m                      

                       Computation: 56961 steps/s (collection: 1.614s, learning 0.112s)
             Mean action noise std: 2.48
          Mean value_function loss: 23.2144
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 40.4877
                       Mean reward: 734.84
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7209
    Episode_Reward/rotating_object: 144.1071
        Episode_Reward/action_rate: -0.0290
          Episode_Reward/joint_vel: -0.0057
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 85131264
                    Iteration time: 1.73s
                      Time elapsed: 00:27:56
                               ETA: 00:20:29

################################################################################
                     [1m Learning iteration 866/1500 [0m                      

                       Computation: 53930 steps/s (collection: 1.684s, learning 0.139s)
             Mean action noise std: 2.49
          Mean value_function loss: 27.4438
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 40.5081
                       Mean reward: 731.97
               Mean episode length: 247.88
    Episode_Reward/reaching_object: 0.7233
    Episode_Reward/rotating_object: 143.9449
        Episode_Reward/action_rate: -0.0294
          Episode_Reward/joint_vel: -0.0058
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 85229568
                    Iteration time: 1.82s
                      Time elapsed: 00:27:58
                               ETA: 00:20:27

################################################################################
                     [1m Learning iteration 867/1500 [0m                      

                       Computation: 56880 steps/s (collection: 1.595s, learning 0.133s)
             Mean action noise std: 2.49
          Mean value_function loss: 33.1085
               Mean surrogate loss: 0.0088
                 Mean entropy loss: 40.5225
                       Mean reward: 718.19
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7234
    Episode_Reward/rotating_object: 144.9843
        Episode_Reward/action_rate: -0.0293
          Episode_Reward/joint_vel: -0.0056
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 85327872
                    Iteration time: 1.73s
                      Time elapsed: 00:28:00
                               ETA: 00:20:25

################################################################################
                     [1m Learning iteration 868/1500 [0m                      

                       Computation: 55538 steps/s (collection: 1.605s, learning 0.165s)
             Mean action noise std: 2.49
          Mean value_function loss: 21.2535
               Mean surrogate loss: -0.0003
                 Mean entropy loss: 40.5254
                       Mean reward: 727.42
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7266
    Episode_Reward/rotating_object: 146.0980
        Episode_Reward/action_rate: -0.0294
          Episode_Reward/joint_vel: -0.0057
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 85426176
                    Iteration time: 1.77s
                      Time elapsed: 00:28:02
                               ETA: 00:20:23

################################################################################
                     [1m Learning iteration 869/1500 [0m                      

                       Computation: 56791 steps/s (collection: 1.629s, learning 0.102s)
             Mean action noise std: 2.49
          Mean value_function loss: 27.0357
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 40.5281
                       Mean reward: 716.17
               Mean episode length: 247.71
    Episode_Reward/reaching_object: 0.7189
    Episode_Reward/rotating_object: 144.5902
        Episode_Reward/action_rate: -0.0292
          Episode_Reward/joint_vel: -0.0056
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 85524480
                    Iteration time: 1.73s
                      Time elapsed: 00:28:03
                               ETA: 00:20:21

################################################################################
                     [1m Learning iteration 870/1500 [0m                      

                       Computation: 57028 steps/s (collection: 1.622s, learning 0.102s)
             Mean action noise std: 2.49
          Mean value_function loss: 32.1794
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 40.5309
                       Mean reward: 707.61
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7145
    Episode_Reward/rotating_object: 141.1664
        Episode_Reward/action_rate: -0.0293
          Episode_Reward/joint_vel: -0.0057
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 85622784
                    Iteration time: 1.72s
                      Time elapsed: 00:28:05
                               ETA: 00:20:19

################################################################################
                     [1m Learning iteration 871/1500 [0m                      

                       Computation: 55341 steps/s (collection: 1.627s, learning 0.150s)
             Mean action noise std: 2.49
          Mean value_function loss: 33.7895
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 40.5374
                       Mean reward: 719.41
               Mean episode length: 247.70
    Episode_Reward/reaching_object: 0.7125
    Episode_Reward/rotating_object: 141.1911
        Episode_Reward/action_rate: -0.0290
          Episode_Reward/joint_vel: -0.0054
      Episode_Termination/time_out: 18.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 85721088
                    Iteration time: 1.78s
                      Time elapsed: 00:28:07
                               ETA: 00:20:17

################################################################################
                     [1m Learning iteration 872/1500 [0m                      

                       Computation: 57743 steps/s (collection: 1.586s, learning 0.116s)
             Mean action noise std: 2.49
          Mean value_function loss: 28.0969
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 40.5537
                       Mean reward: 724.11
               Mean episode length: 247.83
    Episode_Reward/reaching_object: 0.7183
    Episode_Reward/rotating_object: 142.8089
        Episode_Reward/action_rate: -0.0293
          Episode_Reward/joint_vel: -0.0056
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 85819392
                    Iteration time: 1.70s
                      Time elapsed: 00:28:09
                               ETA: 00:20:15

################################################################################
                     [1m Learning iteration 873/1500 [0m                      

                       Computation: 56487 steps/s (collection: 1.639s, learning 0.101s)
             Mean action noise std: 2.49
          Mean value_function loss: 32.8117
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 40.5635
                       Mean reward: 732.22
               Mean episode length: 247.68
    Episode_Reward/reaching_object: 0.7251
    Episode_Reward/rotating_object: 146.3742
        Episode_Reward/action_rate: -0.0294
          Episode_Reward/joint_vel: -0.0055
      Episode_Termination/time_out: 17.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 85917696
                    Iteration time: 1.74s
                      Time elapsed: 00:28:10
                               ETA: 00:20:13

################################################################################
                     [1m Learning iteration 874/1500 [0m                      

                       Computation: 57780 steps/s (collection: 1.607s, learning 0.094s)
             Mean action noise std: 2.49
          Mean value_function loss: 37.2826
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 40.5738
                       Mean reward: 700.84
               Mean episode length: 241.38
    Episode_Reward/reaching_object: 0.7142
    Episode_Reward/rotating_object: 142.9785
        Episode_Reward/action_rate: -0.0291
          Episode_Reward/joint_vel: -0.0056
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 86016000
                    Iteration time: 1.70s
                      Time elapsed: 00:28:12
                               ETA: 00:20:10

################################################################################
                     [1m Learning iteration 875/1500 [0m                      

                       Computation: 57777 steps/s (collection: 1.595s, learning 0.107s)
             Mean action noise std: 2.50
          Mean value_function loss: 23.3689
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 40.5841
                       Mean reward: 667.88
               Mean episode length: 245.66
    Episode_Reward/reaching_object: 0.7236
    Episode_Reward/rotating_object: 144.5809
        Episode_Reward/action_rate: -0.0296
          Episode_Reward/joint_vel: -0.0055
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 86114304
                    Iteration time: 1.70s
                      Time elapsed: 00:28:14
                               ETA: 00:20:08

################################################################################
                     [1m Learning iteration 876/1500 [0m                      

                       Computation: 57655 steps/s (collection: 1.598s, learning 0.107s)
             Mean action noise std: 2.50
          Mean value_function loss: 28.0605
               Mean surrogate loss: -0.0006
                 Mean entropy loss: 40.5928
                       Mean reward: 700.49
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7186
    Episode_Reward/rotating_object: 141.6835
        Episode_Reward/action_rate: -0.0295
          Episode_Reward/joint_vel: -0.0054
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 86212608
                    Iteration time: 1.71s
                      Time elapsed: 00:28:15
                               ETA: 00:20:06

################################################################################
                     [1m Learning iteration 877/1500 [0m                      

                       Computation: 57356 steps/s (collection: 1.626s, learning 0.088s)
             Mean action noise std: 2.50
          Mean value_function loss: 30.4526
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 40.6000
                       Mean reward: 733.10
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7297
    Episode_Reward/rotating_object: 144.9767
        Episode_Reward/action_rate: -0.0298
          Episode_Reward/joint_vel: -0.0054
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 86310912
                    Iteration time: 1.71s
                      Time elapsed: 00:28:17
                               ETA: 00:20:04

################################################################################
                     [1m Learning iteration 878/1500 [0m                      

                       Computation: 56856 steps/s (collection: 1.609s, learning 0.120s)
             Mean action noise std: 2.50
          Mean value_function loss: 30.4611
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 40.6068
                       Mean reward: 741.15
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7262
    Episode_Reward/rotating_object: 144.8261
        Episode_Reward/action_rate: -0.0296
          Episode_Reward/joint_vel: -0.0054
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 86409216
                    Iteration time: 1.73s
                      Time elapsed: 00:28:19
                               ETA: 00:20:02

################################################################################
                     [1m Learning iteration 879/1500 [0m                      

                       Computation: 55891 steps/s (collection: 1.628s, learning 0.131s)
             Mean action noise std: 2.50
          Mean value_function loss: 32.7188
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 40.6113
                       Mean reward: 724.89
               Mean episode length: 245.47
    Episode_Reward/reaching_object: 0.7216
    Episode_Reward/rotating_object: 143.1993
        Episode_Reward/action_rate: -0.0295
          Episode_Reward/joint_vel: -0.0056
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 86507520
                    Iteration time: 1.76s
                      Time elapsed: 00:28:21
                               ETA: 00:20:00

################################################################################
                     [1m Learning iteration 880/1500 [0m                      

                       Computation: 54803 steps/s (collection: 1.692s, learning 0.102s)
             Mean action noise std: 2.50
          Mean value_function loss: 29.8102
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 40.6203
                       Mean reward: 745.28
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7254
    Episode_Reward/rotating_object: 143.4994
        Episode_Reward/action_rate: -0.0296
          Episode_Reward/joint_vel: -0.0055
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 86605824
                    Iteration time: 1.79s
                      Time elapsed: 00:28:22
                               ETA: 00:19:58

################################################################################
                     [1m Learning iteration 881/1500 [0m                      

                       Computation: 57653 steps/s (collection: 1.615s, learning 0.090s)
             Mean action noise std: 2.50
          Mean value_function loss: 27.5102
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 40.6281
                       Mean reward: 724.94
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7338
    Episode_Reward/rotating_object: 145.2964
        Episode_Reward/action_rate: -0.0297
          Episode_Reward/joint_vel: -0.0054
      Episode_Termination/time_out: 17.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 86704128
                    Iteration time: 1.71s
                      Time elapsed: 00:28:24
                               ETA: 00:19:56

################################################################################
                     [1m Learning iteration 882/1500 [0m                      

                       Computation: 56278 steps/s (collection: 1.609s, learning 0.137s)
             Mean action noise std: 2.51
          Mean value_function loss: 34.5905
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 40.6327
                       Mean reward: 702.68
               Mean episode length: 238.71
    Episode_Reward/reaching_object: 0.7184
    Episode_Reward/rotating_object: 141.5197
        Episode_Reward/action_rate: -0.0294
          Episode_Reward/joint_vel: -0.0055
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 86802432
                    Iteration time: 1.75s
                      Time elapsed: 00:28:26
                               ETA: 00:19:54

################################################################################
                     [1m Learning iteration 883/1500 [0m                      

                       Computation: 58288 steps/s (collection: 1.583s, learning 0.104s)
             Mean action noise std: 2.51
          Mean value_function loss: 34.5737
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 40.6409
                       Mean reward: 720.55
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7269
    Episode_Reward/rotating_object: 143.5061
        Episode_Reward/action_rate: -0.0296
          Episode_Reward/joint_vel: -0.0055
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 86900736
                    Iteration time: 1.69s
                      Time elapsed: 00:28:28
                               ETA: 00:19:52

################################################################################
                     [1m Learning iteration 884/1500 [0m                      

                       Computation: 57943 steps/s (collection: 1.604s, learning 0.092s)
             Mean action noise std: 2.51
          Mean value_function loss: 28.5749
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 40.6506
                       Mean reward: 720.98
               Mean episode length: 247.70
    Episode_Reward/reaching_object: 0.7322
    Episode_Reward/rotating_object: 144.2358
        Episode_Reward/action_rate: -0.0297
          Episode_Reward/joint_vel: -0.0055
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 86999040
                    Iteration time: 1.70s
                      Time elapsed: 00:28:29
                               ETA: 00:19:50

################################################################################
                     [1m Learning iteration 885/1500 [0m                      

                       Computation: 57593 steps/s (collection: 1.574s, learning 0.133s)
             Mean action noise std: 2.51
          Mean value_function loss: 34.3835
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 40.6639
                       Mean reward: 722.94
               Mean episode length: 245.41
    Episode_Reward/reaching_object: 0.7245
    Episode_Reward/rotating_object: 142.5174
        Episode_Reward/action_rate: -0.0294
          Episode_Reward/joint_vel: -0.0053
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 87097344
                    Iteration time: 1.71s
                      Time elapsed: 00:28:31
                               ETA: 00:19:48

################################################################################
                     [1m Learning iteration 886/1500 [0m                      

                       Computation: 58695 steps/s (collection: 1.559s, learning 0.116s)
             Mean action noise std: 2.51
          Mean value_function loss: 35.0429
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 40.6740
                       Mean reward: 703.18
               Mean episode length: 243.28
    Episode_Reward/reaching_object: 0.7265
    Episode_Reward/rotating_object: 143.8548
        Episode_Reward/action_rate: -0.0295
          Episode_Reward/joint_vel: -0.0053
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 87195648
                    Iteration time: 1.67s
                      Time elapsed: 00:28:33
                               ETA: 00:19:45

################################################################################
                     [1m Learning iteration 887/1500 [0m                      

                       Computation: 57903 steps/s (collection: 1.608s, learning 0.090s)
             Mean action noise std: 2.51
          Mean value_function loss: 30.6197
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 40.6807
                       Mean reward: 704.16
               Mean episode length: 243.39
    Episode_Reward/reaching_object: 0.7235
    Episode_Reward/rotating_object: 143.0299
        Episode_Reward/action_rate: -0.0297
          Episode_Reward/joint_vel: -0.0052
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 87293952
                    Iteration time: 1.70s
                      Time elapsed: 00:28:34
                               ETA: 00:19:43

################################################################################
                     [1m Learning iteration 888/1500 [0m                      

                       Computation: 57680 steps/s (collection: 1.600s, learning 0.105s)
             Mean action noise std: 2.51
          Mean value_function loss: 28.9802
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 40.6859
                       Mean reward: 715.81
               Mean episode length: 245.88
    Episode_Reward/reaching_object: 0.7263
    Episode_Reward/rotating_object: 142.0881
        Episode_Reward/action_rate: -0.0297
          Episode_Reward/joint_vel: -0.0055
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 87392256
                    Iteration time: 1.70s
                      Time elapsed: 00:28:36
                               ETA: 00:19:41

################################################################################
                     [1m Learning iteration 889/1500 [0m                      

                       Computation: 56767 steps/s (collection: 1.637s, learning 0.095s)
             Mean action noise std: 2.52
          Mean value_function loss: 26.9320
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 40.6910
                       Mean reward: 726.35
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7248
    Episode_Reward/rotating_object: 144.9909
        Episode_Reward/action_rate: -0.0297
          Episode_Reward/joint_vel: -0.0054
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 87490560
                    Iteration time: 1.73s
                      Time elapsed: 00:28:38
                               ETA: 00:19:39

################################################################################
                     [1m Learning iteration 890/1500 [0m                      

                       Computation: 57876 steps/s (collection: 1.606s, learning 0.093s)
             Mean action noise std: 2.52
          Mean value_function loss: 25.8226
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 40.7046
                       Mean reward: 703.48
               Mean episode length: 246.09
    Episode_Reward/reaching_object: 0.7295
    Episode_Reward/rotating_object: 146.0149
        Episode_Reward/action_rate: -0.0299
          Episode_Reward/joint_vel: -0.0055
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 87588864
                    Iteration time: 1.70s
                      Time elapsed: 00:28:40
                               ETA: 00:19:37

################################################################################
                     [1m Learning iteration 891/1500 [0m                      

                       Computation: 56962 steps/s (collection: 1.611s, learning 0.115s)
             Mean action noise std: 2.52
          Mean value_function loss: 31.7504
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 40.7150
                       Mean reward: 696.52
               Mean episode length: 243.11
    Episode_Reward/reaching_object: 0.7237
    Episode_Reward/rotating_object: 143.0036
        Episode_Reward/action_rate: -0.0300
          Episode_Reward/joint_vel: -0.0055
      Episode_Termination/time_out: 17.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 87687168
                    Iteration time: 1.73s
                      Time elapsed: 00:28:41
                               ETA: 00:19:35

################################################################################
                     [1m Learning iteration 892/1500 [0m                      

                       Computation: 57778 steps/s (collection: 1.605s, learning 0.096s)
             Mean action noise std: 2.52
          Mean value_function loss: 26.4139
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 40.7210
                       Mean reward: 725.87
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7215
    Episode_Reward/rotating_object: 142.2120
        Episode_Reward/action_rate: -0.0301
          Episode_Reward/joint_vel: -0.0056
      Episode_Termination/time_out: 17.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 87785472
                    Iteration time: 1.70s
                      Time elapsed: 00:28:43
                               ETA: 00:19:33

################################################################################
                     [1m Learning iteration 893/1500 [0m                      

                       Computation: 57984 steps/s (collection: 1.605s, learning 0.091s)
             Mean action noise std: 2.52
          Mean value_function loss: 26.0911
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 40.7264
                       Mean reward: 717.61
               Mean episode length: 247.81
    Episode_Reward/reaching_object: 0.7281
    Episode_Reward/rotating_object: 145.6001
        Episode_Reward/action_rate: -0.0301
          Episode_Reward/joint_vel: -0.0054
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 87883776
                    Iteration time: 1.70s
                      Time elapsed: 00:28:45
                               ETA: 00:19:31

################################################################################
                     [1m Learning iteration 894/1500 [0m                      

                       Computation: 57836 steps/s (collection: 1.594s, learning 0.106s)
             Mean action noise std: 2.52
          Mean value_function loss: 31.6876
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 40.7336
                       Mean reward: 751.27
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7241
    Episode_Reward/rotating_object: 144.4796
        Episode_Reward/action_rate: -0.0300
          Episode_Reward/joint_vel: -0.0055
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 87982080
                    Iteration time: 1.70s
                      Time elapsed: 00:28:46
                               ETA: 00:19:29

################################################################################
                     [1m Learning iteration 895/1500 [0m                      

                       Computation: 58752 steps/s (collection: 1.571s, learning 0.103s)
             Mean action noise std: 2.52
          Mean value_function loss: 36.8402
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 40.7432
                       Mean reward: 702.42
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7236
    Episode_Reward/rotating_object: 144.8544
        Episode_Reward/action_rate: -0.0300
          Episode_Reward/joint_vel: -0.0053
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 88080384
                    Iteration time: 1.67s
                      Time elapsed: 00:28:48
                               ETA: 00:19:27

################################################################################
                     [1m Learning iteration 896/1500 [0m                      

                       Computation: 56898 steps/s (collection: 1.595s, learning 0.133s)
             Mean action noise std: 2.53
          Mean value_function loss: 32.8586
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 40.7485
                       Mean reward: 723.07
               Mean episode length: 241.29
    Episode_Reward/reaching_object: 0.7251
    Episode_Reward/rotating_object: 144.0248
        Episode_Reward/action_rate: -0.0298
          Episode_Reward/joint_vel: -0.0056
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 88178688
                    Iteration time: 1.73s
                      Time elapsed: 00:28:50
                               ETA: 00:19:25

################################################################################
                     [1m Learning iteration 897/1500 [0m                      

                       Computation: 57848 steps/s (collection: 1.601s, learning 0.098s)
             Mean action noise std: 2.53
          Mean value_function loss: 27.1095
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 40.7540
                       Mean reward: 713.40
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7269
    Episode_Reward/rotating_object: 143.5518
        Episode_Reward/action_rate: -0.0302
          Episode_Reward/joint_vel: -0.0052
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 88276992
                    Iteration time: 1.70s
                      Time elapsed: 00:28:51
                               ETA: 00:19:22

################################################################################
                     [1m Learning iteration 898/1500 [0m                      

                       Computation: 57118 steps/s (collection: 1.612s, learning 0.109s)
             Mean action noise std: 2.53
          Mean value_function loss: 32.4243
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 40.7617
                       Mean reward: 717.50
               Mean episode length: 246.04
    Episode_Reward/reaching_object: 0.7337
    Episode_Reward/rotating_object: 146.1353
        Episode_Reward/action_rate: -0.0304
          Episode_Reward/joint_vel: -0.0056
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 88375296
                    Iteration time: 1.72s
                      Time elapsed: 00:28:53
                               ETA: 00:19:20

################################################################################
                     [1m Learning iteration 899/1500 [0m                      

                       Computation: 56985 steps/s (collection: 1.606s, learning 0.120s)
             Mean action noise std: 2.53
          Mean value_function loss: 29.0638
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 40.7710
                       Mean reward: 736.65
               Mean episode length: 247.78
    Episode_Reward/reaching_object: 0.7325
    Episode_Reward/rotating_object: 144.6311
        Episode_Reward/action_rate: -0.0303
          Episode_Reward/joint_vel: -0.0052
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 88473600
                    Iteration time: 1.73s
                      Time elapsed: 00:28:55
                               ETA: 00:19:18

################################################################################
                     [1m Learning iteration 900/1500 [0m                      

                       Computation: 57924 steps/s (collection: 1.584s, learning 0.113s)
             Mean action noise std: 2.53
          Mean value_function loss: 31.1913
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 40.7772
                       Mean reward: 711.20
               Mean episode length: 245.40
    Episode_Reward/reaching_object: 0.7363
    Episode_Reward/rotating_object: 145.5928
        Episode_Reward/action_rate: -0.0305
          Episode_Reward/joint_vel: -0.0053
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 88571904
                    Iteration time: 1.70s
                      Time elapsed: 00:28:57
                               ETA: 00:19:16

################################################################################
                     [1m Learning iteration 901/1500 [0m                      

                       Computation: 54984 steps/s (collection: 1.689s, learning 0.099s)
             Mean action noise std: 2.53
          Mean value_function loss: 27.2062
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 40.7856
                       Mean reward: 714.93
               Mean episode length: 243.47
    Episode_Reward/reaching_object: 0.7364
    Episode_Reward/rotating_object: 145.6431
        Episode_Reward/action_rate: -0.0303
          Episode_Reward/joint_vel: -0.0055
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 88670208
                    Iteration time: 1.79s
                      Time elapsed: 00:28:58
                               ETA: 00:19:14

################################################################################
                     [1m Learning iteration 902/1500 [0m                      

                       Computation: 55829 steps/s (collection: 1.666s, learning 0.095s)
             Mean action noise std: 2.53
          Mean value_function loss: 43.8303
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 40.7881
                       Mean reward: 704.71
               Mean episode length: 245.45
    Episode_Reward/reaching_object: 0.7272
    Episode_Reward/rotating_object: 140.6605
        Episode_Reward/action_rate: -0.0303
          Episode_Reward/joint_vel: -0.0055
      Episode_Termination/time_out: 18.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 88768512
                    Iteration time: 1.76s
                      Time elapsed: 00:29:00
                               ETA: 00:19:12

################################################################################
                     [1m Learning iteration 903/1500 [0m                      

                       Computation: 53845 steps/s (collection: 1.672s, learning 0.154s)
             Mean action noise std: 2.53
          Mean value_function loss: 36.9978
               Mean surrogate loss: 0.0004
                 Mean entropy loss: 40.7960
                       Mean reward: 727.78
               Mean episode length: 247.71
    Episode_Reward/reaching_object: 0.7276
    Episode_Reward/rotating_object: 142.7476
        Episode_Reward/action_rate: -0.0301
          Episode_Reward/joint_vel: -0.0051
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 88866816
                    Iteration time: 1.83s
                      Time elapsed: 00:29:02
                               ETA: 00:19:10

################################################################################
                     [1m Learning iteration 904/1500 [0m                      

                       Computation: 57257 steps/s (collection: 1.606s, learning 0.111s)
             Mean action noise std: 2.54
          Mean value_function loss: 33.9867
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 40.8019
                       Mean reward: 727.94
               Mean episode length: 247.74
    Episode_Reward/reaching_object: 0.7337
    Episode_Reward/rotating_object: 141.8681
        Episode_Reward/action_rate: -0.0305
          Episode_Reward/joint_vel: -0.0058
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 88965120
                    Iteration time: 1.72s
                      Time elapsed: 00:29:04
                               ETA: 00:19:08

################################################################################
                     [1m Learning iteration 905/1500 [0m                      

                       Computation: 56004 steps/s (collection: 1.622s, learning 0.134s)
             Mean action noise std: 2.54
          Mean value_function loss: 29.2152
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 40.8091
                       Mean reward: 741.34
               Mean episode length: 247.74
    Episode_Reward/reaching_object: 0.7402
    Episode_Reward/rotating_object: 144.2768
        Episode_Reward/action_rate: -0.0305
          Episode_Reward/joint_vel: -0.0054
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 89063424
                    Iteration time: 1.76s
                      Time elapsed: 00:29:05
                               ETA: 00:19:06

################################################################################
                     [1m Learning iteration 906/1500 [0m                      

                       Computation: 58015 steps/s (collection: 1.604s, learning 0.090s)
             Mean action noise std: 2.54
          Mean value_function loss: 29.9021
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 40.8183
                       Mean reward: 712.48
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7387
    Episode_Reward/rotating_object: 143.6575
        Episode_Reward/action_rate: -0.0305
          Episode_Reward/joint_vel: -0.0054
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 89161728
                    Iteration time: 1.69s
                      Time elapsed: 00:29:07
                               ETA: 00:19:04

################################################################################
                     [1m Learning iteration 907/1500 [0m                      

                       Computation: 55032 steps/s (collection: 1.685s, learning 0.101s)
             Mean action noise std: 2.54
          Mean value_function loss: 35.4756
               Mean surrogate loss: 0.0032
                 Mean entropy loss: 40.8294
                       Mean reward: 728.29
               Mean episode length: 248.79
    Episode_Reward/reaching_object: 0.7419
    Episode_Reward/rotating_object: 145.7078
        Episode_Reward/action_rate: -0.0305
          Episode_Reward/joint_vel: -0.0057
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 89260032
                    Iteration time: 1.79s
                      Time elapsed: 00:29:09
                               ETA: 00:19:02

################################################################################
                     [1m Learning iteration 908/1500 [0m                      

                       Computation: 57765 steps/s (collection: 1.607s, learning 0.095s)
             Mean action noise std: 2.54
          Mean value_function loss: 32.1167
               Mean surrogate loss: 0.0001
                 Mean entropy loss: 40.8313
                       Mean reward: 714.74
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7406
    Episode_Reward/rotating_object: 144.1804
        Episode_Reward/action_rate: -0.0306
          Episode_Reward/joint_vel: -0.0058
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 89358336
                    Iteration time: 1.70s
                      Time elapsed: 00:29:11
                               ETA: 00:19:00

################################################################################
                     [1m Learning iteration 909/1500 [0m                      

                       Computation: 57967 steps/s (collection: 1.596s, learning 0.100s)
             Mean action noise std: 2.54
          Mean value_function loss: 31.3080
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 40.8337
                       Mean reward: 722.02
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7408
    Episode_Reward/rotating_object: 145.1373
        Episode_Reward/action_rate: -0.0307
          Episode_Reward/joint_vel: -0.0058
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 89456640
                    Iteration time: 1.70s
                      Time elapsed: 00:29:12
                               ETA: 00:18:58

################################################################################
                     [1m Learning iteration 910/1500 [0m                      

                       Computation: 57716 steps/s (collection: 1.577s, learning 0.127s)
             Mean action noise std: 2.54
          Mean value_function loss: 29.4279
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 40.8406
                       Mean reward: 695.98
               Mean episode length: 244.61
    Episode_Reward/reaching_object: 0.7328
    Episode_Reward/rotating_object: 143.3070
        Episode_Reward/action_rate: -0.0306
          Episode_Reward/joint_vel: -0.0055
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 89554944
                    Iteration time: 1.70s
                      Time elapsed: 00:29:14
                               ETA: 00:18:56

################################################################################
                     [1m Learning iteration 911/1500 [0m                      

                       Computation: 58655 steps/s (collection: 1.575s, learning 0.101s)
             Mean action noise std: 2.54
          Mean value_function loss: 28.0126
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 40.8467
                       Mean reward: 739.60
               Mean episode length: 248.19
    Episode_Reward/reaching_object: 0.7286
    Episode_Reward/rotating_object: 143.0660
        Episode_Reward/action_rate: -0.0305
          Episode_Reward/joint_vel: -0.0054
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 89653248
                    Iteration time: 1.68s
                      Time elapsed: 00:29:16
                               ETA: 00:18:54

################################################################################
                     [1m Learning iteration 912/1500 [0m                      

                       Computation: 57330 steps/s (collection: 1.622s, learning 0.093s)
             Mean action noise std: 2.55
          Mean value_function loss: 24.9064
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 40.8549
                       Mean reward: 736.28
               Mean episode length: 247.68
    Episode_Reward/reaching_object: 0.7356
    Episode_Reward/rotating_object: 146.5590
        Episode_Reward/action_rate: -0.0305
          Episode_Reward/joint_vel: -0.0054
      Episode_Termination/time_out: 17.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 89751552
                    Iteration time: 1.71s
                      Time elapsed: 00:29:17
                               ETA: 00:18:52

################################################################################
                     [1m Learning iteration 913/1500 [0m                      

                       Computation: 56802 steps/s (collection: 1.614s, learning 0.117s)
             Mean action noise std: 2.55
          Mean value_function loss: 36.6834
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 40.8667
                       Mean reward: 706.03
               Mean episode length: 247.72
    Episode_Reward/reaching_object: 0.7305
    Episode_Reward/rotating_object: 144.3053
        Episode_Reward/action_rate: -0.0307
          Episode_Reward/joint_vel: -0.0055
      Episode_Termination/time_out: 17.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 89849856
                    Iteration time: 1.73s
                      Time elapsed: 00:29:19
                               ETA: 00:18:50

################################################################################
                     [1m Learning iteration 914/1500 [0m                      

                       Computation: 57703 steps/s (collection: 1.582s, learning 0.122s)
             Mean action noise std: 2.55
          Mean value_function loss: 35.2365
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 40.8818
                       Mean reward: 726.06
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7226
    Episode_Reward/rotating_object: 142.3792
        Episode_Reward/action_rate: -0.0305
          Episode_Reward/joint_vel: -0.0053
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 89948160
                    Iteration time: 1.70s
                      Time elapsed: 00:29:21
                               ETA: 00:18:48

################################################################################
                     [1m Learning iteration 915/1500 [0m                      

                       Computation: 57600 steps/s (collection: 1.605s, learning 0.102s)
             Mean action noise std: 2.55
          Mean value_function loss: 25.4935
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 40.8899
                       Mean reward: 711.75
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7309
    Episode_Reward/rotating_object: 145.0936
        Episode_Reward/action_rate: -0.0308
          Episode_Reward/joint_vel: -0.0053
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 90046464
                    Iteration time: 1.71s
                      Time elapsed: 00:29:23
                               ETA: 00:18:45

################################################################################
                     [1m Learning iteration 916/1500 [0m                      

                       Computation: 57534 steps/s (collection: 1.614s, learning 0.095s)
             Mean action noise std: 2.55
          Mean value_function loss: 31.9384
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 40.8960
                       Mean reward: 713.07
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7333
    Episode_Reward/rotating_object: 145.4948
        Episode_Reward/action_rate: -0.0309
          Episode_Reward/joint_vel: -0.0055
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 90144768
                    Iteration time: 1.71s
                      Time elapsed: 00:29:24
                               ETA: 00:18:43

################################################################################
                     [1m Learning iteration 917/1500 [0m                      

                       Computation: 56756 steps/s (collection: 1.616s, learning 0.116s)
             Mean action noise std: 2.55
          Mean value_function loss: 28.7941
               Mean surrogate loss: -0.0000
                 Mean entropy loss: 40.9039
                       Mean reward: 714.02
               Mean episode length: 247.68
    Episode_Reward/reaching_object: 0.7206
    Episode_Reward/rotating_object: 142.1726
        Episode_Reward/action_rate: -0.0307
          Episode_Reward/joint_vel: -0.0055
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 90243072
                    Iteration time: 1.73s
                      Time elapsed: 00:29:26
                               ETA: 00:18:41

################################################################################
                     [1m Learning iteration 918/1500 [0m                      

                       Computation: 57224 steps/s (collection: 1.616s, learning 0.102s)
             Mean action noise std: 2.55
          Mean value_function loss: 22.5623
               Mean surrogate loss: -0.0003
                 Mean entropy loss: 40.9071
                       Mean reward: 720.17
               Mean episode length: 247.73
    Episode_Reward/reaching_object: 0.7313
    Episode_Reward/rotating_object: 146.0404
        Episode_Reward/action_rate: -0.0310
          Episode_Reward/joint_vel: -0.0054
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 90341376
                    Iteration time: 1.72s
                      Time elapsed: 00:29:28
                               ETA: 00:18:39

################################################################################
                     [1m Learning iteration 919/1500 [0m                      

                       Computation: 56811 steps/s (collection: 1.627s, learning 0.103s)
             Mean action noise std: 2.56
          Mean value_function loss: 26.4719
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 40.9103
                       Mean reward: 711.39
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7217
    Episode_Reward/rotating_object: 144.5152
        Episode_Reward/action_rate: -0.0306
          Episode_Reward/joint_vel: -0.0054
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 90439680
                    Iteration time: 1.73s
                      Time elapsed: 00:29:29
                               ETA: 00:18:37

################################################################################
                     [1m Learning iteration 920/1500 [0m                      

                       Computation: 56740 steps/s (collection: 1.628s, learning 0.105s)
             Mean action noise std: 2.56
          Mean value_function loss: 30.9016
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 40.9207
                       Mean reward: 719.95
               Mean episode length: 247.79
    Episode_Reward/reaching_object: 0.7240
    Episode_Reward/rotating_object: 144.6478
        Episode_Reward/action_rate: -0.0309
          Episode_Reward/joint_vel: -0.0058
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 90537984
                    Iteration time: 1.73s
                      Time elapsed: 00:29:31
                               ETA: 00:18:35

################################################################################
                     [1m Learning iteration 921/1500 [0m                      

                       Computation: 55265 steps/s (collection: 1.627s, learning 0.152s)
             Mean action noise std: 2.56
          Mean value_function loss: 35.5617
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 40.9377
                       Mean reward: 722.55
               Mean episode length: 245.43
    Episode_Reward/reaching_object: 0.7224
    Episode_Reward/rotating_object: 146.8604
        Episode_Reward/action_rate: -0.0305
          Episode_Reward/joint_vel: -0.0052
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 90636288
                    Iteration time: 1.78s
                      Time elapsed: 00:29:33
                               ETA: 00:18:33

################################################################################
                     [1m Learning iteration 922/1500 [0m                      

                       Computation: 55104 steps/s (collection: 1.673s, learning 0.111s)
             Mean action noise std: 2.56
          Mean value_function loss: 29.1070
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 40.9470
                       Mean reward: 700.65
               Mean episode length: 245.54
    Episode_Reward/reaching_object: 0.7214
    Episode_Reward/rotating_object: 144.4298
        Episode_Reward/action_rate: -0.0309
          Episode_Reward/joint_vel: -0.0054
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 90734592
                    Iteration time: 1.78s
                      Time elapsed: 00:29:35
                               ETA: 00:18:31

################################################################################
                     [1m Learning iteration 923/1500 [0m                      

                       Computation: 54865 steps/s (collection: 1.615s, learning 0.177s)
             Mean action noise std: 2.56
          Mean value_function loss: 24.4520
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 40.9538
                       Mean reward: 727.42
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7206
    Episode_Reward/rotating_object: 144.9646
        Episode_Reward/action_rate: -0.0311
          Episode_Reward/joint_vel: -0.0053
      Episode_Termination/time_out: 18.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 90832896
                    Iteration time: 1.79s
                      Time elapsed: 00:29:37
                               ETA: 00:18:29

################################################################################
                     [1m Learning iteration 924/1500 [0m                      

                       Computation: 56900 steps/s (collection: 1.593s, learning 0.135s)
             Mean action noise std: 2.56
          Mean value_function loss: 33.4940
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 40.9599
                       Mean reward: 730.02
               Mean episode length: 248.09
    Episode_Reward/reaching_object: 0.7207
    Episode_Reward/rotating_object: 143.8456
        Episode_Reward/action_rate: -0.0310
          Episode_Reward/joint_vel: -0.0058
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 90931200
                    Iteration time: 1.73s
                      Time elapsed: 00:29:38
                               ETA: 00:18:27

################################################################################
                     [1m Learning iteration 925/1500 [0m                      

                       Computation: 53710 steps/s (collection: 1.670s, learning 0.160s)
             Mean action noise std: 2.57
          Mean value_function loss: 27.7839
               Mean surrogate loss: 0.0021
                 Mean entropy loss: 40.9700
                       Mean reward: 711.44
               Mean episode length: 245.33
    Episode_Reward/reaching_object: 0.7229
    Episode_Reward/rotating_object: 145.9244
        Episode_Reward/action_rate: -0.0312
          Episode_Reward/joint_vel: -0.0056
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 91029504
                    Iteration time: 1.83s
                      Time elapsed: 00:29:40
                               ETA: 00:18:25

################################################################################
                     [1m Learning iteration 926/1500 [0m                      

                       Computation: 57388 steps/s (collection: 1.618s, learning 0.095s)
             Mean action noise std: 2.57
          Mean value_function loss: 32.5111
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 40.9798
                       Mean reward: 720.52
               Mean episode length: 247.70
    Episode_Reward/reaching_object: 0.7236
    Episode_Reward/rotating_object: 144.5079
        Episode_Reward/action_rate: -0.0311
          Episode_Reward/joint_vel: -0.0054
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 91127808
                    Iteration time: 1.71s
                      Time elapsed: 00:29:42
                               ETA: 00:18:23

################################################################################
                     [1m Learning iteration 927/1500 [0m                      

                       Computation: 56999 steps/s (collection: 1.614s, learning 0.111s)
             Mean action noise std: 2.57
          Mean value_function loss: 27.1564
               Mean surrogate loss: 0.0010
                 Mean entropy loss: 40.9929
                       Mean reward: 741.86
               Mean episode length: 249.70
    Episode_Reward/reaching_object: 0.7297
    Episode_Reward/rotating_object: 148.5388
        Episode_Reward/action_rate: -0.0313
          Episode_Reward/joint_vel: -0.0056
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 91226112
                    Iteration time: 1.72s
                      Time elapsed: 00:29:44
                               ETA: 00:18:21

################################################################################
                     [1m Learning iteration 928/1500 [0m                      

                       Computation: 56263 steps/s (collection: 1.625s, learning 0.122s)
             Mean action noise std: 2.57
          Mean value_function loss: 28.4507
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 41.0029
                       Mean reward: 745.45
               Mean episode length: 247.79
    Episode_Reward/reaching_object: 0.7259
    Episode_Reward/rotating_object: 146.4492
        Episode_Reward/action_rate: -0.0312
          Episode_Reward/joint_vel: -0.0053
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 91324416
                    Iteration time: 1.75s
                      Time elapsed: 00:29:45
                               ETA: 00:18:19

################################################################################
                     [1m Learning iteration 929/1500 [0m                      

                       Computation: 54511 steps/s (collection: 1.662s, learning 0.141s)
             Mean action noise std: 2.57
          Mean value_function loss: 28.0598
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 41.0172
                       Mean reward: 709.46
               Mean episode length: 247.68
    Episode_Reward/reaching_object: 0.7169
    Episode_Reward/rotating_object: 144.5963
        Episode_Reward/action_rate: -0.0312
          Episode_Reward/joint_vel: -0.0053
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 91422720
                    Iteration time: 1.80s
                      Time elapsed: 00:29:47
                               ETA: 00:18:17

################################################################################
                     [1m Learning iteration 930/1500 [0m                      

                       Computation: 55852 steps/s (collection: 1.656s, learning 0.104s)
             Mean action noise std: 2.58
          Mean value_function loss: 30.7017
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 41.0315
                       Mean reward: 736.98
               Mean episode length: 248.27
    Episode_Reward/reaching_object: 0.7175
    Episode_Reward/rotating_object: 143.9820
        Episode_Reward/action_rate: -0.0310
          Episode_Reward/joint_vel: -0.0053
      Episode_Termination/time_out: 13.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 91521024
                    Iteration time: 1.76s
                      Time elapsed: 00:29:49
                               ETA: 00:18:15

################################################################################
                     [1m Learning iteration 931/1500 [0m                      

                       Computation: 54641 steps/s (collection: 1.683s, learning 0.116s)
             Mean action noise std: 2.58
          Mean value_function loss: 21.1585
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 41.0504
                       Mean reward: 746.61
               Mean episode length: 246.59
    Episode_Reward/reaching_object: 0.7213
    Episode_Reward/rotating_object: 145.6359
        Episode_Reward/action_rate: -0.0312
          Episode_Reward/joint_vel: -0.0056
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 91619328
                    Iteration time: 1.80s
                      Time elapsed: 00:29:51
                               ETA: 00:18:13

################################################################################
                     [1m Learning iteration 932/1500 [0m                      

                       Computation: 55947 steps/s (collection: 1.649s, learning 0.108s)
             Mean action noise std: 2.58
          Mean value_function loss: 25.9015
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 41.0618
                       Mean reward: 744.23
               Mean episode length: 247.77
    Episode_Reward/reaching_object: 0.7274
    Episode_Reward/rotating_object: 146.0473
        Episode_Reward/action_rate: -0.0315
          Episode_Reward/joint_vel: -0.0055
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 91717632
                    Iteration time: 1.76s
                      Time elapsed: 00:29:52
                               ETA: 00:18:11

################################################################################
                     [1m Learning iteration 933/1500 [0m                      

                       Computation: 51606 steps/s (collection: 1.792s, learning 0.113s)
             Mean action noise std: 2.58
          Mean value_function loss: 31.4704
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 41.0714
                       Mean reward: 720.20
               Mean episode length: 249.92
    Episode_Reward/reaching_object: 0.7225
    Episode_Reward/rotating_object: 143.1655
        Episode_Reward/action_rate: -0.0315
          Episode_Reward/joint_vel: -0.0055
      Episode_Termination/time_out: 17.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 91815936
                    Iteration time: 1.90s
                      Time elapsed: 00:29:54
                               ETA: 00:18:09

################################################################################
                     [1m Learning iteration 934/1500 [0m                      

                       Computation: 51823 steps/s (collection: 1.712s, learning 0.185s)
             Mean action noise std: 2.58
          Mean value_function loss: 27.0258
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 41.0780
                       Mean reward: 743.88
               Mean episode length: 247.70
    Episode_Reward/reaching_object: 0.7296
    Episode_Reward/rotating_object: 145.9764
        Episode_Reward/action_rate: -0.0316
          Episode_Reward/joint_vel: -0.0054
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 91914240
                    Iteration time: 1.90s
                      Time elapsed: 00:29:56
                               ETA: 00:18:07

################################################################################
                     [1m Learning iteration 935/1500 [0m                      

                       Computation: 51273 steps/s (collection: 1.784s, learning 0.134s)
             Mean action noise std: 2.58
          Mean value_function loss: 29.2988
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 41.0792
                       Mean reward: 727.99
               Mean episode length: 247.70
    Episode_Reward/reaching_object: 0.7314
    Episode_Reward/rotating_object: 146.2201
        Episode_Reward/action_rate: -0.0317
          Episode_Reward/joint_vel: -0.0057
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 92012544
                    Iteration time: 1.92s
                      Time elapsed: 00:29:58
                               ETA: 00:18:05

################################################################################
                     [1m Learning iteration 936/1500 [0m                      

                       Computation: 56135 steps/s (collection: 1.654s, learning 0.097s)
             Mean action noise std: 2.58
          Mean value_function loss: 27.2717
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 41.0813
                       Mean reward: 737.29
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7279
    Episode_Reward/rotating_object: 145.7828
        Episode_Reward/action_rate: -0.0317
          Episode_Reward/joint_vel: -0.0056
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 92110848
                    Iteration time: 1.75s
                      Time elapsed: 00:30:00
                               ETA: 00:18:03

################################################################################
                     [1m Learning iteration 937/1500 [0m                      

                       Computation: 55797 steps/s (collection: 1.667s, learning 0.095s)
             Mean action noise std: 2.59
          Mean value_function loss: 23.9347
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 41.0861
                       Mean reward: 727.76
               Mean episode length: 248.03
    Episode_Reward/reaching_object: 0.7322
    Episode_Reward/rotating_object: 146.4856
        Episode_Reward/action_rate: -0.0317
          Episode_Reward/joint_vel: -0.0054
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 92209152
                    Iteration time: 1.76s
                      Time elapsed: 00:30:02
                               ETA: 00:18:01

################################################################################
                     [1m Learning iteration 938/1500 [0m                      

                       Computation: 53623 steps/s (collection: 1.729s, learning 0.105s)
             Mean action noise std: 2.59
          Mean value_function loss: 28.6415
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 41.0889
                       Mean reward: 714.69
               Mean episode length: 247.82
    Episode_Reward/reaching_object: 0.7236
    Episode_Reward/rotating_object: 144.0950
        Episode_Reward/action_rate: -0.0317
          Episode_Reward/joint_vel: -0.0063
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 92307456
                    Iteration time: 1.83s
                      Time elapsed: 00:30:03
                               ETA: 00:17:59

################################################################################
                     [1m Learning iteration 939/1500 [0m                      

                       Computation: 54385 steps/s (collection: 1.676s, learning 0.132s)
             Mean action noise std: 2.59
          Mean value_function loss: 24.5918
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 41.0864
                       Mean reward: 743.34
               Mean episode length: 246.59
    Episode_Reward/reaching_object: 0.7345
    Episode_Reward/rotating_object: 148.6385
        Episode_Reward/action_rate: -0.0317
          Episode_Reward/joint_vel: -0.0058
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 92405760
                    Iteration time: 1.81s
                      Time elapsed: 00:30:05
                               ETA: 00:17:57

################################################################################
                     [1m Learning iteration 940/1500 [0m                      

                       Computation: 56812 steps/s (collection: 1.622s, learning 0.109s)
             Mean action noise std: 2.59
          Mean value_function loss: 26.8375
               Mean surrogate loss: 0.0003
                 Mean entropy loss: 41.0864
                       Mean reward: 752.86
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7285
    Episode_Reward/rotating_object: 146.1900
        Episode_Reward/action_rate: -0.0318
          Episode_Reward/joint_vel: -0.0055
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 92504064
                    Iteration time: 1.73s
                      Time elapsed: 00:30:07
                               ETA: 00:17:55

################################################################################
                     [1m Learning iteration 941/1500 [0m                      

                       Computation: 54906 steps/s (collection: 1.678s, learning 0.112s)
             Mean action noise std: 2.59
          Mean value_function loss: 25.6078
               Mean surrogate loss: -0.0000
                 Mean entropy loss: 41.0895
                       Mean reward: 708.74
               Mean episode length: 247.82
    Episode_Reward/reaching_object: 0.7258
    Episode_Reward/rotating_object: 145.7744
        Episode_Reward/action_rate: -0.0318
          Episode_Reward/joint_vel: -0.0058
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 92602368
                    Iteration time: 1.79s
                      Time elapsed: 00:30:09
                               ETA: 00:17:53

################################################################################
                     [1m Learning iteration 942/1500 [0m                      

                       Computation: 54870 steps/s (collection: 1.696s, learning 0.096s)
             Mean action noise std: 2.59
          Mean value_function loss: 28.1409
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 41.0962
                       Mean reward: 715.88
               Mean episode length: 248.05
    Episode_Reward/reaching_object: 0.7246
    Episode_Reward/rotating_object: 145.1582
        Episode_Reward/action_rate: -0.0320
          Episode_Reward/joint_vel: -0.0058
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 92700672
                    Iteration time: 1.79s
                      Time elapsed: 00:30:11
                               ETA: 00:17:51

################################################################################
                     [1m Learning iteration 943/1500 [0m                      

                       Computation: 54125 steps/s (collection: 1.687s, learning 0.130s)
             Mean action noise std: 2.59
          Mean value_function loss: 26.1067
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 41.1035
                       Mean reward: 746.81
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7302
    Episode_Reward/rotating_object: 147.6336
        Episode_Reward/action_rate: -0.0319
          Episode_Reward/joint_vel: -0.0056
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 92798976
                    Iteration time: 1.82s
                      Time elapsed: 00:30:12
                               ETA: 00:17:49

################################################################################
                     [1m Learning iteration 944/1500 [0m                      

                       Computation: 55034 steps/s (collection: 1.666s, learning 0.120s)
             Mean action noise std: 2.59
          Mean value_function loss: 28.6900
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 41.1090
                       Mean reward: 752.61
               Mean episode length: 247.71
    Episode_Reward/reaching_object: 0.7273
    Episode_Reward/rotating_object: 146.5358
        Episode_Reward/action_rate: -0.0319
          Episode_Reward/joint_vel: -0.0060
      Episode_Termination/time_out: 18.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 92897280
                    Iteration time: 1.79s
                      Time elapsed: 00:30:14
                               ETA: 00:17:47

################################################################################
                     [1m Learning iteration 945/1500 [0m                      

                       Computation: 55319 steps/s (collection: 1.666s, learning 0.111s)
             Mean action noise std: 2.59
          Mean value_function loss: 23.4486
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 41.1121
                       Mean reward: 749.16
               Mean episode length: 247.68
    Episode_Reward/reaching_object: 0.7328
    Episode_Reward/rotating_object: 148.6816
        Episode_Reward/action_rate: -0.0321
          Episode_Reward/joint_vel: -0.0056
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 92995584
                    Iteration time: 1.78s
                      Time elapsed: 00:30:16
                               ETA: 00:17:45

################################################################################
                     [1m Learning iteration 946/1500 [0m                      

                       Computation: 55569 steps/s (collection: 1.669s, learning 0.100s)
             Mean action noise std: 2.60
          Mean value_function loss: 23.3834
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 41.1143
                       Mean reward: 751.00
               Mean episode length: 247.90
    Episode_Reward/reaching_object: 0.7265
    Episode_Reward/rotating_object: 146.4968
        Episode_Reward/action_rate: -0.0319
          Episode_Reward/joint_vel: -0.0055
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 93093888
                    Iteration time: 1.77s
                      Time elapsed: 00:30:18
                               ETA: 00:17:43

################################################################################
                     [1m Learning iteration 947/1500 [0m                      

                       Computation: 55605 steps/s (collection: 1.650s, learning 0.117s)
             Mean action noise std: 2.60
          Mean value_function loss: 31.3736
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 41.1227
                       Mean reward: 708.18
               Mean episode length: 247.71
    Episode_Reward/reaching_object: 0.7277
    Episode_Reward/rotating_object: 146.5460
        Episode_Reward/action_rate: -0.0320
          Episode_Reward/joint_vel: -0.0054
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 93192192
                    Iteration time: 1.77s
                      Time elapsed: 00:30:19
                               ETA: 00:17:41

################################################################################
                     [1m Learning iteration 948/1500 [0m                      

                       Computation: 56730 steps/s (collection: 1.636s, learning 0.097s)
             Mean action noise std: 2.60
          Mean value_function loss: 32.5177
               Mean surrogate loss: 0.0000
                 Mean entropy loss: 41.1343
                       Mean reward: 713.71
               Mean episode length: 245.73
    Episode_Reward/reaching_object: 0.7197
    Episode_Reward/rotating_object: 144.1848
        Episode_Reward/action_rate: -0.0320
          Episode_Reward/joint_vel: -0.0055
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 93290496
                    Iteration time: 1.73s
                      Time elapsed: 00:30:21
                               ETA: 00:17:39

################################################################################
                     [1m Learning iteration 949/1500 [0m                      

                       Computation: 56517 steps/s (collection: 1.640s, learning 0.100s)
             Mean action noise std: 2.60
          Mean value_function loss: 28.8301
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 41.1414
                       Mean reward: 733.27
               Mean episode length: 243.48
    Episode_Reward/reaching_object: 0.7222
    Episode_Reward/rotating_object: 145.3661
        Episode_Reward/action_rate: -0.0322
          Episode_Reward/joint_vel: -0.0061
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 93388800
                    Iteration time: 1.74s
                      Time elapsed: 00:30:23
                               ETA: 00:17:37

################################################################################
                     [1m Learning iteration 950/1500 [0m                      

                       Computation: 55608 steps/s (collection: 1.642s, learning 0.126s)
             Mean action noise std: 2.60
          Mean value_function loss: 25.9573
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 41.1481
                       Mean reward: 710.01
               Mean episode length: 248.01
    Episode_Reward/reaching_object: 0.7257
    Episode_Reward/rotating_object: 145.6730
        Episode_Reward/action_rate: -0.0323
          Episode_Reward/joint_vel: -0.0056
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 93487104
                    Iteration time: 1.77s
                      Time elapsed: 00:30:25
                               ETA: 00:17:35

################################################################################
                     [1m Learning iteration 951/1500 [0m                      

                       Computation: 53426 steps/s (collection: 1.733s, learning 0.107s)
             Mean action noise std: 2.60
          Mean value_function loss: 27.9038
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 41.1563
                       Mean reward: 746.04
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7295
    Episode_Reward/rotating_object: 148.3298
        Episode_Reward/action_rate: -0.0322
          Episode_Reward/joint_vel: -0.0054
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 93585408
                    Iteration time: 1.84s
                      Time elapsed: 00:30:27
                               ETA: 00:17:33

################################################################################
                     [1m Learning iteration 952/1500 [0m                      

                       Computation: 56544 steps/s (collection: 1.625s, learning 0.114s)
             Mean action noise std: 2.61
          Mean value_function loss: 23.5003
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 41.1630
                       Mean reward: 743.36
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7330
    Episode_Reward/rotating_object: 148.2610
        Episode_Reward/action_rate: -0.0324
          Episode_Reward/joint_vel: -0.0056
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 93683712
                    Iteration time: 1.74s
                      Time elapsed: 00:30:28
                               ETA: 00:17:31

################################################################################
                     [1m Learning iteration 953/1500 [0m                      

                       Computation: 55449 steps/s (collection: 1.620s, learning 0.153s)
             Mean action noise std: 2.61
          Mean value_function loss: 25.3427
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 41.1706
                       Mean reward: 752.63
               Mean episode length: 247.96
    Episode_Reward/reaching_object: 0.7377
    Episode_Reward/rotating_object: 150.7127
        Episode_Reward/action_rate: -0.0324
          Episode_Reward/joint_vel: -0.0057
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 93782016
                    Iteration time: 1.77s
                      Time elapsed: 00:30:30
                               ETA: 00:17:29

################################################################################
                     [1m Learning iteration 954/1500 [0m                      

                       Computation: 56565 steps/s (collection: 1.639s, learning 0.098s)
             Mean action noise std: 2.61
          Mean value_function loss: 28.9839
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 41.1772
                       Mean reward: 726.70
               Mean episode length: 248.22
    Episode_Reward/reaching_object: 0.7308
    Episode_Reward/rotating_object: 148.2705
        Episode_Reward/action_rate: -0.0324
          Episode_Reward/joint_vel: -0.0053
      Episode_Termination/time_out: 17.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 93880320
                    Iteration time: 1.74s
                      Time elapsed: 00:30:32
                               ETA: 00:17:27

################################################################################
                     [1m Learning iteration 955/1500 [0m                      

                       Computation: 55113 steps/s (collection: 1.687s, learning 0.097s)
             Mean action noise std: 2.61
          Mean value_function loss: 24.5381
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 41.1836
                       Mean reward: 752.37
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7424
    Episode_Reward/rotating_object: 151.2768
        Episode_Reward/action_rate: -0.0325
          Episode_Reward/joint_vel: -0.0053
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 93978624
                    Iteration time: 1.78s
                      Time elapsed: 00:30:34
                               ETA: 00:17:25

################################################################################
                     [1m Learning iteration 956/1500 [0m                      

                       Computation: 55581 steps/s (collection: 1.659s, learning 0.110s)
             Mean action noise std: 2.61
          Mean value_function loss: 32.4829
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 41.1868
                       Mean reward: 746.93
               Mean episode length: 247.76
    Episode_Reward/reaching_object: 0.7292
    Episode_Reward/rotating_object: 146.2399
        Episode_Reward/action_rate: -0.0324
          Episode_Reward/joint_vel: -0.0056
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 94076928
                    Iteration time: 1.77s
                      Time elapsed: 00:30:35
                               ETA: 00:17:23

################################################################################
                     [1m Learning iteration 957/1500 [0m                      

                       Computation: 54380 steps/s (collection: 1.702s, learning 0.106s)
             Mean action noise std: 2.61
          Mean value_function loss: 29.4448
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 41.1982
                       Mean reward: 761.47
               Mean episode length: 248.04
    Episode_Reward/reaching_object: 0.7362
    Episode_Reward/rotating_object: 148.2937
        Episode_Reward/action_rate: -0.0326
          Episode_Reward/joint_vel: -0.0054
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 94175232
                    Iteration time: 1.81s
                      Time elapsed: 00:30:37
                               ETA: 00:17:21

################################################################################
                     [1m Learning iteration 958/1500 [0m                      

                       Computation: 53373 steps/s (collection: 1.697s, learning 0.145s)
             Mean action noise std: 2.61
          Mean value_function loss: 27.5119
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 41.2063
                       Mean reward: 721.09
               Mean episode length: 242.62
    Episode_Reward/reaching_object: 0.7298
    Episode_Reward/rotating_object: 145.9166
        Episode_Reward/action_rate: -0.0324
          Episode_Reward/joint_vel: -0.0054
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 94273536
                    Iteration time: 1.84s
                      Time elapsed: 00:30:39
                               ETA: 00:17:19

################################################################################
                     [1m Learning iteration 959/1500 [0m                      

                       Computation: 55200 steps/s (collection: 1.675s, learning 0.106s)
             Mean action noise std: 2.62
          Mean value_function loss: 28.2856
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 41.2102
                       Mean reward: 741.79
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7345
    Episode_Reward/rotating_object: 146.5354
        Episode_Reward/action_rate: -0.0326
          Episode_Reward/joint_vel: -0.0053
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 94371840
                    Iteration time: 1.78s
                      Time elapsed: 00:30:41
                               ETA: 00:17:17

################################################################################
                     [1m Learning iteration 960/1500 [0m                      

                       Computation: 54117 steps/s (collection: 1.719s, learning 0.098s)
             Mean action noise std: 2.62
          Mean value_function loss: 32.2715
               Mean surrogate loss: 0.0008
                 Mean entropy loss: 41.2166
                       Mean reward: 749.29
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7282
    Episode_Reward/rotating_object: 145.1440
        Episode_Reward/action_rate: -0.0324
          Episode_Reward/joint_vel: -0.0054
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 94470144
                    Iteration time: 1.82s
                      Time elapsed: 00:30:43
                               ETA: 00:17:15

################################################################################
                     [1m Learning iteration 961/1500 [0m                      

                       Computation: 55204 steps/s (collection: 1.661s, learning 0.120s)
             Mean action noise std: 2.62
          Mean value_function loss: 28.4149
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 41.2246
                       Mean reward: 767.03
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7355
    Episode_Reward/rotating_object: 147.8685
        Episode_Reward/action_rate: -0.0326
          Episode_Reward/joint_vel: -0.0054
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 94568448
                    Iteration time: 1.78s
                      Time elapsed: 00:30:44
                               ETA: 00:17:13

################################################################################
                     [1m Learning iteration 962/1500 [0m                      

                       Computation: 53535 steps/s (collection: 1.662s, learning 0.175s)
             Mean action noise std: 2.62
          Mean value_function loss: 23.6373
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 41.2377
                       Mean reward: 724.72
               Mean episode length: 247.72
    Episode_Reward/reaching_object: 0.7334
    Episode_Reward/rotating_object: 146.1727
        Episode_Reward/action_rate: -0.0325
          Episode_Reward/joint_vel: -0.0054
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 94666752
                    Iteration time: 1.84s
                      Time elapsed: 00:30:46
                               ETA: 00:17:11

################################################################################
                     [1m Learning iteration 963/1500 [0m                      

                       Computation: 55079 steps/s (collection: 1.659s, learning 0.125s)
             Mean action noise std: 2.62
          Mean value_function loss: 29.5981
               Mean surrogate loss: -0.0005
                 Mean entropy loss: 41.2406
                       Mean reward: 732.29
               Mean episode length: 245.48
    Episode_Reward/reaching_object: 0.7290
    Episode_Reward/rotating_object: 146.5276
        Episode_Reward/action_rate: -0.0325
          Episode_Reward/joint_vel: -0.0053
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 94765056
                    Iteration time: 1.78s
                      Time elapsed: 00:30:48
                               ETA: 00:17:09

################################################################################
                     [1m Learning iteration 964/1500 [0m                      

                       Computation: 51374 steps/s (collection: 1.751s, learning 0.163s)
             Mean action noise std: 2.62
          Mean value_function loss: 26.1920
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 41.2443
                       Mean reward: 733.95
               Mean episode length: 247.68
    Episode_Reward/reaching_object: 0.7371
    Episode_Reward/rotating_object: 148.4949
        Episode_Reward/action_rate: -0.0328
          Episode_Reward/joint_vel: -0.0052
      Episode_Termination/time_out: 17.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 94863360
                    Iteration time: 1.91s
                      Time elapsed: 00:30:50
                               ETA: 00:17:07

################################################################################
                     [1m Learning iteration 965/1500 [0m                      

                       Computation: 52718 steps/s (collection: 1.750s, learning 0.115s)
             Mean action noise std: 2.62
          Mean value_function loss: 26.4197
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 41.2463
                       Mean reward: 742.49
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7308
    Episode_Reward/rotating_object: 148.3847
        Episode_Reward/action_rate: -0.0327
          Episode_Reward/joint_vel: -0.0053
      Episode_Termination/time_out: 17.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 94961664
                    Iteration time: 1.86s
                      Time elapsed: 00:30:52
                               ETA: 00:17:05

################################################################################
                     [1m Learning iteration 966/1500 [0m                      

                       Computation: 53931 steps/s (collection: 1.711s, learning 0.112s)
             Mean action noise std: 2.62
          Mean value_function loss: 28.3207
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 41.2458
                       Mean reward: 752.22
               Mean episode length: 248.03
    Episode_Reward/reaching_object: 0.7380
    Episode_Reward/rotating_object: 149.8848
        Episode_Reward/action_rate: -0.0327
          Episode_Reward/joint_vel: -0.0053
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 95059968
                    Iteration time: 1.82s
                      Time elapsed: 00:30:54
                               ETA: 00:17:03

################################################################################
                     [1m Learning iteration 967/1500 [0m                      

                       Computation: 51045 steps/s (collection: 1.825s, learning 0.101s)
             Mean action noise std: 2.63
          Mean value_function loss: 23.6767
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 41.2478
                       Mean reward: 739.73
               Mean episode length: 249.18
    Episode_Reward/reaching_object: 0.7296
    Episode_Reward/rotating_object: 146.6737
        Episode_Reward/action_rate: -0.0330
          Episode_Reward/joint_vel: -0.0056
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 95158272
                    Iteration time: 1.93s
                      Time elapsed: 00:30:56
                               ETA: 00:17:01

################################################################################
                     [1m Learning iteration 968/1500 [0m                      

                       Computation: 54335 steps/s (collection: 1.672s, learning 0.137s)
             Mean action noise std: 2.63
          Mean value_function loss: 23.5237
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 41.2541
                       Mean reward: 746.97
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7318
    Episode_Reward/rotating_object: 149.5460
        Episode_Reward/action_rate: -0.0328
          Episode_Reward/joint_vel: -0.0055
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 95256576
                    Iteration time: 1.81s
                      Time elapsed: 00:30:57
                               ETA: 00:16:59

################################################################################
                     [1m Learning iteration 969/1500 [0m                      

                       Computation: 54547 steps/s (collection: 1.659s, learning 0.144s)
             Mean action noise std: 2.63
          Mean value_function loss: 25.1499
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 41.2636
                       Mean reward: 735.31
               Mean episode length: 245.50
    Episode_Reward/reaching_object: 0.7198
    Episode_Reward/rotating_object: 145.7901
        Episode_Reward/action_rate: -0.0328
          Episode_Reward/joint_vel: -0.0051
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 95354880
                    Iteration time: 1.80s
                      Time elapsed: 00:30:59
                               ETA: 00:16:58

################################################################################
                     [1m Learning iteration 970/1500 [0m                      

                       Computation: 55015 steps/s (collection: 1.692s, learning 0.095s)
             Mean action noise std: 2.63
          Mean value_function loss: 30.4154
               Mean surrogate loss: 0.0011
                 Mean entropy loss: 41.2706
                       Mean reward: 737.93
               Mean episode length: 241.10
    Episode_Reward/reaching_object: 0.7196
    Episode_Reward/rotating_object: 146.3395
        Episode_Reward/action_rate: -0.0326
          Episode_Reward/joint_vel: -0.0052
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 95453184
                    Iteration time: 1.79s
                      Time elapsed: 00:31:01
                               ETA: 00:16:56

################################################################################
                     [1m Learning iteration 971/1500 [0m                      

                       Computation: 54424 steps/s (collection: 1.712s, learning 0.095s)
             Mean action noise std: 2.63
          Mean value_function loss: 23.2963
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 41.2744
                       Mean reward: 752.42
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7263
    Episode_Reward/rotating_object: 149.0027
        Episode_Reward/action_rate: -0.0331
          Episode_Reward/joint_vel: -0.0051
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 95551488
                    Iteration time: 1.81s
                      Time elapsed: 00:31:03
                               ETA: 00:16:54

################################################################################
                     [1m Learning iteration 972/1500 [0m                      

                       Computation: 50862 steps/s (collection: 1.737s, learning 0.196s)
             Mean action noise std: 2.63
          Mean value_function loss: 25.1426
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 41.2766
                       Mean reward: 754.93
               Mean episode length: 249.33
    Episode_Reward/reaching_object: 0.7257
    Episode_Reward/rotating_object: 148.4998
        Episode_Reward/action_rate: -0.0331
          Episode_Reward/joint_vel: -0.0054
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 95649792
                    Iteration time: 1.93s
                      Time elapsed: 00:31:05
                               ETA: 00:16:52

################################################################################
                     [1m Learning iteration 973/1500 [0m                      

                       Computation: 54260 steps/s (collection: 1.686s, learning 0.126s)
             Mean action noise std: 2.63
          Mean value_function loss: 29.5990
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 41.2767
                       Mean reward: 726.28
               Mean episode length: 245.86
    Episode_Reward/reaching_object: 0.7241
    Episode_Reward/rotating_object: 147.4109
        Episode_Reward/action_rate: -0.0332
          Episode_Reward/joint_vel: -0.0057
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 95748096
                    Iteration time: 1.81s
                      Time elapsed: 00:31:06
                               ETA: 00:16:50

################################################################################
                     [1m Learning iteration 974/1500 [0m                      

                       Computation: 54440 steps/s (collection: 1.668s, learning 0.138s)
             Mean action noise std: 2.64
          Mean value_function loss: 25.8197
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 41.2778
                       Mean reward: 765.59
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7338
    Episode_Reward/rotating_object: 150.3633
        Episode_Reward/action_rate: -0.0331
          Episode_Reward/joint_vel: -0.0053
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 95846400
                    Iteration time: 1.81s
                      Time elapsed: 00:31:08
                               ETA: 00:16:48

################################################################################
                     [1m Learning iteration 975/1500 [0m                      

                       Computation: 51820 steps/s (collection: 1.728s, learning 0.169s)
             Mean action noise std: 2.64
          Mean value_function loss: 33.7500
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 41.2858
                       Mean reward: 744.56
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7263
    Episode_Reward/rotating_object: 147.6442
        Episode_Reward/action_rate: -0.0330
          Episode_Reward/joint_vel: -0.0051
      Episode_Termination/time_out: 18.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 95944704
                    Iteration time: 1.90s
                      Time elapsed: 00:31:10
                               ETA: 00:16:46

################################################################################
                     [1m Learning iteration 976/1500 [0m                      

                       Computation: 53897 steps/s (collection: 1.719s, learning 0.105s)
             Mean action noise std: 2.64
          Mean value_function loss: 25.1705
               Mean surrogate loss: -0.0003
                 Mean entropy loss: 41.2922
                       Mean reward: 764.32
               Mean episode length: 247.76
    Episode_Reward/reaching_object: 0.7346
    Episode_Reward/rotating_object: 148.9867
        Episode_Reward/action_rate: -0.0333
          Episode_Reward/joint_vel: -0.0054
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 96043008
                    Iteration time: 1.82s
                      Time elapsed: 00:31:12
                               ETA: 00:16:44

################################################################################
                     [1m Learning iteration 977/1500 [0m                      

                       Computation: 53624 steps/s (collection: 1.726s, learning 0.108s)
             Mean action noise std: 2.64
          Mean value_function loss: 28.1248
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 41.2980
                       Mean reward: 750.04
               Mean episode length: 247.93
    Episode_Reward/reaching_object: 0.7385
    Episode_Reward/rotating_object: 150.8247
        Episode_Reward/action_rate: -0.0332
          Episode_Reward/joint_vel: -0.0052
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 96141312
                    Iteration time: 1.83s
                      Time elapsed: 00:31:14
                               ETA: 00:16:42

################################################################################
                     [1m Learning iteration 978/1500 [0m                      

                       Computation: 54539 steps/s (collection: 1.700s, learning 0.103s)
             Mean action noise std: 2.64
          Mean value_function loss: 31.6182
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 41.3189
                       Mean reward: 746.24
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7410
    Episode_Reward/rotating_object: 149.9098
        Episode_Reward/action_rate: -0.0332
          Episode_Reward/joint_vel: -0.0053
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 96239616
                    Iteration time: 1.80s
                      Time elapsed: 00:31:16
                               ETA: 00:16:40

################################################################################
                     [1m Learning iteration 979/1500 [0m                      

                       Computation: 55167 steps/s (collection: 1.677s, learning 0.105s)
             Mean action noise std: 2.65
          Mean value_function loss: 21.5744
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 41.3333
                       Mean reward: 741.16
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7400
    Episode_Reward/rotating_object: 149.2018
        Episode_Reward/action_rate: -0.0333
          Episode_Reward/joint_vel: -0.0051
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 96337920
                    Iteration time: 1.78s
                      Time elapsed: 00:31:17
                               ETA: 00:16:38

################################################################################
                     [1m Learning iteration 980/1500 [0m                      

                       Computation: 55831 steps/s (collection: 1.653s, learning 0.108s)
             Mean action noise std: 2.65
          Mean value_function loss: 26.7877
               Mean surrogate loss: -0.0004
                 Mean entropy loss: 41.3374
                       Mean reward: 732.47
               Mean episode length: 244.22
    Episode_Reward/reaching_object: 0.7347
    Episode_Reward/rotating_object: 148.9880
        Episode_Reward/action_rate: -0.0332
          Episode_Reward/joint_vel: -0.0052
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 96436224
                    Iteration time: 1.76s
                      Time elapsed: 00:31:19
                               ETA: 00:16:36

################################################################################
                     [1m Learning iteration 981/1500 [0m                      

                       Computation: 51493 steps/s (collection: 1.712s, learning 0.197s)
             Mean action noise std: 2.65
          Mean value_function loss: 23.3342
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 41.3436
                       Mean reward: 718.81
               Mean episode length: 246.68
    Episode_Reward/reaching_object: 0.7307
    Episode_Reward/rotating_object: 147.7246
        Episode_Reward/action_rate: -0.0333
          Episode_Reward/joint_vel: -0.0052
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 96534528
                    Iteration time: 1.91s
                      Time elapsed: 00:31:21
                               ETA: 00:16:34

################################################################################
                     [1m Learning iteration 982/1500 [0m                      

                       Computation: 54661 steps/s (collection: 1.692s, learning 0.107s)
             Mean action noise std: 2.65
          Mean value_function loss: 24.4250
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 41.3526
                       Mean reward: 750.42
               Mean episode length: 247.77
    Episode_Reward/reaching_object: 0.7390
    Episode_Reward/rotating_object: 150.8574
        Episode_Reward/action_rate: -0.0334
          Episode_Reward/joint_vel: -0.0051
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 96632832
                    Iteration time: 1.80s
                      Time elapsed: 00:31:23
                               ETA: 00:16:32

################################################################################
                     [1m Learning iteration 983/1500 [0m                      

                       Computation: 51960 steps/s (collection: 1.795s, learning 0.097s)
             Mean action noise std: 2.65
          Mean value_function loss: 21.4905
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 41.3591
                       Mean reward: 732.80
               Mean episode length: 243.40
    Episode_Reward/reaching_object: 0.7349
    Episode_Reward/rotating_object: 148.4185
        Episode_Reward/action_rate: -0.0334
          Episode_Reward/joint_vel: -0.0052
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 96731136
                    Iteration time: 1.89s
                      Time elapsed: 00:31:25
                               ETA: 00:16:30

################################################################################
                     [1m Learning iteration 984/1500 [0m                      

                       Computation: 54956 steps/s (collection: 1.684s, learning 0.105s)
             Mean action noise std: 2.65
          Mean value_function loss: 27.3330
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 41.3590
                       Mean reward: 759.80
               Mean episode length: 247.73
    Episode_Reward/reaching_object: 0.7344
    Episode_Reward/rotating_object: 148.6508
        Episode_Reward/action_rate: -0.0336
          Episode_Reward/joint_vel: -0.0057
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 96829440
                    Iteration time: 1.79s
                      Time elapsed: 00:31:27
                               ETA: 00:16:28

################################################################################
                     [1m Learning iteration 985/1500 [0m                      

                       Computation: 53230 steps/s (collection: 1.711s, learning 0.136s)
             Mean action noise std: 2.65
          Mean value_function loss: 25.4559
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 41.3592
                       Mean reward: 754.27
               Mean episode length: 247.76
    Episode_Reward/reaching_object: 0.7384
    Episode_Reward/rotating_object: 151.5561
        Episode_Reward/action_rate: -0.0335
          Episode_Reward/joint_vel: -0.0051
      Episode_Termination/time_out: 17.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 96927744
                    Iteration time: 1.85s
                      Time elapsed: 00:31:28
                               ETA: 00:16:26

################################################################################
                     [1m Learning iteration 986/1500 [0m                      

                       Computation: 53475 steps/s (collection: 1.661s, learning 0.178s)
             Mean action noise std: 2.65
          Mean value_function loss: 23.3448
               Mean surrogate loss: -0.0005
                 Mean entropy loss: 41.3603
                       Mean reward: 743.96
               Mean episode length: 247.75
    Episode_Reward/reaching_object: 0.7335
    Episode_Reward/rotating_object: 148.5907
        Episode_Reward/action_rate: -0.0336
          Episode_Reward/joint_vel: -0.0054
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 97026048
                    Iteration time: 1.84s
                      Time elapsed: 00:31:30
                               ETA: 00:16:24

################################################################################
                     [1m Learning iteration 987/1500 [0m                      

                       Computation: 53997 steps/s (collection: 1.714s, learning 0.106s)
             Mean action noise std: 2.65
          Mean value_function loss: 25.0364
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 41.3623
                       Mean reward: 757.46
               Mean episode length: 247.94
    Episode_Reward/reaching_object: 0.7339
    Episode_Reward/rotating_object: 148.9231
        Episode_Reward/action_rate: -0.0337
          Episode_Reward/joint_vel: -0.0052
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 97124352
                    Iteration time: 1.82s
                      Time elapsed: 00:31:32
                               ETA: 00:16:22

################################################################################
                     [1m Learning iteration 988/1500 [0m                      

                       Computation: 54050 steps/s (collection: 1.702s, learning 0.117s)
             Mean action noise std: 2.65
          Mean value_function loss: 22.6030
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 41.3692
                       Mean reward: 748.31
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7365
    Episode_Reward/rotating_object: 149.8893
        Episode_Reward/action_rate: -0.0338
          Episode_Reward/joint_vel: -0.0054
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 97222656
                    Iteration time: 1.82s
                      Time elapsed: 00:31:34
                               ETA: 00:16:20

################################################################################
                     [1m Learning iteration 989/1500 [0m                      

                       Computation: 52147 steps/s (collection: 1.717s, learning 0.169s)
             Mean action noise std: 2.66
          Mean value_function loss: 26.1626
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 41.3783
                       Mean reward: 748.71
               Mean episode length: 247.74
    Episode_Reward/reaching_object: 0.7393
    Episode_Reward/rotating_object: 150.5067
        Episode_Reward/action_rate: -0.0338
          Episode_Reward/joint_vel: -0.0050
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 97320960
                    Iteration time: 1.89s
                      Time elapsed: 00:31:36
                               ETA: 00:16:18

################################################################################
                     [1m Learning iteration 990/1500 [0m                      

                       Computation: 54250 steps/s (collection: 1.695s, learning 0.117s)
             Mean action noise std: 2.66
          Mean value_function loss: 26.7077
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 41.3842
                       Mean reward: 721.18
               Mean episode length: 243.29
    Episode_Reward/reaching_object: 0.7335
    Episode_Reward/rotating_object: 148.6398
        Episode_Reward/action_rate: -0.0335
          Episode_Reward/joint_vel: -0.0048
      Episode_Termination/time_out: 17.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 97419264
                    Iteration time: 1.81s
                      Time elapsed: 00:31:38
                               ETA: 00:16:16

################################################################################
                     [1m Learning iteration 991/1500 [0m                      

                       Computation: 53295 steps/s (collection: 1.696s, learning 0.148s)
             Mean action noise std: 2.66
          Mean value_function loss: 25.9239
               Mean surrogate loss: -0.0002
                 Mean entropy loss: 41.3864
                       Mean reward: 734.38
               Mean episode length: 246.31
    Episode_Reward/reaching_object: 0.7380
    Episode_Reward/rotating_object: 148.9955
        Episode_Reward/action_rate: -0.0338
          Episode_Reward/joint_vel: -0.0047
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 97517568
                    Iteration time: 1.84s
                      Time elapsed: 00:31:39
                               ETA: 00:16:14

################################################################################
                     [1m Learning iteration 992/1500 [0m                      

                       Computation: 55155 steps/s (collection: 1.680s, learning 0.102s)
             Mean action noise std: 2.66
          Mean value_function loss: 24.5346
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 41.3939
                       Mean reward: 756.79
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7411
    Episode_Reward/rotating_object: 151.4079
        Episode_Reward/action_rate: -0.0340
          Episode_Reward/joint_vel: -0.0048
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 97615872
                    Iteration time: 1.78s
                      Time elapsed: 00:31:41
                               ETA: 00:16:12

################################################################################
                     [1m Learning iteration 993/1500 [0m                      

                       Computation: 55485 steps/s (collection: 1.655s, learning 0.116s)
             Mean action noise std: 2.66
          Mean value_function loss: 20.3799
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 41.4026
                       Mean reward: 737.70
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7372
    Episode_Reward/rotating_object: 149.1761
        Episode_Reward/action_rate: -0.0340
          Episode_Reward/joint_vel: -0.0051
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 97714176
                    Iteration time: 1.77s
                      Time elapsed: 00:31:43
                               ETA: 00:16:10

################################################################################
                     [1m Learning iteration 994/1500 [0m                      

                       Computation: 53973 steps/s (collection: 1.725s, learning 0.097s)
             Mean action noise std: 2.66
          Mean value_function loss: 24.1160
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 41.4068
                       Mean reward: 741.03
               Mean episode length: 245.78
    Episode_Reward/reaching_object: 0.7383
    Episode_Reward/rotating_object: 150.4666
        Episode_Reward/action_rate: -0.0338
          Episode_Reward/joint_vel: -0.0051
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 97812480
                    Iteration time: 1.82s
                      Time elapsed: 00:31:45
                               ETA: 00:16:08

################################################################################
                     [1m Learning iteration 995/1500 [0m                      

                       Computation: 54983 steps/s (collection: 1.683s, learning 0.105s)
             Mean action noise std: 2.66
          Mean value_function loss: 26.2348
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 41.4154
                       Mean reward: 741.20
               Mean episode length: 243.38
    Episode_Reward/reaching_object: 0.7333
    Episode_Reward/rotating_object: 149.7899
        Episode_Reward/action_rate: -0.0339
          Episode_Reward/joint_vel: -0.0051
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 97910784
                    Iteration time: 1.79s
                      Time elapsed: 00:31:47
                               ETA: 00:16:06

################################################################################
                     [1m Learning iteration 996/1500 [0m                      

                       Computation: 54326 steps/s (collection: 1.665s, learning 0.145s)
             Mean action noise std: 2.67
          Mean value_function loss: 24.7062
               Mean surrogate loss: -0.0004
                 Mean entropy loss: 41.4323
                       Mean reward: 738.12
               Mean episode length: 247.82
    Episode_Reward/reaching_object: 0.7331
    Episode_Reward/rotating_object: 150.1420
        Episode_Reward/action_rate: -0.0341
          Episode_Reward/joint_vel: -0.0050
      Episode_Termination/time_out: 18.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 98009088
                    Iteration time: 1.81s
                      Time elapsed: 00:31:48
                               ETA: 00:16:04

################################################################################
                     [1m Learning iteration 997/1500 [0m                      

                       Computation: 52823 steps/s (collection: 1.671s, learning 0.190s)
             Mean action noise std: 2.67
          Mean value_function loss: 31.7160
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 41.4473
                       Mean reward: 733.21
               Mean episode length: 239.84
    Episode_Reward/reaching_object: 0.7262
    Episode_Reward/rotating_object: 149.2169
        Episode_Reward/action_rate: -0.0337
          Episode_Reward/joint_vel: -0.0049
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 98107392
                    Iteration time: 1.86s
                      Time elapsed: 00:31:50
                               ETA: 00:16:03

################################################################################
                     [1m Learning iteration 998/1500 [0m                      

                       Computation: 50226 steps/s (collection: 1.792s, learning 0.166s)
             Mean action noise std: 2.67
          Mean value_function loss: 25.2140
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 41.4576
                       Mean reward: 756.60
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7335
    Episode_Reward/rotating_object: 150.0679
        Episode_Reward/action_rate: -0.0342
          Episode_Reward/joint_vel: -0.0051
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 98205696
                    Iteration time: 1.96s
                      Time elapsed: 00:31:52
                               ETA: 00:16:01

################################################################################
                     [1m Learning iteration 999/1500 [0m                      

                       Computation: 55383 steps/s (collection: 1.673s, learning 0.102s)
             Mean action noise std: 2.67
          Mean value_function loss: 26.1484
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 41.4718
                       Mean reward: 785.84
               Mean episode length: 245.48
    Episode_Reward/reaching_object: 0.7320
    Episode_Reward/rotating_object: 152.5441
        Episode_Reward/action_rate: -0.0341
          Episode_Reward/joint_vel: -0.0048
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 98304000
                    Iteration time: 1.77s
                      Time elapsed: 00:31:54
                               ETA: 00:15:59

################################################################################
                     [1m Learning iteration 1000/1500 [0m                     

                       Computation: 14886 steps/s (collection: 6.456s, learning 0.148s)
             Mean action noise std: 2.68
          Mean value_function loss: 31.4288
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 41.4875
                       Mean reward: 730.81
               Mean episode length: 247.71
    Episode_Reward/reaching_object: 0.7168
    Episode_Reward/rotating_object: 146.4579
        Episode_Reward/action_rate: -0.0339
          Episode_Reward/joint_vel: -0.0049
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 98402304
                    Iteration time: 6.60s
                      Time elapsed: 00:32:01
                               ETA: 00:15:59

################################################################################
                     [1m Learning iteration 1001/1500 [0m                     

                       Computation: 14518 steps/s (collection: 6.586s, learning 0.185s)
             Mean action noise std: 2.68
          Mean value_function loss: 22.0952
               Mean surrogate loss: -0.0004
                 Mean entropy loss: 41.5006
                       Mean reward: 766.38
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7287
    Episode_Reward/rotating_object: 150.0059
        Episode_Reward/action_rate: -0.0343
          Episode_Reward/joint_vel: -0.0051
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 98500608
                    Iteration time: 6.77s
                      Time elapsed: 00:32:07
                               ETA: 00:16:00

################################################################################
                     [1m Learning iteration 1002/1500 [0m                     

                       Computation: 14809 steps/s (collection: 6.518s, learning 0.121s)
             Mean action noise std: 2.68
          Mean value_function loss: 28.2862
               Mean surrogate loss: 0.0015
                 Mean entropy loss: 41.5075
                       Mean reward: 760.17
               Mean episode length: 247.68
    Episode_Reward/reaching_object: 0.7285
    Episode_Reward/rotating_object: 150.2054
        Episode_Reward/action_rate: -0.0341
          Episode_Reward/joint_vel: -0.0047
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 98598912
                    Iteration time: 6.64s
                      Time elapsed: 00:32:14
                               ETA: 00:16:00

################################################################################
                     [1m Learning iteration 1003/1500 [0m                     

                       Computation: 14994 steps/s (collection: 6.377s, learning 0.179s)
             Mean action noise std: 2.68
          Mean value_function loss: 28.2194
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 41.5074
                       Mean reward: 755.03
               Mean episode length: 247.70
    Episode_Reward/reaching_object: 0.7320
    Episode_Reward/rotating_object: 149.9829
        Episode_Reward/action_rate: -0.0345
          Episode_Reward/joint_vel: -0.0047
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 98697216
                    Iteration time: 6.56s
                      Time elapsed: 00:32:21
                               ETA: 00:16:00

################################################################################
                     [1m Learning iteration 1004/1500 [0m                     

                       Computation: 14959 steps/s (collection: 6.450s, learning 0.121s)
             Mean action noise std: 2.68
          Mean value_function loss: 26.1730
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 41.5108
                       Mean reward: 768.58
               Mean episode length: 248.05
    Episode_Reward/reaching_object: 0.7362
    Episode_Reward/rotating_object: 151.8836
        Episode_Reward/action_rate: -0.0343
          Episode_Reward/joint_vel: -0.0048
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 98795520
                    Iteration time: 6.57s
                      Time elapsed: 00:32:27
                               ETA: 00:16:01

################################################################################
                     [1m Learning iteration 1005/1500 [0m                     

                       Computation: 14878 steps/s (collection: 6.430s, learning 0.177s)
             Mean action noise std: 2.68
          Mean value_function loss: 21.0284
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 41.5193
                       Mean reward: 772.09
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7404
    Episode_Reward/rotating_object: 151.7498
        Episode_Reward/action_rate: -0.0347
          Episode_Reward/joint_vel: -0.0049
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 98893824
                    Iteration time: 6.61s
                      Time elapsed: 00:32:34
                               ETA: 00:16:01

################################################################################
                     [1m Learning iteration 1006/1500 [0m                     

                       Computation: 15367 steps/s (collection: 6.215s, learning 0.182s)
             Mean action noise std: 2.68
          Mean value_function loss: 24.6212
               Mean surrogate loss: 0.0004
                 Mean entropy loss: 41.5267
                       Mean reward: 766.90
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7344
    Episode_Reward/rotating_object: 150.9980
        Episode_Reward/action_rate: -0.0345
          Episode_Reward/joint_vel: -0.0047
      Episode_Termination/time_out: 17.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 98992128
                    Iteration time: 6.40s
                      Time elapsed: 00:32:40
                               ETA: 00:16:01

################################################################################
                     [1m Learning iteration 1007/1500 [0m                     

                       Computation: 15056 steps/s (collection: 6.407s, learning 0.122s)
             Mean action noise std: 2.68
          Mean value_function loss: 28.0826
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 41.5300
                       Mean reward: 760.10
               Mean episode length: 245.68
    Episode_Reward/reaching_object: 0.7223
    Episode_Reward/rotating_object: 148.8133
        Episode_Reward/action_rate: -0.0344
          Episode_Reward/joint_vel: -0.0050
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 99090432
                    Iteration time: 6.53s
                      Time elapsed: 00:32:47
                               ETA: 00:16:02

################################################################################
                     [1m Learning iteration 1008/1500 [0m                     

                       Computation: 17967 steps/s (collection: 5.375s, learning 0.096s)
             Mean action noise std: 2.69
          Mean value_function loss: 25.1291
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 41.5338
                       Mean reward: 782.95
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7389
    Episode_Reward/rotating_object: 154.1742
        Episode_Reward/action_rate: -0.0347
          Episode_Reward/joint_vel: -0.0053
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 99188736
                    Iteration time: 5.47s
                      Time elapsed: 00:32:52
                               ETA: 00:16:01

################################################################################
                     [1m Learning iteration 1009/1500 [0m                     

                       Computation: 55272 steps/s (collection: 1.621s, learning 0.158s)
             Mean action noise std: 2.69
          Mean value_function loss: 28.1851
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 41.5409
                       Mean reward: 753.80
               Mean episode length: 247.69
    Episode_Reward/reaching_object: 0.7209
    Episode_Reward/rotating_object: 148.5831
        Episode_Reward/action_rate: -0.0345
          Episode_Reward/joint_vel: -0.0051
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 99287040
                    Iteration time: 1.78s
                      Time elapsed: 00:32:54
                               ETA: 00:15:59

################################################################################
                     [1m Learning iteration 1010/1500 [0m                     

                       Computation: 60116 steps/s (collection: 1.547s, learning 0.089s)
             Mean action noise std: 2.69
          Mean value_function loss: 25.2233
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 41.5489
                       Mean reward: 758.80
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7241
    Episode_Reward/rotating_object: 149.9827
        Episode_Reward/action_rate: -0.0345
          Episode_Reward/joint_vel: -0.0051
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 99385344
                    Iteration time: 1.64s
                      Time elapsed: 00:32:56
                               ETA: 00:15:57

################################################################################
                     [1m Learning iteration 1011/1500 [0m                     

                       Computation: 58070 steps/s (collection: 1.587s, learning 0.106s)
             Mean action noise std: 2.69
          Mean value_function loss: 23.0544
               Mean surrogate loss: 0.0007
                 Mean entropy loss: 41.5574
                       Mean reward: 761.56
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7266
    Episode_Reward/rotating_object: 151.5689
        Episode_Reward/action_rate: -0.0348
          Episode_Reward/joint_vel: -0.0052
      Episode_Termination/time_out: 17.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 99483648
                    Iteration time: 1.69s
                      Time elapsed: 00:32:57
                               ETA: 00:15:55

################################################################################
                     [1m Learning iteration 1012/1500 [0m                     

                       Computation: 58718 steps/s (collection: 1.555s, learning 0.119s)
             Mean action noise std: 2.69
          Mean value_function loss: 26.2624
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 41.5586
                       Mean reward: 771.59
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7220
    Episode_Reward/rotating_object: 152.3322
        Episode_Reward/action_rate: -0.0348
          Episode_Reward/joint_vel: -0.0050
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 99581952
                    Iteration time: 1.67s
                      Time elapsed: 00:32:59
                               ETA: 00:15:53

################################################################################
                     [1m Learning iteration 1013/1500 [0m                     

                       Computation: 60146 steps/s (collection: 1.527s, learning 0.108s)
             Mean action noise std: 2.69
          Mean value_function loss: 22.7060
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 41.5599
                       Mean reward: 761.26
               Mean episode length: 247.78
    Episode_Reward/reaching_object: 0.7178
    Episode_Reward/rotating_object: 150.1619
        Episode_Reward/action_rate: -0.0347
          Episode_Reward/joint_vel: -0.0052
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 99680256
                    Iteration time: 1.63s
                      Time elapsed: 00:33:01
                               ETA: 00:15:51

################################################################################
                     [1m Learning iteration 1014/1500 [0m                     

                       Computation: 59524 steps/s (collection: 1.558s, learning 0.094s)
             Mean action noise std: 2.69
          Mean value_function loss: 24.2598
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 41.5684
                       Mean reward: 750.96
               Mean episode length: 247.80
    Episode_Reward/reaching_object: 0.7099
    Episode_Reward/rotating_object: 147.7442
        Episode_Reward/action_rate: -0.0347
          Episode_Reward/joint_vel: -0.0052
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 99778560
                    Iteration time: 1.65s
                      Time elapsed: 00:33:02
                               ETA: 00:15:49

################################################################################
                     [1m Learning iteration 1015/1500 [0m                     

                       Computation: 58469 steps/s (collection: 1.573s, learning 0.108s)
             Mean action noise std: 2.69
          Mean value_function loss: 26.1068
               Mean surrogate loss: -0.0006
                 Mean entropy loss: 41.5754
                       Mean reward: 773.17
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7220
    Episode_Reward/rotating_object: 152.2096
        Episode_Reward/action_rate: -0.0349
          Episode_Reward/joint_vel: -0.0049
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 99876864
                    Iteration time: 1.68s
                      Time elapsed: 00:33:04
                               ETA: 00:15:47

################################################################################
                     [1m Learning iteration 1016/1500 [0m                     

                       Computation: 56355 steps/s (collection: 1.646s, learning 0.098s)
             Mean action noise std: 2.70
          Mean value_function loss: 26.5155
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 41.5827
                       Mean reward: 746.75
               Mean episode length: 245.50
    Episode_Reward/reaching_object: 0.7182
    Episode_Reward/rotating_object: 150.3673
        Episode_Reward/action_rate: -0.0348
          Episode_Reward/joint_vel: -0.0049
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 99975168
                    Iteration time: 1.74s
                      Time elapsed: 00:33:06
                               ETA: 00:15:45

################################################################################
                     [1m Learning iteration 1017/1500 [0m                     

                       Computation: 58501 steps/s (collection: 1.593s, learning 0.088s)
             Mean action noise std: 2.70
          Mean value_function loss: 24.5688
               Mean surrogate loss: -0.0002
                 Mean entropy loss: 41.5880
                       Mean reward: 750.30
               Mean episode length: 247.70
    Episode_Reward/reaching_object: 0.7228
    Episode_Reward/rotating_object: 152.1106
        Episode_Reward/action_rate: -0.0349
          Episode_Reward/joint_vel: -0.0049
      Episode_Termination/time_out: 17.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 100073472
                    Iteration time: 1.68s
                      Time elapsed: 00:33:07
                               ETA: 00:15:43

################################################################################
                     [1m Learning iteration 1018/1500 [0m                     

                       Computation: 55290 steps/s (collection: 1.611s, learning 0.167s)
             Mean action noise std: 2.70
          Mean value_function loss: 26.6961
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 41.5913
                       Mean reward: 760.59
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7174
    Episode_Reward/rotating_object: 150.6866
        Episode_Reward/action_rate: -0.0349
          Episode_Reward/joint_vel: -0.0050
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 100171776
                    Iteration time: 1.78s
                      Time elapsed: 00:33:09
                               ETA: 00:15:41

################################################################################
                     [1m Learning iteration 1019/1500 [0m                     

                       Computation: 58822 steps/s (collection: 1.564s, learning 0.108s)
             Mean action noise std: 2.70
          Mean value_function loss: 29.2966
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 41.6008
                       Mean reward: 716.39
               Mean episode length: 241.31
    Episode_Reward/reaching_object: 0.7111
    Episode_Reward/rotating_object: 146.5956
        Episode_Reward/action_rate: -0.0347
          Episode_Reward/joint_vel: -0.0052
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 100270080
                    Iteration time: 1.67s
                      Time elapsed: 00:33:11
                               ETA: 00:15:39

################################################################################
                     [1m Learning iteration 1020/1500 [0m                     

                       Computation: 59077 steps/s (collection: 1.567s, learning 0.097s)
             Mean action noise std: 2.70
          Mean value_function loss: 19.8178
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 41.6084
                       Mean reward: 725.47
               Mean episode length: 247.93
    Episode_Reward/reaching_object: 0.7231
    Episode_Reward/rotating_object: 149.7882
        Episode_Reward/action_rate: -0.0352
          Episode_Reward/joint_vel: -0.0051
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 100368384
                    Iteration time: 1.66s
                      Time elapsed: 00:33:12
                               ETA: 00:15:36

################################################################################
                     [1m Learning iteration 1021/1500 [0m                     

                       Computation: 58561 steps/s (collection: 1.580s, learning 0.099s)
             Mean action noise std: 2.70
          Mean value_function loss: 25.0756
               Mean surrogate loss: -0.0002
                 Mean entropy loss: 41.6141
                       Mean reward: 767.83
               Mean episode length: 247.73
    Episode_Reward/reaching_object: 0.7259
    Episode_Reward/rotating_object: 149.0916
        Episode_Reward/action_rate: -0.0351
          Episode_Reward/joint_vel: -0.0050
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 100466688
                    Iteration time: 1.68s
                      Time elapsed: 00:33:14
                               ETA: 00:15:34

################################################################################
                     [1m Learning iteration 1022/1500 [0m                     

                       Computation: 59180 steps/s (collection: 1.532s, learning 0.129s)
             Mean action noise std: 2.70
          Mean value_function loss: 25.4148
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 41.6195
                       Mean reward: 757.25
               Mean episode length: 247.67
    Episode_Reward/reaching_object: 0.7246
    Episode_Reward/rotating_object: 150.7483
        Episode_Reward/action_rate: -0.0347
          Episode_Reward/joint_vel: -0.0047
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 100564992
                    Iteration time: 1.66s
                      Time elapsed: 00:33:16
                               ETA: 00:15:32

################################################################################
                     [1m Learning iteration 1023/1500 [0m                     

                       Computation: 58518 steps/s (collection: 1.577s, learning 0.103s)
             Mean action noise std: 2.71
          Mean value_function loss: 24.4490
               Mean surrogate loss: -0.0004
                 Mean entropy loss: 41.6249
                       Mean reward: 771.33
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7329
    Episode_Reward/rotating_object: 151.1406
        Episode_Reward/action_rate: -0.0353
          Episode_Reward/joint_vel: -0.0052
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 100663296
                    Iteration time: 1.68s
                      Time elapsed: 00:33:17
                               ETA: 00:15:30

################################################################################
                     [1m Learning iteration 1024/1500 [0m                     

                       Computation: 58257 steps/s (collection: 1.582s, learning 0.105s)
             Mean action noise std: 2.71
          Mean value_function loss: 22.7557
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 41.6314
                       Mean reward: 741.17
               Mean episode length: 246.20
    Episode_Reward/reaching_object: 0.7225
    Episode_Reward/rotating_object: 148.1518
        Episode_Reward/action_rate: -0.0348
          Episode_Reward/joint_vel: -0.0050
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 100761600
                    Iteration time: 1.69s
                      Time elapsed: 00:33:19
                               ETA: 00:15:28

################################################################################
                     [1m Learning iteration 1025/1500 [0m                     

                       Computation: 57533 steps/s (collection: 1.566s, learning 0.143s)
             Mean action noise std: 2.71
          Mean value_function loss: 27.4052
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 41.6369
                       Mean reward: 747.86
               Mean episode length: 243.18
    Episode_Reward/reaching_object: 0.7249
    Episode_Reward/rotating_object: 150.1756
        Episode_Reward/action_rate: -0.0349
          Episode_Reward/joint_vel: -0.0048
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 100859904
                    Iteration time: 1.71s
                      Time elapsed: 00:33:21
                               ETA: 00:15:26

################################################################################
                     [1m Learning iteration 1026/1500 [0m                     

                       Computation: 59078 steps/s (collection: 1.570s, learning 0.094s)
             Mean action noise std: 2.71
          Mean value_function loss: 21.7706
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 41.6422
                       Mean reward: 766.56
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7338
    Episode_Reward/rotating_object: 152.5283
        Episode_Reward/action_rate: -0.0353
          Episode_Reward/joint_vel: -0.0050
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 100958208
                    Iteration time: 1.66s
                      Time elapsed: 00:33:23
                               ETA: 00:15:24

################################################################################
                     [1m Learning iteration 1027/1500 [0m                     

                       Computation: 58559 steps/s (collection: 1.579s, learning 0.100s)
             Mean action noise std: 2.71
          Mean value_function loss: 20.1150
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 41.6499
                       Mean reward: 758.50
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7339
    Episode_Reward/rotating_object: 151.8344
        Episode_Reward/action_rate: -0.0352
          Episode_Reward/joint_vel: -0.0048
      Episode_Termination/time_out: 18.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 101056512
                    Iteration time: 1.68s
                      Time elapsed: 00:33:24
                               ETA: 00:15:22

################################################################################
                     [1m Learning iteration 1028/1500 [0m                     

                       Computation: 58775 steps/s (collection: 1.560s, learning 0.113s)
             Mean action noise std: 2.72
          Mean value_function loss: 24.4334
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 41.6598
                       Mean reward: 758.71
               Mean episode length: 247.76
    Episode_Reward/reaching_object: 0.7218
    Episode_Reward/rotating_object: 149.2918
        Episode_Reward/action_rate: -0.0351
          Episode_Reward/joint_vel: -0.0050
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 101154816
                    Iteration time: 1.67s
                      Time elapsed: 00:33:26
                               ETA: 00:15:20

################################################################################
                     [1m Learning iteration 1029/1500 [0m                     

                       Computation: 59166 steps/s (collection: 1.563s, learning 0.099s)
             Mean action noise std: 2.72
          Mean value_function loss: 22.8567
               Mean surrogate loss: -0.0007
                 Mean entropy loss: 41.6758
                       Mean reward: 754.47
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7306
    Episode_Reward/rotating_object: 151.3404
        Episode_Reward/action_rate: -0.0352
          Episode_Reward/joint_vel: -0.0051
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 101253120
                    Iteration time: 1.66s
                      Time elapsed: 00:33:28
                               ETA: 00:15:18

################################################################################
                     [1m Learning iteration 1030/1500 [0m                     

                       Computation: 58947 steps/s (collection: 1.568s, learning 0.100s)
             Mean action noise std: 2.72
          Mean value_function loss: 21.2571
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 41.6827
                       Mean reward: 769.77
               Mean episode length: 247.71
    Episode_Reward/reaching_object: 0.7323
    Episode_Reward/rotating_object: 153.0793
        Episode_Reward/action_rate: -0.0352
          Episode_Reward/joint_vel: -0.0051
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 101351424
                    Iteration time: 1.67s
                      Time elapsed: 00:33:29
                               ETA: 00:15:16

################################################################################
                     [1m Learning iteration 1031/1500 [0m                     

                       Computation: 58986 steps/s (collection: 1.543s, learning 0.124s)
             Mean action noise std: 2.72
          Mean value_function loss: 23.8139
               Mean surrogate loss: -0.0002
                 Mean entropy loss: 41.6902
                       Mean reward: 765.86
               Mean episode length: 247.92
    Episode_Reward/reaching_object: 0.7214
    Episode_Reward/rotating_object: 149.0368
        Episode_Reward/action_rate: -0.0352
          Episode_Reward/joint_vel: -0.0055
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 101449728
                    Iteration time: 1.67s
                      Time elapsed: 00:33:31
                               ETA: 00:15:14

################################################################################
                     [1m Learning iteration 1032/1500 [0m                     

                       Computation: 58779 steps/s (collection: 1.577s, learning 0.095s)
             Mean action noise std: 2.72
          Mean value_function loss: 22.3660
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 41.6954
                       Mean reward: 764.38
               Mean episode length: 247.80
    Episode_Reward/reaching_object: 0.7259
    Episode_Reward/rotating_object: 151.5270
        Episode_Reward/action_rate: -0.0352
          Episode_Reward/joint_vel: -0.0052
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 101548032
                    Iteration time: 1.67s
                      Time elapsed: 00:33:33
                               ETA: 00:15:12

################################################################################
                     [1m Learning iteration 1033/1500 [0m                     

                       Computation: 59354 steps/s (collection: 1.567s, learning 0.089s)
             Mean action noise std: 2.72
          Mean value_function loss: 24.2663
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 41.7008
                       Mean reward: 760.67
               Mean episode length: 247.76
    Episode_Reward/reaching_object: 0.7300
    Episode_Reward/rotating_object: 152.4669
        Episode_Reward/action_rate: -0.0354
          Episode_Reward/joint_vel: -0.0052
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 101646336
                    Iteration time: 1.66s
                      Time elapsed: 00:33:34
                               ETA: 00:15:09

################################################################################
                     [1m Learning iteration 1034/1500 [0m                     

                       Computation: 54552 steps/s (collection: 1.617s, learning 0.185s)
             Mean action noise std: 2.72
          Mean value_function loss: 26.2509
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 41.7044
                       Mean reward: 768.27
               Mean episode length: 246.13
    Episode_Reward/reaching_object: 0.7175
    Episode_Reward/rotating_object: 150.2610
        Episode_Reward/action_rate: -0.0350
          Episode_Reward/joint_vel: -0.0049
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 101744640
                    Iteration time: 1.80s
                      Time elapsed: 00:33:36
                               ETA: 00:15:07

################################################################################
                     [1m Learning iteration 1035/1500 [0m                     

                       Computation: 59831 steps/s (collection: 1.554s, learning 0.089s)
             Mean action noise std: 2.72
          Mean value_function loss: 28.8627
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 41.7145
                       Mean reward: 733.31
               Mean episode length: 243.23
    Episode_Reward/reaching_object: 0.7206
    Episode_Reward/rotating_object: 150.0492
        Episode_Reward/action_rate: -0.0353
          Episode_Reward/joint_vel: -0.0052
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 101842944
                    Iteration time: 1.64s
                      Time elapsed: 00:33:38
                               ETA: 00:15:05

################################################################################
                     [1m Learning iteration 1036/1500 [0m                     

                       Computation: 58367 steps/s (collection: 1.596s, learning 0.089s)
             Mean action noise std: 2.73
          Mean value_function loss: 24.2139
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 41.7263
                       Mean reward: 759.10
               Mean episode length: 248.19
    Episode_Reward/reaching_object: 0.7291
    Episode_Reward/rotating_object: 153.5013
        Episode_Reward/action_rate: -0.0356
          Episode_Reward/joint_vel: -0.0052
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 101941248
                    Iteration time: 1.68s
                      Time elapsed: 00:33:39
                               ETA: 00:15:03

################################################################################
                     [1m Learning iteration 1037/1500 [0m                     

                       Computation: 57652 steps/s (collection: 1.569s, learning 0.136s)
             Mean action noise std: 2.73
          Mean value_function loss: 30.8188
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 41.7337
                       Mean reward: 760.15
               Mean episode length: 247.66
    Episode_Reward/reaching_object: 0.7232
    Episode_Reward/rotating_object: 152.9269
        Episode_Reward/action_rate: -0.0353
          Episode_Reward/joint_vel: -0.0050
      Episode_Termination/time_out: 17.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 102039552
                    Iteration time: 1.71s
                      Time elapsed: 00:33:41
                               ETA: 00:15:01

################################################################################
                     [1m Learning iteration 1038/1500 [0m                     

                       Computation: 58877 steps/s (collection: 1.563s, learning 0.106s)
             Mean action noise std: 2.73
          Mean value_function loss: 27.1275
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 41.7445
                       Mean reward: 759.13
               Mean episode length: 245.85
    Episode_Reward/reaching_object: 0.7231
    Episode_Reward/rotating_object: 153.7916
        Episode_Reward/action_rate: -0.0356
          Episode_Reward/joint_vel: -0.0050
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 102137856
                    Iteration time: 1.67s
                      Time elapsed: 00:33:43
                               ETA: 00:14:59

################################################################################
                     [1m Learning iteration 1039/1500 [0m                     

                       Computation: 58229 steps/s (collection: 1.578s, learning 0.111s)
             Mean action noise std: 2.73
          Mean value_function loss: 30.8061
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 41.7503
                       Mean reward: 783.39
               Mean episode length: 247.80
    Episode_Reward/reaching_object: 0.7137
    Episode_Reward/rotating_object: 151.6172
        Episode_Reward/action_rate: -0.0354
          Episode_Reward/joint_vel: -0.0052
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 102236160
                    Iteration time: 1.69s
                      Time elapsed: 00:33:44
                               ETA: 00:14:57

################################################################################
                     [1m Learning iteration 1040/1500 [0m                     

                       Computation: 57862 steps/s (collection: 1.564s, learning 0.135s)
             Mean action noise std: 2.73
          Mean value_function loss: 24.4488
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 41.7611
                       Mean reward: 794.24
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7217
    Episode_Reward/rotating_object: 153.9057
        Episode_Reward/action_rate: -0.0357
          Episode_Reward/joint_vel: -0.0052
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 102334464
                    Iteration time: 1.70s
                      Time elapsed: 00:33:46
                               ETA: 00:14:55

################################################################################
                     [1m Learning iteration 1041/1500 [0m                     

                       Computation: 59238 steps/s (collection: 1.569s, learning 0.090s)
             Mean action noise std: 2.73
          Mean value_function loss: 25.1448
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 41.7692
                       Mean reward: 766.90
               Mean episode length: 248.09
    Episode_Reward/reaching_object: 0.7111
    Episode_Reward/rotating_object: 150.9576
        Episode_Reward/action_rate: -0.0357
          Episode_Reward/joint_vel: -0.0050
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 102432768
                    Iteration time: 1.66s
                      Time elapsed: 00:33:48
                               ETA: 00:14:53

################################################################################
                     [1m Learning iteration 1042/1500 [0m                     

                       Computation: 58478 steps/s (collection: 1.580s, learning 0.101s)
             Mean action noise std: 2.74
          Mean value_function loss: 22.3311
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 41.7799
                       Mean reward: 729.76
               Mean episode length: 245.86
    Episode_Reward/reaching_object: 0.7103
    Episode_Reward/rotating_object: 151.4355
        Episode_Reward/action_rate: -0.0357
          Episode_Reward/joint_vel: -0.0053
      Episode_Termination/time_out: 17.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 102531072
                    Iteration time: 1.68s
                      Time elapsed: 00:33:49
                               ETA: 00:14:51

################################################################################
                     [1m Learning iteration 1043/1500 [0m                     

                       Computation: 59414 steps/s (collection: 1.546s, learning 0.108s)
             Mean action noise std: 2.74
          Mean value_function loss: 26.3750
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 41.7946
                       Mean reward: 751.42
               Mean episode length: 248.47
    Episode_Reward/reaching_object: 0.7071
    Episode_Reward/rotating_object: 150.6639
        Episode_Reward/action_rate: -0.0358
          Episode_Reward/joint_vel: -0.0053
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 102629376
                    Iteration time: 1.65s
                      Time elapsed: 00:33:51
                               ETA: 00:14:49

################################################################################
                     [1m Learning iteration 1044/1500 [0m                     

                       Computation: 59014 steps/s (collection: 1.578s, learning 0.088s)
             Mean action noise std: 2.74
          Mean value_function loss: 25.5411
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 41.8054
                       Mean reward: 767.25
               Mean episode length: 248.37
    Episode_Reward/reaching_object: 0.7063
    Episode_Reward/rotating_object: 151.4619
        Episode_Reward/action_rate: -0.0358
          Episode_Reward/joint_vel: -0.0052
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 102727680
                    Iteration time: 1.67s
                      Time elapsed: 00:33:53
                               ETA: 00:14:47

################################################################################
                     [1m Learning iteration 1045/1500 [0m                     

                       Computation: 59818 steps/s (collection: 1.552s, learning 0.092s)
             Mean action noise std: 2.74
          Mean value_function loss: 26.3738
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 41.8126
                       Mean reward: 741.87
               Mean episode length: 247.92
    Episode_Reward/reaching_object: 0.6977
    Episode_Reward/rotating_object: 148.4553
        Episode_Reward/action_rate: -0.0359
          Episode_Reward/joint_vel: -0.0057
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 102825984
                    Iteration time: 1.64s
                      Time elapsed: 00:33:54
                               ETA: 00:14:45

################################################################################
                     [1m Learning iteration 1046/1500 [0m                     

                       Computation: 58211 steps/s (collection: 1.565s, learning 0.124s)
             Mean action noise std: 2.74
          Mean value_function loss: 23.4456
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 41.8189
                       Mean reward: 765.06
               Mean episode length: 245.97
    Episode_Reward/reaching_object: 0.7019
    Episode_Reward/rotating_object: 151.4395
        Episode_Reward/action_rate: -0.0360
          Episode_Reward/joint_vel: -0.0053
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 102924288
                    Iteration time: 1.69s
                      Time elapsed: 00:33:56
                               ETA: 00:14:43

################################################################################
                     [1m Learning iteration 1047/1500 [0m                     

                       Computation: 59507 steps/s (collection: 1.563s, learning 0.089s)
             Mean action noise std: 2.75
          Mean value_function loss: 29.1081
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 41.8231
                       Mean reward: 761.95
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7005
    Episode_Reward/rotating_object: 150.5950
        Episode_Reward/action_rate: -0.0363
          Episode_Reward/joint_vel: -0.0058
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 103022592
                    Iteration time: 1.65s
                      Time elapsed: 00:33:58
                               ETA: 00:14:41

################################################################################
                     [1m Learning iteration 1048/1500 [0m                     

                       Computation: 59265 steps/s (collection: 1.568s, learning 0.090s)
             Mean action noise std: 2.75
          Mean value_function loss: 20.9521
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 41.8289
                       Mean reward: 740.53
               Mean episode length: 248.04
    Episode_Reward/reaching_object: 0.6949
    Episode_Reward/rotating_object: 149.3932
        Episode_Reward/action_rate: -0.0363
          Episode_Reward/joint_vel: -0.0055
      Episode_Termination/time_out: 17.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 103120896
                    Iteration time: 1.66s
                      Time elapsed: 00:33:59
                               ETA: 00:14:38

################################################################################
                     [1m Learning iteration 1049/1500 [0m                     

                       Computation: 58613 steps/s (collection: 1.576s, learning 0.102s)
             Mean action noise std: 2.75
          Mean value_function loss: 25.8007
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 41.8368
                       Mean reward: 751.96
               Mean episode length: 247.83
    Episode_Reward/reaching_object: 0.6981
    Episode_Reward/rotating_object: 150.8595
        Episode_Reward/action_rate: -0.0362
          Episode_Reward/joint_vel: -0.0054
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 103219200
                    Iteration time: 1.68s
                      Time elapsed: 00:34:01
                               ETA: 00:14:36

################################################################################
                     [1m Learning iteration 1050/1500 [0m                     

                       Computation: 59793 steps/s (collection: 1.545s, learning 0.099s)
             Mean action noise std: 2.75
          Mean value_function loss: 23.6234
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 41.8414
                       Mean reward: 794.43
               Mean episode length: 248.36
    Episode_Reward/reaching_object: 0.6976
    Episode_Reward/rotating_object: 153.0616
        Episode_Reward/action_rate: -0.0364
          Episode_Reward/joint_vel: -0.0052
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 103317504
                    Iteration time: 1.64s
                      Time elapsed: 00:34:03
                               ETA: 00:14:34

################################################################################
                     [1m Learning iteration 1051/1500 [0m                     

                       Computation: 55646 steps/s (collection: 1.658s, learning 0.109s)
             Mean action noise std: 2.75
          Mean value_function loss: 20.3559
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 41.8455
                       Mean reward: 781.89
               Mean episode length: 247.80
    Episode_Reward/reaching_object: 0.7010
    Episode_Reward/rotating_object: 154.6185
        Episode_Reward/action_rate: -0.0367
          Episode_Reward/joint_vel: -0.0051
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 103415808
                    Iteration time: 1.77s
                      Time elapsed: 00:34:04
                               ETA: 00:14:32

################################################################################
                     [1m Learning iteration 1052/1500 [0m                     

                       Computation: 57333 steps/s (collection: 1.581s, learning 0.134s)
             Mean action noise std: 2.75
          Mean value_function loss: 19.8523
               Mean surrogate loss: -0.0005
                 Mean entropy loss: 41.8505
                       Mean reward: 762.48
               Mean episode length: 248.43
    Episode_Reward/reaching_object: 0.6991
    Episode_Reward/rotating_object: 155.1365
        Episode_Reward/action_rate: -0.0368
          Episode_Reward/joint_vel: -0.0056
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 103514112
                    Iteration time: 1.71s
                      Time elapsed: 00:34:06
                               ETA: 00:14:30

################################################################################
                     [1m Learning iteration 1053/1500 [0m                     

                       Computation: 56360 steps/s (collection: 1.587s, learning 0.158s)
             Mean action noise std: 2.75
          Mean value_function loss: 21.0536
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 41.8556
                       Mean reward: 776.53
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6875
    Episode_Reward/rotating_object: 151.5549
        Episode_Reward/action_rate: -0.0366
          Episode_Reward/joint_vel: -0.0056
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 103612416
                    Iteration time: 1.74s
                      Time elapsed: 00:34:08
                               ETA: 00:14:28

################################################################################
                     [1m Learning iteration 1054/1500 [0m                     

                       Computation: 59465 steps/s (collection: 1.562s, learning 0.092s)
             Mean action noise std: 2.75
          Mean value_function loss: 19.9529
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 41.8619
                       Mean reward: 774.57
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6904
    Episode_Reward/rotating_object: 152.2619
        Episode_Reward/action_rate: -0.0368
          Episode_Reward/joint_vel: -0.0055
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 103710720
                    Iteration time: 1.65s
                      Time elapsed: 00:34:10
                               ETA: 00:14:26

################################################################################
                     [1m Learning iteration 1055/1500 [0m                     

                       Computation: 57350 steps/s (collection: 1.610s, learning 0.104s)
             Mean action noise std: 2.76
          Mean value_function loss: 20.7231
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 41.8672
                       Mean reward: 761.97
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6812
    Episode_Reward/rotating_object: 151.1784
        Episode_Reward/action_rate: -0.0365
          Episode_Reward/joint_vel: -0.0053
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 103809024
                    Iteration time: 1.71s
                      Time elapsed: 00:34:11
                               ETA: 00:14:24

################################################################################
                     [1m Learning iteration 1056/1500 [0m                     

                       Computation: 56619 steps/s (collection: 1.624s, learning 0.112s)
             Mean action noise std: 2.76
          Mean value_function loss: 20.4716
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 41.8712
                       Mean reward: 755.25
               Mean episode length: 248.04
    Episode_Reward/reaching_object: 0.6885
    Episode_Reward/rotating_object: 150.7548
        Episode_Reward/action_rate: -0.0368
          Episode_Reward/joint_vel: -0.0058
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 103907328
                    Iteration time: 1.74s
                      Time elapsed: 00:34:13
                               ETA: 00:14:22

################################################################################
                     [1m Learning iteration 1057/1500 [0m                     

                       Computation: 59241 steps/s (collection: 1.562s, learning 0.098s)
             Mean action noise std: 2.76
          Mean value_function loss: 24.0343
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 41.8778
                       Mean reward: 780.68
               Mean episode length: 247.69
    Episode_Reward/reaching_object: 0.6923
    Episode_Reward/rotating_object: 152.9928
        Episode_Reward/action_rate: -0.0367
          Episode_Reward/joint_vel: -0.0051
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 104005632
                    Iteration time: 1.66s
                      Time elapsed: 00:34:15
                               ETA: 00:14:20

################################################################################
                     [1m Learning iteration 1058/1500 [0m                     

                       Computation: 59199 steps/s (collection: 1.571s, learning 0.090s)
             Mean action noise std: 2.76
          Mean value_function loss: 23.3158
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 41.8847
                       Mean reward: 751.88
               Mean episode length: 245.57
    Episode_Reward/reaching_object: 0.6852
    Episode_Reward/rotating_object: 150.2850
        Episode_Reward/action_rate: -0.0365
          Episode_Reward/joint_vel: -0.0048
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 104103936
                    Iteration time: 1.66s
                      Time elapsed: 00:34:16
                               ETA: 00:14:18

################################################################################
                     [1m Learning iteration 1059/1500 [0m                     

                       Computation: 59187 steps/s (collection: 1.569s, learning 0.092s)
             Mean action noise std: 2.76
          Mean value_function loss: 25.2519
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 41.8937
                       Mean reward: 766.67
               Mean episode length: 247.76
    Episode_Reward/reaching_object: 0.6856
    Episode_Reward/rotating_object: 148.7160
        Episode_Reward/action_rate: -0.0366
          Episode_Reward/joint_vel: -0.0054
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 104202240
                    Iteration time: 1.66s
                      Time elapsed: 00:34:18
                               ETA: 00:14:16

################################################################################
                     [1m Learning iteration 1060/1500 [0m                     

                       Computation: 57528 steps/s (collection: 1.617s, learning 0.091s)
             Mean action noise std: 2.76
          Mean value_function loss: 25.3985
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 41.9049
                       Mean reward: 754.12
               Mean episode length: 245.35
    Episode_Reward/reaching_object: 0.7007
    Episode_Reward/rotating_object: 152.0347
        Episode_Reward/action_rate: -0.0369
          Episode_Reward/joint_vel: -0.0049
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 104300544
                    Iteration time: 1.71s
                      Time elapsed: 00:34:20
                               ETA: 00:14:14

################################################################################
                     [1m Learning iteration 1061/1500 [0m                     

                       Computation: 57650 steps/s (collection: 1.608s, learning 0.097s)
             Mean action noise std: 2.76
          Mean value_function loss: 16.4564
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 41.9102
                       Mean reward: 772.18
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6999
    Episode_Reward/rotating_object: 151.7801
        Episode_Reward/action_rate: -0.0370
          Episode_Reward/joint_vel: -0.0050
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 104398848
                    Iteration time: 1.71s
                      Time elapsed: 00:34:21
                               ETA: 00:14:12

################################################################################
                     [1m Learning iteration 1062/1500 [0m                     

                       Computation: 56566 steps/s (collection: 1.581s, learning 0.157s)
             Mean action noise std: 2.77
          Mean value_function loss: 19.8748
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 41.9148
                       Mean reward: 742.20
               Mean episode length: 247.68
    Episode_Reward/reaching_object: 0.7058
    Episode_Reward/rotating_object: 151.7001
        Episode_Reward/action_rate: -0.0369
          Episode_Reward/joint_vel: -0.0058
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 104497152
                    Iteration time: 1.74s
                      Time elapsed: 00:34:23
                               ETA: 00:14:10

################################################################################
                     [1m Learning iteration 1063/1500 [0m                     

                       Computation: 58663 steps/s (collection: 1.584s, learning 0.092s)
             Mean action noise std: 2.77
          Mean value_function loss: 17.8296
               Mean surrogate loss: 0.0031
                 Mean entropy loss: 41.9222
                       Mean reward: 773.67
               Mean episode length: 247.69
    Episode_Reward/reaching_object: 0.7055
    Episode_Reward/rotating_object: 152.0266
        Episode_Reward/action_rate: -0.0369
          Episode_Reward/joint_vel: -0.0053
      Episode_Termination/time_out: 17.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 104595456
                    Iteration time: 1.68s
                      Time elapsed: 00:34:25
                               ETA: 00:14:08

################################################################################
                     [1m Learning iteration 1064/1500 [0m                     

                       Computation: 58709 steps/s (collection: 1.582s, learning 0.092s)
             Mean action noise std: 2.77
          Mean value_function loss: 17.4502
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 41.9253
                       Mean reward: 780.64
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7085
    Episode_Reward/rotating_object: 153.5640
        Episode_Reward/action_rate: -0.0369
          Episode_Reward/joint_vel: -0.0053
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 104693760
                    Iteration time: 1.67s
                      Time elapsed: 00:34:27
                               ETA: 00:14:06

################################################################################
                     [1m Learning iteration 1065/1500 [0m                     

                       Computation: 58534 steps/s (collection: 1.569s, learning 0.111s)
             Mean action noise std: 2.77
          Mean value_function loss: 24.2996
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 41.9367
                       Mean reward: 766.52
               Mean episode length: 247.87
    Episode_Reward/reaching_object: 0.7022
    Episode_Reward/rotating_object: 152.0746
        Episode_Reward/action_rate: -0.0369
          Episode_Reward/joint_vel: -0.0049
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 104792064
                    Iteration time: 1.68s
                      Time elapsed: 00:34:28
                               ETA: 00:14:04

################################################################################
                     [1m Learning iteration 1066/1500 [0m                     

                       Computation: 60255 steps/s (collection: 1.541s, learning 0.090s)
             Mean action noise std: 2.77
          Mean value_function loss: 22.5878
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 41.9440
                       Mean reward: 760.91
               Mean episode length: 245.93
    Episode_Reward/reaching_object: 0.7080
    Episode_Reward/rotating_object: 154.4622
        Episode_Reward/action_rate: -0.0371
          Episode_Reward/joint_vel: -0.0052
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 104890368
                    Iteration time: 1.63s
                      Time elapsed: 00:34:30
                               ETA: 00:14:02

################################################################################
                     [1m Learning iteration 1067/1500 [0m                     

                       Computation: 57754 steps/s (collection: 1.592s, learning 0.111s)
             Mean action noise std: 2.77
          Mean value_function loss: 15.8214
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 41.9480
                       Mean reward: 766.64
               Mean episode length: 247.98
    Episode_Reward/reaching_object: 0.7094
    Episode_Reward/rotating_object: 154.6231
        Episode_Reward/action_rate: -0.0371
          Episode_Reward/joint_vel: -0.0054
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 104988672
                    Iteration time: 1.70s
                      Time elapsed: 00:34:32
                               ETA: 00:14:00

################################################################################
                     [1m Learning iteration 1068/1500 [0m                     

                       Computation: 58240 steps/s (collection: 1.575s, learning 0.113s)
             Mean action noise std: 2.77
          Mean value_function loss: 22.3312
               Mean surrogate loss: -0.0007
                 Mean entropy loss: 41.9545
                       Mean reward: 765.92
               Mean episode length: 245.54
    Episode_Reward/reaching_object: 0.7064
    Episode_Reward/rotating_object: 153.8334
        Episode_Reward/action_rate: -0.0371
          Episode_Reward/joint_vel: -0.0049
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 105086976
                    Iteration time: 1.69s
                      Time elapsed: 00:34:33
                               ETA: 00:13:58

################################################################################
                     [1m Learning iteration 1069/1500 [0m                     

                       Computation: 58006 steps/s (collection: 1.591s, learning 0.104s)
             Mean action noise std: 2.78
          Mean value_function loss: 20.0762
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 41.9580
                       Mean reward: 767.63
               Mean episode length: 247.88
    Episode_Reward/reaching_object: 0.6964
    Episode_Reward/rotating_object: 150.9245
        Episode_Reward/action_rate: -0.0371
          Episode_Reward/joint_vel: -0.0052
      Episode_Termination/time_out: 17.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 105185280
                    Iteration time: 1.69s
                      Time elapsed: 00:34:35
                               ETA: 00:13:55

################################################################################
                     [1m Learning iteration 1070/1500 [0m                     

                       Computation: 57452 steps/s (collection: 1.596s, learning 0.115s)
             Mean action noise std: 2.78
          Mean value_function loss: 23.2321
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 41.9656
                       Mean reward: 746.96
               Mean episode length: 247.73
    Episode_Reward/reaching_object: 0.7001
    Episode_Reward/rotating_object: 150.4386
        Episode_Reward/action_rate: -0.0370
          Episode_Reward/joint_vel: -0.0049
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 105283584
                    Iteration time: 1.71s
                      Time elapsed: 00:34:37
                               ETA: 00:13:53

################################################################################
                     [1m Learning iteration 1071/1500 [0m                     

                       Computation: 59068 steps/s (collection: 1.577s, learning 0.088s)
             Mean action noise std: 2.78
          Mean value_function loss: 20.4511
               Mean surrogate loss: 0.0082
                 Mean entropy loss: 41.9729
                       Mean reward: 764.83
               Mean episode length: 246.40
    Episode_Reward/reaching_object: 0.7062
    Episode_Reward/rotating_object: 153.4505
        Episode_Reward/action_rate: -0.0372
          Episode_Reward/joint_vel: -0.0048
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 105381888
                    Iteration time: 1.66s
                      Time elapsed: 00:34:38
                               ETA: 00:13:51

################################################################################
                     [1m Learning iteration 1072/1500 [0m                     

                       Computation: 57162 steps/s (collection: 1.616s, learning 0.104s)
             Mean action noise std: 2.78
          Mean value_function loss: 15.6658
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 41.9735
                       Mean reward: 764.37
               Mean episode length: 247.86
    Episode_Reward/reaching_object: 0.7071
    Episode_Reward/rotating_object: 153.3266
        Episode_Reward/action_rate: -0.0374
          Episode_Reward/joint_vel: -0.0050
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 105480192
                    Iteration time: 1.72s
                      Time elapsed: 00:34:40
                               ETA: 00:13:49

################################################################################
                     [1m Learning iteration 1073/1500 [0m                     

                       Computation: 57865 steps/s (collection: 1.601s, learning 0.098s)
             Mean action noise std: 2.78
          Mean value_function loss: 20.9280
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 41.9733
                       Mean reward: 749.06
               Mean episode length: 247.79
    Episode_Reward/reaching_object: 0.7088
    Episode_Reward/rotating_object: 154.2940
        Episode_Reward/action_rate: -0.0374
          Episode_Reward/joint_vel: -0.0049
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 105578496
                    Iteration time: 1.70s
                      Time elapsed: 00:34:42
                               ETA: 00:13:47

################################################################################
                     [1m Learning iteration 1074/1500 [0m                     

                       Computation: 59228 steps/s (collection: 1.570s, learning 0.090s)
             Mean action noise std: 2.78
          Mean value_function loss: 23.5605
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 41.9770
                       Mean reward: 751.55
               Mean episode length: 241.16
    Episode_Reward/reaching_object: 0.6979
    Episode_Reward/rotating_object: 151.1617
        Episode_Reward/action_rate: -0.0371
          Episode_Reward/joint_vel: -0.0049
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 105676800
                    Iteration time: 1.66s
                      Time elapsed: 00:34:43
                               ETA: 00:13:45

################################################################################
                     [1m Learning iteration 1075/1500 [0m                     

                       Computation: 58068 steps/s (collection: 1.599s, learning 0.094s)
             Mean action noise std: 2.78
          Mean value_function loss: 18.2266
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 41.9847
                       Mean reward: 777.73
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7118
    Episode_Reward/rotating_object: 154.0759
        Episode_Reward/action_rate: -0.0377
          Episode_Reward/joint_vel: -0.0052
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 105775104
                    Iteration time: 1.69s
                      Time elapsed: 00:34:45
                               ETA: 00:13:43

################################################################################
                     [1m Learning iteration 1076/1500 [0m                     

                       Computation: 57357 steps/s (collection: 1.592s, learning 0.122s)
             Mean action noise std: 2.78
          Mean value_function loss: 17.3868
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 41.9894
                       Mean reward: 767.44
               Mean episode length: 248.09
    Episode_Reward/reaching_object: 0.7081
    Episode_Reward/rotating_object: 153.9527
        Episode_Reward/action_rate: -0.0375
          Episode_Reward/joint_vel: -0.0052
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 105873408
                    Iteration time: 1.71s
                      Time elapsed: 00:34:47
                               ETA: 00:13:41

################################################################################
                     [1m Learning iteration 1077/1500 [0m                     

                       Computation: 58622 steps/s (collection: 1.580s, learning 0.097s)
             Mean action noise std: 2.78
          Mean value_function loss: 16.7082
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 41.9925
                       Mean reward: 779.37
               Mean episode length: 247.67
    Episode_Reward/reaching_object: 0.7126
    Episode_Reward/rotating_object: 153.5894
        Episode_Reward/action_rate: -0.0374
          Episode_Reward/joint_vel: -0.0050
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 105971712
                    Iteration time: 1.68s
                      Time elapsed: 00:34:48
                               ETA: 00:13:39

################################################################################
                     [1m Learning iteration 1078/1500 [0m                     

                       Computation: 53765 steps/s (collection: 1.721s, learning 0.108s)
             Mean action noise std: 2.78
          Mean value_function loss: 20.1010
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 41.9936
                       Mean reward: 789.69
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7246
    Episode_Reward/rotating_object: 156.7499
        Episode_Reward/action_rate: -0.0377
          Episode_Reward/joint_vel: -0.0051
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 106070016
                    Iteration time: 1.83s
                      Time elapsed: 00:34:50
                               ETA: 00:13:37

################################################################################
                     [1m Learning iteration 1079/1500 [0m                     

                       Computation: 57907 steps/s (collection: 1.578s, learning 0.120s)
             Mean action noise std: 2.79
          Mean value_function loss: 25.4880
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 41.9974
                       Mean reward: 741.76
               Mean episode length: 241.61
    Episode_Reward/reaching_object: 0.7153
    Episode_Reward/rotating_object: 153.3474
        Episode_Reward/action_rate: -0.0374
          Episode_Reward/joint_vel: -0.0052
      Episode_Termination/time_out: 17.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 106168320
                    Iteration time: 1.70s
                      Time elapsed: 00:34:52
                               ETA: 00:13:35

################################################################################
                     [1m Learning iteration 1080/1500 [0m                     

                       Computation: 58193 steps/s (collection: 1.600s, learning 0.089s)
             Mean action noise std: 2.79
          Mean value_function loss: 23.0814
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 42.0041
                       Mean reward: 789.46
               Mean episode length: 247.75
    Episode_Reward/reaching_object: 0.7195
    Episode_Reward/rotating_object: 154.7589
        Episode_Reward/action_rate: -0.0375
          Episode_Reward/joint_vel: -0.0050
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 106266624
                    Iteration time: 1.69s
                      Time elapsed: 00:34:54
                               ETA: 00:13:33

################################################################################
                     [1m Learning iteration 1081/1500 [0m                     

                       Computation: 55039 steps/s (collection: 1.659s, learning 0.127s)
             Mean action noise std: 2.79
          Mean value_function loss: 15.7305
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 42.0133
                       Mean reward: 775.05
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7220
    Episode_Reward/rotating_object: 154.9351
        Episode_Reward/action_rate: -0.0378
          Episode_Reward/joint_vel: -0.0050
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 106364928
                    Iteration time: 1.79s
                      Time elapsed: 00:34:55
                               ETA: 00:13:31

################################################################################
                     [1m Learning iteration 1082/1500 [0m                     

                       Computation: 55420 steps/s (collection: 1.665s, learning 0.109s)
             Mean action noise std: 2.79
          Mean value_function loss: 18.9665
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 42.0205
                       Mean reward: 784.58
               Mean episode length: 247.77
    Episode_Reward/reaching_object: 0.7177
    Episode_Reward/rotating_object: 154.5578
        Episode_Reward/action_rate: -0.0374
          Episode_Reward/joint_vel: -0.0050
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 106463232
                    Iteration time: 1.77s
                      Time elapsed: 00:34:57
                               ETA: 00:13:29

################################################################################
                     [1m Learning iteration 1083/1500 [0m                     

                       Computation: 58380 steps/s (collection: 1.592s, learning 0.092s)
             Mean action noise std: 2.79
          Mean value_function loss: 23.5857
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 42.0274
                       Mean reward: 773.72
               Mean episode length: 247.90
    Episode_Reward/reaching_object: 0.7069
    Episode_Reward/rotating_object: 150.9677
        Episode_Reward/action_rate: -0.0374
          Episode_Reward/joint_vel: -0.0054
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 106561536
                    Iteration time: 1.68s
                      Time elapsed: 00:34:59
                               ETA: 00:13:27

################################################################################
                     [1m Learning iteration 1084/1500 [0m                     

                       Computation: 56951 steps/s (collection: 1.625s, learning 0.102s)
             Mean action noise std: 2.79
          Mean value_function loss: 15.9898
               Mean surrogate loss: -0.0003
                 Mean entropy loss: 42.0357
                       Mean reward: 772.63
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7215
    Episode_Reward/rotating_object: 155.8302
        Episode_Reward/action_rate: -0.0377
          Episode_Reward/joint_vel: -0.0052
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 106659840
                    Iteration time: 1.73s
                      Time elapsed: 00:35:01
                               ETA: 00:13:25

################################################################################
                     [1m Learning iteration 1085/1500 [0m                     

                       Computation: 57783 steps/s (collection: 1.604s, learning 0.097s)
             Mean action noise std: 2.79
          Mean value_function loss: 20.4149
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 42.0402
                       Mean reward: 787.40
               Mean episode length: 248.31
    Episode_Reward/reaching_object: 0.7163
    Episode_Reward/rotating_object: 154.3001
        Episode_Reward/action_rate: -0.0377
          Episode_Reward/joint_vel: -0.0052
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 106758144
                    Iteration time: 1.70s
                      Time elapsed: 00:35:02
                               ETA: 00:13:23

################################################################################
                     [1m Learning iteration 1086/1500 [0m                     

                       Computation: 57009 steps/s (collection: 1.589s, learning 0.135s)
             Mean action noise std: 2.80
          Mean value_function loss: 18.6259
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 42.0432
                       Mean reward: 756.59
               Mean episode length: 245.76
    Episode_Reward/reaching_object: 0.7119
    Episode_Reward/rotating_object: 153.3684
        Episode_Reward/action_rate: -0.0374
          Episode_Reward/joint_vel: -0.0049
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 106856448
                    Iteration time: 1.72s
                      Time elapsed: 00:35:04
                               ETA: 00:13:21

################################################################################
                     [1m Learning iteration 1087/1500 [0m                     

                       Computation: 57791 steps/s (collection: 1.606s, learning 0.095s)
             Mean action noise std: 2.80
          Mean value_function loss: 16.8665
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 42.0481
                       Mean reward: 790.95
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7156
    Episode_Reward/rotating_object: 155.1720
        Episode_Reward/action_rate: -0.0377
          Episode_Reward/joint_vel: -0.0049
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 106954752
                    Iteration time: 1.70s
                      Time elapsed: 00:35:06
                               ETA: 00:13:19

################################################################################
                     [1m Learning iteration 1088/1500 [0m                     

                       Computation: 56803 steps/s (collection: 1.618s, learning 0.113s)
             Mean action noise std: 2.80
          Mean value_function loss: 17.9383
               Mean surrogate loss: -0.0006
                 Mean entropy loss: 42.0533
                       Mean reward: 763.00
               Mean episode length: 246.01
    Episode_Reward/reaching_object: 0.7036
    Episode_Reward/rotating_object: 151.1545
        Episode_Reward/action_rate: -0.0374
          Episode_Reward/joint_vel: -0.0051
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 107053056
                    Iteration time: 1.73s
                      Time elapsed: 00:35:08
                               ETA: 00:13:17

################################################################################
                     [1m Learning iteration 1089/1500 [0m                     

                       Computation: 55846 steps/s (collection: 1.623s, learning 0.137s)
             Mean action noise std: 2.80
          Mean value_function loss: 23.3198
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 42.0576
                       Mean reward: 774.84
               Mean episode length: 247.83
    Episode_Reward/reaching_object: 0.7178
    Episode_Reward/rotating_object: 154.8780
        Episode_Reward/action_rate: -0.0378
          Episode_Reward/joint_vel: -0.0049
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 107151360
                    Iteration time: 1.76s
                      Time elapsed: 00:35:09
                               ETA: 00:13:15

################################################################################
                     [1m Learning iteration 1090/1500 [0m                     

                       Computation: 57937 steps/s (collection: 1.605s, learning 0.092s)
             Mean action noise std: 2.80
          Mean value_function loss: 20.4222
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 42.0657
                       Mean reward: 783.84
               Mean episode length: 247.95
    Episode_Reward/reaching_object: 0.7148
    Episode_Reward/rotating_object: 153.9225
        Episode_Reward/action_rate: -0.0375
          Episode_Reward/joint_vel: -0.0049
      Episode_Termination/time_out: 17.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 107249664
                    Iteration time: 1.70s
                      Time elapsed: 00:35:11
                               ETA: 00:13:13

################################################################################
                     [1m Learning iteration 1091/1500 [0m                     

                       Computation: 56600 steps/s (collection: 1.644s, learning 0.093s)
             Mean action noise std: 2.80
          Mean value_function loss: 23.2102
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 42.0712
                       Mean reward: 769.75
               Mean episode length: 247.88
    Episode_Reward/reaching_object: 0.7192
    Episode_Reward/rotating_object: 155.6075
        Episode_Reward/action_rate: -0.0379
          Episode_Reward/joint_vel: -0.0051
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 107347968
                    Iteration time: 1.74s
                      Time elapsed: 00:35:13
                               ETA: 00:13:11

################################################################################
                     [1m Learning iteration 1092/1500 [0m                     

                       Computation: 57467 steps/s (collection: 1.613s, learning 0.098s)
             Mean action noise std: 2.80
          Mean value_function loss: 16.9396
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 42.0782
                       Mean reward: 774.38
               Mean episode length: 246.01
    Episode_Reward/reaching_object: 0.7181
    Episode_Reward/rotating_object: 154.2013
        Episode_Reward/action_rate: -0.0377
          Episode_Reward/joint_vel: -0.0051
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 107446272
                    Iteration time: 1.71s
                      Time elapsed: 00:35:14
                               ETA: 00:13:09

################################################################################
                     [1m Learning iteration 1093/1500 [0m                     

                       Computation: 54994 steps/s (collection: 1.644s, learning 0.143s)
             Mean action noise std: 2.81
          Mean value_function loss: 16.0696
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 42.0836
                       Mean reward: 775.54
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7215
    Episode_Reward/rotating_object: 154.0959
        Episode_Reward/action_rate: -0.0379
          Episode_Reward/joint_vel: -0.0050
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 107544576
                    Iteration time: 1.79s
                      Time elapsed: 00:35:16
                               ETA: 00:13:07

################################################################################
                     [1m Learning iteration 1094/1500 [0m                     

                       Computation: 57053 steps/s (collection: 1.604s, learning 0.119s)
             Mean action noise std: 2.81
          Mean value_function loss: 15.3998
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 42.0922
                       Mean reward: 772.99
               Mean episode length: 245.71
    Episode_Reward/reaching_object: 0.7216
    Episode_Reward/rotating_object: 154.6183
        Episode_Reward/action_rate: -0.0379
          Episode_Reward/joint_vel: -0.0054
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 107642880
                    Iteration time: 1.72s
                      Time elapsed: 00:35:18
                               ETA: 00:13:05

################################################################################
                     [1m Learning iteration 1095/1500 [0m                     

                       Computation: 56025 steps/s (collection: 1.637s, learning 0.118s)
             Mean action noise std: 2.81
          Mean value_function loss: 19.1145
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 42.1018
                       Mean reward: 765.16
               Mean episode length: 246.51
    Episode_Reward/reaching_object: 0.7216
    Episode_Reward/rotating_object: 154.4227
        Episode_Reward/action_rate: -0.0380
          Episode_Reward/joint_vel: -0.0054
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 107741184
                    Iteration time: 1.75s
                      Time elapsed: 00:35:20
                               ETA: 00:13:03

################################################################################
                     [1m Learning iteration 1096/1500 [0m                     

                       Computation: 57145 steps/s (collection: 1.631s, learning 0.089s)
             Mean action noise std: 2.81
          Mean value_function loss: 20.6372
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 42.1084
                       Mean reward: 776.46
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7256
    Episode_Reward/rotating_object: 154.9584
        Episode_Reward/action_rate: -0.0380
          Episode_Reward/joint_vel: -0.0050
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 107839488
                    Iteration time: 1.72s
                      Time elapsed: 00:35:21
                               ETA: 00:13:01

################################################################################
                     [1m Learning iteration 1097/1500 [0m                     

                       Computation: 57085 steps/s (collection: 1.576s, learning 0.146s)
             Mean action noise std: 2.81
          Mean value_function loss: 18.6045
               Mean surrogate loss: 0.0031
                 Mean entropy loss: 42.1153
                       Mean reward: 790.29
               Mean episode length: 247.67
    Episode_Reward/reaching_object: 0.7342
    Episode_Reward/rotating_object: 157.4049
        Episode_Reward/action_rate: -0.0381
          Episode_Reward/joint_vel: -0.0051
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 107937792
                    Iteration time: 1.72s
                      Time elapsed: 00:35:23
                               ETA: 00:12:59

################################################################################
                     [1m Learning iteration 1098/1500 [0m                     

                       Computation: 56891 steps/s (collection: 1.627s, learning 0.101s)
             Mean action noise std: 2.81
          Mean value_function loss: 17.3388
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 42.1180
                       Mean reward: 749.13
               Mean episode length: 243.29
    Episode_Reward/reaching_object: 0.7218
    Episode_Reward/rotating_object: 153.2875
        Episode_Reward/action_rate: -0.0379
          Episode_Reward/joint_vel: -0.0050
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 108036096
                    Iteration time: 1.73s
                      Time elapsed: 00:35:25
                               ETA: 00:12:57

################################################################################
                     [1m Learning iteration 1099/1500 [0m                     

                       Computation: 57133 steps/s (collection: 1.609s, learning 0.112s)
             Mean action noise std: 2.81
          Mean value_function loss: 17.1885
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 42.1233
                       Mean reward: 760.27
               Mean episode length: 248.40
    Episode_Reward/reaching_object: 0.7245
    Episode_Reward/rotating_object: 153.5391
        Episode_Reward/action_rate: -0.0382
          Episode_Reward/joint_vel: -0.0054
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 108134400
                    Iteration time: 1.72s
                      Time elapsed: 00:35:27
                               ETA: 00:12:55

################################################################################
                     [1m Learning iteration 1100/1500 [0m                     

                       Computation: 56817 steps/s (collection: 1.626s, learning 0.104s)
             Mean action noise std: 2.82
          Mean value_function loss: 20.8959
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 42.1315
                       Mean reward: 786.61
               Mean episode length: 247.67
    Episode_Reward/reaching_object: 0.7292
    Episode_Reward/rotating_object: 155.3701
        Episode_Reward/action_rate: -0.0382
          Episode_Reward/joint_vel: -0.0052
      Episode_Termination/time_out: 18.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 108232704
                    Iteration time: 1.73s
                      Time elapsed: 00:35:28
                               ETA: 00:12:53

################################################################################
                     [1m Learning iteration 1101/1500 [0m                     

                       Computation: 54128 steps/s (collection: 1.698s, learning 0.118s)
             Mean action noise std: 2.82
          Mean value_function loss: 17.3296
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 42.1406
                       Mean reward: 781.76
               Mean episode length: 247.80
    Episode_Reward/reaching_object: 0.7303
    Episode_Reward/rotating_object: 156.1887
        Episode_Reward/action_rate: -0.0381
          Episode_Reward/joint_vel: -0.0049
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 108331008
                    Iteration time: 1.82s
                      Time elapsed: 00:35:30
                               ETA: 00:12:51

################################################################################
                     [1m Learning iteration 1102/1500 [0m                     

                       Computation: 54890 steps/s (collection: 1.680s, learning 0.111s)
             Mean action noise std: 2.82
          Mean value_function loss: 23.3778
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 42.1428
                       Mean reward: 781.41
               Mean episode length: 247.79
    Episode_Reward/reaching_object: 0.7262
    Episode_Reward/rotating_object: 154.8481
        Episode_Reward/action_rate: -0.0382
          Episode_Reward/joint_vel: -0.0051
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 108429312
                    Iteration time: 1.79s
                      Time elapsed: 00:35:32
                               ETA: 00:12:49

################################################################################
                     [1m Learning iteration 1103/1500 [0m                     

                       Computation: 56955 steps/s (collection: 1.635s, learning 0.091s)
             Mean action noise std: 2.82
          Mean value_function loss: 18.0115
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 42.1423
                       Mean reward: 799.48
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7309
    Episode_Reward/rotating_object: 156.2993
        Episode_Reward/action_rate: -0.0382
          Episode_Reward/joint_vel: -0.0049
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 108527616
                    Iteration time: 1.73s
                      Time elapsed: 00:35:34
                               ETA: 00:12:47

################################################################################
                     [1m Learning iteration 1104/1500 [0m                     

                       Computation: 52297 steps/s (collection: 1.757s, learning 0.123s)
             Mean action noise std: 2.82
          Mean value_function loss: 21.7691
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 42.1471
                       Mean reward: 781.87
               Mean episode length: 247.66
    Episode_Reward/reaching_object: 0.7250
    Episode_Reward/rotating_object: 155.5374
        Episode_Reward/action_rate: -0.0379
          Episode_Reward/joint_vel: -0.0048
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 108625920
                    Iteration time: 1.88s
                      Time elapsed: 00:35:36
                               ETA: 00:12:45

################################################################################
                     [1m Learning iteration 1105/1500 [0m                     

                       Computation: 52561 steps/s (collection: 1.701s, learning 0.170s)
             Mean action noise std: 2.82
          Mean value_function loss: 22.6137
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 42.1601
                       Mean reward: 791.69
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7205
    Episode_Reward/rotating_object: 153.9659
        Episode_Reward/action_rate: -0.0382
          Episode_Reward/joint_vel: -0.0051
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 108724224
                    Iteration time: 1.87s
                      Time elapsed: 00:35:37
                               ETA: 00:12:43

################################################################################
                     [1m Learning iteration 1106/1500 [0m                     

                       Computation: 55823 steps/s (collection: 1.614s, learning 0.147s)
             Mean action noise std: 2.83
          Mean value_function loss: 25.2861
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 42.1758
                       Mean reward: 778.92
               Mean episode length: 245.82
    Episode_Reward/reaching_object: 0.7189
    Episode_Reward/rotating_object: 153.8211
        Episode_Reward/action_rate: -0.0380
          Episode_Reward/joint_vel: -0.0049
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 108822528
                    Iteration time: 1.76s
                      Time elapsed: 00:35:39
                               ETA: 00:12:41

################################################################################
                     [1m Learning iteration 1107/1500 [0m                     

                       Computation: 52873 steps/s (collection: 1.767s, learning 0.093s)
             Mean action noise std: 2.83
          Mean value_function loss: 16.3722
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 42.1939
                       Mean reward: 760.97
               Mean episode length: 245.80
    Episode_Reward/reaching_object: 0.7145
    Episode_Reward/rotating_object: 151.7697
        Episode_Reward/action_rate: -0.0381
          Episode_Reward/joint_vel: -0.0052
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 108920832
                    Iteration time: 1.86s
                      Time elapsed: 00:35:41
                               ETA: 00:12:39

################################################################################
                     [1m Learning iteration 1108/1500 [0m                     

                       Computation: 54999 steps/s (collection: 1.685s, learning 0.102s)
             Mean action noise std: 2.83
          Mean value_function loss: 20.1143
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 42.2056
                       Mean reward: 787.04
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7269
    Episode_Reward/rotating_object: 157.0796
        Episode_Reward/action_rate: -0.0384
          Episode_Reward/joint_vel: -0.0049
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 109019136
                    Iteration time: 1.79s
                      Time elapsed: 00:35:43
                               ETA: 00:12:37

################################################################################
                     [1m Learning iteration 1109/1500 [0m                     

                       Computation: 56247 steps/s (collection: 1.622s, learning 0.126s)
             Mean action noise std: 2.83
          Mean value_function loss: 19.1627
               Mean surrogate loss: -0.0005
                 Mean entropy loss: 42.2139
                       Mean reward: 741.17
               Mean episode length: 245.69
    Episode_Reward/reaching_object: 0.7134
    Episode_Reward/rotating_object: 153.0216
        Episode_Reward/action_rate: -0.0383
          Episode_Reward/joint_vel: -0.0052
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 109117440
                    Iteration time: 1.75s
                      Time elapsed: 00:35:45
                               ETA: 00:12:35

################################################################################
                     [1m Learning iteration 1110/1500 [0m                     

                       Computation: 56885 steps/s (collection: 1.602s, learning 0.126s)
             Mean action noise std: 2.83
          Mean value_function loss: 21.3552
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 42.2201
                       Mean reward: 777.20
               Mean episode length: 248.16
    Episode_Reward/reaching_object: 0.7216
    Episode_Reward/rotating_object: 155.3343
        Episode_Reward/action_rate: -0.0383
          Episode_Reward/joint_vel: -0.0048
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 109215744
                    Iteration time: 1.73s
                      Time elapsed: 00:35:46
                               ETA: 00:12:33

################################################################################
                     [1m Learning iteration 1111/1500 [0m                     

                       Computation: 54237 steps/s (collection: 1.677s, learning 0.136s)
             Mean action noise std: 2.84
          Mean value_function loss: 20.9556
               Mean surrogate loss: -0.0003
                 Mean entropy loss: 42.2253
                       Mean reward: 782.61
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7218
    Episode_Reward/rotating_object: 156.4564
        Episode_Reward/action_rate: -0.0385
          Episode_Reward/joint_vel: -0.0049
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 109314048
                    Iteration time: 1.81s
                      Time elapsed: 00:35:48
                               ETA: 00:12:31

################################################################################
                     [1m Learning iteration 1112/1500 [0m                     

                       Computation: 52809 steps/s (collection: 1.714s, learning 0.147s)
             Mean action noise std: 2.84
          Mean value_function loss: 22.8624
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 42.2299
                       Mean reward: 794.70
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7173
    Episode_Reward/rotating_object: 153.9951
        Episode_Reward/action_rate: -0.0385
          Episode_Reward/joint_vel: -0.0050
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 109412352
                    Iteration time: 1.86s
                      Time elapsed: 00:35:50
                               ETA: 00:12:29

################################################################################
                     [1m Learning iteration 1113/1500 [0m                     

                       Computation: 53110 steps/s (collection: 1.731s, learning 0.120s)
             Mean action noise std: 2.84
          Mean value_function loss: 18.9668
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 42.2368
                       Mean reward: 777.69
               Mean episode length: 247.74
    Episode_Reward/reaching_object: 0.7242
    Episode_Reward/rotating_object: 155.5522
        Episode_Reward/action_rate: -0.0386
          Episode_Reward/joint_vel: -0.0051
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 109510656
                    Iteration time: 1.85s
                      Time elapsed: 00:35:52
                               ETA: 00:12:27

################################################################################
                     [1m Learning iteration 1114/1500 [0m                     

                       Computation: 55670 steps/s (collection: 1.633s, learning 0.133s)
             Mean action noise std: 2.84
          Mean value_function loss: 17.7066
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 42.2407
                       Mean reward: 778.30
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7197
    Episode_Reward/rotating_object: 154.4470
        Episode_Reward/action_rate: -0.0387
          Episode_Reward/joint_vel: -0.0054
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 109608960
                    Iteration time: 1.77s
                      Time elapsed: 00:35:54
                               ETA: 00:12:25

################################################################################
                     [1m Learning iteration 1115/1500 [0m                     

                       Computation: 54244 steps/s (collection: 1.642s, learning 0.171s)
             Mean action noise std: 2.84
          Mean value_function loss: 15.5807
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 42.2477
                       Mean reward: 767.38
               Mean episode length: 243.13
    Episode_Reward/reaching_object: 0.7215
    Episode_Reward/rotating_object: 156.1929
        Episode_Reward/action_rate: -0.0388
          Episode_Reward/joint_vel: -0.0052
      Episode_Termination/time_out: 17.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 109707264
                    Iteration time: 1.81s
                      Time elapsed: 00:35:55
                               ETA: 00:12:23

################################################################################
                     [1m Learning iteration 1116/1500 [0m                     

                       Computation: 56042 steps/s (collection: 1.619s, learning 0.135s)
             Mean action noise std: 2.84
          Mean value_function loss: 18.7708
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 42.2616
                       Mean reward: 798.65
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7222
    Episode_Reward/rotating_object: 154.7948
        Episode_Reward/action_rate: -0.0390
          Episode_Reward/joint_vel: -0.0054
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 109805568
                    Iteration time: 1.75s
                      Time elapsed: 00:35:57
                               ETA: 00:12:21

################################################################################
                     [1m Learning iteration 1117/1500 [0m                     

                       Computation: 55511 steps/s (collection: 1.679s, learning 0.092s)
             Mean action noise std: 2.84
          Mean value_function loss: 21.2826
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 42.2697
                       Mean reward: 787.18
               Mean episode length: 247.98
    Episode_Reward/reaching_object: 0.7259
    Episode_Reward/rotating_object: 156.6970
        Episode_Reward/action_rate: -0.0389
          Episode_Reward/joint_vel: -0.0051
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 109903872
                    Iteration time: 1.77s
                      Time elapsed: 00:35:59
                               ETA: 00:12:19

################################################################################
                     [1m Learning iteration 1118/1500 [0m                     

                       Computation: 57322 steps/s (collection: 1.621s, learning 0.094s)
             Mean action noise std: 2.85
          Mean value_function loss: 20.0758
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 42.2743
                       Mean reward: 781.04
               Mean episode length: 245.64
    Episode_Reward/reaching_object: 0.7142
    Episode_Reward/rotating_object: 154.5468
        Episode_Reward/action_rate: -0.0387
          Episode_Reward/joint_vel: -0.0049
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 110002176
                    Iteration time: 1.71s
                      Time elapsed: 00:36:01
                               ETA: 00:12:17

################################################################################
                     [1m Learning iteration 1119/1500 [0m                     

                       Computation: 58295 steps/s (collection: 1.583s, learning 0.104s)
             Mean action noise std: 2.85
          Mean value_function loss: 19.9117
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 42.2776
                       Mean reward: 765.94
               Mean episode length: 245.58
    Episode_Reward/reaching_object: 0.7149
    Episode_Reward/rotating_object: 154.2594
        Episode_Reward/action_rate: -0.0387
          Episode_Reward/joint_vel: -0.0050
      Episode_Termination/time_out: 17.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 110100480
                    Iteration time: 1.69s
                      Time elapsed: 00:36:02
                               ETA: 00:12:15

################################################################################
                     [1m Learning iteration 1120/1500 [0m                     

                       Computation: 58198 steps/s (collection: 1.589s, learning 0.100s)
             Mean action noise std: 2.85
          Mean value_function loss: 18.7330
               Mean surrogate loss: -0.0006
                 Mean entropy loss: 42.2855
                       Mean reward: 788.10
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7140
    Episode_Reward/rotating_object: 155.3958
        Episode_Reward/action_rate: -0.0387
          Episode_Reward/joint_vel: -0.0054
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 110198784
                    Iteration time: 1.69s
                      Time elapsed: 00:36:04
                               ETA: 00:12:13

################################################################################
                     [1m Learning iteration 1121/1500 [0m                     

                       Computation: 56753 steps/s (collection: 1.625s, learning 0.107s)
             Mean action noise std: 2.85
          Mean value_function loss: 20.1381
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 42.2926
                       Mean reward: 762.63
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7160
    Episode_Reward/rotating_object: 154.1432
        Episode_Reward/action_rate: -0.0393
          Episode_Reward/joint_vel: -0.0053
      Episode_Termination/time_out: 17.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 110297088
                    Iteration time: 1.73s
                      Time elapsed: 00:36:06
                               ETA: 00:12:11

################################################################################
                     [1m Learning iteration 1122/1500 [0m                     

                       Computation: 57381 steps/s (collection: 1.586s, learning 0.128s)
             Mean action noise std: 2.85
          Mean value_function loss: 22.0560
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 42.2990
                       Mean reward: 772.75
               Mean episode length: 245.86
    Episode_Reward/reaching_object: 0.7039
    Episode_Reward/rotating_object: 151.7758
        Episode_Reward/action_rate: -0.0387
          Episode_Reward/joint_vel: -0.0053
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 110395392
                    Iteration time: 1.71s
                      Time elapsed: 00:36:07
                               ETA: 00:12:09

################################################################################
                     [1m Learning iteration 1123/1500 [0m                     

                       Computation: 58809 steps/s (collection: 1.581s, learning 0.090s)
             Mean action noise std: 2.85
          Mean value_function loss: 15.3420
               Mean surrogate loss: -0.0007
                 Mean entropy loss: 42.3031
                       Mean reward: 796.41
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7141
    Episode_Reward/rotating_object: 155.8928
        Episode_Reward/action_rate: -0.0389
          Episode_Reward/joint_vel: -0.0051
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 110493696
                    Iteration time: 1.67s
                      Time elapsed: 00:36:09
                               ETA: 00:12:07

################################################################################
                     [1m Learning iteration 1124/1500 [0m                     

                       Computation: 56873 steps/s (collection: 1.624s, learning 0.105s)
             Mean action noise std: 2.85
          Mean value_function loss: 20.3685
               Mean surrogate loss: 0.0003
                 Mean entropy loss: 42.3075
                       Mean reward: 773.39
               Mean episode length: 246.26
    Episode_Reward/reaching_object: 0.7136
    Episode_Reward/rotating_object: 156.9878
        Episode_Reward/action_rate: -0.0390
          Episode_Reward/joint_vel: -0.0050
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 110592000
                    Iteration time: 1.73s
                      Time elapsed: 00:36:11
                               ETA: 00:12:05

################################################################################
                     [1m Learning iteration 1125/1500 [0m                     

                       Computation: 56387 steps/s (collection: 1.619s, learning 0.125s)
             Mean action noise std: 2.86
          Mean value_function loss: 15.7990
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 42.3177
                       Mean reward: 801.31
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7151
    Episode_Reward/rotating_object: 157.1707
        Episode_Reward/action_rate: -0.0392
          Episode_Reward/joint_vel: -0.0052
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 110690304
                    Iteration time: 1.74s
                      Time elapsed: 00:36:13
                               ETA: 00:12:03

################################################################################
                     [1m Learning iteration 1126/1500 [0m                     

                       Computation: 55801 steps/s (collection: 1.647s, learning 0.115s)
             Mean action noise std: 2.86
          Mean value_function loss: 17.5956
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 42.3247
                       Mean reward: 758.87
               Mean episode length: 244.15
    Episode_Reward/reaching_object: 0.7129
    Episode_Reward/rotating_object: 154.9377
        Episode_Reward/action_rate: -0.0391
          Episode_Reward/joint_vel: -0.0054
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 110788608
                    Iteration time: 1.76s
                      Time elapsed: 00:36:14
                               ETA: 00:12:01

################################################################################
                     [1m Learning iteration 1127/1500 [0m                     

                       Computation: 57674 steps/s (collection: 1.614s, learning 0.091s)
             Mean action noise std: 2.86
          Mean value_function loss: 19.2234
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 42.3267
                       Mean reward: 779.85
               Mean episode length: 248.74
    Episode_Reward/reaching_object: 0.7064
    Episode_Reward/rotating_object: 154.5227
        Episode_Reward/action_rate: -0.0389
          Episode_Reward/joint_vel: -0.0051
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 110886912
                    Iteration time: 1.70s
                      Time elapsed: 00:36:16
                               ETA: 00:11:59

################################################################################
                     [1m Learning iteration 1128/1500 [0m                     

                       Computation: 58314 steps/s (collection: 1.592s, learning 0.094s)
             Mean action noise std: 2.86
          Mean value_function loss: 19.1593
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 42.3295
                       Mean reward: 788.06
               Mean episode length: 245.71
    Episode_Reward/reaching_object: 0.7004
    Episode_Reward/rotating_object: 154.2303
        Episode_Reward/action_rate: -0.0385
          Episode_Reward/joint_vel: -0.0051
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 110985216
                    Iteration time: 1.69s
                      Time elapsed: 00:36:18
                               ETA: 00:11:57

################################################################################
                     [1m Learning iteration 1129/1500 [0m                     

                       Computation: 56366 steps/s (collection: 1.594s, learning 0.150s)
             Mean action noise std: 2.86
          Mean value_function loss: 22.4344
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 42.3343
                       Mean reward: 773.42
               Mean episode length: 245.70
    Episode_Reward/reaching_object: 0.7065
    Episode_Reward/rotating_object: 155.4485
        Episode_Reward/action_rate: -0.0388
          Episode_Reward/joint_vel: -0.0050
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 111083520
                    Iteration time: 1.74s
                      Time elapsed: 00:36:19
                               ETA: 00:11:55

################################################################################
                     [1m Learning iteration 1130/1500 [0m                     

                       Computation: 57878 steps/s (collection: 1.593s, learning 0.105s)
             Mean action noise std: 2.86
          Mean value_function loss: 16.5048
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 42.3404
                       Mean reward: 758.76
               Mean episode length: 247.97
    Episode_Reward/reaching_object: 0.7086
    Episode_Reward/rotating_object: 154.5332
        Episode_Reward/action_rate: -0.0392
          Episode_Reward/joint_vel: -0.0050
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 111181824
                    Iteration time: 1.70s
                      Time elapsed: 00:36:21
                               ETA: 00:11:53

################################################################################
                     [1m Learning iteration 1131/1500 [0m                     

                       Computation: 56921 steps/s (collection: 1.617s, learning 0.110s)
             Mean action noise std: 2.86
          Mean value_function loss: 20.1316
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 42.3484
                       Mean reward: 790.20
               Mean episode length: 247.84
    Episode_Reward/reaching_object: 0.7039
    Episode_Reward/rotating_object: 155.0796
        Episode_Reward/action_rate: -0.0389
          Episode_Reward/joint_vel: -0.0050
      Episode_Termination/time_out: 17.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 111280128
                    Iteration time: 1.73s
                      Time elapsed: 00:36:23
                               ETA: 00:11:51

################################################################################
                     [1m Learning iteration 1132/1500 [0m                     

                       Computation: 57192 steps/s (collection: 1.623s, learning 0.095s)
             Mean action noise std: 2.86
          Mean value_function loss: 24.2982
               Mean surrogate loss: 0.0001
                 Mean entropy loss: 42.3572
                       Mean reward: 781.93
               Mean episode length: 245.64
    Episode_Reward/reaching_object: 0.7002
    Episode_Reward/rotating_object: 154.3747
        Episode_Reward/action_rate: -0.0386
          Episode_Reward/joint_vel: -0.0049
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 111378432
                    Iteration time: 1.72s
                      Time elapsed: 00:36:25
                               ETA: 00:11:49

################################################################################
                     [1m Learning iteration 1133/1500 [0m                     

                       Computation: 56078 steps/s (collection: 1.608s, learning 0.145s)
             Mean action noise std: 2.87
          Mean value_function loss: 17.6213
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 42.3642
                       Mean reward: 776.45
               Mean episode length: 245.87
    Episode_Reward/reaching_object: 0.7022
    Episode_Reward/rotating_object: 154.7133
        Episode_Reward/action_rate: -0.0389
          Episode_Reward/joint_vel: -0.0050
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 111476736
                    Iteration time: 1.75s
                      Time elapsed: 00:36:26
                               ETA: 00:11:47

################################################################################
                     [1m Learning iteration 1134/1500 [0m                     

                       Computation: 59080 steps/s (collection: 1.570s, learning 0.094s)
             Mean action noise std: 2.87
          Mean value_function loss: 13.3621
               Mean surrogate loss: -0.0003
                 Mean entropy loss: 42.3676
                       Mean reward: 788.61
               Mean episode length: 247.93
    Episode_Reward/reaching_object: 0.7047
    Episode_Reward/rotating_object: 155.8051
        Episode_Reward/action_rate: -0.0391
          Episode_Reward/joint_vel: -0.0051
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 111575040
                    Iteration time: 1.66s
                      Time elapsed: 00:36:28
                               ETA: 00:11:45

################################################################################
                     [1m Learning iteration 1135/1500 [0m                     

                       Computation: 54821 steps/s (collection: 1.653s, learning 0.140s)
             Mean action noise std: 2.87
          Mean value_function loss: 17.3611
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 42.3717
                       Mean reward: 786.25
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7091
    Episode_Reward/rotating_object: 156.2364
        Episode_Reward/action_rate: -0.0393
          Episode_Reward/joint_vel: -0.0053
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 111673344
                    Iteration time: 1.79s
                      Time elapsed: 00:36:30
                               ETA: 00:11:43

################################################################################
                     [1m Learning iteration 1136/1500 [0m                     

                       Computation: 56621 steps/s (collection: 1.647s, learning 0.090s)
             Mean action noise std: 2.87
          Mean value_function loss: 21.5906
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 42.3781
                       Mean reward: 771.27
               Mean episode length: 243.44
    Episode_Reward/reaching_object: 0.7018
    Episode_Reward/rotating_object: 154.7668
        Episode_Reward/action_rate: -0.0389
          Episode_Reward/joint_vel: -0.0052
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 111771648
                    Iteration time: 1.74s
                      Time elapsed: 00:36:32
                               ETA: 00:11:41

################################################################################
                     [1m Learning iteration 1137/1500 [0m                     

                       Computation: 56204 steps/s (collection: 1.652s, learning 0.097s)
             Mean action noise std: 2.87
          Mean value_function loss: 14.2493
               Mean surrogate loss: 0.0006
                 Mean entropy loss: 42.3812
                       Mean reward: 796.50
               Mean episode length: 248.39
    Episode_Reward/reaching_object: 0.7055
    Episode_Reward/rotating_object: 156.6540
        Episode_Reward/action_rate: -0.0390
          Episode_Reward/joint_vel: -0.0049
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 111869952
                    Iteration time: 1.75s
                      Time elapsed: 00:36:33
                               ETA: 00:11:39

################################################################################
                     [1m Learning iteration 1138/1500 [0m                     

                       Computation: 55290 steps/s (collection: 1.636s, learning 0.142s)
             Mean action noise std: 2.87
          Mean value_function loss: 14.2866
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 42.3840
                       Mean reward: 775.66
               Mean episode length: 247.92
    Episode_Reward/reaching_object: 0.7097
    Episode_Reward/rotating_object: 156.1109
        Episode_Reward/action_rate: -0.0394
          Episode_Reward/joint_vel: -0.0050
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 111968256
                    Iteration time: 1.78s
                      Time elapsed: 00:36:35
                               ETA: 00:11:37

################################################################################
                     [1m Learning iteration 1139/1500 [0m                     

                       Computation: 59089 steps/s (collection: 1.571s, learning 0.093s)
             Mean action noise std: 2.87
          Mean value_function loss: 18.3303
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 42.3899
                       Mean reward: 799.87
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7116
    Episode_Reward/rotating_object: 158.0195
        Episode_Reward/action_rate: -0.0391
          Episode_Reward/joint_vel: -0.0049
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 112066560
                    Iteration time: 1.66s
                      Time elapsed: 00:36:37
                               ETA: 00:11:35

################################################################################
                     [1m Learning iteration 1140/1500 [0m                     

                       Computation: 57149 steps/s (collection: 1.620s, learning 0.101s)
             Mean action noise std: 2.87
          Mean value_function loss: 22.6339
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 42.3980
                       Mean reward: 792.86
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7153
    Episode_Reward/rotating_object: 158.5146
        Episode_Reward/action_rate: -0.0394
          Episode_Reward/joint_vel: -0.0050
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 112164864
                    Iteration time: 1.72s
                      Time elapsed: 00:36:38
                               ETA: 00:11:33

################################################################################
                     [1m Learning iteration 1141/1500 [0m                     

                       Computation: 58027 steps/s (collection: 1.596s, learning 0.099s)
             Mean action noise std: 2.87
          Mean value_function loss: 17.0367
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 42.4038
                       Mean reward: 777.60
               Mean episode length: 247.79
    Episode_Reward/reaching_object: 0.7052
    Episode_Reward/rotating_object: 153.7751
        Episode_Reward/action_rate: -0.0392
          Episode_Reward/joint_vel: -0.0052
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 112263168
                    Iteration time: 1.69s
                      Time elapsed: 00:36:40
                               ETA: 00:11:31

################################################################################
                     [1m Learning iteration 1142/1500 [0m                     

                       Computation: 57982 steps/s (collection: 1.608s, learning 0.088s)
             Mean action noise std: 2.88
          Mean value_function loss: 20.1388
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 42.4105
                       Mean reward: 776.73
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7145
    Episode_Reward/rotating_object: 156.8675
        Episode_Reward/action_rate: -0.0395
          Episode_Reward/joint_vel: -0.0053
      Episode_Termination/time_out: 17.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 112361472
                    Iteration time: 1.70s
                      Time elapsed: 00:36:42
                               ETA: 00:11:29

################################################################################
                     [1m Learning iteration 1143/1500 [0m                     

                       Computation: 55704 steps/s (collection: 1.611s, learning 0.153s)
             Mean action noise std: 2.88
          Mean value_function loss: 20.2334
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 42.4189
                       Mean reward: 789.06
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7123
    Episode_Reward/rotating_object: 155.7503
        Episode_Reward/action_rate: -0.0393
          Episode_Reward/joint_vel: -0.0053
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 112459776
                    Iteration time: 1.76s
                      Time elapsed: 00:36:44
                               ETA: 00:11:27

################################################################################
                     [1m Learning iteration 1144/1500 [0m                     

                       Computation: 58642 steps/s (collection: 1.546s, learning 0.131s)
             Mean action noise std: 2.88
          Mean value_function loss: 14.9945
               Mean surrogate loss: -0.0001
                 Mean entropy loss: 42.4310
                       Mean reward: 778.06
               Mean episode length: 246.00
    Episode_Reward/reaching_object: 0.7139
    Episode_Reward/rotating_object: 155.4770
        Episode_Reward/action_rate: -0.0394
          Episode_Reward/joint_vel: -0.0052
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 112558080
                    Iteration time: 1.68s
                      Time elapsed: 00:36:45
                               ETA: 00:11:25

################################################################################
                     [1m Learning iteration 1145/1500 [0m                     

                       Computation: 58375 steps/s (collection: 1.595s, learning 0.089s)
             Mean action noise std: 2.88
          Mean value_function loss: 22.5374
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 42.4365
                       Mean reward: 778.77
               Mean episode length: 247.67
    Episode_Reward/reaching_object: 0.7091
    Episode_Reward/rotating_object: 156.0115
        Episode_Reward/action_rate: -0.0391
          Episode_Reward/joint_vel: -0.0052
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 112656384
                    Iteration time: 1.68s
                      Time elapsed: 00:36:47
                               ETA: 00:11:23

################################################################################
                     [1m Learning iteration 1146/1500 [0m                     

                       Computation: 57214 steps/s (collection: 1.623s, learning 0.096s)
             Mean action noise std: 2.88
          Mean value_function loss: 15.8464
               Mean surrogate loss: -0.0003
                 Mean entropy loss: 42.4439
                       Mean reward: 791.48
               Mean episode length: 248.07
    Episode_Reward/reaching_object: 0.7113
    Episode_Reward/rotating_object: 154.9745
        Episode_Reward/action_rate: -0.0395
          Episode_Reward/joint_vel: -0.0052
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 112754688
                    Iteration time: 1.72s
                      Time elapsed: 00:36:49
                               ETA: 00:11:21

################################################################################
                     [1m Learning iteration 1147/1500 [0m                     

                       Computation: 58123 steps/s (collection: 1.575s, learning 0.117s)
             Mean action noise std: 2.88
          Mean value_function loss: 15.4966
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 42.4507
                       Mean reward: 797.34
               Mean episode length: 248.08
    Episode_Reward/reaching_object: 0.7135
    Episode_Reward/rotating_object: 156.8605
        Episode_Reward/action_rate: -0.0393
          Episode_Reward/joint_vel: -0.0050
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 112852992
                    Iteration time: 1.69s
                      Time elapsed: 00:36:50
                               ETA: 00:11:19

################################################################################
                     [1m Learning iteration 1148/1500 [0m                     

                       Computation: 57533 steps/s (collection: 1.607s, learning 0.102s)
             Mean action noise std: 2.88
          Mean value_function loss: 18.4971
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 42.4547
                       Mean reward: 785.37
               Mean episode length: 248.34
    Episode_Reward/reaching_object: 0.7157
    Episode_Reward/rotating_object: 157.8757
        Episode_Reward/action_rate: -0.0397
          Episode_Reward/joint_vel: -0.0050
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 112951296
                    Iteration time: 1.71s
                      Time elapsed: 00:36:52
                               ETA: 00:11:17

################################################################################
                     [1m Learning iteration 1149/1500 [0m                     

                       Computation: 58381 steps/s (collection: 1.580s, learning 0.104s)
             Mean action noise std: 2.89
          Mean value_function loss: 13.2827
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 42.4625
                       Mean reward: 791.38
               Mean episode length: 248.04
    Episode_Reward/reaching_object: 0.7119
    Episode_Reward/rotating_object: 156.8047
        Episode_Reward/action_rate: -0.0396
          Episode_Reward/joint_vel: -0.0051
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 113049600
                    Iteration time: 1.68s
                      Time elapsed: 00:36:54
                               ETA: 00:11:15

################################################################################
                     [1m Learning iteration 1150/1500 [0m                     

                       Computation: 58697 steps/s (collection: 1.580s, learning 0.095s)
             Mean action noise std: 2.89
          Mean value_function loss: 18.1793
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 42.4711
                       Mean reward: 769.23
               Mean episode length: 245.42
    Episode_Reward/reaching_object: 0.7065
    Episode_Reward/rotating_object: 155.1631
        Episode_Reward/action_rate: -0.0395
          Episode_Reward/joint_vel: -0.0053
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 113147904
                    Iteration time: 1.67s
                      Time elapsed: 00:36:55
                               ETA: 00:11:13

################################################################################
                     [1m Learning iteration 1151/1500 [0m                     

                       Computation: 55669 steps/s (collection: 1.667s, learning 0.099s)
             Mean action noise std: 2.89
          Mean value_function loss: 13.9252
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 42.4815
                       Mean reward: 796.93
               Mean episode length: 248.02
    Episode_Reward/reaching_object: 0.7170
    Episode_Reward/rotating_object: 157.7752
        Episode_Reward/action_rate: -0.0399
          Episode_Reward/joint_vel: -0.0051
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 113246208
                    Iteration time: 1.77s
                      Time elapsed: 00:36:57
                               ETA: 00:11:11

################################################################################
                     [1m Learning iteration 1152/1500 [0m                     

                       Computation: 57132 steps/s (collection: 1.629s, learning 0.092s)
             Mean action noise std: 2.89
          Mean value_function loss: 13.2355
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 42.4875
                       Mean reward: 765.34
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7090
    Episode_Reward/rotating_object: 155.8463
        Episode_Reward/action_rate: -0.0399
          Episode_Reward/joint_vel: -0.0054
      Episode_Termination/time_out: 18.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 113344512
                    Iteration time: 1.72s
                      Time elapsed: 00:36:59
                               ETA: 00:11:09

################################################################################
                     [1m Learning iteration 1153/1500 [0m                     

                       Computation: 59128 steps/s (collection: 1.555s, learning 0.108s)
             Mean action noise std: 2.89
          Mean value_function loss: 16.2889
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 42.4890
                       Mean reward: 774.93
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7080
    Episode_Reward/rotating_object: 155.9096
        Episode_Reward/action_rate: -0.0398
          Episode_Reward/joint_vel: -0.0049
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 113442816
                    Iteration time: 1.66s
                      Time elapsed: 00:37:01
                               ETA: 00:11:07

################################################################################
                     [1m Learning iteration 1154/1500 [0m                     

                       Computation: 56864 steps/s (collection: 1.634s, learning 0.095s)
             Mean action noise std: 2.89
          Mean value_function loss: 13.8313
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 42.4958
                       Mean reward: 784.69
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7121
    Episode_Reward/rotating_object: 157.8293
        Episode_Reward/action_rate: -0.0400
          Episode_Reward/joint_vel: -0.0049
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 113541120
                    Iteration time: 1.73s
                      Time elapsed: 00:37:02
                               ETA: 00:11:05

################################################################################
                     [1m Learning iteration 1155/1500 [0m                     

                       Computation: 57721 steps/s (collection: 1.598s, learning 0.105s)
             Mean action noise std: 2.90
          Mean value_function loss: 16.0491
               Mean surrogate loss: -0.0005
                 Mean entropy loss: 42.5020
                       Mean reward: 789.02
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7074
    Episode_Reward/rotating_object: 156.2805
        Episode_Reward/action_rate: -0.0400
          Episode_Reward/joint_vel: -0.0048
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 113639424
                    Iteration time: 1.70s
                      Time elapsed: 00:37:04
                               ETA: 00:11:03

################################################################################
                     [1m Learning iteration 1156/1500 [0m                     

                       Computation: 56952 steps/s (collection: 1.605s, learning 0.121s)
             Mean action noise std: 2.90
          Mean value_function loss: 16.3628
               Mean surrogate loss: -0.0001
                 Mean entropy loss: 42.5065
                       Mean reward: 792.56
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7101
    Episode_Reward/rotating_object: 157.4681
        Episode_Reward/action_rate: -0.0399
          Episode_Reward/joint_vel: -0.0049
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 113737728
                    Iteration time: 1.73s
                      Time elapsed: 00:37:06
                               ETA: 00:11:01

################################################################################
                     [1m Learning iteration 1157/1500 [0m                     

                       Computation: 57843 steps/s (collection: 1.584s, learning 0.116s)
             Mean action noise std: 2.90
          Mean value_function loss: 18.7585
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 42.5072
                       Mean reward: 802.94
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7049
    Episode_Reward/rotating_object: 155.7395
        Episode_Reward/action_rate: -0.0399
          Episode_Reward/joint_vel: -0.0051
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 113836032
                    Iteration time: 1.70s
                      Time elapsed: 00:37:07
                               ETA: 00:10:59

################################################################################
                     [1m Learning iteration 1158/1500 [0m                     

                       Computation: 58050 steps/s (collection: 1.604s, learning 0.090s)
             Mean action noise std: 2.90
          Mean value_function loss: 17.4582
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 42.5109
                       Mean reward: 795.09
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7071
    Episode_Reward/rotating_object: 158.0620
        Episode_Reward/action_rate: -0.0400
          Episode_Reward/joint_vel: -0.0050
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 113934336
                    Iteration time: 1.69s
                      Time elapsed: 00:37:09
                               ETA: 00:10:57

################################################################################
                     [1m Learning iteration 1159/1500 [0m                     

                       Computation: 57708 steps/s (collection: 1.605s, learning 0.098s)
             Mean action noise std: 2.90
          Mean value_function loss: 21.1276
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 42.5154
                       Mean reward: 808.45
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7017
    Episode_Reward/rotating_object: 156.5182
        Episode_Reward/action_rate: -0.0398
          Episode_Reward/joint_vel: -0.0050
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 114032640
                    Iteration time: 1.70s
                      Time elapsed: 00:37:11
                               ETA: 00:10:55

################################################################################
                     [1m Learning iteration 1160/1500 [0m                     

                       Computation: 59007 steps/s (collection: 1.569s, learning 0.097s)
             Mean action noise std: 2.90
          Mean value_function loss: 21.5422
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 42.5289
                       Mean reward: 781.92
               Mean episode length: 247.70
    Episode_Reward/reaching_object: 0.6943
    Episode_Reward/rotating_object: 154.5197
        Episode_Reward/action_rate: -0.0397
          Episode_Reward/joint_vel: -0.0053
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 114130944
                    Iteration time: 1.67s
                      Time elapsed: 00:37:13
                               ETA: 00:10:53

################################################################################
                     [1m Learning iteration 1161/1500 [0m                     

                       Computation: 59248 steps/s (collection: 1.569s, learning 0.091s)
             Mean action noise std: 2.91
          Mean value_function loss: 17.5124
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 42.5457
                       Mean reward: 807.28
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7029
    Episode_Reward/rotating_object: 158.5636
        Episode_Reward/action_rate: -0.0399
          Episode_Reward/joint_vel: -0.0049
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 114229248
                    Iteration time: 1.66s
                      Time elapsed: 00:37:14
                               ETA: 00:10:51

################################################################################
                     [1m Learning iteration 1162/1500 [0m                     

                       Computation: 59526 steps/s (collection: 1.562s, learning 0.089s)
             Mean action noise std: 2.91
          Mean value_function loss: 11.8046
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 42.5616
                       Mean reward: 797.26
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7076
    Episode_Reward/rotating_object: 159.3147
        Episode_Reward/action_rate: -0.0403
          Episode_Reward/joint_vel: -0.0049
      Episode_Termination/time_out: 17.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 114327552
                    Iteration time: 1.65s
                      Time elapsed: 00:37:16
                               ETA: 00:10:49

################################################################################
                     [1m Learning iteration 1163/1500 [0m                     

                       Computation: 58174 steps/s (collection: 1.597s, learning 0.093s)
             Mean action noise std: 2.91
          Mean value_function loss: 15.5964
               Mean surrogate loss: 0.0007
                 Mean entropy loss: 42.5680
                       Mean reward: 774.37
               Mean episode length: 247.69
    Episode_Reward/reaching_object: 0.6980
    Episode_Reward/rotating_object: 156.5674
        Episode_Reward/action_rate: -0.0400
          Episode_Reward/joint_vel: -0.0048
      Episode_Termination/time_out: 17.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 114425856
                    Iteration time: 1.69s
                      Time elapsed: 00:37:18
                               ETA: 00:10:47

################################################################################
                     [1m Learning iteration 1164/1500 [0m                     

                       Computation: 55956 steps/s (collection: 1.665s, learning 0.092s)
             Mean action noise std: 2.91
          Mean value_function loss: 17.1900
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 42.5736
                       Mean reward: 779.87
               Mean episode length: 247.79
    Episode_Reward/reaching_object: 0.6989
    Episode_Reward/rotating_object: 155.5474
        Episode_Reward/action_rate: -0.0401
          Episode_Reward/joint_vel: -0.0051
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 114524160
                    Iteration time: 1.76s
                      Time elapsed: 00:37:19
                               ETA: 00:10:45

################################################################################
                     [1m Learning iteration 1165/1500 [0m                     

                       Computation: 59140 steps/s (collection: 1.570s, learning 0.093s)
             Mean action noise std: 2.91
          Mean value_function loss: 11.7224
               Mean surrogate loss: -0.0004
                 Mean entropy loss: 42.5813
                       Mean reward: 798.21
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7004
    Episode_Reward/rotating_object: 157.0426
        Episode_Reward/action_rate: -0.0401
          Episode_Reward/joint_vel: -0.0049
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 114622464
                    Iteration time: 1.66s
                      Time elapsed: 00:37:21
                               ETA: 00:10:43

################################################################################
                     [1m Learning iteration 1166/1500 [0m                     

                       Computation: 58414 steps/s (collection: 1.569s, learning 0.114s)
             Mean action noise std: 2.91
          Mean value_function loss: 19.7315
               Mean surrogate loss: -0.0007
                 Mean entropy loss: 42.5847
                       Mean reward: 774.00
               Mean episode length: 243.39
    Episode_Reward/reaching_object: 0.6966
    Episode_Reward/rotating_object: 155.8921
        Episode_Reward/action_rate: -0.0399
          Episode_Reward/joint_vel: -0.0049
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 114720768
                    Iteration time: 1.68s
                      Time elapsed: 00:37:23
                               ETA: 00:10:41

################################################################################
                     [1m Learning iteration 1167/1500 [0m                     

                       Computation: 55100 steps/s (collection: 1.659s, learning 0.125s)
             Mean action noise std: 2.91
          Mean value_function loss: 15.0463
               Mean surrogate loss: -0.0003
                 Mean entropy loss: 42.5897
                       Mean reward: 806.52
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6958
    Episode_Reward/rotating_object: 156.3994
        Episode_Reward/action_rate: -0.0401
          Episode_Reward/joint_vel: -0.0049
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 114819072
                    Iteration time: 1.78s
                      Time elapsed: 00:37:24
                               ETA: 00:10:40

################################################################################
                     [1m Learning iteration 1168/1500 [0m                     

                       Computation: 58715 steps/s (collection: 1.577s, learning 0.097s)
             Mean action noise std: 2.92
          Mean value_function loss: 19.5498
               Mean surrogate loss: -0.0006
                 Mean entropy loss: 42.5972
                       Mean reward: 802.94
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.6932
    Episode_Reward/rotating_object: 156.0731
        Episode_Reward/action_rate: -0.0398
          Episode_Reward/joint_vel: -0.0049
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 114917376
                    Iteration time: 1.67s
                      Time elapsed: 00:37:26
                               ETA: 00:10:38

################################################################################
                     [1m Learning iteration 1169/1500 [0m                     

                       Computation: 56878 steps/s (collection: 1.617s, learning 0.112s)
             Mean action noise std: 2.92
          Mean value_function loss: 20.0330
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 42.6072
                       Mean reward: 785.90
               Mean episode length: 247.88
    Episode_Reward/reaching_object: 0.6971
    Episode_Reward/rotating_object: 157.1329
        Episode_Reward/action_rate: -0.0402
          Episode_Reward/joint_vel: -0.0049
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 115015680
                    Iteration time: 1.73s
                      Time elapsed: 00:37:28
                               ETA: 00:10:36

################################################################################
                     [1m Learning iteration 1170/1500 [0m                     

                       Computation: 57814 steps/s (collection: 1.571s, learning 0.129s)
             Mean action noise std: 2.92
          Mean value_function loss: 28.1850
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 42.6173
                       Mean reward: 774.52
               Mean episode length: 245.86
    Episode_Reward/reaching_object: 0.6893
    Episode_Reward/rotating_object: 154.6350
        Episode_Reward/action_rate: -0.0398
          Episode_Reward/joint_vel: -0.0048
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 115113984
                    Iteration time: 1.70s
                      Time elapsed: 00:37:30
                               ETA: 00:10:34

################################################################################
                     [1m Learning iteration 1171/1500 [0m                     

                       Computation: 58393 steps/s (collection: 1.593s, learning 0.090s)
             Mean action noise std: 2.92
          Mean value_function loss: 29.5259
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 42.6282
                       Mean reward: 757.44
               Mean episode length: 236.98
    Episode_Reward/reaching_object: 0.6890
    Episode_Reward/rotating_object: 154.0760
        Episode_Reward/action_rate: -0.0399
          Episode_Reward/joint_vel: -0.0049
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 115212288
                    Iteration time: 1.68s
                      Time elapsed: 00:37:31
                               ETA: 00:10:32

################################################################################
                     [1m Learning iteration 1172/1500 [0m                     

                       Computation: 57531 steps/s (collection: 1.614s, learning 0.095s)
             Mean action noise std: 2.92
          Mean value_function loss: 16.0928
               Mean surrogate loss: -0.0004
                 Mean entropy loss: 42.6429
                       Mean reward: 801.36
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7016
    Episode_Reward/rotating_object: 157.9203
        Episode_Reward/action_rate: -0.0400
          Episode_Reward/joint_vel: -0.0047
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 115310592
                    Iteration time: 1.71s
                      Time elapsed: 00:37:33
                               ETA: 00:10:30

################################################################################
                     [1m Learning iteration 1173/1500 [0m                     

                       Computation: 54614 steps/s (collection: 1.663s, learning 0.137s)
             Mean action noise std: 2.92
          Mean value_function loss: 24.7853
               Mean surrogate loss: 0.0004
                 Mean entropy loss: 42.6516
                       Mean reward: 795.62
               Mean episode length: 247.80
    Episode_Reward/reaching_object: 0.7058
    Episode_Reward/rotating_object: 159.2979
        Episode_Reward/action_rate: -0.0404
          Episode_Reward/joint_vel: -0.0049
      Episode_Termination/time_out: 17.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 115408896
                    Iteration time: 1.80s
                      Time elapsed: 00:37:35
                               ETA: 00:10:28

################################################################################
                     [1m Learning iteration 1174/1500 [0m                     

                       Computation: 58477 steps/s (collection: 1.592s, learning 0.089s)
             Mean action noise std: 2.93
          Mean value_function loss: 17.8413
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 42.6576
                       Mean reward: 785.14
               Mean episode length: 245.73
    Episode_Reward/reaching_object: 0.7032
    Episode_Reward/rotating_object: 157.4997
        Episode_Reward/action_rate: -0.0403
          Episode_Reward/joint_vel: -0.0051
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 115507200
                    Iteration time: 1.68s
                      Time elapsed: 00:37:36
                               ETA: 00:10:26

################################################################################
                     [1m Learning iteration 1175/1500 [0m                     

                       Computation: 57053 steps/s (collection: 1.618s, learning 0.105s)
             Mean action noise std: 2.93
          Mean value_function loss: 16.5748
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 42.6643
                       Mean reward: 793.14
               Mean episode length: 248.16
    Episode_Reward/reaching_object: 0.7058
    Episode_Reward/rotating_object: 158.3336
        Episode_Reward/action_rate: -0.0403
          Episode_Reward/joint_vel: -0.0049
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 115605504
                    Iteration time: 1.72s
                      Time elapsed: 00:37:38
                               ETA: 00:10:24

################################################################################
                     [1m Learning iteration 1176/1500 [0m                     

                       Computation: 58520 steps/s (collection: 1.578s, learning 0.102s)
             Mean action noise std: 2.93
          Mean value_function loss: 24.4885
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 42.6715
                       Mean reward: 812.02
               Mean episode length: 247.86
    Episode_Reward/reaching_object: 0.7043
    Episode_Reward/rotating_object: 158.6096
        Episode_Reward/action_rate: -0.0402
          Episode_Reward/joint_vel: -0.0048
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 115703808
                    Iteration time: 1.68s
                      Time elapsed: 00:37:40
                               ETA: 00:10:22

################################################################################
                     [1m Learning iteration 1177/1500 [0m                     

                       Computation: 58380 steps/s (collection: 1.549s, learning 0.135s)
             Mean action noise std: 2.93
          Mean value_function loss: 15.2209
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 42.6800
                       Mean reward: 773.47
               Mean episode length: 246.13
    Episode_Reward/reaching_object: 0.7005
    Episode_Reward/rotating_object: 155.0623
        Episode_Reward/action_rate: -0.0403
          Episode_Reward/joint_vel: -0.0048
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 115802112
                    Iteration time: 1.68s
                      Time elapsed: 00:37:41
                               ETA: 00:10:20

################################################################################
                     [1m Learning iteration 1178/1500 [0m                     

                       Computation: 57663 steps/s (collection: 1.604s, learning 0.101s)
             Mean action noise std: 2.93
          Mean value_function loss: 15.4651
               Mean surrogate loss: -0.0005
                 Mean entropy loss: 42.6907
                       Mean reward: 800.68
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7101
    Episode_Reward/rotating_object: 158.9491
        Episode_Reward/action_rate: -0.0407
          Episode_Reward/joint_vel: -0.0049
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 115900416
                    Iteration time: 1.70s
                      Time elapsed: 00:37:43
                               ETA: 00:10:18

################################################################################
                     [1m Learning iteration 1179/1500 [0m                     

                       Computation: 56748 steps/s (collection: 1.638s, learning 0.094s)
             Mean action noise std: 2.93
          Mean value_function loss: 15.4052
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 42.6996
                       Mean reward: 792.95
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7055
    Episode_Reward/rotating_object: 155.7472
        Episode_Reward/action_rate: -0.0406
          Episode_Reward/joint_vel: -0.0049
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 115998720
                    Iteration time: 1.73s
                      Time elapsed: 00:37:45
                               ETA: 00:10:16

################################################################################
                     [1m Learning iteration 1180/1500 [0m                     

                       Computation: 57305 steps/s (collection: 1.587s, learning 0.128s)
             Mean action noise std: 2.94
          Mean value_function loss: 25.5850
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 42.7070
                       Mean reward: 767.89
               Mean episode length: 246.55
    Episode_Reward/reaching_object: 0.6979
    Episode_Reward/rotating_object: 154.2347
        Episode_Reward/action_rate: -0.0402
          Episode_Reward/joint_vel: -0.0049
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 116097024
                    Iteration time: 1.72s
                      Time elapsed: 00:37:47
                               ETA: 00:10:14

################################################################################
                     [1m Learning iteration 1181/1500 [0m                     

                       Computation: 57994 steps/s (collection: 1.587s, learning 0.108s)
             Mean action noise std: 2.94
          Mean value_function loss: 23.5388
               Mean surrogate loss: -0.0006
                 Mean entropy loss: 42.7212
                       Mean reward: 764.89
               Mean episode length: 244.92
    Episode_Reward/reaching_object: 0.7011
    Episode_Reward/rotating_object: 154.8232
        Episode_Reward/action_rate: -0.0403
          Episode_Reward/joint_vel: -0.0051
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 116195328
                    Iteration time: 1.70s
                      Time elapsed: 00:37:48
                               ETA: 00:10:12

################################################################################
                     [1m Learning iteration 1182/1500 [0m                     

                       Computation: 56903 steps/s (collection: 1.629s, learning 0.099s)
             Mean action noise std: 2.94
          Mean value_function loss: 15.6211
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 42.7334
                       Mean reward: 786.78
               Mean episode length: 247.77
    Episode_Reward/reaching_object: 0.7153
    Episode_Reward/rotating_object: 157.5069
        Episode_Reward/action_rate: -0.0407
          Episode_Reward/joint_vel: -0.0050
      Episode_Termination/time_out: 17.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 116293632
                    Iteration time: 1.73s
                      Time elapsed: 00:37:50
                               ETA: 00:10:10

################################################################################
                     [1m Learning iteration 1183/1500 [0m                     

                       Computation: 57560 steps/s (collection: 1.590s, learning 0.117s)
             Mean action noise std: 2.94
          Mean value_function loss: 17.6841
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 42.7423
                       Mean reward: 804.75
               Mean episode length: 245.88
    Episode_Reward/reaching_object: 0.7140
    Episode_Reward/rotating_object: 157.1681
        Episode_Reward/action_rate: -0.0409
          Episode_Reward/joint_vel: -0.0049
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 116391936
                    Iteration time: 1.71s
                      Time elapsed: 00:37:52
                               ETA: 00:10:08

################################################################################
                     [1m Learning iteration 1184/1500 [0m                     

                       Computation: 58334 steps/s (collection: 1.583s, learning 0.102s)
             Mean action noise std: 2.94
          Mean value_function loss: 19.2627
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 42.7509
                       Mean reward: 787.27
               Mean episode length: 247.79
    Episode_Reward/reaching_object: 0.7129
    Episode_Reward/rotating_object: 157.1213
        Episode_Reward/action_rate: -0.0406
          Episode_Reward/joint_vel: -0.0048
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 116490240
                    Iteration time: 1.69s
                      Time elapsed: 00:37:53
                               ETA: 00:10:06

################################################################################
                     [1m Learning iteration 1185/1500 [0m                     

                       Computation: 58842 steps/s (collection: 1.577s, learning 0.094s)
             Mean action noise std: 2.94
          Mean value_function loss: 13.2815
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 42.7585
                       Mean reward: 789.12
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7178
    Episode_Reward/rotating_object: 157.8543
        Episode_Reward/action_rate: -0.0408
          Episode_Reward/joint_vel: -0.0050
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 116588544
                    Iteration time: 1.67s
                      Time elapsed: 00:37:55
                               ETA: 00:10:04

################################################################################
                     [1m Learning iteration 1186/1500 [0m                     

                       Computation: 57030 steps/s (collection: 1.618s, learning 0.106s)
             Mean action noise std: 2.95
          Mean value_function loss: 17.0422
               Mean surrogate loss: 0.0010
                 Mean entropy loss: 42.7642
                       Mean reward: 799.24
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7195
    Episode_Reward/rotating_object: 156.8158
        Episode_Reward/action_rate: -0.0409
          Episode_Reward/joint_vel: -0.0051
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 116686848
                    Iteration time: 1.72s
                      Time elapsed: 00:37:57
                               ETA: 00:10:02

################################################################################
                     [1m Learning iteration 1187/1500 [0m                     

                       Computation: 57290 steps/s (collection: 1.598s, learning 0.118s)
             Mean action noise std: 2.95
          Mean value_function loss: 12.8763
               Mean surrogate loss: -0.0004
                 Mean entropy loss: 42.7676
                       Mean reward: 815.18
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7223
    Episode_Reward/rotating_object: 159.0273
        Episode_Reward/action_rate: -0.0410
          Episode_Reward/joint_vel: -0.0048
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 116785152
                    Iteration time: 1.72s
                      Time elapsed: 00:37:59
                               ETA: 00:10:00

################################################################################
                     [1m Learning iteration 1188/1500 [0m                     

                       Computation: 57757 steps/s (collection: 1.602s, learning 0.100s)
             Mean action noise std: 2.95
          Mean value_function loss: 17.1498
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 42.7730
                       Mean reward: 777.34
               Mean episode length: 248.11
    Episode_Reward/reaching_object: 0.7207
    Episode_Reward/rotating_object: 156.7799
        Episode_Reward/action_rate: -0.0411
          Episode_Reward/joint_vel: -0.0050
      Episode_Termination/time_out: 17.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 116883456
                    Iteration time: 1.70s
                      Time elapsed: 00:38:00
                               ETA: 00:09:58

################################################################################
                     [1m Learning iteration 1189/1500 [0m                     

                       Computation: 56945 steps/s (collection: 1.624s, learning 0.102s)
             Mean action noise std: 2.95
          Mean value_function loss: 14.9125
               Mean surrogate loss: 0.0004
                 Mean entropy loss: 42.7837
                       Mean reward: 777.98
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7208
    Episode_Reward/rotating_object: 156.9209
        Episode_Reward/action_rate: -0.0413
          Episode_Reward/joint_vel: -0.0054
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 116981760
                    Iteration time: 1.73s
                      Time elapsed: 00:38:02
                               ETA: 00:09:56

################################################################################
                     [1m Learning iteration 1190/1500 [0m                     

                       Computation: 58185 steps/s (collection: 1.596s, learning 0.094s)
             Mean action noise std: 2.95
          Mean value_function loss: 17.3617
               Mean surrogate loss: 0.0013
                 Mean entropy loss: 42.7935
                       Mean reward: 795.44
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7162
    Episode_Reward/rotating_object: 156.6959
        Episode_Reward/action_rate: -0.0409
          Episode_Reward/joint_vel: -0.0051
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 117080064
                    Iteration time: 1.69s
                      Time elapsed: 00:38:04
                               ETA: 00:09:54

################################################################################
                     [1m Learning iteration 1191/1500 [0m                     

                       Computation: 57628 steps/s (collection: 1.611s, learning 0.095s)
             Mean action noise std: 2.95
          Mean value_function loss: 16.8950
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 42.7972
                       Mean reward: 812.70
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7222
    Episode_Reward/rotating_object: 158.7500
        Episode_Reward/action_rate: -0.0411
          Episode_Reward/joint_vel: -0.0050
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 117178368
                    Iteration time: 1.71s
                      Time elapsed: 00:38:05
                               ETA: 00:09:52

################################################################################
                     [1m Learning iteration 1192/1500 [0m                     

                       Computation: 58110 steps/s (collection: 1.604s, learning 0.088s)
             Mean action noise std: 2.96
          Mean value_function loss: 16.0767
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 42.8085
                       Mean reward: 795.87
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7266
    Episode_Reward/rotating_object: 158.1838
        Episode_Reward/action_rate: -0.0412
          Episode_Reward/joint_vel: -0.0048
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 117276672
                    Iteration time: 1.69s
                      Time elapsed: 00:38:07
                               ETA: 00:09:50

################################################################################
                     [1m Learning iteration 1193/1500 [0m                     

                       Computation: 57035 steps/s (collection: 1.609s, learning 0.114s)
             Mean action noise std: 2.96
          Mean value_function loss: 19.6734
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 42.8215
                       Mean reward: 788.49
               Mean episode length: 247.75
    Episode_Reward/reaching_object: 0.7262
    Episode_Reward/rotating_object: 157.3989
        Episode_Reward/action_rate: -0.0411
          Episode_Reward/joint_vel: -0.0048
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 117374976
                    Iteration time: 1.72s
                      Time elapsed: 00:38:09
                               ETA: 00:09:48

################################################################################
                     [1m Learning iteration 1194/1500 [0m                     

                       Computation: 56282 steps/s (collection: 1.612s, learning 0.135s)
             Mean action noise std: 2.96
          Mean value_function loss: 22.1291
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 42.8309
                       Mean reward: 802.52
               Mean episode length: 247.76
    Episode_Reward/reaching_object: 0.7276
    Episode_Reward/rotating_object: 159.5404
        Episode_Reward/action_rate: -0.0411
          Episode_Reward/joint_vel: -0.0047
      Episode_Termination/time_out: 17.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 117473280
                    Iteration time: 1.75s
                      Time elapsed: 00:38:11
                               ETA: 00:09:46

################################################################################
                     [1m Learning iteration 1195/1500 [0m                     

                       Computation: 58056 steps/s (collection: 1.605s, learning 0.089s)
             Mean action noise std: 2.96
          Mean value_function loss: 18.8282
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 42.8368
                       Mean reward: 790.62
               Mean episode length: 247.82
    Episode_Reward/reaching_object: 0.7260
    Episode_Reward/rotating_object: 158.4613
        Episode_Reward/action_rate: -0.0412
          Episode_Reward/joint_vel: -0.0048
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 117571584
                    Iteration time: 1.69s
                      Time elapsed: 00:38:12
                               ETA: 00:09:44

################################################################################
                     [1m Learning iteration 1196/1500 [0m                     

                       Computation: 55470 steps/s (collection: 1.649s, learning 0.124s)
             Mean action noise std: 2.96
          Mean value_function loss: 21.8923
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 42.8445
                       Mean reward: 794.51
               Mean episode length: 245.33
    Episode_Reward/reaching_object: 0.7216
    Episode_Reward/rotating_object: 156.3794
        Episode_Reward/action_rate: -0.0409
          Episode_Reward/joint_vel: -0.0049
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 117669888
                    Iteration time: 1.77s
                      Time elapsed: 00:38:14
                               ETA: 00:09:42

################################################################################
                     [1m Learning iteration 1197/1500 [0m                     

                       Computation: 55495 steps/s (collection: 1.652s, learning 0.120s)
             Mean action noise std: 2.96
          Mean value_function loss: 17.5162
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 42.8518
                       Mean reward: 796.36
               Mean episode length: 247.75
    Episode_Reward/reaching_object: 0.7237
    Episode_Reward/rotating_object: 157.1882
        Episode_Reward/action_rate: -0.0412
          Episode_Reward/joint_vel: -0.0049
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 117768192
                    Iteration time: 1.77s
                      Time elapsed: 00:38:16
                               ETA: 00:09:40

################################################################################
                     [1m Learning iteration 1198/1500 [0m                     

                       Computation: 59184 steps/s (collection: 1.560s, learning 0.101s)
             Mean action noise std: 2.96
          Mean value_function loss: 16.3700
               Mean surrogate loss: 0.0015
                 Mean entropy loss: 42.8549
                       Mean reward: 794.37
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7232
    Episode_Reward/rotating_object: 155.7640
        Episode_Reward/action_rate: -0.0411
          Episode_Reward/joint_vel: -0.0047
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 117866496
                    Iteration time: 1.66s
                      Time elapsed: 00:38:17
                               ETA: 00:09:38

################################################################################
                     [1m Learning iteration 1199/1500 [0m                     

                       Computation: 55324 steps/s (collection: 1.671s, learning 0.106s)
             Mean action noise std: 2.96
          Mean value_function loss: 18.0342
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 42.8582
                       Mean reward: 776.87
               Mean episode length: 245.72
    Episode_Reward/reaching_object: 0.7221
    Episode_Reward/rotating_object: 156.2363
        Episode_Reward/action_rate: -0.0412
          Episode_Reward/joint_vel: -0.0050
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 117964800
                    Iteration time: 1.78s
                      Time elapsed: 00:38:19
                               ETA: 00:09:36

################################################################################
                     [1m Learning iteration 1200/1500 [0m                     

                       Computation: 57159 steps/s (collection: 1.613s, learning 0.107s)
             Mean action noise std: 2.97
          Mean value_function loss: 19.7190
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 42.8667
                       Mean reward: 775.14
               Mean episode length: 246.16
    Episode_Reward/reaching_object: 0.7237
    Episode_Reward/rotating_object: 155.4310
        Episode_Reward/action_rate: -0.0410
          Episode_Reward/joint_vel: -0.0049
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 118063104
                    Iteration time: 1.72s
                      Time elapsed: 00:38:21
                               ETA: 00:09:34

################################################################################
                     [1m Learning iteration 1201/1500 [0m                     

                       Computation: 55128 steps/s (collection: 1.652s, learning 0.132s)
             Mean action noise std: 2.97
          Mean value_function loss: 13.0981
               Mean surrogate loss: -0.0005
                 Mean entropy loss: 42.8776
                       Mean reward: 768.32
               Mean episode length: 245.75
    Episode_Reward/reaching_object: 0.7254
    Episode_Reward/rotating_object: 155.7266
        Episode_Reward/action_rate: -0.0412
          Episode_Reward/joint_vel: -0.0049
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 118161408
                    Iteration time: 1.78s
                      Time elapsed: 00:38:23
                               ETA: 00:09:32

################################################################################
                     [1m Learning iteration 1202/1500 [0m                     

                       Computation: 58071 steps/s (collection: 1.597s, learning 0.096s)
             Mean action noise std: 2.97
          Mean value_function loss: 18.4944
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 42.8838
                       Mean reward: 776.49
               Mean episode length: 247.89
    Episode_Reward/reaching_object: 0.7335
    Episode_Reward/rotating_object: 158.6095
        Episode_Reward/action_rate: -0.0416
          Episode_Reward/joint_vel: -0.0050
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 118259712
                    Iteration time: 1.69s
                      Time elapsed: 00:38:24
                               ETA: 00:09:30

################################################################################
                     [1m Learning iteration 1203/1500 [0m                     

                       Computation: 57372 steps/s (collection: 1.623s, learning 0.090s)
             Mean action noise std: 2.97
          Mean value_function loss: 19.1486
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 42.8974
                       Mean reward: 797.89
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7321
    Episode_Reward/rotating_object: 157.2966
        Episode_Reward/action_rate: -0.0415
          Episode_Reward/joint_vel: -0.0046
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 118358016
                    Iteration time: 1.71s
                      Time elapsed: 00:38:26
                               ETA: 00:09:28

################################################################################
                     [1m Learning iteration 1204/1500 [0m                     

                       Computation: 57511 steps/s (collection: 1.606s, learning 0.103s)
             Mean action noise std: 2.98
          Mean value_function loss: 24.1772
               Mean surrogate loss: -0.0006
                 Mean entropy loss: 42.9117
                       Mean reward: 792.59
               Mean episode length: 247.85
    Episode_Reward/reaching_object: 0.7303
    Episode_Reward/rotating_object: 156.3494
        Episode_Reward/action_rate: -0.0414
          Episode_Reward/joint_vel: -0.0047
      Episode_Termination/time_out: 17.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 118456320
                    Iteration time: 1.71s
                      Time elapsed: 00:38:28
                               ETA: 00:09:27

################################################################################
                     [1m Learning iteration 1205/1500 [0m                     

                       Computation: 53567 steps/s (collection: 1.738s, learning 0.098s)
             Mean action noise std: 2.98
          Mean value_function loss: 18.3822
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 42.9183
                       Mean reward: 786.46
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7363
    Episode_Reward/rotating_object: 157.6643
        Episode_Reward/action_rate: -0.0414
          Episode_Reward/joint_vel: -0.0048
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 118554624
                    Iteration time: 1.84s
                      Time elapsed: 00:38:30
                               ETA: 00:09:25

################################################################################
                     [1m Learning iteration 1206/1500 [0m                     

                       Computation: 56754 steps/s (collection: 1.641s, learning 0.092s)
             Mean action noise std: 2.98
          Mean value_function loss: 16.6267
               Mean surrogate loss: -0.0006
                 Mean entropy loss: 42.9245
                       Mean reward: 804.53
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7422
    Episode_Reward/rotating_object: 159.2056
        Episode_Reward/action_rate: -0.0418
          Episode_Reward/joint_vel: -0.0050
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 118652928
                    Iteration time: 1.73s
                      Time elapsed: 00:38:31
                               ETA: 00:09:23

################################################################################
                     [1m Learning iteration 1207/1500 [0m                     

                       Computation: 56944 steps/s (collection: 1.626s, learning 0.100s)
             Mean action noise std: 2.98
          Mean value_function loss: 19.5469
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 42.9279
                       Mean reward: 798.09
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7431
    Episode_Reward/rotating_object: 158.2838
        Episode_Reward/action_rate: -0.0418
          Episode_Reward/joint_vel: -0.0048
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 118751232
                    Iteration time: 1.73s
                      Time elapsed: 00:38:33
                               ETA: 00:09:21

################################################################################
                     [1m Learning iteration 1208/1500 [0m                     

                       Computation: 53751 steps/s (collection: 1.723s, learning 0.106s)
             Mean action noise std: 2.98
          Mean value_function loss: 15.7405
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 42.9349
                       Mean reward: 785.47
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7399
    Episode_Reward/rotating_object: 158.7493
        Episode_Reward/action_rate: -0.0418
          Episode_Reward/joint_vel: -0.0050
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 118849536
                    Iteration time: 1.83s
                      Time elapsed: 00:38:35
                               ETA: 00:09:19

################################################################################
                     [1m Learning iteration 1209/1500 [0m                     

                       Computation: 57508 steps/s (collection: 1.590s, learning 0.120s)
             Mean action noise std: 2.98
          Mean value_function loss: 18.7191
               Mean surrogate loss: 0.0001
                 Mean entropy loss: 42.9460
                       Mean reward: 801.26
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7430
    Episode_Reward/rotating_object: 158.5109
        Episode_Reward/action_rate: -0.0419
          Episode_Reward/joint_vel: -0.0046
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 118947840
                    Iteration time: 1.71s
                      Time elapsed: 00:38:37
                               ETA: 00:09:17

################################################################################
                     [1m Learning iteration 1210/1500 [0m                     

                       Computation: 58071 steps/s (collection: 1.604s, learning 0.088s)
             Mean action noise std: 2.98
          Mean value_function loss: 17.2059
               Mean surrogate loss: 0.0036
                 Mean entropy loss: 42.9553
                       Mean reward: 787.13
               Mean episode length: 247.73
    Episode_Reward/reaching_object: 0.7373
    Episode_Reward/rotating_object: 157.1304
        Episode_Reward/action_rate: -0.0417
          Episode_Reward/joint_vel: -0.0048
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 119046144
                    Iteration time: 1.69s
                      Time elapsed: 00:38:38
                               ETA: 00:09:15

################################################################################
                     [1m Learning iteration 1211/1500 [0m                     

                       Computation: 57592 steps/s (collection: 1.599s, learning 0.108s)
             Mean action noise std: 2.99
          Mean value_function loss: 18.0985
               Mean surrogate loss: -0.0003
                 Mean entropy loss: 42.9566
                       Mean reward: 798.93
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7427
    Episode_Reward/rotating_object: 159.0402
        Episode_Reward/action_rate: -0.0421
          Episode_Reward/joint_vel: -0.0047
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 119144448
                    Iteration time: 1.71s
                      Time elapsed: 00:38:40
                               ETA: 00:09:13

################################################################################
                     [1m Learning iteration 1212/1500 [0m                     

                       Computation: 57317 steps/s (collection: 1.599s, learning 0.116s)
             Mean action noise std: 2.99
          Mean value_function loss: 17.4478
               Mean surrogate loss: 0.0002
                 Mean entropy loss: 42.9613
                       Mean reward: 784.89
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7353
    Episode_Reward/rotating_object: 157.7527
        Episode_Reward/action_rate: -0.0421
          Episode_Reward/joint_vel: -0.0049
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 119242752
                    Iteration time: 1.72s
                      Time elapsed: 00:38:42
                               ETA: 00:09:11

################################################################################
                     [1m Learning iteration 1213/1500 [0m                     

                       Computation: 55383 steps/s (collection: 1.607s, learning 0.168s)
             Mean action noise std: 2.99
          Mean value_function loss: 21.0510
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 42.9670
                       Mean reward: 791.55
               Mean episode length: 248.83
    Episode_Reward/reaching_object: 0.7301
    Episode_Reward/rotating_object: 155.9500
        Episode_Reward/action_rate: -0.0418
          Episode_Reward/joint_vel: -0.0048
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 119341056
                    Iteration time: 1.77s
                      Time elapsed: 00:38:44
                               ETA: 00:09:09

################################################################################
                     [1m Learning iteration 1214/1500 [0m                     

                       Computation: 54076 steps/s (collection: 1.720s, learning 0.098s)
             Mean action noise std: 2.99
          Mean value_function loss: 17.6260
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 42.9761
                       Mean reward: 815.17
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7351
    Episode_Reward/rotating_object: 158.9931
        Episode_Reward/action_rate: -0.0420
          Episode_Reward/joint_vel: -0.0047
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 119439360
                    Iteration time: 1.82s
                      Time elapsed: 00:38:45
                               ETA: 00:09:07

################################################################################
                     [1m Learning iteration 1215/1500 [0m                     

                       Computation: 58150 steps/s (collection: 1.598s, learning 0.092s)
             Mean action noise std: 2.99
          Mean value_function loss: 16.1066
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 42.9809
                       Mean reward: 792.74
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7319
    Episode_Reward/rotating_object: 157.7566
        Episode_Reward/action_rate: -0.0420
          Episode_Reward/joint_vel: -0.0046
      Episode_Termination/time_out: 17.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 119537664
                    Iteration time: 1.69s
                      Time elapsed: 00:38:47
                               ETA: 00:09:05

################################################################################
                     [1m Learning iteration 1216/1500 [0m                     

                       Computation: 53156 steps/s (collection: 1.673s, learning 0.177s)
             Mean action noise std: 2.99
          Mean value_function loss: 22.4907
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 42.9878
                       Mean reward: 789.43
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7312
    Episode_Reward/rotating_object: 158.5811
        Episode_Reward/action_rate: -0.0421
          Episode_Reward/joint_vel: -0.0045
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 119635968
                    Iteration time: 1.85s
                      Time elapsed: 00:38:49
                               ETA: 00:09:03

################################################################################
                     [1m Learning iteration 1217/1500 [0m                     

                       Computation: 55238 steps/s (collection: 1.617s, learning 0.163s)
             Mean action noise std: 2.99
          Mean value_function loss: 21.4251
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 42.9987
                       Mean reward: 794.88
               Mean episode length: 248.41
    Episode_Reward/reaching_object: 0.7197
    Episode_Reward/rotating_object: 155.6468
        Episode_Reward/action_rate: -0.0418
          Episode_Reward/joint_vel: -0.0048
      Episode_Termination/time_out: 17.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 119734272
                    Iteration time: 1.78s
                      Time elapsed: 00:38:51
                               ETA: 00:09:01

################################################################################
                     [1m Learning iteration 1218/1500 [0m                     

                       Computation: 58109 steps/s (collection: 1.584s, learning 0.108s)
             Mean action noise std: 3.00
          Mean value_function loss: 25.2982
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 43.0060
                       Mean reward: 795.07
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7198
    Episode_Reward/rotating_object: 156.5178
        Episode_Reward/action_rate: -0.0419
          Episode_Reward/joint_vel: -0.0047
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 119832576
                    Iteration time: 1.69s
                      Time elapsed: 00:38:52
                               ETA: 00:08:59

################################################################################
                     [1m Learning iteration 1219/1500 [0m                     

                       Computation: 58012 steps/s (collection: 1.604s, learning 0.091s)
             Mean action noise std: 3.00
          Mean value_function loss: 16.8263
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 43.0104
                       Mean reward: 765.28
               Mean episode length: 247.55
    Episode_Reward/reaching_object: 0.7211
    Episode_Reward/rotating_object: 156.7931
        Episode_Reward/action_rate: -0.0418
          Episode_Reward/joint_vel: -0.0046
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 119930880
                    Iteration time: 1.69s
                      Time elapsed: 00:38:54
                               ETA: 00:08:57

################################################################################
                     [1m Learning iteration 1220/1500 [0m                     

                       Computation: 56819 steps/s (collection: 1.637s, learning 0.093s)
             Mean action noise std: 3.00
          Mean value_function loss: 16.4817
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 43.0127
                       Mean reward: 781.70
               Mean episode length: 245.74
    Episode_Reward/reaching_object: 0.7246
    Episode_Reward/rotating_object: 157.3192
        Episode_Reward/action_rate: -0.0419
          Episode_Reward/joint_vel: -0.0047
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 120029184
                    Iteration time: 1.73s
                      Time elapsed: 00:38:56
                               ETA: 00:08:55

################################################################################
                     [1m Learning iteration 1221/1500 [0m                     

                       Computation: 57495 steps/s (collection: 1.598s, learning 0.111s)
             Mean action noise std: 3.00
          Mean value_function loss: 16.7966
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 43.0179
                       Mean reward: 782.90
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7226
    Episode_Reward/rotating_object: 157.1052
        Episode_Reward/action_rate: -0.0420
          Episode_Reward/joint_vel: -0.0048
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 120127488
                    Iteration time: 1.71s
                      Time elapsed: 00:38:58
                               ETA: 00:08:53

################################################################################
                     [1m Learning iteration 1222/1500 [0m                     

                       Computation: 56895 steps/s (collection: 1.622s, learning 0.106s)
             Mean action noise std: 3.00
          Mean value_function loss: 16.8115
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 43.0227
                       Mean reward: 796.78
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7214
    Episode_Reward/rotating_object: 155.8278
        Episode_Reward/action_rate: -0.0422
          Episode_Reward/joint_vel: -0.0048
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 120225792
                    Iteration time: 1.73s
                      Time elapsed: 00:38:59
                               ETA: 00:08:51

################################################################################
                     [1m Learning iteration 1223/1500 [0m                     

                       Computation: 57453 steps/s (collection: 1.582s, learning 0.129s)
             Mean action noise std: 3.00
          Mean value_function loss: 13.7038
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 43.0276
                       Mean reward: 796.17
               Mean episode length: 249.02
    Episode_Reward/reaching_object: 0.7245
    Episode_Reward/rotating_object: 157.3210
        Episode_Reward/action_rate: -0.0422
          Episode_Reward/joint_vel: -0.0048
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 120324096
                    Iteration time: 1.71s
                      Time elapsed: 00:39:01
                               ETA: 00:08:49

################################################################################
                     [1m Learning iteration 1224/1500 [0m                     

                       Computation: 56177 steps/s (collection: 1.627s, learning 0.123s)
             Mean action noise std: 3.00
          Mean value_function loss: 20.1493
               Mean surrogate loss: -0.0002
                 Mean entropy loss: 43.0327
                       Mean reward: 789.48
               Mean episode length: 248.39
    Episode_Reward/reaching_object: 0.7291
    Episode_Reward/rotating_object: 158.3172
        Episode_Reward/action_rate: -0.0422
          Episode_Reward/joint_vel: -0.0047
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 120422400
                    Iteration time: 1.75s
                      Time elapsed: 00:39:03
                               ETA: 00:08:47

################################################################################
                     [1m Learning iteration 1225/1500 [0m                     

                       Computation: 58203 steps/s (collection: 1.600s, learning 0.089s)
             Mean action noise std: 3.00
          Mean value_function loss: 20.3936
               Mean surrogate loss: 0.0004
                 Mean entropy loss: 43.0424
                       Mean reward: 782.29
               Mean episode length: 247.78
    Episode_Reward/reaching_object: 0.7230
    Episode_Reward/rotating_object: 157.6882
        Episode_Reward/action_rate: -0.0420
          Episode_Reward/joint_vel: -0.0047
      Episode_Termination/time_out: 17.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 120520704
                    Iteration time: 1.69s
                      Time elapsed: 00:39:04
                               ETA: 00:08:45

################################################################################
                     [1m Learning iteration 1226/1500 [0m                     

                       Computation: 55735 steps/s (collection: 1.665s, learning 0.099s)
             Mean action noise std: 3.01
          Mean value_function loss: 21.8569
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 43.0508
                       Mean reward: 797.75
               Mean episode length: 248.12
    Episode_Reward/reaching_object: 0.7279
    Episode_Reward/rotating_object: 158.0119
        Episode_Reward/action_rate: -0.0423
          Episode_Reward/joint_vel: -0.0048
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 120619008
                    Iteration time: 1.76s
                      Time elapsed: 00:39:06
                               ETA: 00:08:44

################################################################################
                     [1m Learning iteration 1227/1500 [0m                     

                       Computation: 56733 steps/s (collection: 1.601s, learning 0.132s)
             Mean action noise std: 3.01
          Mean value_function loss: 25.5146
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 43.0639
                       Mean reward: 792.08
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7212
    Episode_Reward/rotating_object: 156.0792
        Episode_Reward/action_rate: -0.0421
          Episode_Reward/joint_vel: -0.0048
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 120717312
                    Iteration time: 1.73s
                      Time elapsed: 00:39:08
                               ETA: 00:08:42

################################################################################
                     [1m Learning iteration 1228/1500 [0m                     

                       Computation: 58334 steps/s (collection: 1.588s, learning 0.098s)
             Mean action noise std: 3.01
          Mean value_function loss: 25.2265
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 43.0808
                       Mean reward: 758.65
               Mean episode length: 245.83
    Episode_Reward/reaching_object: 0.7120
    Episode_Reward/rotating_object: 152.3089
        Episode_Reward/action_rate: -0.0420
          Episode_Reward/joint_vel: -0.0051
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 120815616
                    Iteration time: 1.69s
                      Time elapsed: 00:39:10
                               ETA: 00:08:40

################################################################################
                     [1m Learning iteration 1229/1500 [0m                     

                       Computation: 57555 steps/s (collection: 1.618s, learning 0.090s)
             Mean action noise std: 3.01
          Mean value_function loss: 21.2029
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 43.0906
                       Mean reward: 803.48
               Mean episode length: 248.29
    Episode_Reward/reaching_object: 0.7273
    Episode_Reward/rotating_object: 158.9973
        Episode_Reward/action_rate: -0.0424
          Episode_Reward/joint_vel: -0.0047
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 120913920
                    Iteration time: 1.71s
                      Time elapsed: 00:39:11
                               ETA: 00:08:38

################################################################################
                     [1m Learning iteration 1230/1500 [0m                     

                       Computation: 56212 steps/s (collection: 1.638s, learning 0.111s)
             Mean action noise std: 3.01
          Mean value_function loss: 16.7949
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 43.1011
                       Mean reward: 777.88
               Mean episode length: 247.14
    Episode_Reward/reaching_object: 0.7132
    Episode_Reward/rotating_object: 155.6164
        Episode_Reward/action_rate: -0.0421
          Episode_Reward/joint_vel: -0.0049
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 121012224
                    Iteration time: 1.75s
                      Time elapsed: 00:39:13
                               ETA: 00:08:36

################################################################################
                     [1m Learning iteration 1231/1500 [0m                     

                       Computation: 57641 steps/s (collection: 1.591s, learning 0.115s)
             Mean action noise std: 3.02
          Mean value_function loss: 20.2106
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 43.1126
                       Mean reward: 809.27
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7233
    Episode_Reward/rotating_object: 157.8974
        Episode_Reward/action_rate: -0.0425
          Episode_Reward/joint_vel: -0.0049
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 121110528
                    Iteration time: 1.71s
                      Time elapsed: 00:39:15
                               ETA: 00:08:34

################################################################################
                     [1m Learning iteration 1232/1500 [0m                     

                       Computation: 56873 steps/s (collection: 1.623s, learning 0.106s)
             Mean action noise std: 3.02
          Mean value_function loss: 23.6097
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 43.1229
                       Mean reward: 777.09
               Mean episode length: 246.21
    Episode_Reward/reaching_object: 0.7172
    Episode_Reward/rotating_object: 157.9545
        Episode_Reward/action_rate: -0.0421
          Episode_Reward/joint_vel: -0.0047
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 121208832
                    Iteration time: 1.73s
                      Time elapsed: 00:39:16
                               ETA: 00:08:32

################################################################################
                     [1m Learning iteration 1233/1500 [0m                     

                       Computation: 57509 steps/s (collection: 1.607s, learning 0.103s)
             Mean action noise std: 3.02
          Mean value_function loss: 20.3779
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 43.1314
                       Mean reward: 771.55
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7156
    Episode_Reward/rotating_object: 154.6454
        Episode_Reward/action_rate: -0.0426
          Episode_Reward/joint_vel: -0.0047
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 121307136
                    Iteration time: 1.71s
                      Time elapsed: 00:39:18
                               ETA: 00:08:30

################################################################################
                     [1m Learning iteration 1234/1500 [0m                     

                       Computation: 56841 steps/s (collection: 1.595s, learning 0.134s)
             Mean action noise std: 3.02
          Mean value_function loss: 22.9670
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 43.1357
                       Mean reward: 806.82
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7148
    Episode_Reward/rotating_object: 155.4224
        Episode_Reward/action_rate: -0.0422
          Episode_Reward/joint_vel: -0.0048
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 121405440
                    Iteration time: 1.73s
                      Time elapsed: 00:39:20
                               ETA: 00:08:28

################################################################################
                     [1m Learning iteration 1235/1500 [0m                     

                       Computation: 57496 steps/s (collection: 1.620s, learning 0.090s)
             Mean action noise std: 3.02
          Mean value_function loss: 26.4221
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 43.1401
                       Mean reward: 788.98
               Mean episode length: 247.81
    Episode_Reward/reaching_object: 0.7213
    Episode_Reward/rotating_object: 155.9492
        Episode_Reward/action_rate: -0.0428
          Episode_Reward/joint_vel: -0.0048
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 121503744
                    Iteration time: 1.71s
                      Time elapsed: 00:39:22
                               ETA: 00:08:26

################################################################################
                     [1m Learning iteration 1236/1500 [0m                     

                       Computation: 58082 steps/s (collection: 1.604s, learning 0.089s)
             Mean action noise std: 3.02
          Mean value_function loss: 22.5603
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 43.1510
                       Mean reward: 772.37
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7196
    Episode_Reward/rotating_object: 155.8016
        Episode_Reward/action_rate: -0.0429
          Episode_Reward/joint_vel: -0.0050
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 121602048
                    Iteration time: 1.69s
                      Time elapsed: 00:39:23
                               ETA: 00:08:24

################################################################################
                     [1m Learning iteration 1237/1500 [0m                     

                       Computation: 56168 steps/s (collection: 1.608s, learning 0.142s)
             Mean action noise std: 3.03
          Mean value_function loss: 30.1063
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 43.1580
                       Mean reward: 760.75
               Mean episode length: 245.85
    Episode_Reward/reaching_object: 0.7162
    Episode_Reward/rotating_object: 155.1250
        Episode_Reward/action_rate: -0.0425
          Episode_Reward/joint_vel: -0.0049
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 121700352
                    Iteration time: 1.75s
                      Time elapsed: 00:39:25
                               ETA: 00:08:22

################################################################################
                     [1m Learning iteration 1238/1500 [0m                     

                       Computation: 58464 steps/s (collection: 1.590s, learning 0.091s)
             Mean action noise std: 3.03
          Mean value_function loss: 22.9155
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 43.1671
                       Mean reward: 761.48
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7213
    Episode_Reward/rotating_object: 156.5396
        Episode_Reward/action_rate: -0.0430
          Episode_Reward/joint_vel: -0.0052
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 121798656
                    Iteration time: 1.68s
                      Time elapsed: 00:39:27
                               ETA: 00:08:20

################################################################################
                     [1m Learning iteration 1239/1500 [0m                     

                       Computation: 56391 steps/s (collection: 1.634s, learning 0.109s)
             Mean action noise std: 3.03
          Mean value_function loss: 21.2643
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 43.1850
                       Mean reward: 764.55
               Mean episode length: 246.19
    Episode_Reward/reaching_object: 0.7195
    Episode_Reward/rotating_object: 155.8143
        Episode_Reward/action_rate: -0.0428
          Episode_Reward/joint_vel: -0.0050
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 121896960
                    Iteration time: 1.74s
                      Time elapsed: 00:39:28
                               ETA: 00:08:18

################################################################################
                     [1m Learning iteration 1240/1500 [0m                     

                       Computation: 56563 steps/s (collection: 1.604s, learning 0.134s)
             Mean action noise std: 3.03
          Mean value_function loss: 24.5054
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 43.1972
                       Mean reward: 789.04
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7172
    Episode_Reward/rotating_object: 155.2619
        Episode_Reward/action_rate: -0.0427
          Episode_Reward/joint_vel: -0.0051
      Episode_Termination/time_out: 17.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 121995264
                    Iteration time: 1.74s
                      Time elapsed: 00:39:30
                               ETA: 00:08:16

################################################################################
                     [1m Learning iteration 1241/1500 [0m                     

                       Computation: 57993 steps/s (collection: 1.578s, learning 0.117s)
             Mean action noise std: 3.03
          Mean value_function loss: 27.9293
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 43.2001
                       Mean reward: 770.56
               Mean episode length: 244.11
    Episode_Reward/reaching_object: 0.7137
    Episode_Reward/rotating_object: 154.0558
        Episode_Reward/action_rate: -0.0427
          Episode_Reward/joint_vel: -0.0051
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 122093568
                    Iteration time: 1.70s
                      Time elapsed: 00:39:32
                               ETA: 00:08:14

################################################################################
                     [1m Learning iteration 1242/1500 [0m                     

                       Computation: 54537 steps/s (collection: 1.652s, learning 0.151s)
             Mean action noise std: 3.03
          Mean value_function loss: 30.7078
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 43.2085
                       Mean reward: 777.94
               Mean episode length: 243.40
    Episode_Reward/reaching_object: 0.7174
    Episode_Reward/rotating_object: 156.4693
        Episode_Reward/action_rate: -0.0429
          Episode_Reward/joint_vel: -0.0051
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 122191872
                    Iteration time: 1.80s
                      Time elapsed: 00:39:34
                               ETA: 00:08:12

################################################################################
                     [1m Learning iteration 1243/1500 [0m                     

                       Computation: 57068 steps/s (collection: 1.625s, learning 0.097s)
             Mean action noise std: 3.04
          Mean value_function loss: 20.3140
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 43.2205
                       Mean reward: 779.88
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7145
    Episode_Reward/rotating_object: 154.4148
        Episode_Reward/action_rate: -0.0431
          Episode_Reward/joint_vel: -0.0050
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 122290176
                    Iteration time: 1.72s
                      Time elapsed: 00:39:35
                               ETA: 00:08:10

################################################################################
                     [1m Learning iteration 1244/1500 [0m                     

                       Computation: 57704 steps/s (collection: 1.607s, learning 0.097s)
             Mean action noise std: 3.04
          Mean value_function loss: 17.6436
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 43.2375
                       Mean reward: 774.27
               Mean episode length: 248.25
    Episode_Reward/reaching_object: 0.7154
    Episode_Reward/rotating_object: 153.9440
        Episode_Reward/action_rate: -0.0432
          Episode_Reward/joint_vel: -0.0051
      Episode_Termination/time_out: 17.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 122388480
                    Iteration time: 1.70s
                      Time elapsed: 00:39:37
                               ETA: 00:08:08

################################################################################
                     [1m Learning iteration 1245/1500 [0m                     

                       Computation: 57941 steps/s (collection: 1.603s, learning 0.094s)
             Mean action noise std: 3.04
          Mean value_function loss: 14.6698
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 43.2510
                       Mean reward: 785.72
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7200
    Episode_Reward/rotating_object: 155.6910
        Episode_Reward/action_rate: -0.0435
          Episode_Reward/joint_vel: -0.0050
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 122486784
                    Iteration time: 1.70s
                      Time elapsed: 00:39:39
                               ETA: 00:08:06

################################################################################
                     [1m Learning iteration 1246/1500 [0m                     

                       Computation: 56946 steps/s (collection: 1.622s, learning 0.105s)
             Mean action noise std: 3.04
          Mean value_function loss: 18.2126
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 43.2613
                       Mean reward: 793.39
               Mean episode length: 248.25
    Episode_Reward/reaching_object: 0.7193
    Episode_Reward/rotating_object: 156.7417
        Episode_Reward/action_rate: -0.0434
          Episode_Reward/joint_vel: -0.0050
      Episode_Termination/time_out: 17.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 122585088
                    Iteration time: 1.73s
                      Time elapsed: 00:39:41
                               ETA: 00:08:04

################################################################################
                     [1m Learning iteration 1247/1500 [0m                     

                       Computation: 58432 steps/s (collection: 1.592s, learning 0.091s)
             Mean action noise std: 3.04
          Mean value_function loss: 19.8989
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 43.2715
                       Mean reward: 811.14
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7159
    Episode_Reward/rotating_object: 155.7759
        Episode_Reward/action_rate: -0.0435
          Episode_Reward/joint_vel: -0.0056
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 122683392
                    Iteration time: 1.68s
                      Time elapsed: 00:39:42
                               ETA: 00:08:03

################################################################################
                     [1m Learning iteration 1248/1500 [0m                     

                       Computation: 57057 steps/s (collection: 1.627s, learning 0.096s)
             Mean action noise std: 3.05
          Mean value_function loss: 19.6573
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 43.2740
                       Mean reward: 761.88
               Mean episode length: 247.45
    Episode_Reward/reaching_object: 0.7156
    Episode_Reward/rotating_object: 155.6619
        Episode_Reward/action_rate: -0.0434
          Episode_Reward/joint_vel: -0.0052
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 122781696
                    Iteration time: 1.72s
                      Time elapsed: 00:39:44
                               ETA: 00:08:01

################################################################################
                     [1m Learning iteration 1249/1500 [0m                     

                       Computation: 56873 steps/s (collection: 1.629s, learning 0.100s)
             Mean action noise std: 3.05
          Mean value_function loss: 25.9543
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 43.2740
                       Mean reward: 767.33
               Mean episode length: 245.57
    Episode_Reward/reaching_object: 0.7120
    Episode_Reward/rotating_object: 154.1387
        Episode_Reward/action_rate: -0.0434
          Episode_Reward/joint_vel: -0.0051
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 122880000
                    Iteration time: 1.73s
                      Time elapsed: 00:39:46
                               ETA: 00:07:59

################################################################################
                     [1m Learning iteration 1250/1500 [0m                     

                       Computation: 56029 steps/s (collection: 1.651s, learning 0.103s)
             Mean action noise std: 3.05
          Mean value_function loss: 12.7960
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 43.2819
                       Mean reward: 793.56
               Mean episode length: 247.96
    Episode_Reward/reaching_object: 0.7183
    Episode_Reward/rotating_object: 156.0944
        Episode_Reward/action_rate: -0.0434
          Episode_Reward/joint_vel: -0.0052
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 122978304
                    Iteration time: 1.75s
                      Time elapsed: 00:39:47
                               ETA: 00:07:57

################################################################################
                     [1m Learning iteration 1251/1500 [0m                     

                       Computation: 50625 steps/s (collection: 1.817s, learning 0.125s)
             Mean action noise std: 3.05
          Mean value_function loss: 30.3986
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 43.2932
                       Mean reward: 778.11
               Mean episode length: 249.83
    Episode_Reward/reaching_object: 0.7238
    Episode_Reward/rotating_object: 156.9207
        Episode_Reward/action_rate: -0.0439
          Episode_Reward/joint_vel: -0.0053
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 123076608
                    Iteration time: 1.94s
                      Time elapsed: 00:39:49
                               ETA: 00:07:55

################################################################################
                     [1m Learning iteration 1252/1500 [0m                     

                       Computation: 51576 steps/s (collection: 1.743s, learning 0.163s)
             Mean action noise std: 3.05
          Mean value_function loss: 23.9926
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 43.3039
                       Mean reward: 780.11
               Mean episode length: 248.16
    Episode_Reward/reaching_object: 0.7148
    Episode_Reward/rotating_object: 151.7966
        Episode_Reward/action_rate: -0.0437
          Episode_Reward/joint_vel: -0.0057
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 123174912
                    Iteration time: 1.91s
                      Time elapsed: 00:39:51
                               ETA: 00:07:53

################################################################################
                     [1m Learning iteration 1253/1500 [0m                     

                       Computation: 54545 steps/s (collection: 1.683s, learning 0.120s)
             Mean action noise std: 3.05
          Mean value_function loss: 25.6906
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 43.3110
                       Mean reward: 777.57
               Mean episode length: 243.21
    Episode_Reward/reaching_object: 0.7128
    Episode_Reward/rotating_object: 153.6722
        Episode_Reward/action_rate: -0.0433
          Episode_Reward/joint_vel: -0.0056
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 123273216
                    Iteration time: 1.80s
                      Time elapsed: 00:39:53
                               ETA: 00:07:51

################################################################################
                     [1m Learning iteration 1254/1500 [0m                     

                       Computation: 55164 steps/s (collection: 1.686s, learning 0.096s)
             Mean action noise std: 3.06
          Mean value_function loss: 18.9640
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 43.3178
                       Mean reward: 779.47
               Mean episode length: 248.05
    Episode_Reward/reaching_object: 0.7219
    Episode_Reward/rotating_object: 155.8499
        Episode_Reward/action_rate: -0.0437
          Episode_Reward/joint_vel: -0.0052
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 123371520
                    Iteration time: 1.78s
                      Time elapsed: 00:39:55
                               ETA: 00:07:49

################################################################################
                     [1m Learning iteration 1255/1500 [0m                     

                       Computation: 51211 steps/s (collection: 1.761s, learning 0.158s)
             Mean action noise std: 3.06
          Mean value_function loss: 22.7776
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 43.3243
                       Mean reward: 780.97
               Mean episode length: 248.66
    Episode_Reward/reaching_object: 0.7289
    Episode_Reward/rotating_object: 158.4955
        Episode_Reward/action_rate: -0.0439
          Episode_Reward/joint_vel: -0.0052
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 123469824
                    Iteration time: 1.92s
                      Time elapsed: 00:39:57
                               ETA: 00:07:47

################################################################################
                     [1m Learning iteration 1256/1500 [0m                     

                       Computation: 55034 steps/s (collection: 1.676s, learning 0.110s)
             Mean action noise std: 3.06
          Mean value_function loss: 18.5098
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 43.3246
                       Mean reward: 797.17
               Mean episode length: 247.93
    Episode_Reward/reaching_object: 0.7303
    Episode_Reward/rotating_object: 158.3158
        Episode_Reward/action_rate: -0.0440
          Episode_Reward/joint_vel: -0.0053
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 123568128
                    Iteration time: 1.79s
                      Time elapsed: 00:39:59
                               ETA: 00:07:45

################################################################################
                     [1m Learning iteration 1257/1500 [0m                     

                       Computation: 55117 steps/s (collection: 1.649s, learning 0.134s)
             Mean action noise std: 3.06
          Mean value_function loss: 21.9360
               Mean surrogate loss: -0.0001
                 Mean entropy loss: 43.3270
                       Mean reward: 804.35
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7284
    Episode_Reward/rotating_object: 158.3309
        Episode_Reward/action_rate: -0.0441
          Episode_Reward/joint_vel: -0.0057
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 123666432
                    Iteration time: 1.78s
                      Time elapsed: 00:40:00
                               ETA: 00:07:43

################################################################################
                     [1m Learning iteration 1258/1500 [0m                     

                       Computation: 53504 steps/s (collection: 1.677s, learning 0.160s)
             Mean action noise std: 3.06
          Mean value_function loss: 18.9771
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 43.3298
                       Mean reward: 783.07
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7278
    Episode_Reward/rotating_object: 155.9720
        Episode_Reward/action_rate: -0.0442
          Episode_Reward/joint_vel: -0.0054
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 123764736
                    Iteration time: 1.84s
                      Time elapsed: 00:40:02
                               ETA: 00:07:41

################################################################################
                     [1m Learning iteration 1259/1500 [0m                     

                       Computation: 55862 steps/s (collection: 1.653s, learning 0.107s)
             Mean action noise std: 3.06
          Mean value_function loss: 22.0644
               Mean surrogate loss: 0.0006
                 Mean entropy loss: 43.3311
                       Mean reward: 782.80
               Mean episode length: 245.34
    Episode_Reward/reaching_object: 0.7198
    Episode_Reward/rotating_object: 156.4775
        Episode_Reward/action_rate: -0.0435
          Episode_Reward/joint_vel: -0.0056
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 123863040
                    Iteration time: 1.76s
                      Time elapsed: 00:40:04
                               ETA: 00:07:39

################################################################################
                     [1m Learning iteration 1260/1500 [0m                     

                       Computation: 55658 steps/s (collection: 1.666s, learning 0.100s)
             Mean action noise std: 3.06
          Mean value_function loss: 12.6861
               Mean surrogate loss: 0.0017
                 Mean entropy loss: 43.3319
                       Mean reward: 788.34
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7270
    Episode_Reward/rotating_object: 157.7737
        Episode_Reward/action_rate: -0.0442
          Episode_Reward/joint_vel: -0.0056
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 123961344
                    Iteration time: 1.77s
                      Time elapsed: 00:40:06
                               ETA: 00:07:37

################################################################################
                     [1m Learning iteration 1261/1500 [0m                     

                       Computation: 56352 steps/s (collection: 1.634s, learning 0.111s)
             Mean action noise std: 3.06
          Mean value_function loss: 10.9056
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 43.3332
                       Mean reward: 773.59
               Mean episode length: 247.76
    Episode_Reward/reaching_object: 0.7210
    Episode_Reward/rotating_object: 154.9673
        Episode_Reward/action_rate: -0.0441
          Episode_Reward/joint_vel: -0.0056
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 124059648
                    Iteration time: 1.74s
                      Time elapsed: 00:40:07
                               ETA: 00:07:36

################################################################################
                     [1m Learning iteration 1262/1500 [0m                     

                       Computation: 52565 steps/s (collection: 1.731s, learning 0.139s)
             Mean action noise std: 3.06
          Mean value_function loss: 19.4816
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 43.3394
                       Mean reward: 778.71
               Mean episode length: 246.09
    Episode_Reward/reaching_object: 0.7189
    Episode_Reward/rotating_object: 156.4926
        Episode_Reward/action_rate: -0.0439
          Episode_Reward/joint_vel: -0.0055
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 124157952
                    Iteration time: 1.87s
                      Time elapsed: 00:40:09
                               ETA: 00:07:34

################################################################################
                     [1m Learning iteration 1263/1500 [0m                     

                       Computation: 52958 steps/s (collection: 1.688s, learning 0.168s)
             Mean action noise std: 3.06
          Mean value_function loss: 18.2048
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 43.3517
                       Mean reward: 787.21
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7256
    Episode_Reward/rotating_object: 156.5794
        Episode_Reward/action_rate: -0.0442
          Episode_Reward/joint_vel: -0.0053
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 124256256
                    Iteration time: 1.86s
                      Time elapsed: 00:40:11
                               ETA: 00:07:32

################################################################################
                     [1m Learning iteration 1264/1500 [0m                     

                       Computation: 52952 steps/s (collection: 1.747s, learning 0.110s)
             Mean action noise std: 3.07
          Mean value_function loss: 16.8502
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 43.3617
                       Mean reward: 821.64
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7260
    Episode_Reward/rotating_object: 158.7321
        Episode_Reward/action_rate: -0.0442
          Episode_Reward/joint_vel: -0.0054
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 124354560
                    Iteration time: 1.86s
                      Time elapsed: 00:40:13
                               ETA: 00:07:30

################################################################################
                     [1m Learning iteration 1265/1500 [0m                     

                       Computation: 55194 steps/s (collection: 1.673s, learning 0.109s)
             Mean action noise std: 3.07
          Mean value_function loss: 21.7498
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 43.3705
                       Mean reward: 799.39
               Mean episode length: 247.85
    Episode_Reward/reaching_object: 0.7264
    Episode_Reward/rotating_object: 157.8802
        Episode_Reward/action_rate: -0.0441
          Episode_Reward/joint_vel: -0.0054
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 124452864
                    Iteration time: 1.78s
                      Time elapsed: 00:40:15
                               ETA: 00:07:28

################################################################################
                     [1m Learning iteration 1266/1500 [0m                     

                       Computation: 55080 steps/s (collection: 1.687s, learning 0.098s)
             Mean action noise std: 3.07
          Mean value_function loss: 19.7690
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 43.3794
                       Mean reward: 789.70
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7272
    Episode_Reward/rotating_object: 157.1791
        Episode_Reward/action_rate: -0.0443
          Episode_Reward/joint_vel: -0.0053
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 124551168
                    Iteration time: 1.78s
                      Time elapsed: 00:40:17
                               ETA: 00:07:26

################################################################################
                     [1m Learning iteration 1267/1500 [0m                     

                       Computation: 54200 steps/s (collection: 1.698s, learning 0.116s)
             Mean action noise std: 3.07
          Mean value_function loss: 25.6011
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 43.3897
                       Mean reward: 790.48
               Mean episode length: 247.71
    Episode_Reward/reaching_object: 0.7279
    Episode_Reward/rotating_object: 157.3333
        Episode_Reward/action_rate: -0.0441
          Episode_Reward/joint_vel: -0.0052
      Episode_Termination/time_out: 17.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 124649472
                    Iteration time: 1.81s
                      Time elapsed: 00:40:18
                               ETA: 00:07:24

################################################################################
                     [1m Learning iteration 1268/1500 [0m                     

                       Computation: 54650 steps/s (collection: 1.663s, learning 0.136s)
             Mean action noise std: 3.07
          Mean value_function loss: 15.3783
               Mean surrogate loss: -0.0003
                 Mean entropy loss: 43.3965
                       Mean reward: 792.91
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7285
    Episode_Reward/rotating_object: 157.5683
        Episode_Reward/action_rate: -0.0443
          Episode_Reward/joint_vel: -0.0055
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 124747776
                    Iteration time: 1.80s
                      Time elapsed: 00:40:20
                               ETA: 00:07:22

################################################################################
                     [1m Learning iteration 1269/1500 [0m                     

                       Computation: 56543 steps/s (collection: 1.631s, learning 0.108s)
             Mean action noise std: 3.07
          Mean value_function loss: 24.8678
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 43.3999
                       Mean reward: 795.77
               Mean episode length: 247.84
    Episode_Reward/reaching_object: 0.7336
    Episode_Reward/rotating_object: 157.8698
        Episode_Reward/action_rate: -0.0441
          Episode_Reward/joint_vel: -0.0052
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 124846080
                    Iteration time: 1.74s
                      Time elapsed: 00:40:22
                               ETA: 00:07:20

################################################################################
                     [1m Learning iteration 1270/1500 [0m                     

                       Computation: 54844 steps/s (collection: 1.695s, learning 0.097s)
             Mean action noise std: 3.08
          Mean value_function loss: 28.6130
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 43.4059
                       Mean reward: 785.68
               Mean episode length: 243.51
    Episode_Reward/reaching_object: 0.7375
    Episode_Reward/rotating_object: 157.8782
        Episode_Reward/action_rate: -0.0441
          Episode_Reward/joint_vel: -0.0053
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 124944384
                    Iteration time: 1.79s
                      Time elapsed: 00:40:24
                               ETA: 00:07:18

################################################################################
                     [1m Learning iteration 1271/1500 [0m                     

                       Computation: 54905 steps/s (collection: 1.697s, learning 0.093s)
             Mean action noise std: 3.08
          Mean value_function loss: 22.2276
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 43.4122
                       Mean reward: 788.33
               Mean episode length: 249.18
    Episode_Reward/reaching_object: 0.7427
    Episode_Reward/rotating_object: 157.7839
        Episode_Reward/action_rate: -0.0446
          Episode_Reward/joint_vel: -0.0056
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 125042688
                    Iteration time: 1.79s
                      Time elapsed: 00:40:26
                               ETA: 00:07:16

################################################################################
                     [1m Learning iteration 1272/1500 [0m                     

                       Computation: 54140 steps/s (collection: 1.690s, learning 0.125s)
             Mean action noise std: 3.08
          Mean value_function loss: 27.6552
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 43.4204
                       Mean reward: 779.36
               Mean episode length: 245.92
    Episode_Reward/reaching_object: 0.7289
    Episode_Reward/rotating_object: 155.1627
        Episode_Reward/action_rate: -0.0439
          Episode_Reward/joint_vel: -0.0053
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 125140992
                    Iteration time: 1.82s
                      Time elapsed: 00:40:27
                               ETA: 00:07:14

################################################################################
                     [1m Learning iteration 1273/1500 [0m                     

                       Computation: 50652 steps/s (collection: 1.781s, learning 0.160s)
             Mean action noise std: 3.08
          Mean value_function loss: 20.5338
               Mean surrogate loss: -0.0005
                 Mean entropy loss: 43.4230
                       Mean reward: 778.07
               Mean episode length: 245.83
    Episode_Reward/reaching_object: 0.7394
    Episode_Reward/rotating_object: 157.0107
        Episode_Reward/action_rate: -0.0444
          Episode_Reward/joint_vel: -0.0052
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 125239296
                    Iteration time: 1.94s
                      Time elapsed: 00:40:29
                               ETA: 00:07:12

################################################################################
                     [1m Learning iteration 1274/1500 [0m                     

                       Computation: 54938 steps/s (collection: 1.666s, learning 0.123s)
             Mean action noise std: 3.08
          Mean value_function loss: 16.4718
               Mean surrogate loss: -0.0006
                 Mean entropy loss: 43.4257
                       Mean reward: 791.72
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7359
    Episode_Reward/rotating_object: 157.1167
        Episode_Reward/action_rate: -0.0445
          Episode_Reward/joint_vel: -0.0055
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 125337600
                    Iteration time: 1.79s
                      Time elapsed: 00:40:31
                               ETA: 00:07:11

################################################################################
                     [1m Learning iteration 1275/1500 [0m                     

                       Computation: 50220 steps/s (collection: 1.808s, learning 0.149s)
             Mean action noise std: 3.08
          Mean value_function loss: 20.5644
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 43.4299
                       Mean reward: 791.08
               Mean episode length: 245.75
    Episode_Reward/reaching_object: 0.7293
    Episode_Reward/rotating_object: 154.3074
        Episode_Reward/action_rate: -0.0446
          Episode_Reward/joint_vel: -0.0058
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 125435904
                    Iteration time: 1.96s
                      Time elapsed: 00:40:33
                               ETA: 00:07:09

################################################################################
                     [1m Learning iteration 1276/1500 [0m                     

                       Computation: 55792 steps/s (collection: 1.658s, learning 0.104s)
             Mean action noise std: 3.08
          Mean value_function loss: 19.8828
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 43.4355
                       Mean reward: 799.65
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7389
    Episode_Reward/rotating_object: 159.1378
        Episode_Reward/action_rate: -0.0447
          Episode_Reward/joint_vel: -0.0053
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 125534208
                    Iteration time: 1.76s
                      Time elapsed: 00:40:35
                               ETA: 00:07:07

################################################################################
                     [1m Learning iteration 1277/1500 [0m                     

                       Computation: 55880 steps/s (collection: 1.660s, learning 0.099s)
             Mean action noise std: 3.09
          Mean value_function loss: 24.5951
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 43.4483
                       Mean reward: 809.29
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7294
    Episode_Reward/rotating_object: 157.6011
        Episode_Reward/action_rate: -0.0444
          Episode_Reward/joint_vel: -0.0055
      Episode_Termination/time_out: 17.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 125632512
                    Iteration time: 1.76s
                      Time elapsed: 00:40:37
                               ETA: 00:07:05

################################################################################
                     [1m Learning iteration 1278/1500 [0m                     

                       Computation: 55809 steps/s (collection: 1.667s, learning 0.094s)
             Mean action noise std: 3.09
          Mean value_function loss: 19.5810
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 43.4605
                       Mean reward: 790.97
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7329
    Episode_Reward/rotating_object: 157.7058
        Episode_Reward/action_rate: -0.0448
          Episode_Reward/joint_vel: -0.0053
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 125730816
                    Iteration time: 1.76s
                      Time elapsed: 00:40:38
                               ETA: 00:07:03

################################################################################
                     [1m Learning iteration 1279/1500 [0m                     

                       Computation: 54529 steps/s (collection: 1.661s, learning 0.142s)
             Mean action noise std: 3.09
          Mean value_function loss: 14.9401
               Mean surrogate loss: -0.0001
                 Mean entropy loss: 43.4675
                       Mean reward: 767.88
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7279
    Episode_Reward/rotating_object: 156.1166
        Episode_Reward/action_rate: -0.0449
          Episode_Reward/joint_vel: -0.0056
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 125829120
                    Iteration time: 1.80s
                      Time elapsed: 00:40:40
                               ETA: 00:07:01

################################################################################
                     [1m Learning iteration 1280/1500 [0m                     

                       Computation: 55892 steps/s (collection: 1.664s, learning 0.095s)
             Mean action noise std: 3.09
          Mean value_function loss: 22.4799
               Mean surrogate loss: 0.0013
                 Mean entropy loss: 43.4718
                       Mean reward: 805.77
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7269
    Episode_Reward/rotating_object: 157.6124
        Episode_Reward/action_rate: -0.0447
          Episode_Reward/joint_vel: -0.0055
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 125927424
                    Iteration time: 1.76s
                      Time elapsed: 00:40:42
                               ETA: 00:06:59

################################################################################
                     [1m Learning iteration 1281/1500 [0m                     

                       Computation: 54781 steps/s (collection: 1.676s, learning 0.118s)
             Mean action noise std: 3.09
          Mean value_function loss: 17.1318
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 43.4762
                       Mean reward: 811.58
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7197
    Episode_Reward/rotating_object: 155.8569
        Episode_Reward/action_rate: -0.0447
          Episode_Reward/joint_vel: -0.0055
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 126025728
                    Iteration time: 1.79s
                      Time elapsed: 00:40:44
                               ETA: 00:06:57

################################################################################
                     [1m Learning iteration 1282/1500 [0m                     

                       Computation: 54397 steps/s (collection: 1.703s, learning 0.105s)
             Mean action noise std: 3.09
          Mean value_function loss: 28.6213
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 43.4840
                       Mean reward: 762.35
               Mean episode length: 245.17
    Episode_Reward/reaching_object: 0.7074
    Episode_Reward/rotating_object: 152.8416
        Episode_Reward/action_rate: -0.0442
          Episode_Reward/joint_vel: -0.0055
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 126124032
                    Iteration time: 1.81s
                      Time elapsed: 00:40:46
                               ETA: 00:06:55

################################################################################
                     [1m Learning iteration 1283/1500 [0m                     

                       Computation: 54859 steps/s (collection: 1.682s, learning 0.110s)
             Mean action noise std: 3.09
          Mean value_function loss: 20.9317
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 43.4942
                       Mean reward: 788.84
               Mean episode length: 246.58
    Episode_Reward/reaching_object: 0.7103
    Episode_Reward/rotating_object: 155.5633
        Episode_Reward/action_rate: -0.0443
          Episode_Reward/joint_vel: -0.0053
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5000
--------------------------------------------------------------------------------
                   Total timesteps: 126222336
                    Iteration time: 1.79s
                      Time elapsed: 00:40:47
                               ETA: 00:06:53

################################################################################
                     [1m Learning iteration 1284/1500 [0m                     

                       Computation: 56030 steps/s (collection: 1.649s, learning 0.106s)
             Mean action noise std: 3.10
          Mean value_function loss: 19.8863
               Mean surrogate loss: -0.0007
                 Mean entropy loss: 43.5052
                       Mean reward: 786.18
               Mean episode length: 246.48
    Episode_Reward/reaching_object: 0.7124
    Episode_Reward/rotating_object: 156.1825
        Episode_Reward/action_rate: -0.0445
          Episode_Reward/joint_vel: -0.0055
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 126320640
                    Iteration time: 1.75s
                      Time elapsed: 00:40:49
                               ETA: 00:06:51

################################################################################
                     [1m Learning iteration 1285/1500 [0m                     

                       Computation: 54802 steps/s (collection: 1.693s, learning 0.101s)
             Mean action noise std: 3.10
          Mean value_function loss: 17.6034
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 43.5112
                       Mean reward: 770.43
               Mean episode length: 245.56
    Episode_Reward/reaching_object: 0.7178
    Episode_Reward/rotating_object: 157.5059
        Episode_Reward/action_rate: -0.0449
          Episode_Reward/joint_vel: -0.0056
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 126418944
                    Iteration time: 1.79s
                      Time elapsed: 00:40:51
                               ETA: 00:06:49

################################################################################
                     [1m Learning iteration 1286/1500 [0m                     

                       Computation: 55811 steps/s (collection: 1.665s, learning 0.096s)
             Mean action noise std: 3.10
          Mean value_function loss: 19.1182
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 43.5141
                       Mean reward: 776.14
               Mean episode length: 247.76
    Episode_Reward/reaching_object: 0.7125
    Episode_Reward/rotating_object: 156.1931
        Episode_Reward/action_rate: -0.0448
          Episode_Reward/joint_vel: -0.0055
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 126517248
                    Iteration time: 1.76s
                      Time elapsed: 00:40:53
                               ETA: 00:06:47

################################################################################
                     [1m Learning iteration 1287/1500 [0m                     

                       Computation: 56167 steps/s (collection: 1.650s, learning 0.100s)
             Mean action noise std: 3.10
          Mean value_function loss: 18.4954
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 43.5183
                       Mean reward: 801.22
               Mean episode length: 248.24
    Episode_Reward/reaching_object: 0.7189
    Episode_Reward/rotating_object: 158.6742
        Episode_Reward/action_rate: -0.0449
          Episode_Reward/joint_vel: -0.0055
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 126615552
                    Iteration time: 1.75s
                      Time elapsed: 00:40:54
                               ETA: 00:06:45

################################################################################
                     [1m Learning iteration 1288/1500 [0m                     

                       Computation: 54091 steps/s (collection: 1.678s, learning 0.140s)
             Mean action noise std: 3.10
          Mean value_function loss: 24.1711
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 43.5269
                       Mean reward: 776.42
               Mean episode length: 245.96
    Episode_Reward/reaching_object: 0.7167
    Episode_Reward/rotating_object: 157.1309
        Episode_Reward/action_rate: -0.0450
          Episode_Reward/joint_vel: -0.0058
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 126713856
                    Iteration time: 1.82s
                      Time elapsed: 00:40:56
                               ETA: 00:06:44

################################################################################
                     [1m Learning iteration 1289/1500 [0m                     

                       Computation: 56126 steps/s (collection: 1.655s, learning 0.097s)
             Mean action noise std: 3.10
          Mean value_function loss: 21.9556
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 43.5383
                       Mean reward: 794.85
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7168
    Episode_Reward/rotating_object: 156.8667
        Episode_Reward/action_rate: -0.0453
          Episode_Reward/joint_vel: -0.0058
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 126812160
                    Iteration time: 1.75s
                      Time elapsed: 00:40:58
                               ETA: 00:06:42

################################################################################
                     [1m Learning iteration 1290/1500 [0m                     

                       Computation: 56299 steps/s (collection: 1.648s, learning 0.098s)
             Mean action noise std: 3.11
          Mean value_function loss: 22.7330
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 43.5470
                       Mean reward: 796.19
               Mean episode length: 247.71
    Episode_Reward/reaching_object: 0.7164
    Episode_Reward/rotating_object: 157.2928
        Episode_Reward/action_rate: -0.0450
          Episode_Reward/joint_vel: -0.0054
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 126910464
                    Iteration time: 1.75s
                      Time elapsed: 00:41:00
                               ETA: 00:06:40

################################################################################
                     [1m Learning iteration 1291/1500 [0m                     

                       Computation: 54244 steps/s (collection: 1.677s, learning 0.135s)
             Mean action noise std: 3.11
          Mean value_function loss: 21.4765
               Mean surrogate loss: 0.0038
                 Mean entropy loss: 43.5516
                       Mean reward: 797.61
               Mean episode length: 247.90
    Episode_Reward/reaching_object: 0.7146
    Episode_Reward/rotating_object: 155.4911
        Episode_Reward/action_rate: -0.0453
          Episode_Reward/joint_vel: -0.0060
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 127008768
                    Iteration time: 1.81s
                      Time elapsed: 00:41:01
                               ETA: 00:06:38

################################################################################
                     [1m Learning iteration 1292/1500 [0m                     

                       Computation: 53571 steps/s (collection: 1.661s, learning 0.174s)
             Mean action noise std: 3.11
          Mean value_function loss: 22.2833
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 43.5549
                       Mean reward: 776.54
               Mean episode length: 246.46
    Episode_Reward/reaching_object: 0.7182
    Episode_Reward/rotating_object: 155.8374
        Episode_Reward/action_rate: -0.0454
          Episode_Reward/joint_vel: -0.0060
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 127107072
                    Iteration time: 1.84s
                      Time elapsed: 00:41:03
                               ETA: 00:06:36

################################################################################
                     [1m Learning iteration 1293/1500 [0m                     

                       Computation: 54809 steps/s (collection: 1.670s, learning 0.124s)
             Mean action noise std: 3.11
          Mean value_function loss: 24.9256
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 43.5626
                       Mean reward: 783.66
               Mean episode length: 247.94
    Episode_Reward/reaching_object: 0.7153
    Episode_Reward/rotating_object: 156.3776
        Episode_Reward/action_rate: -0.0452
          Episode_Reward/joint_vel: -0.0062
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 127205376
                    Iteration time: 1.79s
                      Time elapsed: 00:41:05
                               ETA: 00:06:34

################################################################################
                     [1m Learning iteration 1294/1500 [0m                     

                       Computation: 54982 steps/s (collection: 1.672s, learning 0.116s)
             Mean action noise std: 3.11
          Mean value_function loss: 24.6076
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 43.5756
                       Mean reward: 784.90
               Mean episode length: 247.79
    Episode_Reward/reaching_object: 0.7132
    Episode_Reward/rotating_object: 156.0101
        Episode_Reward/action_rate: -0.0451
          Episode_Reward/joint_vel: -0.0058
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 127303680
                    Iteration time: 1.79s
                      Time elapsed: 00:41:07
                               ETA: 00:06:32

################################################################################
                     [1m Learning iteration 1295/1500 [0m                     

                       Computation: 54693 steps/s (collection: 1.682s, learning 0.116s)
             Mean action noise std: 3.11
          Mean value_function loss: 14.8342
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 43.5913
                       Mean reward: 773.68
               Mean episode length: 249.03
    Episode_Reward/reaching_object: 0.7192
    Episode_Reward/rotating_object: 156.9469
        Episode_Reward/action_rate: -0.0455
          Episode_Reward/joint_vel: -0.0059
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 127401984
                    Iteration time: 1.80s
                      Time elapsed: 00:41:09
                               ETA: 00:06:30

################################################################################
                     [1m Learning iteration 1296/1500 [0m                     

                       Computation: 54476 steps/s (collection: 1.684s, learning 0.120s)
             Mean action noise std: 3.11
          Mean value_function loss: 21.2094
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 43.5985
                       Mean reward: 778.31
               Mean episode length: 244.24
    Episode_Reward/reaching_object: 0.7179
    Episode_Reward/rotating_object: 155.7592
        Episode_Reward/action_rate: -0.0455
          Episode_Reward/joint_vel: -0.0059
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 127500288
                    Iteration time: 1.80s
                      Time elapsed: 00:41:11
                               ETA: 00:06:28

################################################################################
                     [1m Learning iteration 1297/1500 [0m                     

                       Computation: 52936 steps/s (collection: 1.687s, learning 0.170s)
             Mean action noise std: 3.12
          Mean value_function loss: 23.7952
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 43.6071
                       Mean reward: 785.59
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7158
    Episode_Reward/rotating_object: 157.2996
        Episode_Reward/action_rate: -0.0455
          Episode_Reward/joint_vel: -0.0059
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 127598592
                    Iteration time: 1.86s
                      Time elapsed: 00:41:12
                               ETA: 00:06:26

################################################################################
                     [1m Learning iteration 1298/1500 [0m                     

                       Computation: 49182 steps/s (collection: 1.781s, learning 0.218s)
             Mean action noise std: 3.12
          Mean value_function loss: 20.0236
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 43.6132
                       Mean reward: 791.31
               Mean episode length: 249.16
    Episode_Reward/reaching_object: 0.7243
    Episode_Reward/rotating_object: 159.6495
        Episode_Reward/action_rate: -0.0459
          Episode_Reward/joint_vel: -0.0055
      Episode_Termination/time_out: 17.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 127696896
                    Iteration time: 2.00s
                      Time elapsed: 00:41:14
                               ETA: 00:06:24

################################################################################
                     [1m Learning iteration 1299/1500 [0m                     

                       Computation: 54618 steps/s (collection: 1.671s, learning 0.129s)
             Mean action noise std: 3.12
          Mean value_function loss: 16.3286
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 43.6196
                       Mean reward: 785.15
               Mean episode length: 249.27
    Episode_Reward/reaching_object: 0.7132
    Episode_Reward/rotating_object: 155.8136
        Episode_Reward/action_rate: -0.0457
          Episode_Reward/joint_vel: -0.0058
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 127795200
                    Iteration time: 1.80s
                      Time elapsed: 00:41:16
                               ETA: 00:06:22

################################################################################
                     [1m Learning iteration 1300/1500 [0m                     

                       Computation: 55361 steps/s (collection: 1.672s, learning 0.104s)
             Mean action noise std: 3.12
          Mean value_function loss: 21.4586
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 43.6262
                       Mean reward: 804.40
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7211
    Episode_Reward/rotating_object: 158.1927
        Episode_Reward/action_rate: -0.0459
          Episode_Reward/joint_vel: -0.0055
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 127893504
                    Iteration time: 1.78s
                      Time elapsed: 00:41:18
                               ETA: 00:06:21

################################################################################
                     [1m Learning iteration 1301/1500 [0m                     

                       Computation: 52338 steps/s (collection: 1.758s, learning 0.120s)
             Mean action noise std: 3.12
          Mean value_function loss: 20.8526
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 43.6334
                       Mean reward: 776.36
               Mean episode length: 243.02
    Episode_Reward/reaching_object: 0.7084
    Episode_Reward/rotating_object: 152.9977
        Episode_Reward/action_rate: -0.0452
          Episode_Reward/joint_vel: -0.0057
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 127991808
                    Iteration time: 1.88s
                      Time elapsed: 00:41:20
                               ETA: 00:06:19

################################################################################
                     [1m Learning iteration 1302/1500 [0m                     

                       Computation: 56082 steps/s (collection: 1.646s, learning 0.107s)
             Mean action noise std: 3.12
          Mean value_function loss: 18.6628
               Mean surrogate loss: -0.0003
                 Mean entropy loss: 43.6453
                       Mean reward: 791.73
               Mean episode length: 247.67
    Episode_Reward/reaching_object: 0.7180
    Episode_Reward/rotating_object: 156.2683
        Episode_Reward/action_rate: -0.0456
          Episode_Reward/joint_vel: -0.0054
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 128090112
                    Iteration time: 1.75s
                      Time elapsed: 00:41:22
                               ETA: 00:06:17

################################################################################
                     [1m Learning iteration 1303/1500 [0m                     

                       Computation: 50587 steps/s (collection: 1.783s, learning 0.160s)
             Mean action noise std: 3.12
          Mean value_function loss: 23.6578
               Mean surrogate loss: -0.0000
                 Mean entropy loss: 43.6543
                       Mean reward: 787.59
               Mean episode length: 245.61
    Episode_Reward/reaching_object: 0.7197
    Episode_Reward/rotating_object: 156.5536
        Episode_Reward/action_rate: -0.0457
          Episode_Reward/joint_vel: -0.0055
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 128188416
                    Iteration time: 1.94s
                      Time elapsed: 00:41:24
                               ETA: 00:06:15

################################################################################
                     [1m Learning iteration 1304/1500 [0m                     

                       Computation: 53601 steps/s (collection: 1.651s, learning 0.183s)
             Mean action noise std: 3.13
          Mean value_function loss: 20.9349
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 43.6621
                       Mean reward: 799.15
               Mean episode length: 249.74
    Episode_Reward/reaching_object: 0.7196
    Episode_Reward/rotating_object: 155.0506
        Episode_Reward/action_rate: -0.0458
          Episode_Reward/joint_vel: -0.0057
      Episode_Termination/time_out: 17.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 128286720
                    Iteration time: 1.83s
                      Time elapsed: 00:41:25
                               ETA: 00:06:13

################################################################################
                     [1m Learning iteration 1305/1500 [0m                     

                       Computation: 54702 steps/s (collection: 1.670s, learning 0.127s)
             Mean action noise std: 3.13
          Mean value_function loss: 21.2874
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 43.6692
                       Mean reward: 805.75
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7246
    Episode_Reward/rotating_object: 157.9112
        Episode_Reward/action_rate: -0.0460
          Episode_Reward/joint_vel: -0.0056
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 128385024
                    Iteration time: 1.80s
                      Time elapsed: 00:41:27
                               ETA: 00:06:11

################################################################################
                     [1m Learning iteration 1306/1500 [0m                     

                       Computation: 54464 steps/s (collection: 1.689s, learning 0.116s)
             Mean action noise std: 3.13
          Mean value_function loss: 15.5826
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 43.6741
                       Mean reward: 791.10
               Mean episode length: 247.76
    Episode_Reward/reaching_object: 0.7229
    Episode_Reward/rotating_object: 156.1605
        Episode_Reward/action_rate: -0.0459
          Episode_Reward/joint_vel: -0.0056
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 128483328
                    Iteration time: 1.80s
                      Time elapsed: 00:41:29
                               ETA: 00:06:09

################################################################################
                     [1m Learning iteration 1307/1500 [0m                     

                       Computation: 52078 steps/s (collection: 1.775s, learning 0.112s)
             Mean action noise std: 3.13
          Mean value_function loss: 19.4109
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 43.6777
                       Mean reward: 786.35
               Mean episode length: 245.79
    Episode_Reward/reaching_object: 0.7283
    Episode_Reward/rotating_object: 156.9560
        Episode_Reward/action_rate: -0.0460
          Episode_Reward/joint_vel: -0.0055
      Episode_Termination/time_out: 17.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 128581632
                    Iteration time: 1.89s
                      Time elapsed: 00:41:31
                               ETA: 00:06:07

################################################################################
                     [1m Learning iteration 1308/1500 [0m                     

                       Computation: 50726 steps/s (collection: 1.787s, learning 0.151s)
             Mean action noise std: 3.13
          Mean value_function loss: 27.0610
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 43.6846
                       Mean reward: 801.24
               Mean episode length: 247.90
    Episode_Reward/reaching_object: 0.7268
    Episode_Reward/rotating_object: 156.5280
        Episode_Reward/action_rate: -0.0460
          Episode_Reward/joint_vel: -0.0055
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 128679936
                    Iteration time: 1.94s
                      Time elapsed: 00:41:33
                               ETA: 00:06:05

################################################################################
                     [1m Learning iteration 1309/1500 [0m                     

                       Computation: 49713 steps/s (collection: 1.806s, learning 0.172s)
             Mean action noise std: 3.14
          Mean value_function loss: 23.5217
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 43.6935
                       Mean reward: 769.93
               Mean episode length: 243.74
    Episode_Reward/reaching_object: 0.7265
    Episode_Reward/rotating_object: 156.5168
        Episode_Reward/action_rate: -0.0457
          Episode_Reward/joint_vel: -0.0054
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 128778240
                    Iteration time: 1.98s
                      Time elapsed: 00:41:35
                               ETA: 00:06:03

################################################################################
                     [1m Learning iteration 1310/1500 [0m                     

                       Computation: 49611 steps/s (collection: 1.799s, learning 0.183s)
             Mean action noise std: 3.14
          Mean value_function loss: 17.1060
               Mean surrogate loss: -0.0003
                 Mean entropy loss: 43.7002
                       Mean reward: 791.77
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7321
    Episode_Reward/rotating_object: 156.2245
        Episode_Reward/action_rate: -0.0462
          Episode_Reward/joint_vel: -0.0055
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 128876544
                    Iteration time: 1.98s
                      Time elapsed: 00:41:37
                               ETA: 00:06:01

################################################################################
                     [1m Learning iteration 1311/1500 [0m                     

                       Computation: 51248 steps/s (collection: 1.782s, learning 0.136s)
             Mean action noise std: 3.14
          Mean value_function loss: 16.8559
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 43.7027
                       Mean reward: 779.82
               Mean episode length: 248.09
    Episode_Reward/reaching_object: 0.7318
    Episode_Reward/rotating_object: 156.8989
        Episode_Reward/action_rate: -0.0464
          Episode_Reward/joint_vel: -0.0054
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 128974848
                    Iteration time: 1.92s
                      Time elapsed: 00:41:39
                               ETA: 00:06:00

################################################################################
                     [1m Learning iteration 1312/1500 [0m                     

                       Computation: 50864 steps/s (collection: 1.759s, learning 0.174s)
             Mean action noise std: 3.14
          Mean value_function loss: 20.0192
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 43.7050
                       Mean reward: 802.36
               Mean episode length: 247.75
    Episode_Reward/reaching_object: 0.7404
    Episode_Reward/rotating_object: 159.4585
        Episode_Reward/action_rate: -0.0465
          Episode_Reward/joint_vel: -0.0056
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 129073152
                    Iteration time: 1.93s
                      Time elapsed: 00:41:41
                               ETA: 00:05:58

################################################################################
                     [1m Learning iteration 1313/1500 [0m                     

                       Computation: 52842 steps/s (collection: 1.750s, learning 0.111s)
             Mean action noise std: 3.14
          Mean value_function loss: 23.3335
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 43.7131
                       Mean reward: 799.43
               Mean episode length: 247.78
    Episode_Reward/reaching_object: 0.7345
    Episode_Reward/rotating_object: 156.1268
        Episode_Reward/action_rate: -0.0465
          Episode_Reward/joint_vel: -0.0057
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 129171456
                    Iteration time: 1.86s
                      Time elapsed: 00:41:42
                               ETA: 00:05:56

################################################################################
                     [1m Learning iteration 1314/1500 [0m                     

                       Computation: 53658 steps/s (collection: 1.719s, learning 0.113s)
             Mean action noise std: 3.14
          Mean value_function loss: 22.3917
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 43.7211
                       Mean reward: 797.12
               Mean episode length: 245.54
    Episode_Reward/reaching_object: 0.7377
    Episode_Reward/rotating_object: 158.4113
        Episode_Reward/action_rate: -0.0466
          Episode_Reward/joint_vel: -0.0056
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 129269760
                    Iteration time: 1.83s
                      Time elapsed: 00:41:44
                               ETA: 00:05:54

################################################################################
                     [1m Learning iteration 1315/1500 [0m                     

                       Computation: 54960 steps/s (collection: 1.691s, learning 0.098s)
             Mean action noise std: 3.14
          Mean value_function loss: 29.6319
               Mean surrogate loss: 0.0010
                 Mean entropy loss: 43.7262
                       Mean reward: 789.03
               Mean episode length: 245.46
    Episode_Reward/reaching_object: 0.7328
    Episode_Reward/rotating_object: 156.7629
        Episode_Reward/action_rate: -0.0464
          Episode_Reward/joint_vel: -0.0056
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 129368064
                    Iteration time: 1.79s
                      Time elapsed: 00:41:46
                               ETA: 00:05:52

################################################################################
                     [1m Learning iteration 1316/1500 [0m                     

                       Computation: 47871 steps/s (collection: 1.857s, learning 0.197s)
             Mean action noise std: 3.15
          Mean value_function loss: 18.7542
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 43.7322
                       Mean reward: 804.45
               Mean episode length: 247.79
    Episode_Reward/reaching_object: 0.7328
    Episode_Reward/rotating_object: 156.6951
        Episode_Reward/action_rate: -0.0465
          Episode_Reward/joint_vel: -0.0057
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 129466368
                    Iteration time: 2.05s
                      Time elapsed: 00:41:48
                               ETA: 00:05:50

################################################################################
                     [1m Learning iteration 1317/1500 [0m                     

                       Computation: 55068 steps/s (collection: 1.685s, learning 0.100s)
             Mean action noise std: 3.15
          Mean value_function loss: 20.8016
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 43.7405
                       Mean reward: 800.87
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7332
    Episode_Reward/rotating_object: 156.1019
        Episode_Reward/action_rate: -0.0469
          Episode_Reward/joint_vel: -0.0054
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 129564672
                    Iteration time: 1.79s
                      Time elapsed: 00:41:50
                               ETA: 00:05:48

################################################################################
                     [1m Learning iteration 1318/1500 [0m                     

                       Computation: 53142 steps/s (collection: 1.729s, learning 0.121s)
             Mean action noise std: 3.15
          Mean value_function loss: 22.4085
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 43.7447
                       Mean reward: 788.97
               Mean episode length: 246.09
    Episode_Reward/reaching_object: 0.7301
    Episode_Reward/rotating_object: 156.3699
        Episode_Reward/action_rate: -0.0466
          Episode_Reward/joint_vel: -0.0058
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 129662976
                    Iteration time: 1.85s
                      Time elapsed: 00:41:52
                               ETA: 00:05:46

################################################################################
                     [1m Learning iteration 1319/1500 [0m                     

                       Computation: 52475 steps/s (collection: 1.771s, learning 0.103s)
             Mean action noise std: 3.15
          Mean value_function loss: 22.0146
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 43.7494
                       Mean reward: 782.23
               Mean episode length: 248.20
    Episode_Reward/reaching_object: 0.7293
    Episode_Reward/rotating_object: 156.1346
        Episode_Reward/action_rate: -0.0466
          Episode_Reward/joint_vel: -0.0056
      Episode_Termination/time_out: 17.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 129761280
                    Iteration time: 1.87s
                      Time elapsed: 00:41:54
                               ETA: 00:05:44

################################################################################
                     [1m Learning iteration 1320/1500 [0m                     

                       Computation: 52811 steps/s (collection: 1.710s, learning 0.151s)
             Mean action noise std: 3.15
          Mean value_function loss: 18.8872
               Mean surrogate loss: 0.0047
                 Mean entropy loss: 43.7584
                       Mean reward: 820.42
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7317
    Episode_Reward/rotating_object: 159.0193
        Episode_Reward/action_rate: -0.0466
          Episode_Reward/joint_vel: -0.0053
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 129859584
                    Iteration time: 1.86s
                      Time elapsed: 00:41:55
                               ETA: 00:05:42

################################################################################
                     [1m Learning iteration 1321/1500 [0m                     

                       Computation: 53780 steps/s (collection: 1.663s, learning 0.165s)
             Mean action noise std: 3.15
          Mean value_function loss: 28.5462
               Mean surrogate loss: -0.0001
                 Mean entropy loss: 43.7605
                       Mean reward: 770.70
               Mean episode length: 245.43
    Episode_Reward/reaching_object: 0.7216
    Episode_Reward/rotating_object: 153.9980
        Episode_Reward/action_rate: -0.0464
          Episode_Reward/joint_vel: -0.0053
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 129957888
                    Iteration time: 1.83s
                      Time elapsed: 00:41:57
                               ETA: 00:05:40

################################################################################
                     [1m Learning iteration 1322/1500 [0m                     

                       Computation: 50533 steps/s (collection: 1.818s, learning 0.128s)
             Mean action noise std: 3.15
          Mean value_function loss: 26.0049
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 43.7671
                       Mean reward: 788.68
               Mean episode length: 247.65
    Episode_Reward/reaching_object: 0.7337
    Episode_Reward/rotating_object: 159.3517
        Episode_Reward/action_rate: -0.0469
          Episode_Reward/joint_vel: -0.0053
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 130056192
                    Iteration time: 1.95s
                      Time elapsed: 00:41:59
                               ETA: 00:05:39

################################################################################
                     [1m Learning iteration 1323/1500 [0m                     

                       Computation: 55454 steps/s (collection: 1.674s, learning 0.099s)
             Mean action noise std: 3.16
          Mean value_function loss: 18.9111
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 43.7761
                       Mean reward: 767.44
               Mean episode length: 246.44
    Episode_Reward/reaching_object: 0.7258
    Episode_Reward/rotating_object: 155.9317
        Episode_Reward/action_rate: -0.0468
          Episode_Reward/joint_vel: -0.0054
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 130154496
                    Iteration time: 1.77s
                      Time elapsed: 00:42:01
                               ETA: 00:05:37

################################################################################
                     [1m Learning iteration 1324/1500 [0m                     

                       Computation: 48885 steps/s (collection: 1.813s, learning 0.198s)
             Mean action noise std: 3.16
          Mean value_function loss: 19.0672
               Mean surrogate loss: -0.0007
                 Mean entropy loss: 43.7842
                       Mean reward: 778.88
               Mean episode length: 245.85
    Episode_Reward/reaching_object: 0.7281
    Episode_Reward/rotating_object: 155.5289
        Episode_Reward/action_rate: -0.0472
          Episode_Reward/joint_vel: -0.0056
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 130252800
                    Iteration time: 2.01s
                      Time elapsed: 00:42:03
                               ETA: 00:05:35

################################################################################
                     [1m Learning iteration 1325/1500 [0m                     

                       Computation: 55112 steps/s (collection: 1.681s, learning 0.103s)
             Mean action noise std: 3.16
          Mean value_function loss: 22.4527
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 43.7951
                       Mean reward: 774.81
               Mean episode length: 246.25
    Episode_Reward/reaching_object: 0.7232
    Episode_Reward/rotating_object: 153.6657
        Episode_Reward/action_rate: -0.0469
          Episode_Reward/joint_vel: -0.0054
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 130351104
                    Iteration time: 1.78s
                      Time elapsed: 00:42:05
                               ETA: 00:05:33

################################################################################
                     [1m Learning iteration 1326/1500 [0m                     

                       Computation: 53557 steps/s (collection: 1.728s, learning 0.108s)
             Mean action noise std: 3.16
          Mean value_function loss: 16.7601
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 43.8044
                       Mean reward: 741.13
               Mean episode length: 243.42
    Episode_Reward/reaching_object: 0.7298
    Episode_Reward/rotating_object: 155.8817
        Episode_Reward/action_rate: -0.0470
          Episode_Reward/joint_vel: -0.0056
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 130449408
                    Iteration time: 1.84s
                      Time elapsed: 00:42:07
                               ETA: 00:05:31

################################################################################
                     [1m Learning iteration 1327/1500 [0m                     

                       Computation: 54820 steps/s (collection: 1.689s, learning 0.105s)
             Mean action noise std: 3.16
          Mean value_function loss: 21.1741
               Mean surrogate loss: -0.0004
                 Mean entropy loss: 43.8117
                       Mean reward: 800.10
               Mean episode length: 247.80
    Episode_Reward/reaching_object: 0.7383
    Episode_Reward/rotating_object: 158.3595
        Episode_Reward/action_rate: -0.0474
          Episode_Reward/joint_vel: -0.0053
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 130547712
                    Iteration time: 1.79s
                      Time elapsed: 00:42:08
                               ETA: 00:05:29

################################################################################
                     [1m Learning iteration 1328/1500 [0m                     

                       Computation: 55262 steps/s (collection: 1.675s, learning 0.104s)
             Mean action noise std: 3.16
          Mean value_function loss: 16.6237
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 43.8197
                       Mean reward: 769.19
               Mean episode length: 245.83
    Episode_Reward/reaching_object: 0.7344
    Episode_Reward/rotating_object: 158.1276
        Episode_Reward/action_rate: -0.0475
          Episode_Reward/joint_vel: -0.0055
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 130646016
                    Iteration time: 1.78s
                      Time elapsed: 00:42:10
                               ETA: 00:05:27

################################################################################
                     [1m Learning iteration 1329/1500 [0m                     

                       Computation: 52807 steps/s (collection: 1.721s, learning 0.140s)
             Mean action noise std: 3.17
          Mean value_function loss: 22.9349
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 43.8274
                       Mean reward: 761.60
               Mean episode length: 245.59
    Episode_Reward/reaching_object: 0.7267
    Episode_Reward/rotating_object: 155.3106
        Episode_Reward/action_rate: -0.0472
          Episode_Reward/joint_vel: -0.0054
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 130744320
                    Iteration time: 1.86s
                      Time elapsed: 00:42:12
                               ETA: 00:05:25

################################################################################
                     [1m Learning iteration 1330/1500 [0m                     

                       Computation: 52895 steps/s (collection: 1.755s, learning 0.103s)
             Mean action noise std: 3.17
          Mean value_function loss: 19.7772
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 43.8351
                       Mean reward: 774.77
               Mean episode length: 245.47
    Episode_Reward/reaching_object: 0.7324
    Episode_Reward/rotating_object: 156.4294
        Episode_Reward/action_rate: -0.0472
          Episode_Reward/joint_vel: -0.0053
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 130842624
                    Iteration time: 1.86s
                      Time elapsed: 00:42:14
                               ETA: 00:05:23

################################################################################
                     [1m Learning iteration 1331/1500 [0m                     

                       Computation: 54905 steps/s (collection: 1.694s, learning 0.096s)
             Mean action noise std: 3.17
          Mean value_function loss: 24.4410
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 43.8432
                       Mean reward: 773.89
               Mean episode length: 245.52
    Episode_Reward/reaching_object: 0.7290
    Episode_Reward/rotating_object: 155.0752
        Episode_Reward/action_rate: -0.0472
          Episode_Reward/joint_vel: -0.0056
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 130940928
                    Iteration time: 1.79s
                      Time elapsed: 00:42:16
                               ETA: 00:05:21

################################################################################
                     [1m Learning iteration 1332/1500 [0m                     

                       Computation: 49923 steps/s (collection: 1.762s, learning 0.208s)
             Mean action noise std: 3.17
          Mean value_function loss: 20.8419
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 43.8516
                       Mean reward: 806.57
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7351
    Episode_Reward/rotating_object: 157.3976
        Episode_Reward/action_rate: -0.0474
          Episode_Reward/joint_vel: -0.0053
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 131039232
                    Iteration time: 1.97s
                      Time elapsed: 00:42:18
                               ETA: 00:05:19

################################################################################
                     [1m Learning iteration 1333/1500 [0m                     

                       Computation: 17667 steps/s (collection: 5.386s, learning 0.178s)
             Mean action noise std: 3.17
          Mean value_function loss: 25.4721
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 43.8627
                       Mean reward: 794.05
               Mean episode length: 245.34
    Episode_Reward/reaching_object: 0.7374
    Episode_Reward/rotating_object: 158.3155
        Episode_Reward/action_rate: -0.0475
          Episode_Reward/joint_vel: -0.0053
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 131137536
                    Iteration time: 5.56s
                      Time elapsed: 00:42:23
                               ETA: 00:05:18

################################################################################
                     [1m Learning iteration 1334/1500 [0m                     

                       Computation: 14701 steps/s (collection: 6.563s, learning 0.124s)
             Mean action noise std: 3.18
          Mean value_function loss: 26.0821
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 43.8764
                       Mean reward: 780.69
               Mean episode length: 244.24
    Episode_Reward/reaching_object: 0.7278
    Episode_Reward/rotating_object: 155.0491
        Episode_Reward/action_rate: -0.0471
          Episode_Reward/joint_vel: -0.0054
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 131235840
                    Iteration time: 6.69s
                      Time elapsed: 00:42:30
                               ETA: 00:05:17

################################################################################
                     [1m Learning iteration 1335/1500 [0m                     

                       Computation: 15144 steps/s (collection: 6.320s, learning 0.171s)
             Mean action noise std: 3.18
          Mean value_function loss: 15.9322
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 43.8825
                       Mean reward: 773.78
               Mean episode length: 244.43
    Episode_Reward/reaching_object: 0.7351
    Episode_Reward/rotating_object: 157.1959
        Episode_Reward/action_rate: -0.0476
          Episode_Reward/joint_vel: -0.0056
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 131334144
                    Iteration time: 6.49s
                      Time elapsed: 00:42:36
                               ETA: 00:05:15

################################################################################
                     [1m Learning iteration 1336/1500 [0m                     

                       Computation: 14741 steps/s (collection: 6.537s, learning 0.132s)
             Mean action noise std: 3.18
          Mean value_function loss: 27.9498
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 43.8952
                       Mean reward: 772.27
               Mean episode length: 241.88
    Episode_Reward/reaching_object: 0.7303
    Episode_Reward/rotating_object: 155.6541
        Episode_Reward/action_rate: -0.0473
          Episode_Reward/joint_vel: -0.0055
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 131432448
                    Iteration time: 6.67s
                      Time elapsed: 00:42:43
                               ETA: 00:05:14

################################################################################
                     [1m Learning iteration 1337/1500 [0m                     

                       Computation: 15043 steps/s (collection: 6.337s, learning 0.197s)
             Mean action noise std: 3.18
          Mean value_function loss: 20.2183
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 43.9089
                       Mean reward: 802.65
               Mean episode length: 248.49
    Episode_Reward/reaching_object: 0.7317
    Episode_Reward/rotating_object: 156.4771
        Episode_Reward/action_rate: -0.0473
          Episode_Reward/joint_vel: -0.0054
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 131530752
                    Iteration time: 6.53s
                      Time elapsed: 00:42:50
                               ETA: 00:05:13

################################################################################
                     [1m Learning iteration 1338/1500 [0m                     

                       Computation: 15394 steps/s (collection: 6.253s, learning 0.133s)
             Mean action noise std: 3.18
          Mean value_function loss: 14.9080
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 43.9146
                       Mean reward: 813.75
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7371
    Episode_Reward/rotating_object: 157.8195
        Episode_Reward/action_rate: -0.0478
          Episode_Reward/joint_vel: -0.0055
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 131629056
                    Iteration time: 6.39s
                      Time elapsed: 00:42:56
                               ETA: 00:05:11

################################################################################
                     [1m Learning iteration 1339/1500 [0m                     

                       Computation: 14696 steps/s (collection: 6.514s, learning 0.175s)
             Mean action noise std: 3.19
          Mean value_function loss: 28.8651
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 43.9201
                       Mean reward: 786.11
               Mean episode length: 243.63
    Episode_Reward/reaching_object: 0.7224
    Episode_Reward/rotating_object: 154.5759
        Episode_Reward/action_rate: -0.0470
          Episode_Reward/joint_vel: -0.0052
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 131727360
                    Iteration time: 6.69s
                      Time elapsed: 00:43:03
                               ETA: 00:05:10

################################################################################
                     [1m Learning iteration 1340/1500 [0m                     

                       Computation: 14494 steps/s (collection: 6.638s, learning 0.144s)
             Mean action noise std: 3.19
          Mean value_function loss: 17.3069
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 43.9293
                       Mean reward: 784.21
               Mean episode length: 247.84
    Episode_Reward/reaching_object: 0.7405
    Episode_Reward/rotating_object: 159.6484
        Episode_Reward/action_rate: -0.0480
          Episode_Reward/joint_vel: -0.0052
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 131825664
                    Iteration time: 6.78s
                      Time elapsed: 00:43:10
                               ETA: 00:05:09

################################################################################
                     [1m Learning iteration 1341/1500 [0m                     

                       Computation: 13065 steps/s (collection: 7.344s, learning 0.180s)
             Mean action noise std: 3.19
          Mean value_function loss: 19.5456
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 43.9336
                       Mean reward: 806.15
               Mean episode length: 247.74
    Episode_Reward/reaching_object: 0.7307
    Episode_Reward/rotating_object: 157.1570
        Episode_Reward/action_rate: -0.0475
          Episode_Reward/joint_vel: -0.0052
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 131923968
                    Iteration time: 7.52s
                      Time elapsed: 00:43:17
                               ETA: 00:05:07

################################################################################
                     [1m Learning iteration 1342/1500 [0m                     

                       Computation: 45279 steps/s (collection: 2.049s, learning 0.122s)
             Mean action noise std: 3.19
          Mean value_function loss: 25.0322
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 43.9411
                       Mean reward: 771.60
               Mean episode length: 241.87
    Episode_Reward/reaching_object: 0.7278
    Episode_Reward/rotating_object: 155.9981
        Episode_Reward/action_rate: -0.0475
          Episode_Reward/joint_vel: -0.0055
      Episode_Termination/time_out: 17.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 132022272
                    Iteration time: 2.17s
                      Time elapsed: 00:43:19
                               ETA: 00:05:05

################################################################################
                     [1m Learning iteration 1343/1500 [0m                     

                       Computation: 56742 steps/s (collection: 1.592s, learning 0.140s)
             Mean action noise std: 3.19
          Mean value_function loss: 23.7162
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 43.9543
                       Mean reward: 788.49
               Mean episode length: 245.66
    Episode_Reward/reaching_object: 0.7339
    Episode_Reward/rotating_object: 156.0807
        Episode_Reward/action_rate: -0.0480
          Episode_Reward/joint_vel: -0.0056
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 132120576
                    Iteration time: 1.73s
                      Time elapsed: 00:43:21
                               ETA: 00:05:03

################################################################################
                     [1m Learning iteration 1344/1500 [0m                     

                       Computation: 55639 steps/s (collection: 1.596s, learning 0.171s)
             Mean action noise std: 3.19
          Mean value_function loss: 19.0104
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 43.9610
                       Mean reward: 773.72
               Mean episode length: 243.24
    Episode_Reward/reaching_object: 0.7293
    Episode_Reward/rotating_object: 156.5315
        Episode_Reward/action_rate: -0.0476
          Episode_Reward/joint_vel: -0.0055
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 132218880
                    Iteration time: 1.77s
                      Time elapsed: 00:43:23
                               ETA: 00:05:01

################################################################################
                     [1m Learning iteration 1345/1500 [0m                     

                       Computation: 53207 steps/s (collection: 1.742s, learning 0.105s)
             Mean action noise std: 3.19
          Mean value_function loss: 20.3446
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 43.9733
                       Mean reward: 779.65
               Mean episode length: 249.18
    Episode_Reward/reaching_object: 0.7365
    Episode_Reward/rotating_object: 157.0554
        Episode_Reward/action_rate: -0.0479
          Episode_Reward/joint_vel: -0.0053
      Episode_Termination/time_out: 17.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 132317184
                    Iteration time: 1.85s
                      Time elapsed: 00:43:25
                               ETA: 00:04:59

################################################################################
                     [1m Learning iteration 1346/1500 [0m                     

                       Computation: 53651 steps/s (collection: 1.726s, learning 0.106s)
             Mean action noise std: 3.20
          Mean value_function loss: 22.4796
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 43.9911
                       Mean reward: 808.77
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7346
    Episode_Reward/rotating_object: 156.5627
        Episode_Reward/action_rate: -0.0482
          Episode_Reward/joint_vel: -0.0052
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 132415488
                    Iteration time: 1.83s
                      Time elapsed: 00:43:26
                               ETA: 00:04:58

################################################################################
                     [1m Learning iteration 1347/1500 [0m                     

                       Computation: 55644 steps/s (collection: 1.642s, learning 0.125s)
             Mean action noise std: 3.20
          Mean value_function loss: 14.6116
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 43.9976
                       Mean reward: 810.08
               Mean episode length: 248.40
    Episode_Reward/reaching_object: 0.7387
    Episode_Reward/rotating_object: 159.0333
        Episode_Reward/action_rate: -0.0483
          Episode_Reward/joint_vel: -0.0052
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 132513792
                    Iteration time: 1.77s
                      Time elapsed: 00:43:28
                               ETA: 00:04:56

################################################################################
                     [1m Learning iteration 1348/1500 [0m                     

                       Computation: 57145 steps/s (collection: 1.609s, learning 0.111s)
             Mean action noise std: 3.20
          Mean value_function loss: 28.4392
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 44.0060
                       Mean reward: 794.03
               Mean episode length: 247.67
    Episode_Reward/reaching_object: 0.7283
    Episode_Reward/rotating_object: 155.6238
        Episode_Reward/action_rate: -0.0478
          Episode_Reward/joint_vel: -0.0052
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 132612096
                    Iteration time: 1.72s
                      Time elapsed: 00:43:30
                               ETA: 00:04:54

################################################################################
                     [1m Learning iteration 1349/1500 [0m                     

                       Computation: 57708 steps/s (collection: 1.598s, learning 0.106s)
             Mean action noise std: 3.20
          Mean value_function loss: 16.6775
               Mean surrogate loss: -0.0007
                 Mean entropy loss: 44.0191
                       Mean reward: 779.49
               Mean episode length: 246.20
    Episode_Reward/reaching_object: 0.7300
    Episode_Reward/rotating_object: 156.3733
        Episode_Reward/action_rate: -0.0478
          Episode_Reward/joint_vel: -0.0054
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 132710400
                    Iteration time: 1.70s
                      Time elapsed: 00:43:32
                               ETA: 00:04:52

################################################################################
                     [1m Learning iteration 1350/1500 [0m                     

                       Computation: 55362 steps/s (collection: 1.671s, learning 0.105s)
             Mean action noise std: 3.21
          Mean value_function loss: 26.8061
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 44.0279
                       Mean reward: 799.43
               Mean episode length: 245.77
    Episode_Reward/reaching_object: 0.7265
    Episode_Reward/rotating_object: 155.3859
        Episode_Reward/action_rate: -0.0479
          Episode_Reward/joint_vel: -0.0053
      Episode_Termination/time_out: 17.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 132808704
                    Iteration time: 1.78s
                      Time elapsed: 00:43:33
                               ETA: 00:04:50

################################################################################
                     [1m Learning iteration 1351/1500 [0m                     

                       Computation: 55131 steps/s (collection: 1.667s, learning 0.116s)
             Mean action noise std: 3.21
          Mean value_function loss: 19.1371
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 44.0364
                       Mean reward: 801.41
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7386
    Episode_Reward/rotating_object: 159.9196
        Episode_Reward/action_rate: -0.0485
          Episode_Reward/joint_vel: -0.0055
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 132907008
                    Iteration time: 1.78s
                      Time elapsed: 00:43:35
                               ETA: 00:04:48

################################################################################
                     [1m Learning iteration 1352/1500 [0m                     

                       Computation: 56876 steps/s (collection: 1.618s, learning 0.111s)
             Mean action noise std: 3.21
          Mean value_function loss: 20.0349
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 44.0448
                       Mean reward: 779.87
               Mean episode length: 248.77
    Episode_Reward/reaching_object: 0.7340
    Episode_Reward/rotating_object: 157.3488
        Episode_Reward/action_rate: -0.0487
          Episode_Reward/joint_vel: -0.0059
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 133005312
                    Iteration time: 1.73s
                      Time elapsed: 00:43:37
                               ETA: 00:04:46

################################################################################
                     [1m Learning iteration 1353/1500 [0m                     

                       Computation: 54796 steps/s (collection: 1.706s, learning 0.088s)
             Mean action noise std: 3.21
          Mean value_function loss: 21.0207
               Mean surrogate loss: 0.0001
                 Mean entropy loss: 44.0507
                       Mean reward: 794.23
               Mean episode length: 248.14
    Episode_Reward/reaching_object: 0.7343
    Episode_Reward/rotating_object: 158.0931
        Episode_Reward/action_rate: -0.0486
          Episode_Reward/joint_vel: -0.0057
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 133103616
                    Iteration time: 1.79s
                      Time elapsed: 00:43:39
                               ETA: 00:04:44

################################################################################
                     [1m Learning iteration 1354/1500 [0m                     

                       Computation: 57912 steps/s (collection: 1.608s, learning 0.089s)
             Mean action noise std: 3.21
          Mean value_function loss: 20.9167
               Mean surrogate loss: 0.0010
                 Mean entropy loss: 44.0539
                       Mean reward: 770.68
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7365
    Episode_Reward/rotating_object: 157.5717
        Episode_Reward/action_rate: -0.0486
          Episode_Reward/joint_vel: -0.0053
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 133201920
                    Iteration time: 1.70s
                      Time elapsed: 00:43:40
                               ETA: 00:04:42

################################################################################
                     [1m Learning iteration 1355/1500 [0m                     

                       Computation: 53777 steps/s (collection: 1.641s, learning 0.187s)
             Mean action noise std: 3.21
          Mean value_function loss: 21.1025
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 44.0574
                       Mean reward: 761.18
               Mean episode length: 244.43
    Episode_Reward/reaching_object: 0.7324
    Episode_Reward/rotating_object: 157.3932
        Episode_Reward/action_rate: -0.0482
          Episode_Reward/joint_vel: -0.0052
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 133300224
                    Iteration time: 1.83s
                      Time elapsed: 00:43:42
                               ETA: 00:04:40

################################################################################
                     [1m Learning iteration 1356/1500 [0m                     

                       Computation: 54224 steps/s (collection: 1.684s, learning 0.129s)
             Mean action noise std: 3.21
          Mean value_function loss: 19.1896
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 44.0653
                       Mean reward: 813.75
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7314
    Episode_Reward/rotating_object: 157.7130
        Episode_Reward/action_rate: -0.0484
          Episode_Reward/joint_vel: -0.0051
      Episode_Termination/time_out: 17.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 133398528
                    Iteration time: 1.81s
                      Time elapsed: 00:43:44
                               ETA: 00:04:38

################################################################################
                     [1m Learning iteration 1357/1500 [0m                     

                       Computation: 59372 steps/s (collection: 1.566s, learning 0.090s)
             Mean action noise std: 3.21
          Mean value_function loss: 26.4588
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 44.0691
                       Mean reward: 771.60
               Mean episode length: 244.72
    Episode_Reward/reaching_object: 0.7317
    Episode_Reward/rotating_object: 158.2171
        Episode_Reward/action_rate: -0.0485
          Episode_Reward/joint_vel: -0.0052
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 133496832
                    Iteration time: 1.66s
                      Time elapsed: 00:43:46
                               ETA: 00:04:36

################################################################################
                     [1m Learning iteration 1358/1500 [0m                     

                       Computation: 57273 steps/s (collection: 1.611s, learning 0.105s)
             Mean action noise std: 3.22
          Mean value_function loss: 24.1220
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 44.0794
                       Mean reward: 782.33
               Mean episode length: 241.61
    Episode_Reward/reaching_object: 0.7307
    Episode_Reward/rotating_object: 157.0300
        Episode_Reward/action_rate: -0.0482
          Episode_Reward/joint_vel: -0.0054
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 133595136
                    Iteration time: 1.72s
                      Time elapsed: 00:43:47
                               ETA: 00:04:34

################################################################################
                     [1m Learning iteration 1359/1500 [0m                     

                       Computation: 56565 steps/s (collection: 1.586s, learning 0.152s)
             Mean action noise std: 3.22
          Mean value_function loss: 16.5965
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 44.0902
                       Mean reward: 777.19
               Mean episode length: 247.35
    Episode_Reward/reaching_object: 0.7302
    Episode_Reward/rotating_object: 157.4676
        Episode_Reward/action_rate: -0.0484
          Episode_Reward/joint_vel: -0.0053
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 133693440
                    Iteration time: 1.74s
                      Time elapsed: 00:43:49
                               ETA: 00:04:32

################################################################################
                     [1m Learning iteration 1360/1500 [0m                     

                       Computation: 59129 steps/s (collection: 1.542s, learning 0.121s)
             Mean action noise std: 3.22
          Mean value_function loss: 22.7618
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 44.1051
                       Mean reward: 783.94
               Mean episode length: 244.93
    Episode_Reward/reaching_object: 0.7222
    Episode_Reward/rotating_object: 154.9221
        Episode_Reward/action_rate: -0.0481
          Episode_Reward/joint_vel: -0.0050
      Episode_Termination/time_out: 17.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 133791744
                    Iteration time: 1.66s
                      Time elapsed: 00:43:51
                               ETA: 00:04:30

################################################################################
                     [1m Learning iteration 1361/1500 [0m                     

                       Computation: 56096 steps/s (collection: 1.622s, learning 0.130s)
             Mean action noise std: 3.22
          Mean value_function loss: 23.2759
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 44.1204
                       Mean reward: 790.18
               Mean episode length: 243.37
    Episode_Reward/reaching_object: 0.7254
    Episode_Reward/rotating_object: 156.7997
        Episode_Reward/action_rate: -0.0484
          Episode_Reward/joint_vel: -0.0052
      Episode_Termination/time_out: 17.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 133890048
                    Iteration time: 1.75s
                      Time elapsed: 00:43:53
                               ETA: 00:04:28

################################################################################
                     [1m Learning iteration 1362/1500 [0m                     

                       Computation: 56189 steps/s (collection: 1.641s, learning 0.108s)
             Mean action noise std: 3.22
          Mean value_function loss: 19.9735
               Mean surrogate loss: -0.0007
                 Mean entropy loss: 44.1300
                       Mean reward: 796.16
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7287
    Episode_Reward/rotating_object: 156.5666
        Episode_Reward/action_rate: -0.0491
          Episode_Reward/joint_vel: -0.0050
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 133988352
                    Iteration time: 1.75s
                      Time elapsed: 00:43:54
                               ETA: 00:04:26

################################################################################
                     [1m Learning iteration 1363/1500 [0m                     

                       Computation: 57070 steps/s (collection: 1.612s, learning 0.110s)
             Mean action noise std: 3.23
          Mean value_function loss: 19.7217
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 44.1380
                       Mean reward: 783.18
               Mean episode length: 245.12
    Episode_Reward/reaching_object: 0.7254
    Episode_Reward/rotating_object: 156.9530
        Episode_Reward/action_rate: -0.0487
          Episode_Reward/joint_vel: -0.0052
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 134086656
                    Iteration time: 1.72s
                      Time elapsed: 00:43:56
                               ETA: 00:04:24

################################################################################
                     [1m Learning iteration 1364/1500 [0m                     

                       Computation: 54355 steps/s (collection: 1.620s, learning 0.188s)
             Mean action noise std: 3.23
          Mean value_function loss: 15.5262
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 44.1470
                       Mean reward: 801.50
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7290
    Episode_Reward/rotating_object: 157.4925
        Episode_Reward/action_rate: -0.0487
          Episode_Reward/joint_vel: -0.0050
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 134184960
                    Iteration time: 1.81s
                      Time elapsed: 00:43:58
                               ETA: 00:04:22

################################################################################
                     [1m Learning iteration 1365/1500 [0m                     

                       Computation: 57905 steps/s (collection: 1.604s, learning 0.094s)
             Mean action noise std: 3.23
          Mean value_function loss: 19.2800
               Mean surrogate loss: 0.0005
                 Mean entropy loss: 44.1573
                       Mean reward: 793.11
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7221
    Episode_Reward/rotating_object: 156.2384
        Episode_Reward/action_rate: -0.0486
          Episode_Reward/joint_vel: -0.0052
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 134283264
                    Iteration time: 1.70s
                      Time elapsed: 00:44:00
                               ETA: 00:04:20

################################################################################
                     [1m Learning iteration 1366/1500 [0m                     

                       Computation: 55851 steps/s (collection: 1.630s, learning 0.130s)
             Mean action noise std: 3.23
          Mean value_function loss: 18.2844
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 44.1648
                       Mean reward: 789.64
               Mean episode length: 245.84
    Episode_Reward/reaching_object: 0.7301
    Episode_Reward/rotating_object: 158.5482
        Episode_Reward/action_rate: -0.0488
          Episode_Reward/joint_vel: -0.0051
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 134381568
                    Iteration time: 1.76s
                      Time elapsed: 00:44:01
                               ETA: 00:04:18

################################################################################
                     [1m Learning iteration 1367/1500 [0m                     

                       Computation: 57504 steps/s (collection: 1.610s, learning 0.100s)
             Mean action noise std: 3.23
          Mean value_function loss: 19.4138
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 44.1764
                       Mean reward: 801.90
               Mean episode length: 248.43
    Episode_Reward/reaching_object: 0.7241
    Episode_Reward/rotating_object: 156.8253
        Episode_Reward/action_rate: -0.0490
          Episode_Reward/joint_vel: -0.0050
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 134479872
                    Iteration time: 1.71s
                      Time elapsed: 00:44:03
                               ETA: 00:04:17

################################################################################
                     [1m Learning iteration 1368/1500 [0m                     

                       Computation: 56211 steps/s (collection: 1.633s, learning 0.116s)
             Mean action noise std: 3.24
          Mean value_function loss: 21.2500
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 44.1943
                       Mean reward: 801.28
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7229
    Episode_Reward/rotating_object: 155.4037
        Episode_Reward/action_rate: -0.0487
          Episode_Reward/joint_vel: -0.0054
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 134578176
                    Iteration time: 1.75s
                      Time elapsed: 00:44:05
                               ETA: 00:04:15

################################################################################
                     [1m Learning iteration 1369/1500 [0m                     

                       Computation: 58211 steps/s (collection: 1.573s, learning 0.116s)
             Mean action noise std: 3.24
          Mean value_function loss: 23.9968
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 44.2064
                       Mean reward: 807.19
               Mean episode length: 247.67
    Episode_Reward/reaching_object: 0.7280
    Episode_Reward/rotating_object: 157.9732
        Episode_Reward/action_rate: -0.0488
          Episode_Reward/joint_vel: -0.0047
      Episode_Termination/time_out: 17.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 134676480
                    Iteration time: 1.69s
                      Time elapsed: 00:44:06
                               ETA: 00:04:13

################################################################################
                     [1m Learning iteration 1370/1500 [0m                     

                       Computation: 57089 steps/s (collection: 1.582s, learning 0.140s)
             Mean action noise std: 3.24
          Mean value_function loss: 24.9265
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 44.2135
                       Mean reward: 773.25
               Mean episode length: 244.31
    Episode_Reward/reaching_object: 0.7225
    Episode_Reward/rotating_object: 156.0977
        Episode_Reward/action_rate: -0.0485
          Episode_Reward/joint_vel: -0.0050
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 134774784
                    Iteration time: 1.72s
                      Time elapsed: 00:44:08
                               ETA: 00:04:11

################################################################################
                     [1m Learning iteration 1371/1500 [0m                     

                       Computation: 59456 steps/s (collection: 1.564s, learning 0.089s)
             Mean action noise std: 3.24
          Mean value_function loss: 15.7203
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 44.2188
                       Mean reward: 795.15
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7331
    Episode_Reward/rotating_object: 158.4515
        Episode_Reward/action_rate: -0.0493
          Episode_Reward/joint_vel: -0.0050
      Episode_Termination/time_out: 17.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 134873088
                    Iteration time: 1.65s
                      Time elapsed: 00:44:10
                               ETA: 00:04:09

################################################################################
                     [1m Learning iteration 1372/1500 [0m                     

                       Computation: 56100 steps/s (collection: 1.646s, learning 0.107s)
             Mean action noise std: 3.24
          Mean value_function loss: 23.7062
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 44.2225
                       Mean reward: 798.38
               Mean episode length: 247.76
    Episode_Reward/reaching_object: 0.7289
    Episode_Reward/rotating_object: 157.4971
        Episode_Reward/action_rate: -0.0491
          Episode_Reward/joint_vel: -0.0053
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 134971392
                    Iteration time: 1.75s
                      Time elapsed: 00:44:12
                               ETA: 00:04:07

################################################################################
                     [1m Learning iteration 1373/1500 [0m                     

                       Computation: 59048 steps/s (collection: 1.531s, learning 0.134s)
             Mean action noise std: 3.24
          Mean value_function loss: 25.8364
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 44.2273
                       Mean reward: 775.27
               Mean episode length: 243.21
    Episode_Reward/reaching_object: 0.7387
    Episode_Reward/rotating_object: 158.6441
        Episode_Reward/action_rate: -0.0491
          Episode_Reward/joint_vel: -0.0046
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 135069696
                    Iteration time: 1.66s
                      Time elapsed: 00:44:13
                               ETA: 00:04:05

################################################################################
                     [1m Learning iteration 1374/1500 [0m                     

                       Computation: 58726 steps/s (collection: 1.559s, learning 0.115s)
             Mean action noise std: 3.24
          Mean value_function loss: 15.5370
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 44.2330
                       Mean reward: 796.77
               Mean episode length: 247.77
    Episode_Reward/reaching_object: 0.7383
    Episode_Reward/rotating_object: 158.7019
        Episode_Reward/action_rate: -0.0492
          Episode_Reward/joint_vel: -0.0047
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 135168000
                    Iteration time: 1.67s
                      Time elapsed: 00:44:15
                               ETA: 00:04:03

################################################################################
                     [1m Learning iteration 1375/1500 [0m                     

                       Computation: 57799 steps/s (collection: 1.606s, learning 0.095s)
             Mean action noise std: 3.25
          Mean value_function loss: 23.0766
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 44.2389
                       Mean reward: 792.84
               Mean episode length: 244.43
    Episode_Reward/reaching_object: 0.7284
    Episode_Reward/rotating_object: 155.8629
        Episode_Reward/action_rate: -0.0489
          Episode_Reward/joint_vel: -0.0050
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 135266304
                    Iteration time: 1.70s
                      Time elapsed: 00:44:17
                               ETA: 00:04:01

################################################################################
                     [1m Learning iteration 1376/1500 [0m                     

                       Computation: 49875 steps/s (collection: 1.862s, learning 0.109s)
             Mean action noise std: 3.25
          Mean value_function loss: 17.7146
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 44.2454
                       Mean reward: 788.65
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7353
    Episode_Reward/rotating_object: 155.8220
        Episode_Reward/action_rate: -0.0493
          Episode_Reward/joint_vel: -0.0051
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 135364608
                    Iteration time: 1.97s
                      Time elapsed: 00:44:19
                               ETA: 00:03:59

################################################################################
                     [1m Learning iteration 1377/1500 [0m                     

                       Computation: 57069 steps/s (collection: 1.615s, learning 0.107s)
             Mean action noise std: 3.25
          Mean value_function loss: 22.0834
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 44.2475
                       Mean reward: 793.25
               Mean episode length: 248.33
    Episode_Reward/reaching_object: 0.7303
    Episode_Reward/rotating_object: 155.9999
        Episode_Reward/action_rate: -0.0493
          Episode_Reward/joint_vel: -0.0052
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5417
--------------------------------------------------------------------------------
                   Total timesteps: 135462912
                    Iteration time: 1.72s
                      Time elapsed: 00:44:20
                               ETA: 00:03:57

################################################################################
                     [1m Learning iteration 1378/1500 [0m                     

                       Computation: 57737 steps/s (collection: 1.580s, learning 0.123s)
             Mean action noise std: 3.25
          Mean value_function loss: 24.9472
               Mean surrogate loss: 0.0008
                 Mean entropy loss: 44.2521
                       Mean reward: 788.05
               Mean episode length: 247.73
    Episode_Reward/reaching_object: 0.7304
    Episode_Reward/rotating_object: 156.3746
        Episode_Reward/action_rate: -0.0488
          Episode_Reward/joint_vel: -0.0046
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 135561216
                    Iteration time: 1.70s
                      Time elapsed: 00:44:22
                               ETA: 00:03:55

################################################################################
                     [1m Learning iteration 1379/1500 [0m                     

                       Computation: 54560 steps/s (collection: 1.667s, learning 0.134s)
             Mean action noise std: 3.25
          Mean value_function loss: 19.4907
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 44.2568
                       Mean reward: 797.68
               Mean episode length: 246.61
    Episode_Reward/reaching_object: 0.7395
    Episode_Reward/rotating_object: 157.8518
        Episode_Reward/action_rate: -0.0496
          Episode_Reward/joint_vel: -0.0048
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 135659520
                    Iteration time: 1.80s
                      Time elapsed: 00:44:24
                               ETA: 00:03:53

################################################################################
                     [1m Learning iteration 1380/1500 [0m                     

                       Computation: 52564 steps/s (collection: 1.752s, learning 0.118s)
             Mean action noise std: 3.25
          Mean value_function loss: 22.4406
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 44.2666
                       Mean reward: 797.18
               Mean episode length: 248.14
    Episode_Reward/reaching_object: 0.7370
    Episode_Reward/rotating_object: 157.9394
        Episode_Reward/action_rate: -0.0495
          Episode_Reward/joint_vel: -0.0049
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 135757824
                    Iteration time: 1.87s
                      Time elapsed: 00:44:26
                               ETA: 00:03:51

################################################################################
                     [1m Learning iteration 1381/1500 [0m                     

                       Computation: 58802 steps/s (collection: 1.579s, learning 0.093s)
             Mean action noise std: 3.25
          Mean value_function loss: 19.8995
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 44.2793
                       Mean reward: 778.73
               Mean episode length: 244.88
    Episode_Reward/reaching_object: 0.7325
    Episode_Reward/rotating_object: 157.3036
        Episode_Reward/action_rate: -0.0495
          Episode_Reward/joint_vel: -0.0050
      Episode_Termination/time_out: 17.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 135856128
                    Iteration time: 1.67s
                      Time elapsed: 00:44:27
                               ETA: 00:03:49

################################################################################
                     [1m Learning iteration 1382/1500 [0m                     

                       Computation: 57580 steps/s (collection: 1.584s, learning 0.123s)
             Mean action noise std: 3.26
          Mean value_function loss: 24.5056
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 44.2875
                       Mean reward: 774.81
               Mean episode length: 248.80
    Episode_Reward/reaching_object: 0.7293
    Episode_Reward/rotating_object: 156.4145
        Episode_Reward/action_rate: -0.0496
          Episode_Reward/joint_vel: -0.0048
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 135954432
                    Iteration time: 1.71s
                      Time elapsed: 00:44:29
                               ETA: 00:03:47

################################################################################
                     [1m Learning iteration 1383/1500 [0m                     

                       Computation: 58477 steps/s (collection: 1.595s, learning 0.086s)
             Mean action noise std: 3.26
          Mean value_function loss: 18.7195
               Mean surrogate loss: -0.0003
                 Mean entropy loss: 44.2939
                       Mean reward: 776.10
               Mean episode length: 241.86
    Episode_Reward/reaching_object: 0.7269
    Episode_Reward/rotating_object: 158.0299
        Episode_Reward/action_rate: -0.0492
          Episode_Reward/joint_vel: -0.0047
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 136052736
                    Iteration time: 1.68s
                      Time elapsed: 00:44:31
                               ETA: 00:03:45

################################################################################
                     [1m Learning iteration 1384/1500 [0m                     

                       Computation: 57691 steps/s (collection: 1.552s, learning 0.152s)
             Mean action noise std: 3.26
          Mean value_function loss: 15.3172
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 44.2988
                       Mean reward: 794.82
               Mean episode length: 246.21
    Episode_Reward/reaching_object: 0.7280
    Episode_Reward/rotating_object: 156.9627
        Episode_Reward/action_rate: -0.0496
          Episode_Reward/joint_vel: -0.0048
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 136151040
                    Iteration time: 1.70s
                      Time elapsed: 00:44:32
                               ETA: 00:03:43

################################################################################
                     [1m Learning iteration 1385/1500 [0m                     

                       Computation: 56331 steps/s (collection: 1.657s, learning 0.088s)
             Mean action noise std: 3.26
          Mean value_function loss: 19.3649
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 44.3047
                       Mean reward: 802.60
               Mean episode length: 248.51
    Episode_Reward/reaching_object: 0.7293
    Episode_Reward/rotating_object: 158.6701
        Episode_Reward/action_rate: -0.0496
          Episode_Reward/joint_vel: -0.0047
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 136249344
                    Iteration time: 1.75s
                      Time elapsed: 00:44:34
                               ETA: 00:03:41

################################################################################
                     [1m Learning iteration 1386/1500 [0m                     

                       Computation: 56391 steps/s (collection: 1.642s, learning 0.101s)
             Mean action noise std: 3.26
          Mean value_function loss: 18.8230
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 44.3134
                       Mean reward: 806.60
               Mean episode length: 248.66
    Episode_Reward/reaching_object: 0.7313
    Episode_Reward/rotating_object: 159.4240
        Episode_Reward/action_rate: -0.0498
          Episode_Reward/joint_vel: -0.0048
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 136347648
                    Iteration time: 1.74s
                      Time elapsed: 00:44:36
                               ETA: 00:03:39

################################################################################
                     [1m Learning iteration 1387/1500 [0m                     

                       Computation: 53414 steps/s (collection: 1.691s, learning 0.150s)
             Mean action noise std: 3.26
          Mean value_function loss: 13.0638
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 44.3246
                       Mean reward: 786.29
               Mean episode length: 244.93
    Episode_Reward/reaching_object: 0.7262
    Episode_Reward/rotating_object: 158.5329
        Episode_Reward/action_rate: -0.0498
          Episode_Reward/joint_vel: -0.0049
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 136445952
                    Iteration time: 1.84s
                      Time elapsed: 00:44:38
                               ETA: 00:03:38

################################################################################
                     [1m Learning iteration 1388/1500 [0m                     

                       Computation: 58593 steps/s (collection: 1.583s, learning 0.095s)
             Mean action noise std: 3.27
          Mean value_function loss: 26.1889
               Mean surrogate loss: -0.0005
                 Mean entropy loss: 44.3332
                       Mean reward: 794.25
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7245
    Episode_Reward/rotating_object: 156.9625
        Episode_Reward/action_rate: -0.0501
          Episode_Reward/joint_vel: -0.0052
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 136544256
                    Iteration time: 1.68s
                      Time elapsed: 00:44:39
                               ETA: 00:03:36

################################################################################
                     [1m Learning iteration 1389/1500 [0m                     

                       Computation: 57581 steps/s (collection: 1.598s, learning 0.110s)
             Mean action noise std: 3.27
          Mean value_function loss: 22.8409
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 44.3405
                       Mean reward: 779.83
               Mean episode length: 245.84
    Episode_Reward/reaching_object: 0.7245
    Episode_Reward/rotating_object: 156.3186
        Episode_Reward/action_rate: -0.0498
          Episode_Reward/joint_vel: -0.0051
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 136642560
                    Iteration time: 1.71s
                      Time elapsed: 00:44:41
                               ETA: 00:03:34

################################################################################
                     [1m Learning iteration 1390/1500 [0m                     

                       Computation: 59737 steps/s (collection: 1.553s, learning 0.092s)
             Mean action noise std: 3.27
          Mean value_function loss: 18.1646
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 44.3501
                       Mean reward: 802.60
               Mean episode length: 249.20
    Episode_Reward/reaching_object: 0.7337
    Episode_Reward/rotating_object: 160.0150
        Episode_Reward/action_rate: -0.0503
          Episode_Reward/joint_vel: -0.0047
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 136740864
                    Iteration time: 1.65s
                      Time elapsed: 00:44:43
                               ETA: 00:03:32

################################################################################
                     [1m Learning iteration 1391/1500 [0m                     

                       Computation: 58381 steps/s (collection: 1.596s, learning 0.088s)
             Mean action noise std: 3.27
          Mean value_function loss: 19.8363
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 44.3545
                       Mean reward: 813.89
               Mean episode length: 248.41
    Episode_Reward/reaching_object: 0.7301
    Episode_Reward/rotating_object: 158.2162
        Episode_Reward/action_rate: -0.0500
          Episode_Reward/joint_vel: -0.0049
      Episode_Termination/time_out: 17.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 136839168
                    Iteration time: 1.68s
                      Time elapsed: 00:44:44
                               ETA: 00:03:30

################################################################################
                     [1m Learning iteration 1392/1500 [0m                     

                       Computation: 57438 steps/s (collection: 1.572s, learning 0.139s)
             Mean action noise std: 3.27
          Mean value_function loss: 15.6727
               Mean surrogate loss: 0.0003
                 Mean entropy loss: 44.3593
                       Mean reward: 805.68
               Mean episode length: 248.50
    Episode_Reward/reaching_object: 0.7327
    Episode_Reward/rotating_object: 160.0970
        Episode_Reward/action_rate: -0.0502
          Episode_Reward/joint_vel: -0.0047
      Episode_Termination/time_out: 18.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 136937472
                    Iteration time: 1.71s
                      Time elapsed: 00:44:46
                               ETA: 00:03:28

################################################################################
                     [1m Learning iteration 1393/1500 [0m                     

                       Computation: 54375 steps/s (collection: 1.696s, learning 0.112s)
             Mean action noise std: 3.27
          Mean value_function loss: 18.3874
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 44.3702
                       Mean reward: 798.75
               Mean episode length: 245.93
    Episode_Reward/reaching_object: 0.7275
    Episode_Reward/rotating_object: 158.3066
        Episode_Reward/action_rate: -0.0499
          Episode_Reward/joint_vel: -0.0045
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 137035776
                    Iteration time: 1.81s
                      Time elapsed: 00:44:48
                               ETA: 00:03:26

################################################################################
                     [1m Learning iteration 1394/1500 [0m                     

                       Computation: 56052 steps/s (collection: 1.640s, learning 0.114s)
             Mean action noise std: 3.28
          Mean value_function loss: 17.8917
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 44.3825
                       Mean reward: 807.55
               Mean episode length: 248.22
    Episode_Reward/reaching_object: 0.7325
    Episode_Reward/rotating_object: 160.2904
        Episode_Reward/action_rate: -0.0503
          Episode_Reward/joint_vel: -0.0047
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 137134080
                    Iteration time: 1.75s
                      Time elapsed: 00:44:50
                               ETA: 00:03:24

################################################################################
                     [1m Learning iteration 1395/1500 [0m                     

                       Computation: 56554 steps/s (collection: 1.637s, learning 0.101s)
             Mean action noise std: 3.28
          Mean value_function loss: 19.3350
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 44.3922
                       Mean reward: 798.92
               Mean episode length: 248.08
    Episode_Reward/reaching_object: 0.7274
    Episode_Reward/rotating_object: 158.2702
        Episode_Reward/action_rate: -0.0502
          Episode_Reward/joint_vel: -0.0045
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 137232384
                    Iteration time: 1.74s
                      Time elapsed: 00:44:51
                               ETA: 00:03:22

################################################################################
                     [1m Learning iteration 1396/1500 [0m                     

                       Computation: 56004 steps/s (collection: 1.608s, learning 0.148s)
             Mean action noise std: 3.28
          Mean value_function loss: 14.9745
               Mean surrogate loss: 0.0005
                 Mean entropy loss: 44.4013
                       Mean reward: 807.16
               Mean episode length: 248.31
    Episode_Reward/reaching_object: 0.7347
    Episode_Reward/rotating_object: 160.4630
        Episode_Reward/action_rate: -0.0507
          Episode_Reward/joint_vel: -0.0044
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 137330688
                    Iteration time: 1.76s
                      Time elapsed: 00:44:53
                               ETA: 00:03:20

################################################################################
                     [1m Learning iteration 1397/1500 [0m                     

                       Computation: 55966 steps/s (collection: 1.658s, learning 0.098s)
             Mean action noise std: 3.28
          Mean value_function loss: 14.1164
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 44.4059
                       Mean reward: 771.25
               Mean episode length: 247.53
    Episode_Reward/reaching_object: 0.7312
    Episode_Reward/rotating_object: 159.4007
        Episode_Reward/action_rate: -0.0508
          Episode_Reward/joint_vel: -0.0051
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 137428992
                    Iteration time: 1.76s
                      Time elapsed: 00:44:55
                               ETA: 00:03:18

################################################################################
                     [1m Learning iteration 1398/1500 [0m                     

                       Computation: 58398 steps/s (collection: 1.576s, learning 0.107s)
             Mean action noise std: 3.28
          Mean value_function loss: 24.1618
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 44.4102
                       Mean reward: 789.43
               Mean episode length: 246.13
    Episode_Reward/reaching_object: 0.7185
    Episode_Reward/rotating_object: 156.0069
        Episode_Reward/action_rate: -0.0500
          Episode_Reward/joint_vel: -0.0046
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 137527296
                    Iteration time: 1.68s
                      Time elapsed: 00:44:57
                               ETA: 00:03:16

################################################################################
                     [1m Learning iteration 1399/1500 [0m                     

                       Computation: 55932 steps/s (collection: 1.649s, learning 0.109s)
             Mean action noise std: 3.28
          Mean value_function loss: 15.9177
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 44.4190
                       Mean reward: 790.81
               Mean episode length: 249.83
    Episode_Reward/reaching_object: 0.7263
    Episode_Reward/rotating_object: 157.1981
        Episode_Reward/action_rate: -0.0506
          Episode_Reward/joint_vel: -0.0050
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 137625600
                    Iteration time: 1.76s
                      Time elapsed: 00:44:58
                               ETA: 00:03:14

################################################################################
                     [1m Learning iteration 1400/1500 [0m                     

                       Computation: 58037 steps/s (collection: 1.581s, learning 0.113s)
             Mean action noise std: 3.29
          Mean value_function loss: 16.2321
               Mean surrogate loss: -0.0003
                 Mean entropy loss: 44.4338
                       Mean reward: 800.20
               Mean episode length: 247.77
    Episode_Reward/reaching_object: 0.7300
    Episode_Reward/rotating_object: 158.0759
        Episode_Reward/action_rate: -0.0506
          Episode_Reward/joint_vel: -0.0047
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 137723904
                    Iteration time: 1.69s
                      Time elapsed: 00:45:00
                               ETA: 00:03:12

################################################################################
                     [1m Learning iteration 1401/1500 [0m                     

                       Computation: 52997 steps/s (collection: 1.691s, learning 0.164s)
             Mean action noise std: 3.29
          Mean value_function loss: 21.7103
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 44.4454
                       Mean reward: 791.05
               Mean episode length: 243.82
    Episode_Reward/reaching_object: 0.7269
    Episode_Reward/rotating_object: 158.0248
        Episode_Reward/action_rate: -0.0504
          Episode_Reward/joint_vel: -0.0045
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 137822208
                    Iteration time: 1.85s
                      Time elapsed: 00:45:02
                               ETA: 00:03:10

################################################################################
                     [1m Learning iteration 1402/1500 [0m                     

                       Computation: 55372 steps/s (collection: 1.674s, learning 0.101s)
             Mean action noise std: 3.29
          Mean value_function loss: 15.1461
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 44.4543
                       Mean reward: 808.98
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7367
    Episode_Reward/rotating_object: 160.7853
        Episode_Reward/action_rate: -0.0513
          Episode_Reward/joint_vel: -0.0052
      Episode_Termination/time_out: 18.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 137920512
                    Iteration time: 1.78s
                      Time elapsed: 00:45:04
                               ETA: 00:03:08

################################################################################
                     [1m Learning iteration 1403/1500 [0m                     

                       Computation: 57685 steps/s (collection: 1.608s, learning 0.097s)
             Mean action noise std: 3.29
          Mean value_function loss: 18.1297
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 44.4655
                       Mean reward: 774.56
               Mean episode length: 243.53
    Episode_Reward/reaching_object: 0.7241
    Episode_Reward/rotating_object: 157.7761
        Episode_Reward/action_rate: -0.0503
          Episode_Reward/joint_vel: -0.0047
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 138018816
                    Iteration time: 1.70s
                      Time elapsed: 00:45:05
                               ETA: 00:03:06

################################################################################
                     [1m Learning iteration 1404/1500 [0m                     

                       Computation: 55671 steps/s (collection: 1.570s, learning 0.196s)
             Mean action noise std: 3.29
          Mean value_function loss: 17.3245
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 44.4757
                       Mean reward: 777.21
               Mean episode length: 241.78
    Episode_Reward/reaching_object: 0.7265
    Episode_Reward/rotating_object: 158.3402
        Episode_Reward/action_rate: -0.0506
          Episode_Reward/joint_vel: -0.0045
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 138117120
                    Iteration time: 1.77s
                      Time elapsed: 00:45:07
                               ETA: 00:03:05

################################################################################
                     [1m Learning iteration 1405/1500 [0m                     

                       Computation: 59072 steps/s (collection: 1.573s, learning 0.092s)
             Mean action noise std: 3.30
          Mean value_function loss: 16.9188
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 44.4820
                       Mean reward: 795.23
               Mean episode length: 243.46
    Episode_Reward/reaching_object: 0.7292
    Episode_Reward/rotating_object: 158.6578
        Episode_Reward/action_rate: -0.0507
          Episode_Reward/joint_vel: -0.0046
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 138215424
                    Iteration time: 1.66s
                      Time elapsed: 00:45:09
                               ETA: 00:03:03

################################################################################
                     [1m Learning iteration 1406/1500 [0m                     

                       Computation: 56590 steps/s (collection: 1.638s, learning 0.099s)
             Mean action noise std: 3.30
          Mean value_function loss: 14.1914
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 44.4850
                       Mean reward: 814.65
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7328
    Episode_Reward/rotating_object: 159.5361
        Episode_Reward/action_rate: -0.0508
          Episode_Reward/joint_vel: -0.0046
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 138313728
                    Iteration time: 1.74s
                      Time elapsed: 00:45:11
                               ETA: 00:03:01

################################################################################
                     [1m Learning iteration 1407/1500 [0m                     

                       Computation: 56520 steps/s (collection: 1.571s, learning 0.168s)
             Mean action noise std: 3.30
          Mean value_function loss: 16.2750
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 44.4886
                       Mean reward: 802.32
               Mean episode length: 245.69
    Episode_Reward/reaching_object: 0.7369
    Episode_Reward/rotating_object: 160.6931
        Episode_Reward/action_rate: -0.0512
          Episode_Reward/joint_vel: -0.0046
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 138412032
                    Iteration time: 1.74s
                      Time elapsed: 00:45:12
                               ETA: 00:02:59

################################################################################
                     [1m Learning iteration 1408/1500 [0m                     

                       Computation: 59911 steps/s (collection: 1.539s, learning 0.102s)
             Mean action noise std: 3.30
          Mean value_function loss: 15.3784
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 44.4942
                       Mean reward: 810.83
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7351
    Episode_Reward/rotating_object: 158.9698
        Episode_Reward/action_rate: -0.0511
          Episode_Reward/joint_vel: -0.0048
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 138510336
                    Iteration time: 1.64s
                      Time elapsed: 00:45:14
                               ETA: 00:02:57

################################################################################
                     [1m Learning iteration 1409/1500 [0m                     

                       Computation: 57612 steps/s (collection: 1.617s, learning 0.090s)
             Mean action noise std: 3.30
          Mean value_function loss: 21.1756
               Mean surrogate loss: -0.0006
                 Mean entropy loss: 44.5016
                       Mean reward: 784.90
               Mean episode length: 243.46
    Episode_Reward/reaching_object: 0.7351
    Episode_Reward/rotating_object: 159.0838
        Episode_Reward/action_rate: -0.0509
          Episode_Reward/joint_vel: -0.0046
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 138608640
                    Iteration time: 1.71s
                      Time elapsed: 00:45:16
                               ETA: 00:02:55

################################################################################
                     [1m Learning iteration 1410/1500 [0m                     

                       Computation: 57000 steps/s (collection: 1.609s, learning 0.116s)
             Mean action noise std: 3.30
          Mean value_function loss: 16.4894
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 44.5064
                       Mean reward: 792.33
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7387
    Episode_Reward/rotating_object: 159.1431
        Episode_Reward/action_rate: -0.0512
          Episode_Reward/joint_vel: -0.0046
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 138706944
                    Iteration time: 1.72s
                      Time elapsed: 00:45:17
                               ETA: 00:02:53

################################################################################
                     [1m Learning iteration 1411/1500 [0m                     

                       Computation: 58162 steps/s (collection: 1.589s, learning 0.101s)
             Mean action noise std: 3.30
          Mean value_function loss: 15.2059
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 44.5106
                       Mean reward: 822.81
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7426
    Episode_Reward/rotating_object: 161.0977
        Episode_Reward/action_rate: -0.0512
          Episode_Reward/joint_vel: -0.0046
      Episode_Termination/time_out: 17.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 138805248
                    Iteration time: 1.69s
                      Time elapsed: 00:45:19
                               ETA: 00:02:51

################################################################################
                     [1m Learning iteration 1412/1500 [0m                     

                       Computation: 58991 steps/s (collection: 1.554s, learning 0.113s)
             Mean action noise std: 3.30
          Mean value_function loss: 20.7801
               Mean surrogate loss: -0.0005
                 Mean entropy loss: 44.5182
                       Mean reward: 805.72
               Mean episode length: 247.80
    Episode_Reward/reaching_object: 0.7421
    Episode_Reward/rotating_object: 160.0068
        Episode_Reward/action_rate: -0.0513
          Episode_Reward/joint_vel: -0.0044
      Episode_Termination/time_out: 17.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 138903552
                    Iteration time: 1.67s
                      Time elapsed: 00:45:21
                               ETA: 00:02:49

################################################################################
                     [1m Learning iteration 1413/1500 [0m                     

                       Computation: 56926 steps/s (collection: 1.628s, learning 0.099s)
             Mean action noise std: 3.31
          Mean value_function loss: 18.5455
               Mean surrogate loss: -0.0006
                 Mean entropy loss: 44.5264
                       Mean reward: 800.74
               Mean episode length: 246.02
    Episode_Reward/reaching_object: 0.7463
    Episode_Reward/rotating_object: 158.9782
        Episode_Reward/action_rate: -0.0513
          Episode_Reward/joint_vel: -0.0045
      Episode_Termination/time_out: 17.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 139001856
                    Iteration time: 1.73s
                      Time elapsed: 00:45:23
                               ETA: 00:02:47

################################################################################
                     [1m Learning iteration 1414/1500 [0m                     

                       Computation: 57698 steps/s (collection: 1.601s, learning 0.103s)
             Mean action noise std: 3.31
          Mean value_function loss: 19.0039
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 44.5349
                       Mean reward: 805.96
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7460
    Episode_Reward/rotating_object: 157.7622
        Episode_Reward/action_rate: -0.0513
          Episode_Reward/joint_vel: -0.0048
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 139100160
                    Iteration time: 1.70s
                      Time elapsed: 00:45:24
                               ETA: 00:02:45

################################################################################
                     [1m Learning iteration 1415/1500 [0m                     

                       Computation: 59846 steps/s (collection: 1.538s, learning 0.105s)
             Mean action noise std: 3.31
          Mean value_function loss: 13.8986
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 44.5387
                       Mean reward: 824.20
               Mean episode length: 247.68
    Episode_Reward/reaching_object: 0.7520
    Episode_Reward/rotating_object: 160.4341
        Episode_Reward/action_rate: -0.0517
          Episode_Reward/joint_vel: -0.0047
      Episode_Termination/time_out: 17.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 139198464
                    Iteration time: 1.64s
                      Time elapsed: 00:45:26
                               ETA: 00:02:43

################################################################################
                     [1m Learning iteration 1416/1500 [0m                     

                       Computation: 54630 steps/s (collection: 1.701s, learning 0.098s)
             Mean action noise std: 3.31
          Mean value_function loss: 16.7309
               Mean surrogate loss: -0.0007
                 Mean entropy loss: 44.5486
                       Mean reward: 799.83
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7510
    Episode_Reward/rotating_object: 159.5213
        Episode_Reward/action_rate: -0.0516
          Episode_Reward/joint_vel: -0.0046
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 139296768
                    Iteration time: 1.80s
                      Time elapsed: 00:45:28
                               ETA: 00:02:41

################################################################################
                     [1m Learning iteration 1417/1500 [0m                     

                       Computation: 56984 steps/s (collection: 1.595s, learning 0.130s)
             Mean action noise std: 3.31
          Mean value_function loss: 13.2192
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 44.5545
                       Mean reward: 817.74
               Mean episode length: 248.16
    Episode_Reward/reaching_object: 0.7522
    Episode_Reward/rotating_object: 160.6011
        Episode_Reward/action_rate: -0.0516
          Episode_Reward/joint_vel: -0.0045
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 139395072
                    Iteration time: 1.73s
                      Time elapsed: 00:45:29
                               ETA: 00:02:39

################################################################################
                     [1m Learning iteration 1418/1500 [0m                     

                       Computation: 58182 steps/s (collection: 1.582s, learning 0.107s)
             Mean action noise std: 3.31
          Mean value_function loss: 21.2641
               Mean surrogate loss: 0.0004
                 Mean entropy loss: 44.5570
                       Mean reward: 790.12
               Mean episode length: 247.94
    Episode_Reward/reaching_object: 0.7445
    Episode_Reward/rotating_object: 157.9603
        Episode_Reward/action_rate: -0.0516
          Episode_Reward/joint_vel: -0.0045
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 139493376
                    Iteration time: 1.69s
                      Time elapsed: 00:45:31
                               ETA: 00:02:37

################################################################################
                     [1m Learning iteration 1419/1500 [0m                     

                       Computation: 52707 steps/s (collection: 1.767s, learning 0.099s)
             Mean action noise std: 3.31
          Mean value_function loss: 19.7367
               Mean surrogate loss: -0.0004
                 Mean entropy loss: 44.5580
                       Mean reward: 806.28
               Mean episode length: 247.83
    Episode_Reward/reaching_object: 0.7422
    Episode_Reward/rotating_object: 158.3829
        Episode_Reward/action_rate: -0.0513
          Episode_Reward/joint_vel: -0.0044
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 139591680
                    Iteration time: 1.87s
                      Time elapsed: 00:45:33
                               ETA: 00:02:35

################################################################################
                     [1m Learning iteration 1420/1500 [0m                     

                       Computation: 59516 steps/s (collection: 1.564s, learning 0.088s)
             Mean action noise std: 3.31
          Mean value_function loss: 16.5440
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 44.5605
                       Mean reward: 800.95
               Mean episode length: 247.77
    Episode_Reward/reaching_object: 0.7467
    Episode_Reward/rotating_object: 158.6800
        Episode_Reward/action_rate: -0.0517
          Episode_Reward/joint_vel: -0.0046
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 139689984
                    Iteration time: 1.65s
                      Time elapsed: 00:45:35
                               ETA: 00:02:33

################################################################################
                     [1m Learning iteration 1421/1500 [0m                     

                       Computation: 56203 steps/s (collection: 1.574s, learning 0.175s)
             Mean action noise std: 3.32
          Mean value_function loss: 16.7123
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 44.5656
                       Mean reward: 817.45
               Mean episode length: 248.31
    Episode_Reward/reaching_object: 0.7517
    Episode_Reward/rotating_object: 161.1320
        Episode_Reward/action_rate: -0.0519
          Episode_Reward/joint_vel: -0.0045
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 139788288
                    Iteration time: 1.75s
                      Time elapsed: 00:45:36
                               ETA: 00:02:32

################################################################################
                     [1m Learning iteration 1422/1500 [0m                     

                       Computation: 59962 steps/s (collection: 1.550s, learning 0.090s)
             Mean action noise std: 3.32
          Mean value_function loss: 23.4634
               Mean surrogate loss: -0.0007
                 Mean entropy loss: 44.5741
                       Mean reward: 813.56
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7455
    Episode_Reward/rotating_object: 159.7339
        Episode_Reward/action_rate: -0.0519
          Episode_Reward/joint_vel: -0.0044
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 139886592
                    Iteration time: 1.64s
                      Time elapsed: 00:45:38
                               ETA: 00:02:30

################################################################################
                     [1m Learning iteration 1423/1500 [0m                     

                       Computation: 56991 steps/s (collection: 1.620s, learning 0.105s)
             Mean action noise std: 3.32
          Mean value_function loss: 18.7219
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 44.5821
                       Mean reward: 798.71
               Mean episode length: 247.79
    Episode_Reward/reaching_object: 0.7417
    Episode_Reward/rotating_object: 158.9044
        Episode_Reward/action_rate: -0.0517
          Episode_Reward/joint_vel: -0.0047
      Episode_Termination/time_out: 17.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 139984896
                    Iteration time: 1.72s
                      Time elapsed: 00:45:40
                               ETA: 00:02:28

################################################################################
                     [1m Learning iteration 1424/1500 [0m                     

                       Computation: 53835 steps/s (collection: 1.615s, learning 0.211s)
             Mean action noise std: 3.32
          Mean value_function loss: 20.7508
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 44.5981
                       Mean reward: 807.60
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7474
    Episode_Reward/rotating_object: 159.8421
        Episode_Reward/action_rate: -0.0519
          Episode_Reward/joint_vel: -0.0045
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 140083200
                    Iteration time: 1.83s
                      Time elapsed: 00:45:42
                               ETA: 00:02:26

################################################################################
                     [1m Learning iteration 1425/1500 [0m                     

                       Computation: 55421 steps/s (collection: 1.635s, learning 0.139s)
             Mean action noise std: 3.32
          Mean value_function loss: 25.0359
               Mean surrogate loss: -0.0003
                 Mean entropy loss: 44.6145
                       Mean reward: 783.18
               Mean episode length: 241.78
    Episode_Reward/reaching_object: 0.7356
    Episode_Reward/rotating_object: 156.5790
        Episode_Reward/action_rate: -0.0513
          Episode_Reward/joint_vel: -0.0045
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 140181504
                    Iteration time: 1.77s
                      Time elapsed: 00:45:43
                               ETA: 00:02:24

################################################################################
                     [1m Learning iteration 1426/1500 [0m                     

                       Computation: 58556 steps/s (collection: 1.580s, learning 0.099s)
             Mean action noise std: 3.33
          Mean value_function loss: 20.3426
               Mean surrogate loss: -0.0007
                 Mean entropy loss: 44.6242
                       Mean reward: 788.73
               Mean episode length: 246.45
    Episode_Reward/reaching_object: 0.7398
    Episode_Reward/rotating_object: 157.9529
        Episode_Reward/action_rate: -0.0516
          Episode_Reward/joint_vel: -0.0045
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 140279808
                    Iteration time: 1.68s
                      Time elapsed: 00:45:45
                               ETA: 00:02:22

################################################################################
                     [1m Learning iteration 1427/1500 [0m                     

                       Computation: 57416 steps/s (collection: 1.598s, learning 0.114s)
             Mean action noise std: 3.33
          Mean value_function loss: 19.8823
               Mean surrogate loss: -0.0007
                 Mean entropy loss: 44.6330
                       Mean reward: 768.70
               Mean episode length: 243.57
    Episode_Reward/reaching_object: 0.7393
    Episode_Reward/rotating_object: 157.5536
        Episode_Reward/action_rate: -0.0516
          Episode_Reward/joint_vel: -0.0045
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 140378112
                    Iteration time: 1.71s
                      Time elapsed: 00:45:47
                               ETA: 00:02:20

################################################################################
                     [1m Learning iteration 1428/1500 [0m                     

                       Computation: 56589 steps/s (collection: 1.622s, learning 0.115s)
             Mean action noise std: 3.33
          Mean value_function loss: 20.4370
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 44.6436
                       Mean reward: 820.95
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7437
    Episode_Reward/rotating_object: 158.6648
        Episode_Reward/action_rate: -0.0519
          Episode_Reward/joint_vel: -0.0044
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 140476416
                    Iteration time: 1.74s
                      Time elapsed: 00:45:48
                               ETA: 00:02:18

################################################################################
                     [1m Learning iteration 1429/1500 [0m                     

                       Computation: 56231 steps/s (collection: 1.642s, learning 0.107s)
             Mean action noise std: 3.33
          Mean value_function loss: 18.8280
               Mean surrogate loss: -0.0006
                 Mean entropy loss: 44.6496
                       Mean reward: 789.99
               Mean episode length: 248.26
    Episode_Reward/reaching_object: 0.7508
    Episode_Reward/rotating_object: 160.2702
        Episode_Reward/action_rate: -0.0521
          Episode_Reward/joint_vel: -0.0045
      Episode_Termination/time_out: 17.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 140574720
                    Iteration time: 1.75s
                      Time elapsed: 00:45:50
                               ETA: 00:02:16

################################################################################
                     [1m Learning iteration 1430/1500 [0m                     

                       Computation: 57928 steps/s (collection: 1.596s, learning 0.101s)
             Mean action noise std: 3.33
          Mean value_function loss: 23.4871
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 44.6577
                       Mean reward: 802.17
               Mean episode length: 248.41
    Episode_Reward/reaching_object: 0.7502
    Episode_Reward/rotating_object: 157.7736
        Episode_Reward/action_rate: -0.0523
          Episode_Reward/joint_vel: -0.0047
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 140673024
                    Iteration time: 1.70s
                      Time elapsed: 00:45:52
                               ETA: 00:02:14

################################################################################
                     [1m Learning iteration 1431/1500 [0m                     

                       Computation: 56994 steps/s (collection: 1.612s, learning 0.113s)
             Mean action noise std: 3.33
          Mean value_function loss: 18.7142
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 44.6682
                       Mean reward: 788.59
               Mean episode length: 247.87
    Episode_Reward/reaching_object: 0.7502
    Episode_Reward/rotating_object: 158.4022
        Episode_Reward/action_rate: -0.0523
          Episode_Reward/joint_vel: -0.0045
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 140771328
                    Iteration time: 1.72s
                      Time elapsed: 00:45:54
                               ETA: 00:02:12

################################################################################
                     [1m Learning iteration 1432/1500 [0m                     

                       Computation: 57907 steps/s (collection: 1.568s, learning 0.130s)
             Mean action noise std: 3.34
          Mean value_function loss: 22.8044
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 44.6742
                       Mean reward: 811.02
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7606
    Episode_Reward/rotating_object: 160.2443
        Episode_Reward/action_rate: -0.0526
          Episode_Reward/joint_vel: -0.0044
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 140869632
                    Iteration time: 1.70s
                      Time elapsed: 00:45:55
                               ETA: 00:02:10

################################################################################
                     [1m Learning iteration 1433/1500 [0m                     

                       Computation: 55969 steps/s (collection: 1.634s, learning 0.123s)
             Mean action noise std: 3.34
          Mean value_function loss: 25.6842
               Mean surrogate loss: 0.0000
                 Mean entropy loss: 44.6786
                       Mean reward: 800.96
               Mean episode length: 248.05
    Episode_Reward/reaching_object: 0.7556
    Episode_Reward/rotating_object: 159.8208
        Episode_Reward/action_rate: -0.0525
          Episode_Reward/joint_vel: -0.0046
      Episode_Termination/time_out: 17.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 140967936
                    Iteration time: 1.76s
                      Time elapsed: 00:45:57
                               ETA: 00:02:08

################################################################################
                     [1m Learning iteration 1434/1500 [0m                     

                       Computation: 56202 steps/s (collection: 1.636s, learning 0.114s)
             Mean action noise std: 3.34
          Mean value_function loss: 23.3961
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 44.6835
                       Mean reward: 808.00
               Mean episode length: 247.71
    Episode_Reward/reaching_object: 0.7569
    Episode_Reward/rotating_object: 160.5679
        Episode_Reward/action_rate: -0.0524
          Episode_Reward/joint_vel: -0.0045
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 141066240
                    Iteration time: 1.75s
                      Time elapsed: 00:45:59
                               ETA: 00:02:06

################################################################################
                     [1m Learning iteration 1435/1500 [0m                     

                       Computation: 56490 steps/s (collection: 1.585s, learning 0.156s)
             Mean action noise std: 3.34
          Mean value_function loss: 20.0239
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 44.6893
                       Mean reward: 802.40
               Mean episode length: 247.93
    Episode_Reward/reaching_object: 0.7520
    Episode_Reward/rotating_object: 159.6055
        Episode_Reward/action_rate: -0.0523
          Episode_Reward/joint_vel: -0.0045
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 141164544
                    Iteration time: 1.74s
                      Time elapsed: 00:46:01
                               ETA: 00:02:04

################################################################################
                     [1m Learning iteration 1436/1500 [0m                     

                       Computation: 53074 steps/s (collection: 1.759s, learning 0.094s)
             Mean action noise std: 3.34
          Mean value_function loss: 19.2632
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 44.6973
                       Mean reward: 791.49
               Mean episode length: 245.80
    Episode_Reward/reaching_object: 0.7493
    Episode_Reward/rotating_object: 158.5695
        Episode_Reward/action_rate: -0.0522
          Episode_Reward/joint_vel: -0.0046
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 141262848
                    Iteration time: 1.85s
                      Time elapsed: 00:46:02
                               ETA: 00:02:03

################################################################################
                     [1m Learning iteration 1437/1500 [0m                     

                       Computation: 58583 steps/s (collection: 1.582s, learning 0.096s)
             Mean action noise std: 3.34
          Mean value_function loss: 11.2182
               Mean surrogate loss: 0.0002
                 Mean entropy loss: 44.7098
                       Mean reward: 799.45
               Mean episode length: 247.95
    Episode_Reward/reaching_object: 0.7444
    Episode_Reward/rotating_object: 156.3004
        Episode_Reward/action_rate: -0.0522
          Episode_Reward/joint_vel: -0.0044
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 141361152
                    Iteration time: 1.68s
                      Time elapsed: 00:46:04
                               ETA: 00:02:01

################################################################################
                     [1m Learning iteration 1438/1500 [0m                     

                       Computation: 57749 steps/s (collection: 1.611s, learning 0.091s)
             Mean action noise std: 3.35
          Mean value_function loss: 17.5830
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 44.7213
                       Mean reward: 797.80
               Mean episode length: 246.79
    Episode_Reward/reaching_object: 0.7455
    Episode_Reward/rotating_object: 157.3899
        Episode_Reward/action_rate: -0.0524
          Episode_Reward/joint_vel: -0.0046
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 141459456
                    Iteration time: 1.70s
                      Time elapsed: 00:46:06
                               ETA: 00:01:59

################################################################################
                     [1m Learning iteration 1439/1500 [0m                     

                       Computation: 59072 steps/s (collection: 1.574s, learning 0.091s)
             Mean action noise std: 3.35
          Mean value_function loss: 18.3500
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 44.7340
                       Mean reward: 786.60
               Mean episode length: 245.66
    Episode_Reward/reaching_object: 0.7473
    Episode_Reward/rotating_object: 158.5160
        Episode_Reward/action_rate: -0.0527
          Episode_Reward/joint_vel: -0.0047
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 141557760
                    Iteration time: 1.66s
                      Time elapsed: 00:46:07
                               ETA: 00:01:57

################################################################################
                     [1m Learning iteration 1440/1500 [0m                     

                       Computation: 58454 steps/s (collection: 1.590s, learning 0.092s)
             Mean action noise std: 3.35
          Mean value_function loss: 25.7140
               Mean surrogate loss: 0.0006
                 Mean entropy loss: 44.7458
                       Mean reward: 795.33
               Mean episode length: 247.38
    Episode_Reward/reaching_object: 0.7433
    Episode_Reward/rotating_object: 157.2572
        Episode_Reward/action_rate: -0.0528
          Episode_Reward/joint_vel: -0.0050
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 141656064
                    Iteration time: 1.68s
                      Time elapsed: 00:46:09
                               ETA: 00:01:55

################################################################################
                     [1m Learning iteration 1441/1500 [0m                     

                       Computation: 57226 steps/s (collection: 1.611s, learning 0.107s)
             Mean action noise std: 3.35
          Mean value_function loss: 17.7185
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 44.7526
                       Mean reward: 777.05
               Mean episode length: 245.81
    Episode_Reward/reaching_object: 0.7391
    Episode_Reward/rotating_object: 156.9649
        Episode_Reward/action_rate: -0.0523
          Episode_Reward/joint_vel: -0.0043
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 141754368
                    Iteration time: 1.72s
                      Time elapsed: 00:46:11
                               ETA: 00:01:53

################################################################################
                     [1m Learning iteration 1442/1500 [0m                     

                       Computation: 54395 steps/s (collection: 1.689s, learning 0.118s)
             Mean action noise std: 3.35
          Mean value_function loss: 11.6087
               Mean surrogate loss: -0.0008
                 Mean entropy loss: 44.7620
                       Mean reward: 796.66
               Mean episode length: 248.18
    Episode_Reward/reaching_object: 0.7460
    Episode_Reward/rotating_object: 157.7225
        Episode_Reward/action_rate: -0.0531
          Episode_Reward/joint_vel: -0.0045
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 141852672
                    Iteration time: 1.81s
                      Time elapsed: 00:46:13
                               ETA: 00:01:51

################################################################################
                     [1m Learning iteration 1443/1500 [0m                     

                       Computation: 54935 steps/s (collection: 1.689s, learning 0.100s)
             Mean action noise std: 3.36
          Mean value_function loss: 23.8014
               Mean surrogate loss: -0.0002
                 Mean entropy loss: 44.7697
                       Mean reward: 778.33
               Mean episode length: 245.13
    Episode_Reward/reaching_object: 0.7407
    Episode_Reward/rotating_object: 156.2483
        Episode_Reward/action_rate: -0.0527
          Episode_Reward/joint_vel: -0.0052
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 141950976
                    Iteration time: 1.79s
                      Time elapsed: 00:46:14
                               ETA: 00:01:49

################################################################################
                     [1m Learning iteration 1444/1500 [0m                     

                       Computation: 55719 steps/s (collection: 1.671s, learning 0.094s)
             Mean action noise std: 3.36
          Mean value_function loss: 24.6794
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 44.7755
                       Mean reward: 812.92
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7460
    Episode_Reward/rotating_object: 158.3453
        Episode_Reward/action_rate: -0.0527
          Episode_Reward/joint_vel: -0.0043
      Episode_Termination/time_out: 17.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 142049280
                    Iteration time: 1.76s
                      Time elapsed: 00:46:16
                               ETA: 00:01:47

################################################################################
                     [1m Learning iteration 1445/1500 [0m                     

                       Computation: 58889 steps/s (collection: 1.575s, learning 0.095s)
             Mean action noise std: 3.36
          Mean value_function loss: 21.0157
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 44.7786
                       Mean reward: 791.06
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7542
    Episode_Reward/rotating_object: 160.2256
        Episode_Reward/action_rate: -0.0531
          Episode_Reward/joint_vel: -0.0043
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 142147584
                    Iteration time: 1.67s
                      Time elapsed: 00:46:18
                               ETA: 00:01:45

################################################################################
                     [1m Learning iteration 1446/1500 [0m                     

                       Computation: 57305 steps/s (collection: 1.591s, learning 0.124s)
             Mean action noise std: 3.36
          Mean value_function loss: 19.1961
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 44.7793
                       Mean reward: 823.38
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7432
    Episode_Reward/rotating_object: 158.7496
        Episode_Reward/action_rate: -0.0525
          Episode_Reward/joint_vel: -0.0044
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 142245888
                    Iteration time: 1.72s
                      Time elapsed: 00:46:20
                               ETA: 00:01:43

################################################################################
                     [1m Learning iteration 1447/1500 [0m                     

                       Computation: 56130 steps/s (collection: 1.656s, learning 0.095s)
             Mean action noise std: 3.36
          Mean value_function loss: 21.5684
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 44.7843
                       Mean reward: 782.83
               Mean episode length: 245.91
    Episode_Reward/reaching_object: 0.7454
    Episode_Reward/rotating_object: 156.6905
        Episode_Reward/action_rate: -0.0530
          Episode_Reward/joint_vel: -0.0045
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 142344192
                    Iteration time: 1.75s
                      Time elapsed: 00:46:21
                               ETA: 00:01:41

################################################################################
                     [1m Learning iteration 1448/1500 [0m                     

                       Computation: 55856 steps/s (collection: 1.653s, learning 0.107s)
             Mean action noise std: 3.36
          Mean value_function loss: 13.7900
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 44.7921
                       Mean reward: 795.75
               Mean episode length: 248.50
    Episode_Reward/reaching_object: 0.7471
    Episode_Reward/rotating_object: 157.1646
        Episode_Reward/action_rate: -0.0532
          Episode_Reward/joint_vel: -0.0044
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 142442496
                    Iteration time: 1.76s
                      Time elapsed: 00:46:23
                               ETA: 00:01:39

################################################################################
                     [1m Learning iteration 1449/1500 [0m                     

                       Computation: 57481 steps/s (collection: 1.595s, learning 0.115s)
             Mean action noise std: 3.36
          Mean value_function loss: 20.6718
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 44.7963
                       Mean reward: 782.48
               Mean episode length: 249.68
    Episode_Reward/reaching_object: 0.7511
    Episode_Reward/rotating_object: 157.4892
        Episode_Reward/action_rate: -0.0537
          Episode_Reward/joint_vel: -0.0048
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 142540800
                    Iteration time: 1.71s
                      Time elapsed: 00:46:25
                               ETA: 00:01:37

################################################################################
                     [1m Learning iteration 1450/1500 [0m                     

                       Computation: 51580 steps/s (collection: 1.719s, learning 0.187s)
             Mean action noise std: 3.36
          Mean value_function loss: 20.5248
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 44.8019
                       Mean reward: 801.51
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7500
    Episode_Reward/rotating_object: 157.9272
        Episode_Reward/action_rate: -0.0535
          Episode_Reward/joint_vel: -0.0045
      Episode_Termination/time_out: 17.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 142639104
                    Iteration time: 1.91s
                      Time elapsed: 00:46:27
                               ETA: 00:01:36

################################################################################
                     [1m Learning iteration 1451/1500 [0m                     

                       Computation: 53975 steps/s (collection: 1.698s, learning 0.124s)
             Mean action noise std: 3.37
          Mean value_function loss: 22.1789
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 44.8111
                       Mean reward: 815.14
               Mean episode length: 247.72
    Episode_Reward/reaching_object: 0.7509
    Episode_Reward/rotating_object: 160.3733
        Episode_Reward/action_rate: -0.0531
          Episode_Reward/joint_vel: -0.0045
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 142737408
                    Iteration time: 1.82s
                      Time elapsed: 00:46:29
                               ETA: 00:01:34

################################################################################
                     [1m Learning iteration 1452/1500 [0m                     

                       Computation: 56452 steps/s (collection: 1.633s, learning 0.108s)
             Mean action noise std: 3.37
          Mean value_function loss: 17.6792
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 44.8208
                       Mean reward: 783.84
               Mean episode length: 248.19
    Episode_Reward/reaching_object: 0.7523
    Episode_Reward/rotating_object: 159.4482
        Episode_Reward/action_rate: -0.0537
          Episode_Reward/joint_vel: -0.0045
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 142835712
                    Iteration time: 1.74s
                      Time elapsed: 00:46:30
                               ETA: 00:01:32

################################################################################
                     [1m Learning iteration 1453/1500 [0m                     

                       Computation: 52775 steps/s (collection: 1.738s, learning 0.125s)
             Mean action noise std: 3.37
          Mean value_function loss: 21.8858
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 44.8311
                       Mean reward: 808.06
               Mean episode length: 248.05
    Episode_Reward/reaching_object: 0.7491
    Episode_Reward/rotating_object: 159.0993
        Episode_Reward/action_rate: -0.0532
          Episode_Reward/joint_vel: -0.0043
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 142934016
                    Iteration time: 1.86s
                      Time elapsed: 00:46:32
                               ETA: 00:01:30

################################################################################
                     [1m Learning iteration 1454/1500 [0m                     

                       Computation: 56505 steps/s (collection: 1.643s, learning 0.097s)
             Mean action noise std: 3.37
          Mean value_function loss: 15.0379
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 44.8388
                       Mean reward: 780.15
               Mean episode length: 245.86
    Episode_Reward/reaching_object: 0.7428
    Episode_Reward/rotating_object: 156.2643
        Episode_Reward/action_rate: -0.0530
          Episode_Reward/joint_vel: -0.0047
      Episode_Termination/time_out: 17.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 143032320
                    Iteration time: 1.74s
                      Time elapsed: 00:46:34
                               ETA: 00:01:28

################################################################################
                     [1m Learning iteration 1455/1500 [0m                     

                       Computation: 56166 steps/s (collection: 1.656s, learning 0.095s)
             Mean action noise std: 3.38
          Mean value_function loss: 25.3551
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 44.8506
                       Mean reward: 769.62
               Mean episode length: 243.52
    Episode_Reward/reaching_object: 0.7445
    Episode_Reward/rotating_object: 156.8994
        Episode_Reward/action_rate: -0.0533
          Episode_Reward/joint_vel: -0.0049
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 143130624
                    Iteration time: 1.75s
                      Time elapsed: 00:46:36
                               ETA: 00:01:26

################################################################################
                     [1m Learning iteration 1456/1500 [0m                     

                       Computation: 57873 steps/s (collection: 1.603s, learning 0.096s)
             Mean action noise std: 3.38
          Mean value_function loss: 19.6648
               Mean surrogate loss: -0.0005
                 Mean entropy loss: 44.8659
                       Mean reward: 783.26
               Mean episode length: 245.69
    Episode_Reward/reaching_object: 0.7429
    Episode_Reward/rotating_object: 156.8225
        Episode_Reward/action_rate: -0.0533
          Episode_Reward/joint_vel: -0.0046
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 143228928
                    Iteration time: 1.70s
                      Time elapsed: 00:46:37
                               ETA: 00:01:24

################################################################################
                     [1m Learning iteration 1457/1500 [0m                     

                       Computation: 55472 steps/s (collection: 1.678s, learning 0.095s)
             Mean action noise std: 3.38
          Mean value_function loss: 22.6000
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 44.8764
                       Mean reward: 791.34
               Mean episode length: 247.75
    Episode_Reward/reaching_object: 0.7480
    Episode_Reward/rotating_object: 158.7884
        Episode_Reward/action_rate: -0.0533
          Episode_Reward/joint_vel: -0.0044
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 143327232
                    Iteration time: 1.77s
                      Time elapsed: 00:46:39
                               ETA: 00:01:22

################################################################################
                     [1m Learning iteration 1458/1500 [0m                     

                       Computation: 57080 steps/s (collection: 1.631s, learning 0.091s)
             Mean action noise std: 3.38
          Mean value_function loss: 17.2834
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 44.8930
                       Mean reward: 808.24
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7523
    Episode_Reward/rotating_object: 160.4391
        Episode_Reward/action_rate: -0.0538
          Episode_Reward/joint_vel: -0.0046
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 143425536
                    Iteration time: 1.72s
                      Time elapsed: 00:46:41
                               ETA: 00:01:20

################################################################################
                     [1m Learning iteration 1459/1500 [0m                     

                       Computation: 55301 steps/s (collection: 1.677s, learning 0.101s)
             Mean action noise std: 3.39
          Mean value_function loss: 30.3068
               Mean surrogate loss: 0.0003
                 Mean entropy loss: 44.9143
                       Mean reward: 807.43
               Mean episode length: 245.68
    Episode_Reward/reaching_object: 0.7356
    Episode_Reward/rotating_object: 156.2227
        Episode_Reward/action_rate: -0.0529
          Episode_Reward/joint_vel: -0.0047
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 143523840
                    Iteration time: 1.78s
                      Time elapsed: 00:46:43
                               ETA: 00:01:18

################################################################################
                     [1m Learning iteration 1460/1500 [0m                     

                       Computation: 58353 steps/s (collection: 1.586s, learning 0.099s)
             Mean action noise std: 3.39
          Mean value_function loss: 24.4856
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 44.9210
                       Mean reward: 788.89
               Mean episode length: 245.39
    Episode_Reward/reaching_object: 0.7446
    Episode_Reward/rotating_object: 157.2793
        Episode_Reward/action_rate: -0.0537
          Episode_Reward/joint_vel: -0.0051
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 143622144
                    Iteration time: 1.68s
                      Time elapsed: 00:46:44
                               ETA: 00:01:16

################################################################################
                     [1m Learning iteration 1461/1500 [0m                     

                       Computation: 57043 steps/s (collection: 1.633s, learning 0.091s)
             Mean action noise std: 3.39
          Mean value_function loss: 20.4708
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 44.9282
                       Mean reward: 778.74
               Mean episode length: 245.77
    Episode_Reward/reaching_object: 0.7536
    Episode_Reward/rotating_object: 159.8917
        Episode_Reward/action_rate: -0.0539
          Episode_Reward/joint_vel: -0.0045
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 143720448
                    Iteration time: 1.72s
                      Time elapsed: 00:46:46
                               ETA: 00:01:14

################################################################################
                     [1m Learning iteration 1462/1500 [0m                     

                       Computation: 58995 steps/s (collection: 1.579s, learning 0.088s)
             Mean action noise std: 3.39
          Mean value_function loss: 16.7272
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 44.9346
                       Mean reward: 788.98
               Mean episode length: 243.69
    Episode_Reward/reaching_object: 0.7467
    Episode_Reward/rotating_object: 157.3451
        Episode_Reward/action_rate: -0.0536
          Episode_Reward/joint_vel: -0.0045
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 143818752
                    Iteration time: 1.67s
                      Time elapsed: 00:46:48
                               ETA: 00:01:12

################################################################################
                     [1m Learning iteration 1463/1500 [0m                     

                       Computation: 52870 steps/s (collection: 1.694s, learning 0.166s)
             Mean action noise std: 3.39
          Mean value_function loss: 17.4401
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 44.9404
                       Mean reward: 817.36
               Mean episode length: 247.85
    Episode_Reward/reaching_object: 0.7649
    Episode_Reward/rotating_object: 161.8502
        Episode_Reward/action_rate: -0.0545
          Episode_Reward/joint_vel: -0.0047
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 143917056
                    Iteration time: 1.86s
                      Time elapsed: 00:46:50
                               ETA: 00:01:11

################################################################################
                     [1m Learning iteration 1464/1500 [0m                     

                       Computation: 55146 steps/s (collection: 1.673s, learning 0.110s)
             Mean action noise std: 3.39
          Mean value_function loss: 24.5622
               Mean surrogate loss: -0.0009
                 Mean entropy loss: 44.9500
                       Mean reward: 812.69
               Mean episode length: 248.37
    Episode_Reward/reaching_object: 0.7603
    Episode_Reward/rotating_object: 160.0036
        Episode_Reward/action_rate: -0.0541
          Episode_Reward/joint_vel: -0.0046
      Episode_Termination/time_out: 17.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 144015360
                    Iteration time: 1.78s
                      Time elapsed: 00:46:51
                               ETA: 00:01:09

################################################################################
                     [1m Learning iteration 1465/1500 [0m                     

                       Computation: 55620 steps/s (collection: 1.665s, learning 0.102s)
             Mean action noise std: 3.39
          Mean value_function loss: 27.0144
               Mean surrogate loss: -0.0002
                 Mean entropy loss: 44.9574
                       Mean reward: 782.42
               Mean episode length: 245.16
    Episode_Reward/reaching_object: 0.7558
    Episode_Reward/rotating_object: 158.4482
        Episode_Reward/action_rate: -0.0538
          Episode_Reward/joint_vel: -0.0048
      Episode_Termination/time_out: 17.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 144113664
                    Iteration time: 1.77s
                      Time elapsed: 00:46:53
                               ETA: 00:01:07

################################################################################
                     [1m Learning iteration 1466/1500 [0m                     

                       Computation: 54410 steps/s (collection: 1.689s, learning 0.118s)
             Mean action noise std: 3.40
          Mean value_function loss: 22.7192
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 44.9651
                       Mean reward: 782.18
               Mean episode length: 243.88
    Episode_Reward/reaching_object: 0.7516
    Episode_Reward/rotating_object: 157.0054
        Episode_Reward/action_rate: -0.0537
          Episode_Reward/joint_vel: -0.0048
      Episode_Termination/time_out: 13.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 144211968
                    Iteration time: 1.81s
                      Time elapsed: 00:46:55
                               ETA: 00:01:05

################################################################################
                     [1m Learning iteration 1467/1500 [0m                     

                       Computation: 54383 steps/s (collection: 1.667s, learning 0.141s)
             Mean action noise std: 3.40
          Mean value_function loss: 19.6071
               Mean surrogate loss: -0.0003
                 Mean entropy loss: 44.9729
                       Mean reward: 777.63
               Mean episode length: 245.16
    Episode_Reward/reaching_object: 0.7565
    Episode_Reward/rotating_object: 157.3210
        Episode_Reward/action_rate: -0.0543
          Episode_Reward/joint_vel: -0.0052
      Episode_Termination/time_out: 18.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 144310272
                    Iteration time: 1.81s
                      Time elapsed: 00:46:57
                               ETA: 00:01:03

################################################################################
                     [1m Learning iteration 1468/1500 [0m                     

                       Computation: 54400 steps/s (collection: 1.670s, learning 0.137s)
             Mean action noise std: 3.40
          Mean value_function loss: 25.3152
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 44.9823
                       Mean reward: 790.98
               Mean episode length: 245.41
    Episode_Reward/reaching_object: 0.7559
    Episode_Reward/rotating_object: 157.8567
        Episode_Reward/action_rate: -0.0542
          Episode_Reward/joint_vel: -0.0046
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 144408576
                    Iteration time: 1.81s
                      Time elapsed: 00:46:59
                               ETA: 00:01:01

################################################################################
                     [1m Learning iteration 1469/1500 [0m                     

                       Computation: 54883 steps/s (collection: 1.690s, learning 0.101s)
             Mean action noise std: 3.40
          Mean value_function loss: 18.7178
               Mean surrogate loss: 0.0003
                 Mean entropy loss: 44.9950
                       Mean reward: 787.86
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7502
    Episode_Reward/rotating_object: 154.2545
        Episode_Reward/action_rate: -0.0543
          Episode_Reward/joint_vel: -0.0052
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 144506880
                    Iteration time: 1.79s
                      Time elapsed: 00:47:00
                               ETA: 00:00:59

################################################################################
                     [1m Learning iteration 1470/1500 [0m                     

                       Computation: 56084 steps/s (collection: 1.664s, learning 0.089s)
             Mean action noise std: 3.40
          Mean value_function loss: 16.9191
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 45.0013
                       Mean reward: 800.00
               Mean episode length: 248.19
    Episode_Reward/reaching_object: 0.7624
    Episode_Reward/rotating_object: 159.2622
        Episode_Reward/action_rate: -0.0547
          Episode_Reward/joint_vel: -0.0050
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 144605184
                    Iteration time: 1.75s
                      Time elapsed: 00:47:02
                               ETA: 00:00:57

################################################################################
                     [1m Learning iteration 1471/1500 [0m                     

                       Computation: 55536 steps/s (collection: 1.655s, learning 0.116s)
             Mean action noise std: 3.41
          Mean value_function loss: 20.9255
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 45.0085
                       Mean reward: 786.22
               Mean episode length: 247.96
    Episode_Reward/reaching_object: 0.7557
    Episode_Reward/rotating_object: 158.3629
        Episode_Reward/action_rate: -0.0544
          Episode_Reward/joint_vel: -0.0049
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 144703488
                    Iteration time: 1.77s
                      Time elapsed: 00:47:04
                               ETA: 00:00:55

################################################################################
                     [1m Learning iteration 1472/1500 [0m                     

                       Computation: 55500 steps/s (collection: 1.649s, learning 0.122s)
             Mean action noise std: 3.41
          Mean value_function loss: 17.7946
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 45.0248
                       Mean reward: 791.70
               Mean episode length: 247.74
    Episode_Reward/reaching_object: 0.7547
    Episode_Reward/rotating_object: 157.6462
        Episode_Reward/action_rate: -0.0546
          Episode_Reward/joint_vel: -0.0050
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 144801792
                    Iteration time: 1.77s
                      Time elapsed: 00:47:06
                               ETA: 00:00:53

################################################################################
                     [1m Learning iteration 1473/1500 [0m                     

                       Computation: 56221 steps/s (collection: 1.640s, learning 0.109s)
             Mean action noise std: 3.41
          Mean value_function loss: 19.7345
               Mean surrogate loss: 0.0052
                 Mean entropy loss: 45.0350
                       Mean reward: 780.63
               Mean episode length: 246.64
    Episode_Reward/reaching_object: 0.7501
    Episode_Reward/rotating_object: 157.0366
        Episode_Reward/action_rate: -0.0547
          Episode_Reward/joint_vel: -0.0052
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 144900096
                    Iteration time: 1.75s
                      Time elapsed: 00:47:07
                               ETA: 00:00:51

################################################################################
                     [1m Learning iteration 1474/1500 [0m                     

                       Computation: 54990 steps/s (collection: 1.673s, learning 0.115s)
             Mean action noise std: 3.41
          Mean value_function loss: 19.7261
               Mean surrogate loss: -0.0019
                 Mean entropy loss: 45.0374
                       Mean reward: 807.84
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7510
    Episode_Reward/rotating_object: 156.9748
        Episode_Reward/action_rate: -0.0548
          Episode_Reward/joint_vel: -0.0049
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0833
--------------------------------------------------------------------------------
                   Total timesteps: 144998400
                    Iteration time: 1.79s
                      Time elapsed: 00:47:09
                               ETA: 00:00:49

################################################################################
                     [1m Learning iteration 1475/1500 [0m                     

                       Computation: 57166 steps/s (collection: 1.616s, learning 0.104s)
             Mean action noise std: 3.41
          Mean value_function loss: 23.0787
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 45.0473
                       Mean reward: 791.58
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7567
    Episode_Reward/rotating_object: 160.3598
        Episode_Reward/action_rate: -0.0549
          Episode_Reward/joint_vel: -0.0047
      Episode_Termination/time_out: 17.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 145096704
                    Iteration time: 1.72s
                      Time elapsed: 00:47:11
                               ETA: 00:00:47

################################################################################
                     [1m Learning iteration 1476/1500 [0m                     

                       Computation: 57366 steps/s (collection: 1.586s, learning 0.128s)
             Mean action noise std: 3.42
          Mean value_function loss: 20.7157
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 45.0602
                       Mean reward: 784.93
               Mean episode length: 243.54
    Episode_Reward/reaching_object: 0.7482
    Episode_Reward/rotating_object: 157.7140
        Episode_Reward/action_rate: -0.0548
          Episode_Reward/joint_vel: -0.0050
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 145195008
                    Iteration time: 1.71s
                      Time elapsed: 00:47:13
                               ETA: 00:00:46

################################################################################
                     [1m Learning iteration 1477/1500 [0m                     

                       Computation: 57494 steps/s (collection: 1.614s, learning 0.096s)
             Mean action noise std: 3.42
          Mean value_function loss: 21.4220
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 45.0753
                       Mean reward: 800.71
               Mean episode length: 245.82
    Episode_Reward/reaching_object: 0.7445
    Episode_Reward/rotating_object: 157.6625
        Episode_Reward/action_rate: -0.0547
          Episode_Reward/joint_vel: -0.0052
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 145293312
                    Iteration time: 1.71s
                      Time elapsed: 00:47:14
                               ETA: 00:00:44

################################################################################
                     [1m Learning iteration 1478/1500 [0m                     

                       Computation: 54092 steps/s (collection: 1.636s, learning 0.182s)
             Mean action noise std: 3.42
          Mean value_function loss: 16.9605
               Mean surrogate loss: -0.0003
                 Mean entropy loss: 45.0869
                       Mean reward: 782.20
               Mean episode length: 245.48
    Episode_Reward/reaching_object: 0.7409
    Episode_Reward/rotating_object: 157.7096
        Episode_Reward/action_rate: -0.0548
          Episode_Reward/joint_vel: -0.0045
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1250
--------------------------------------------------------------------------------
                   Total timesteps: 145391616
                    Iteration time: 1.82s
                      Time elapsed: 00:47:16
                               ETA: 00:00:42

################################################################################
                     [1m Learning iteration 1479/1500 [0m                     

                       Computation: 53927 steps/s (collection: 1.732s, learning 0.091s)
             Mean action noise std: 3.42
          Mean value_function loss: 16.9579
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 45.0901
                       Mean reward: 800.10
               Mean episode length: 245.90
    Episode_Reward/reaching_object: 0.7430
    Episode_Reward/rotating_object: 158.8196
        Episode_Reward/action_rate: -0.0550
          Episode_Reward/joint_vel: -0.0054
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 145489920
                    Iteration time: 1.82s
                      Time elapsed: 00:47:18
                               ETA: 00:00:40

################################################################################
                     [1m Learning iteration 1480/1500 [0m                     

                       Computation: 54040 steps/s (collection: 1.683s, learning 0.136s)
             Mean action noise std: 3.42
          Mean value_function loss: 21.4761
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 45.0962
                       Mean reward: 802.83
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7411
    Episode_Reward/rotating_object: 158.8802
        Episode_Reward/action_rate: -0.0550
          Episode_Reward/joint_vel: -0.0051
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 145588224
                    Iteration time: 1.82s
                      Time elapsed: 00:47:20
                               ETA: 00:00:38

################################################################################
                     [1m Learning iteration 1481/1500 [0m                     

                       Computation: 56640 steps/s (collection: 1.616s, learning 0.119s)
             Mean action noise std: 3.43
          Mean value_function loss: 11.6717
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 45.1042
                       Mean reward: 787.52
               Mean episode length: 248.72
    Episode_Reward/reaching_object: 0.7414
    Episode_Reward/rotating_object: 158.7063
        Episode_Reward/action_rate: -0.0552
          Episode_Reward/joint_vel: -0.0049
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 145686528
                    Iteration time: 1.74s
                      Time elapsed: 00:47:21
                               ETA: 00:00:36

################################################################################
                     [1m Learning iteration 1482/1500 [0m                     

                       Computation: 56796 steps/s (collection: 1.620s, learning 0.111s)
             Mean action noise std: 3.43
          Mean value_function loss: 20.4397
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 45.1118
                       Mean reward: 808.09
               Mean episode length: 248.60
    Episode_Reward/reaching_object: 0.7433
    Episode_Reward/rotating_object: 160.7408
        Episode_Reward/action_rate: -0.0552
          Episode_Reward/joint_vel: -0.0048
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 145784832
                    Iteration time: 1.73s
                      Time elapsed: 00:47:23
                               ETA: 00:00:34

################################################################################
                     [1m Learning iteration 1483/1500 [0m                     

                       Computation: 54323 steps/s (collection: 1.691s, learning 0.119s)
             Mean action noise std: 3.43
          Mean value_function loss: 16.7814
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 45.1189
                       Mean reward: 791.40
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7352
    Episode_Reward/rotating_object: 156.3303
        Episode_Reward/action_rate: -0.0554
          Episode_Reward/joint_vel: -0.0058
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 145883136
                    Iteration time: 1.81s
                      Time elapsed: 00:47:25
                               ETA: 00:00:32

################################################################################
                     [1m Learning iteration 1484/1500 [0m                     

                       Computation: 56160 steps/s (collection: 1.653s, learning 0.097s)
             Mean action noise std: 3.43
          Mean value_function loss: 19.1064
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 45.1258
                       Mean reward: 807.85
               Mean episode length: 248.15
    Episode_Reward/reaching_object: 0.7341
    Episode_Reward/rotating_object: 157.8720
        Episode_Reward/action_rate: -0.0551
          Episode_Reward/joint_vel: -0.0048
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 145981440
                    Iteration time: 1.75s
                      Time elapsed: 00:47:27
                               ETA: 00:00:30

################################################################################
                     [1m Learning iteration 1485/1500 [0m                     

                       Computation: 56503 steps/s (collection: 1.597s, learning 0.143s)
             Mean action noise std: 3.43
          Mean value_function loss: 23.9580
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 45.1322
                       Mean reward: 806.71
               Mean episode length: 247.93
    Episode_Reward/reaching_object: 0.7342
    Episode_Reward/rotating_object: 158.1145
        Episode_Reward/action_rate: -0.0553
          Episode_Reward/joint_vel: -0.0048
      Episode_Termination/time_out: 17.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 146079744
                    Iteration time: 1.74s
                      Time elapsed: 00:47:28
                               ETA: 00:00:28

################################################################################
                     [1m Learning iteration 1486/1500 [0m                     

                       Computation: 50168 steps/s (collection: 1.811s, learning 0.148s)
             Mean action noise std: 3.43
          Mean value_function loss: 13.9773
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 45.1439
                       Mean reward: 770.55
               Mean episode length: 246.52
    Episode_Reward/reaching_object: 0.7317
    Episode_Reward/rotating_object: 157.1212
        Episode_Reward/action_rate: -0.0551
          Episode_Reward/joint_vel: -0.0050
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 146178048
                    Iteration time: 1.96s
                      Time elapsed: 00:47:30
                               ETA: 00:00:26

################################################################################
                     [1m Learning iteration 1487/1500 [0m                     

                       Computation: 53064 steps/s (collection: 1.743s, learning 0.110s)
             Mean action noise std: 3.44
          Mean value_function loss: 17.5750
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 45.1535
                       Mean reward: 804.59
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7310
    Episode_Reward/rotating_object: 158.0817
        Episode_Reward/action_rate: -0.0552
          Episode_Reward/joint_vel: -0.0046
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 146276352
                    Iteration time: 1.85s
                      Time elapsed: 00:47:32
                               ETA: 00:00:24

################################################################################
                     [1m Learning iteration 1488/1500 [0m                     

                       Computation: 56017 steps/s (collection: 1.640s, learning 0.115s)
             Mean action noise std: 3.44
          Mean value_function loss: 17.4566
               Mean surrogate loss: -0.0004
                 Mean entropy loss: 45.1629
                       Mean reward: 786.12
               Mean episode length: 245.66
    Episode_Reward/reaching_object: 0.7339
    Episode_Reward/rotating_object: 159.7519
        Episode_Reward/action_rate: -0.0552
          Episode_Reward/joint_vel: -0.0045
      Episode_Termination/time_out: 17.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 146374656
                    Iteration time: 1.75s
                      Time elapsed: 00:47:34
                               ETA: 00:00:23

################################################################################
                     [1m Learning iteration 1489/1500 [0m                     

                       Computation: 54394 steps/s (collection: 1.678s, learning 0.129s)
             Mean action noise std: 3.44
          Mean value_function loss: 31.5957
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 45.1712
                       Mean reward: 770.32
               Mean episode length: 245.55
    Episode_Reward/reaching_object: 0.7177
    Episode_Reward/rotating_object: 154.0495
        Episode_Reward/action_rate: -0.0549
          Episode_Reward/joint_vel: -0.0051
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 146472960
                    Iteration time: 1.81s
                      Time elapsed: 00:47:36
                               ETA: 00:00:21

################################################################################
                     [1m Learning iteration 1490/1500 [0m                     

                       Computation: 55818 steps/s (collection: 1.644s, learning 0.117s)
             Mean action noise std: 3.44
          Mean value_function loss: 16.9979
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 45.1828
                       Mean reward: 770.63
               Mean episode length: 242.38
    Episode_Reward/reaching_object: 0.7300
    Episode_Reward/rotating_object: 157.9528
        Episode_Reward/action_rate: -0.0551
          Episode_Reward/joint_vel: -0.0049
      Episode_Termination/time_out: 17.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4583
--------------------------------------------------------------------------------
                   Total timesteps: 146571264
                    Iteration time: 1.76s
                      Time elapsed: 00:47:38
                               ETA: 00:00:19

################################################################################
                     [1m Learning iteration 1491/1500 [0m                     

                       Computation: 56189 steps/s (collection: 1.656s, learning 0.094s)
             Mean action noise std: 3.44
          Mean value_function loss: 20.0429
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 45.1929
                       Mean reward: 789.30
               Mean episode length: 245.52
    Episode_Reward/reaching_object: 0.7297
    Episode_Reward/rotating_object: 158.6699
        Episode_Reward/action_rate: -0.0554
          Episode_Reward/joint_vel: -0.0046
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2500
--------------------------------------------------------------------------------
                   Total timesteps: 146669568
                    Iteration time: 1.75s
                      Time elapsed: 00:47:39
                               ETA: 00:00:17

################################################################################
                     [1m Learning iteration 1492/1500 [0m                     

                       Computation: 56714 steps/s (collection: 1.634s, learning 0.100s)
             Mean action noise std: 3.44
          Mean value_function loss: 22.5847
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 45.2031
                       Mean reward: 759.69
               Mean episode length: 243.30
    Episode_Reward/reaching_object: 0.7227
    Episode_Reward/rotating_object: 155.2673
        Episode_Reward/action_rate: -0.0554
          Episode_Reward/joint_vel: -0.0047
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 146767872
                    Iteration time: 1.73s
                      Time elapsed: 00:47:41
                               ETA: 00:00:15

################################################################################
                     [1m Learning iteration 1493/1500 [0m                     

                       Computation: 55261 steps/s (collection: 1.668s, learning 0.111s)
             Mean action noise std: 3.45
          Mean value_function loss: 18.6117
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 45.2083
                       Mean reward: 806.27
               Mean episode length: 249.48
    Episode_Reward/reaching_object: 0.7321
    Episode_Reward/rotating_object: 157.9965
        Episode_Reward/action_rate: -0.0560
          Episode_Reward/joint_vel: -0.0049
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.1667
--------------------------------------------------------------------------------
                   Total timesteps: 146866176
                    Iteration time: 1.78s
                      Time elapsed: 00:47:43
                               ETA: 00:00:13

################################################################################
                     [1m Learning iteration 1494/1500 [0m                     

                       Computation: 55605 steps/s (collection: 1.644s, learning 0.124s)
             Mean action noise std: 3.45
          Mean value_function loss: 22.0719
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 45.2140
                       Mean reward: 782.51
               Mean episode length: 243.76
    Episode_Reward/reaching_object: 0.7315
    Episode_Reward/rotating_object: 158.0038
        Episode_Reward/action_rate: -0.0557
          Episode_Reward/joint_vel: -0.0047
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 146964480
                    Iteration time: 1.77s
                      Time elapsed: 00:47:45
                               ETA: 00:00:11

################################################################################
                     [1m Learning iteration 1495/1500 [0m                     

                       Computation: 54205 steps/s (collection: 1.693s, learning 0.121s)
             Mean action noise std: 3.45
          Mean value_function loss: 22.8564
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 45.2208
                       Mean reward: 791.62
               Mean episode length: 246.01
    Episode_Reward/reaching_object: 0.7319
    Episode_Reward/rotating_object: 157.8293
        Episode_Reward/action_rate: -0.0555
          Episode_Reward/joint_vel: -0.0050
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3750
--------------------------------------------------------------------------------
                   Total timesteps: 147062784
                    Iteration time: 1.81s
                      Time elapsed: 00:47:46
                               ETA: 00:00:09

################################################################################
                     [1m Learning iteration 1496/1500 [0m                     

                       Computation: 55272 steps/s (collection: 1.639s, learning 0.140s)
             Mean action noise std: 3.45
          Mean value_function loss: 19.6513
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 45.2252
                       Mean reward: 808.92
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.7426
    Episode_Reward/rotating_object: 160.4325
        Episode_Reward/action_rate: -0.0563
          Episode_Reward/joint_vel: -0.0049
      Episode_Termination/time_out: 17.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2083
--------------------------------------------------------------------------------
                   Total timesteps: 147161088
                    Iteration time: 1.78s
                      Time elapsed: 00:47:48
                               ETA: 00:00:07

################################################################################
                     [1m Learning iteration 1497/1500 [0m                     

                       Computation: 56292 steps/s (collection: 1.627s, learning 0.119s)
             Mean action noise std: 3.45
          Mean value_function loss: 20.1460
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 45.2310
                       Mean reward: 807.83
               Mean episode length: 247.90
    Episode_Reward/reaching_object: 0.7370
    Episode_Reward/rotating_object: 158.6507
        Episode_Reward/action_rate: -0.0558
          Episode_Reward/joint_vel: -0.0047
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.2917
--------------------------------------------------------------------------------
                   Total timesteps: 147259392
                    Iteration time: 1.75s
                      Time elapsed: 00:47:50
                               ETA: 00:00:05

################################################################################
                     [1m Learning iteration 1498/1500 [0m                     

                       Computation: 56223 steps/s (collection: 1.595s, learning 0.153s)
             Mean action noise std: 3.45
          Mean value_function loss: 24.1866
               Mean surrogate loss: 0.0001
                 Mean entropy loss: 45.2400
                       Mean reward: 777.89
               Mean episode length: 244.61
    Episode_Reward/reaching_object: 0.7353
    Episode_Reward/rotating_object: 157.8572
        Episode_Reward/action_rate: -0.0558
          Episode_Reward/joint_vel: -0.0049
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.4167
--------------------------------------------------------------------------------
                   Total timesteps: 147357696
                    Iteration time: 1.75s
                      Time elapsed: 00:47:52
                               ETA: 00:00:03

################################################################################
                     [1m Learning iteration 1499/1500 [0m                     

                       Computation: 55839 steps/s (collection: 1.670s, learning 0.091s)
             Mean action noise std: 3.45
          Mean value_function loss: 24.5848
               Mean surrogate loss: -0.0004
                 Mean entropy loss: 45.2455
                       Mean reward: 791.92
               Mean episode length: 245.72
    Episode_Reward/reaching_object: 0.7307
    Episode_Reward/rotating_object: 155.9751
        Episode_Reward/action_rate: -0.0557
          Episode_Reward/joint_vel: -0.0047
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.3333
--------------------------------------------------------------------------------
                   Total timesteps: 147456000
                    Iteration time: 1.76s
                      Time elapsed: 00:47:54
                               ETA: 00:00:01

