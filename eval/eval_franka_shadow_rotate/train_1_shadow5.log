################################################################################
                      [1m Learning iteration 0/3000 [0m                       

                       Computation: 10973 steps/s (collection: 8.672s, learning 0.287s)
             Mean action noise std: 1.00
          Mean value_function loss: 0.0043
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 44.0491
                       Mean reward: 0.00
               Mean episode length: 21.93
    Episode_Reward/reaching_object: 0.0010
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0003
          Episode_Reward/joint_vel: -0.0004
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 98304
                    Iteration time: 8.96s
                      Time elapsed: 00:00:08
                               ETA: 07:27:54

################################################################################
                      [1m Learning iteration 1/3000 [0m                       

                       Computation: 15157 steps/s (collection: 6.320s, learning 0.165s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0004
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 44.2051
                       Mean reward: 0.00
               Mean episode length: 45.42
    Episode_Reward/reaching_object: 0.0028
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0009
          Episode_Reward/joint_vel: -0.0013
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 196608
                    Iteration time: 6.49s
                      Time elapsed: 00:00:15
                               ETA: 06:25:57

################################################################################
                      [1m Learning iteration 2/3000 [0m                       

                       Computation: 15157 steps/s (collection: 6.346s, learning 0.140s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0001
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 44.2476
                       Mean reward: 0.00
               Mean episode length: 69.07
    Episode_Reward/reaching_object: 0.0047
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0015
          Episode_Reward/joint_vel: -0.0022
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 294912
                    Iteration time: 6.49s
                      Time elapsed: 00:00:21
                               ETA: 06:05:14

################################################################################
                      [1m Learning iteration 3/3000 [0m                       

                       Computation: 15265 steps/s (collection: 6.304s, learning 0.136s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 44.3083
                       Mean reward: 0.01
               Mean episode length: 93.12
    Episode_Reward/reaching_object: 0.0062
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0021
          Episode_Reward/joint_vel: -0.0031
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 393216
                    Iteration time: 6.44s
                      Time elapsed: 00:00:28
                               ETA: 05:54:15

################################################################################
                      [1m Learning iteration 4/3000 [0m                       

                       Computation: 15041 steps/s (collection: 6.404s, learning 0.131s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 44.3061
                       Mean reward: 0.01
               Mean episode length: 117.84
    Episode_Reward/reaching_object: 0.0086
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0027
          Episode_Reward/joint_vel: -0.0040
      Episode_Termination/time_out: 17.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 491520
                    Iteration time: 6.54s
                      Time elapsed: 00:00:34
                               ETA: 05:48:34

################################################################################
                      [1m Learning iteration 5/3000 [0m                       

                       Computation: 15373 steps/s (collection: 6.239s, learning 0.155s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 44.2998
                       Mean reward: 0.01
               Mean episode length: 141.19
    Episode_Reward/reaching_object: 0.0101
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0033
          Episode_Reward/joint_vel: -0.0049
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 589824
                    Iteration time: 6.39s
                      Time elapsed: 00:00:41
                               ETA: 05:43:34

################################################################################
                      [1m Learning iteration 6/3000 [0m                       

                       Computation: 14645 steps/s (collection: 6.561s, learning 0.151s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0097
                 Mean entropy loss: 44.2686
                       Mean reward: 0.01
               Mean episode length: 165.18
    Episode_Reward/reaching_object: 0.0124
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0040
          Episode_Reward/joint_vel: -0.0058
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 688128
                    Iteration time: 6.71s
                      Time elapsed: 00:00:48
                               ETA: 05:42:14

################################################################################
                      [1m Learning iteration 7/3000 [0m                       

                       Computation: 15073 steps/s (collection: 6.325s, learning 0.197s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 44.2980
                       Mean reward: 0.02
               Mean episode length: 189.88
    Episode_Reward/reaching_object: 0.0149
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0046
          Episode_Reward/joint_vel: -0.0067
      Episode_Termination/time_out: 17.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 786432
                    Iteration time: 6.52s
                      Time elapsed: 00:00:54
                               ETA: 05:40:01

################################################################################
                      [1m Learning iteration 8/3000 [0m                       

                       Computation: 18964 steps/s (collection: 5.082s, learning 0.101s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0095
                 Mean entropy loss: 44.2970
                       Mean reward: 0.03
               Mean episode length: 213.51
    Episode_Reward/reaching_object: 0.0174
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0052
          Episode_Reward/joint_vel: -0.0076
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 884736
                    Iteration time: 5.18s
                      Time elapsed: 00:00:59
                               ETA: 05:30:52

################################################################################
                      [1m Learning iteration 9/3000 [0m                       

                       Computation: 58461 steps/s (collection: 1.565s, learning 0.116s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0101
                 Mean entropy loss: 44.3253
                       Mean reward: 0.02
               Mean episode length: 236.90
    Episode_Reward/reaching_object: 0.0196
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0058
          Episode_Reward/joint_vel: -0.0085
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 983040
                    Iteration time: 1.68s
                      Time elapsed: 00:01:01
                               ETA: 05:06:03

################################################################################
                      [1m Learning iteration 10/3000 [0m                      

                       Computation: 58418 steps/s (collection: 1.568s, learning 0.114s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0000
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 44.3761
                       Mean reward: 0.05
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0237
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0063
          Episode_Reward/joint_vel: -0.0092
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1081344
                    Iteration time: 1.68s
                      Time elapsed: 00:01:03
                               ETA: 04:45:46

################################################################################
                      [1m Learning iteration 11/3000 [0m                      

                       Computation: 59687 steps/s (collection: 1.553s, learning 0.094s)
             Mean action noise std: 1.01
          Mean value_function loss: 0.0001
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 44.4219
                       Mean reward: 0.08
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0306
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0063
          Episode_Reward/joint_vel: -0.0093
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1179648
                    Iteration time: 1.65s
                      Time elapsed: 00:01:04
                               ETA: 04:28:42

################################################################################
                      [1m Learning iteration 12/3000 [0m                      

                       Computation: 60665 steps/s (collection: 1.506s, learning 0.115s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0001
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 44.4535
                       Mean reward: 0.10
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0310
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0064
          Episode_Reward/joint_vel: -0.0093
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1277952
                    Iteration time: 1.62s
                      Time elapsed: 00:01:06
                               ETA: 04:14:09

################################################################################
                      [1m Learning iteration 13/3000 [0m                      

                       Computation: 59781 steps/s (collection: 1.525s, learning 0.119s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0002
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 44.5213
                       Mean reward: 0.15
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0390
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0064
          Episode_Reward/joint_vel: -0.0093
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1376256
                    Iteration time: 1.64s
                      Time elapsed: 00:01:07
                               ETA: 04:01:46

################################################################################
                      [1m Learning iteration 14/3000 [0m                      

                       Computation: 58780 steps/s (collection: 1.552s, learning 0.121s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0004
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 44.6095
                       Mean reward: 0.20
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0542
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0064
          Episode_Reward/joint_vel: -0.0093
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1474560
                    Iteration time: 1.67s
                      Time elapsed: 00:01:09
                               ETA: 03:51:07

################################################################################
                      [1m Learning iteration 15/3000 [0m                      

                       Computation: 60177 steps/s (collection: 1.515s, learning 0.119s)
             Mean action noise std: 1.02
          Mean value_function loss: 0.0006
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 44.6833
                       Mean reward: 0.34
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.0701
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0064
          Episode_Reward/joint_vel: -0.0093
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1572864
                    Iteration time: 1.63s
                      Time elapsed: 00:01:11
                               ETA: 03:41:41

################################################################################
                      [1m Learning iteration 16/3000 [0m                      

                       Computation: 58583 steps/s (collection: 1.569s, learning 0.109s)
             Mean action noise std: 1.03
          Mean value_function loss: 0.0012
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 44.7852
                       Mean reward: 0.39
               Mean episode length: 249.89
    Episode_Reward/reaching_object: 0.0880
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0064
          Episode_Reward/joint_vel: -0.0093
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0417
--------------------------------------------------------------------------------
                   Total timesteps: 1671168
                    Iteration time: 1.68s
                      Time elapsed: 00:01:12
                               ETA: 03:33:29

################################################################################
                      [1m Learning iteration 17/3000 [0m                      

                       Computation: 56279 steps/s (collection: 1.633s, learning 0.114s)
             Mean action noise std: 1.03
          Mean value_function loss: 0.0020
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 44.8553
                       Mean reward: 0.52
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.1221
    Episode_Reward/rotating_object: 0.0002
        Episode_Reward/action_rate: -0.0064
          Episode_Reward/joint_vel: -0.0093
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1769472
                    Iteration time: 1.75s
                      Time elapsed: 00:01:14
                               ETA: 03:26:23

################################################################################
                      [1m Learning iteration 18/3000 [0m                      

                       Computation: 54342 steps/s (collection: 1.693s, learning 0.116s)
             Mean action noise std: 1.03
          Mean value_function loss: 0.0052
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 44.9299
                       Mean reward: 0.85
               Mean episode length: 250.00
    Episode_Reward/reaching_object: 0.1613
    Episode_Reward/rotating_object: 0.0000
        Episode_Reward/action_rate: -0.0064
          Episode_Reward/joint_vel: -0.0093
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 1867776
                    Iteration time: 1.81s
                      Time elapsed: 00:01:16
                               ETA: 03:20:11

################################################################################
                      [1m Learning iteration 19/3000 [0m                      

                       Computation: 54478 steps/s (collection: 1.689s, learning 0.115s)
             Mean action noise std: 1.03
          Mean value_function loss: 0.0044
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 45.0261
                       Mean reward: 1.07
               Mean episode length: 248.99
    Episode_Reward/reaching_object: 0.2047
    Episode_Reward/rotating_object: 0.0012
        Episode_Reward/action_rate: -0.0065
          Episode_Reward/joint_vel: -0.0093
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.5833
--------------------------------------------------------------------------------
                   Total timesteps: 1966080
                    Iteration time: 1.80s
                      Time elapsed: 00:01:18
                               ETA: 03:14:35

################################################################################
                      [1m Learning iteration 20/3000 [0m                      

                       Computation: 53496 steps/s (collection: 1.746s, learning 0.092s)
             Mean action noise std: 1.03
          Mean value_function loss: 0.0128
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 45.0661
                       Mean reward: 1.23
               Mean episode length: 247.62
    Episode_Reward/reaching_object: 0.2462
    Episode_Reward/rotating_object: 0.0017
        Episode_Reward/action_rate: -0.0064
          Episode_Reward/joint_vel: -0.0093
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 2064384
                    Iteration time: 1.84s
                      Time elapsed: 00:01:20
                               ETA: 03:09:37

################################################################################
                      [1m Learning iteration 21/3000 [0m                      

                       Computation: 51987 steps/s (collection: 1.784s, learning 0.107s)
             Mean action noise std: 1.04
          Mean value_function loss: 0.0078
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 45.1171
                       Mean reward: 1.62
               Mean episode length: 244.28
    Episode_Reward/reaching_object: 0.3256
    Episode_Reward/rotating_object: 0.0046
        Episode_Reward/action_rate: -0.0064
          Episode_Reward/joint_vel: -0.0094
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 2162688
                    Iteration time: 1.89s
                      Time elapsed: 00:01:22
                               ETA: 03:05:12

################################################################################
                      [1m Learning iteration 22/3000 [0m                      

                       Computation: 49894 steps/s (collection: 1.851s, learning 0.119s)
             Mean action noise std: 1.04
          Mean value_function loss: 0.0085
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 45.1672
                       Mean reward: 1.91
               Mean episode length: 243.06
    Episode_Reward/reaching_object: 0.3618
    Episode_Reward/rotating_object: 0.0030
        Episode_Reward/action_rate: -0.0064
          Episode_Reward/joint_vel: -0.0094
      Episode_Termination/time_out: 12.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 2260992
                    Iteration time: 1.97s
                      Time elapsed: 00:01:24
                               ETA: 03:01:20

################################################################################
                      [1m Learning iteration 23/3000 [0m                      

                       Computation: 50851 steps/s (collection: 1.821s, learning 0.112s)
             Mean action noise std: 1.04
          Mean value_function loss: 0.0101
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 45.2841
                       Mean reward: 2.15
               Mean episode length: 236.17
    Episode_Reward/reaching_object: 0.4153
    Episode_Reward/rotating_object: 0.0087
        Episode_Reward/action_rate: -0.0063
          Episode_Reward/joint_vel: -0.0094
      Episode_Termination/time_out: 11.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 7.0417
--------------------------------------------------------------------------------
                   Total timesteps: 2359296
                    Iteration time: 1.93s
                      Time elapsed: 00:01:25
                               ETA: 02:57:43

################################################################################
                      [1m Learning iteration 24/3000 [0m                      

                       Computation: 51105 steps/s (collection: 1.813s, learning 0.111s)
             Mean action noise std: 1.05
          Mean value_function loss: 0.0123
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 45.4015
                       Mean reward: 2.28
               Mean episode length: 236.18
    Episode_Reward/reaching_object: 0.4521
    Episode_Reward/rotating_object: 0.0104
        Episode_Reward/action_rate: -0.0062
          Episode_Reward/joint_vel: -0.0093
      Episode_Termination/time_out: 11.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 9.6667
--------------------------------------------------------------------------------
                   Total timesteps: 2457600
                    Iteration time: 1.92s
                      Time elapsed: 00:01:27
                               ETA: 02:54:22

################################################################################
                      [1m Learning iteration 25/3000 [0m                      

                       Computation: 51187 steps/s (collection: 1.819s, learning 0.102s)
             Mean action noise std: 1.05
          Mean value_function loss: 0.0161
               Mean surrogate loss: -0.0096
                 Mean entropy loss: 45.4435
                       Mean reward: 2.33
               Mean episode length: 227.58
    Episode_Reward/reaching_object: 0.4587
    Episode_Reward/rotating_object: 0.0112
        Episode_Reward/action_rate: -0.0062
          Episode_Reward/joint_vel: -0.0093
      Episode_Termination/time_out: 8.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 10.0000
--------------------------------------------------------------------------------
                   Total timesteps: 2555904
                    Iteration time: 1.92s
                      Time elapsed: 00:01:29
                               ETA: 02:51:16

################################################################################
                      [1m Learning iteration 26/3000 [0m                      

                       Computation: 49503 steps/s (collection: 1.872s, learning 0.114s)
             Mean action noise std: 1.05
          Mean value_function loss: 0.0823
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 45.5355
                       Mean reward: 2.60
               Mean episode length: 225.33
    Episode_Reward/reaching_object: 0.4910
    Episode_Reward/rotating_object: 0.0282
        Episode_Reward/action_rate: -0.0061
          Episode_Reward/joint_vel: -0.0092
      Episode_Termination/time_out: 6.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 13.0417
--------------------------------------------------------------------------------
                   Total timesteps: 2654208
                    Iteration time: 1.99s
                      Time elapsed: 00:01:31
                               ETA: 02:48:31

################################################################################
                      [1m Learning iteration 27/3000 [0m                      

                       Computation: 50427 steps/s (collection: 1.850s, learning 0.100s)
             Mean action noise std: 1.06
          Mean value_function loss: 0.1097
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 45.5944
                       Mean reward: 2.87
               Mean episode length: 224.58
    Episode_Reward/reaching_object: 0.5372
    Episode_Reward/rotating_object: 0.0517
        Episode_Reward/action_rate: -0.0060
          Episode_Reward/joint_vel: -0.0092
      Episode_Termination/time_out: 5.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 16.2083
--------------------------------------------------------------------------------
                   Total timesteps: 2752512
                    Iteration time: 1.95s
                      Time elapsed: 00:01:33
                               ETA: 02:45:53

################################################################################
                      [1m Learning iteration 28/3000 [0m                      

                       Computation: 50615 steps/s (collection: 1.834s, learning 0.108s)
             Mean action noise std: 1.06
          Mean value_function loss: 0.0663
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 45.7133
                       Mean reward: 2.65
               Mean episode length: 211.55
    Episode_Reward/reaching_object: 0.5324
    Episode_Reward/rotating_object: 0.0520
        Episode_Reward/action_rate: -0.0059
          Episode_Reward/joint_vel: -0.0090
      Episode_Termination/time_out: 3.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 17.9167
--------------------------------------------------------------------------------
                   Total timesteps: 2850816
                    Iteration time: 1.94s
                      Time elapsed: 00:01:35
                               ETA: 02:43:26

################################################################################
                      [1m Learning iteration 29/3000 [0m                      

                       Computation: 47462 steps/s (collection: 1.933s, learning 0.138s)
             Mean action noise std: 1.07
          Mean value_function loss: 0.0368
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 45.9210
                       Mean reward: 3.23
               Mean episode length: 216.36
    Episode_Reward/reaching_object: 0.5494
    Episode_Reward/rotating_object: 0.0469
        Episode_Reward/action_rate: -0.0058
          Episode_Reward/joint_vel: -0.0090
      Episode_Termination/time_out: 2.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 16.9583
--------------------------------------------------------------------------------
                   Total timesteps: 2949120
                    Iteration time: 2.07s
                      Time elapsed: 00:01:37
                               ETA: 02:41:21

################################################################################
                      [1m Learning iteration 30/3000 [0m                      

                       Computation: 49726 steps/s (collection: 1.852s, learning 0.125s)
             Mean action noise std: 1.07
          Mean value_function loss: 0.2620
               Mean surrogate loss: 0.0000
                 Mean entropy loss: 46.0253
                       Mean reward: 2.85
               Mean episode length: 204.76
    Episode_Reward/reaching_object: 0.5658
    Episode_Reward/rotating_object: 0.0371
        Episode_Reward/action_rate: -0.0057
          Episode_Reward/joint_vel: -0.0090
      Episode_Termination/time_out: 2.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 18.7917
--------------------------------------------------------------------------------
                   Total timesteps: 3047424
                    Iteration time: 1.98s
                      Time elapsed: 00:01:39
                               ETA: 02:39:15

################################################################################
                      [1m Learning iteration 31/3000 [0m                      

                       Computation: 50172 steps/s (collection: 1.864s, learning 0.095s)
             Mean action noise std: 1.07
          Mean value_function loss: 0.1455
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 46.0794
                       Mean reward: 3.36
               Mean episode length: 207.85
    Episode_Reward/reaching_object: 0.6161
    Episode_Reward/rotating_object: 0.0715
        Episode_Reward/action_rate: -0.0058
          Episode_Reward/joint_vel: -0.0091
      Episode_Termination/time_out: 2.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 17.4583
--------------------------------------------------------------------------------
                   Total timesteps: 3145728
                    Iteration time: 1.96s
                      Time elapsed: 00:01:41
                               ETA: 02:37:15

################################################################################
                      [1m Learning iteration 32/3000 [0m                      

                       Computation: 50133 steps/s (collection: 1.858s, learning 0.103s)
             Mean action noise std: 1.08
          Mean value_function loss: 0.1456
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 46.2157
                       Mean reward: 3.49
               Mean episode length: 206.86
    Episode_Reward/reaching_object: 0.6271
    Episode_Reward/rotating_object: 0.1422
        Episode_Reward/action_rate: -0.0057
          Episode_Reward/joint_vel: -0.0091
      Episode_Termination/time_out: 1.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 14.8750
--------------------------------------------------------------------------------
                   Total timesteps: 3244032
                    Iteration time: 1.96s
                      Time elapsed: 00:01:43
                               ETA: 02:35:22

################################################################################
                      [1m Learning iteration 33/3000 [0m                      

                       Computation: 50115 steps/s (collection: 1.846s, learning 0.116s)
             Mean action noise std: 1.08
          Mean value_function loss: 0.3817
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 46.4318
                       Mean reward: 4.98
               Mean episode length: 209.23
    Episode_Reward/reaching_object: 0.6815
    Episode_Reward/rotating_object: 0.1305
        Episode_Reward/action_rate: -0.0059
          Episode_Reward/joint_vel: -0.0095
      Episode_Termination/time_out: 2.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 14.6667
--------------------------------------------------------------------------------
                   Total timesteps: 3342336
                    Iteration time: 1.96s
                      Time elapsed: 00:01:45
                               ETA: 02:33:36

################################################################################
                      [1m Learning iteration 34/3000 [0m                      

                       Computation: 49299 steps/s (collection: 1.864s, learning 0.130s)
             Mean action noise std: 1.09
          Mean value_function loss: 0.4538
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 46.5256
                       Mean reward: 5.15
               Mean episode length: 209.54
    Episode_Reward/reaching_object: 0.7040
    Episode_Reward/rotating_object: 0.1708
        Episode_Reward/action_rate: -0.0060
          Episode_Reward/joint_vel: -0.0097
      Episode_Termination/time_out: 3.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 14.2500
--------------------------------------------------------------------------------
                   Total timesteps: 3440640
                    Iteration time: 1.99s
                      Time elapsed: 00:01:47
                               ETA: 02:31:59

################################################################################
                      [1m Learning iteration 35/3000 [0m                      

                       Computation: 49609 steps/s (collection: 1.856s, learning 0.126s)
             Mean action noise std: 1.09
          Mean value_function loss: 0.3083
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 46.5909
                       Mean reward: 4.08
               Mean episode length: 213.60
    Episode_Reward/reaching_object: 0.7221
    Episode_Reward/rotating_object: 0.1204
        Episode_Reward/action_rate: -0.0061
          Episode_Reward/joint_vel: -0.0100
      Episode_Termination/time_out: 4.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 13.3333
--------------------------------------------------------------------------------
                   Total timesteps: 3538944
                    Iteration time: 1.98s
                      Time elapsed: 00:01:49
                               ETA: 02:30:26

################################################################################
                      [1m Learning iteration 36/3000 [0m                      

                       Computation: 49272 steps/s (collection: 1.877s, learning 0.118s)
             Mean action noise std: 1.10
          Mean value_function loss: 0.1669
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 46.7439
                       Mean reward: 6.42
               Mean episode length: 225.14
    Episode_Reward/reaching_object: 0.8197
    Episode_Reward/rotating_object: 0.3545
        Episode_Reward/action_rate: -0.0064
          Episode_Reward/joint_vel: -0.0107
      Episode_Termination/time_out: 5.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 10.5417
--------------------------------------------------------------------------------
                   Total timesteps: 3637248
                    Iteration time: 2.00s
                      Time elapsed: 00:01:51
                               ETA: 02:28:59

################################################################################
                      [1m Learning iteration 37/3000 [0m                      

                       Computation: 49181 steps/s (collection: 1.879s, learning 0.120s)
             Mean action noise std: 1.10
          Mean value_function loss: 0.4221
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 46.9592
                       Mean reward: 4.73
               Mean episode length: 225.52
    Episode_Reward/reaching_object: 0.8408
    Episode_Reward/rotating_object: 0.2000
        Episode_Reward/action_rate: -0.0066
          Episode_Reward/joint_vel: -0.0110
      Episode_Termination/time_out: 6.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 9.8750
--------------------------------------------------------------------------------
                   Total timesteps: 3735552
                    Iteration time: 2.00s
                      Time elapsed: 00:01:53
                               ETA: 02:27:36

################################################################################
                      [1m Learning iteration 38/3000 [0m                      

                       Computation: 49517 steps/s (collection: 1.865s, learning 0.120s)
             Mean action noise std: 1.11
          Mean value_function loss: 0.4365
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 47.0893
                       Mean reward: 5.29
               Mean episode length: 240.35
    Episode_Reward/reaching_object: 0.9006
    Episode_Reward/rotating_object: 0.1494
        Episode_Reward/action_rate: -0.0069
          Episode_Reward/joint_vel: -0.0115
      Episode_Termination/time_out: 8.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 7.0833
--------------------------------------------------------------------------------
                   Total timesteps: 3833856
                    Iteration time: 1.99s
                      Time elapsed: 00:01:55
                               ETA: 02:26:17

################################################################################
                      [1m Learning iteration 39/3000 [0m                      

                       Computation: 48458 steps/s (collection: 1.913s, learning 0.115s)
             Mean action noise std: 1.11
          Mean value_function loss: 0.7208
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 47.2936
                       Mean reward: 5.74
               Mean episode length: 232.30
    Episode_Reward/reaching_object: 0.8792
    Episode_Reward/rotating_object: 0.2517
        Episode_Reward/action_rate: -0.0069
          Episode_Reward/joint_vel: -0.0118
      Episode_Termination/time_out: 10.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 6.9167
--------------------------------------------------------------------------------
                   Total timesteps: 3932160
                    Iteration time: 2.03s
                      Time elapsed: 00:01:57
                               ETA: 02:25:05

################################################################################
                      [1m Learning iteration 40/3000 [0m                      

                       Computation: 48527 steps/s (collection: 1.889s, learning 0.137s)
             Mean action noise std: 1.12
          Mean value_function loss: 0.5664
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 47.4013
                       Mean reward: 6.08
               Mean episode length: 239.00
    Episode_Reward/reaching_object: 0.9204
    Episode_Reward/rotating_object: 0.6504
        Episode_Reward/action_rate: -0.0071
          Episode_Reward/joint_vel: -0.0118
      Episode_Termination/time_out: 12.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 6.4167
--------------------------------------------------------------------------------
                   Total timesteps: 4030464
                    Iteration time: 2.03s
                      Time elapsed: 00:01:59
                               ETA: 02:23:56

################################################################################
                      [1m Learning iteration 41/3000 [0m                      

                       Computation: 49407 steps/s (collection: 1.866s, learning 0.124s)
             Mean action noise std: 1.12
          Mean value_function loss: 0.5670
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 47.5322
                       Mean reward: 9.29
               Mean episode length: 243.11
    Episode_Reward/reaching_object: 0.9557
    Episode_Reward/rotating_object: 0.4744
        Episode_Reward/action_rate: -0.0073
          Episode_Reward/joint_vel: -0.0122
      Episode_Termination/time_out: 12.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.4583
--------------------------------------------------------------------------------
                   Total timesteps: 4128768
                    Iteration time: 1.99s
                      Time elapsed: 00:02:01
                               ETA: 02:22:48

################################################################################
                      [1m Learning iteration 42/3000 [0m                      

                       Computation: 49175 steps/s (collection: 1.876s, learning 0.123s)
             Mean action noise std: 1.13
          Mean value_function loss: 0.6903
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 47.6567
                       Mean reward: 7.94
               Mean episode length: 240.88
    Episode_Reward/reaching_object: 0.9637
    Episode_Reward/rotating_object: 0.4272
        Episode_Reward/action_rate: -0.0074
          Episode_Reward/joint_vel: -0.0124
      Episode_Termination/time_out: 12.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 4227072
                    Iteration time: 2.00s
                      Time elapsed: 00:02:03
                               ETA: 02:21:43

################################################################################
                      [1m Learning iteration 43/3000 [0m                      

                       Computation: 47855 steps/s (collection: 1.928s, learning 0.127s)
             Mean action noise std: 1.13
          Mean value_function loss: 0.3536
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 47.7598
                       Mean reward: 7.41
               Mean episode length: 238.61
    Episode_Reward/reaching_object: 0.9525
    Episode_Reward/rotating_object: 0.4686
        Episode_Reward/action_rate: -0.0074
          Episode_Reward/joint_vel: -0.0125
      Episode_Termination/time_out: 11.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.4167
--------------------------------------------------------------------------------
                   Total timesteps: 4325376
                    Iteration time: 2.05s
                      Time elapsed: 00:02:05
                               ETA: 02:20:45

################################################################################
                      [1m Learning iteration 44/3000 [0m                      

                       Computation: 49031 steps/s (collection: 1.879s, learning 0.126s)
             Mean action noise std: 1.14
          Mean value_function loss: 0.3692
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 47.9346
                       Mean reward: 6.79
               Mean episode length: 242.53
    Episode_Reward/reaching_object: 0.9559
    Episode_Reward/rotating_object: 0.5016
        Episode_Reward/action_rate: -0.0075
          Episode_Reward/joint_vel: -0.0129
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.6667
--------------------------------------------------------------------------------
                   Total timesteps: 4423680
                    Iteration time: 2.00s
                      Time elapsed: 00:02:07
                               ETA: 02:19:46

################################################################################
                      [1m Learning iteration 45/3000 [0m                      

                       Computation: 47694 steps/s (collection: 1.930s, learning 0.132s)
             Mean action noise std: 1.14
          Mean value_function loss: 0.3546
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 48.0672
                       Mean reward: 7.52
               Mean episode length: 245.13
    Episode_Reward/reaching_object: 0.9562
    Episode_Reward/rotating_object: 0.5061
        Episode_Reward/action_rate: -0.0076
          Episode_Reward/joint_vel: -0.0130
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 4521984
                    Iteration time: 2.06s
                      Time elapsed: 00:02:09
                               ETA: 02:18:54

################################################################################
                      [1m Learning iteration 46/3000 [0m                      

                       Computation: 47772 steps/s (collection: 1.925s, learning 0.132s)
             Mean action noise std: 1.15
          Mean value_function loss: 0.3414
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 48.2012
                       Mean reward: 7.25
               Mean episode length: 237.79
    Episode_Reward/reaching_object: 0.9586
    Episode_Reward/rotating_object: 0.4498
        Episode_Reward/action_rate: -0.0076
          Episode_Reward/joint_vel: -0.0130
      Episode_Termination/time_out: 12.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 4620288
                    Iteration time: 2.06s
                      Time elapsed: 00:02:11
                               ETA: 02:18:03

################################################################################
                      [1m Learning iteration 47/3000 [0m                      

                       Computation: 48230 steps/s (collection: 1.932s, learning 0.107s)
             Mean action noise std: 1.15
          Mean value_function loss: 0.5066
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 48.2999
                       Mean reward: 7.82
               Mean episode length: 243.17
    Episode_Reward/reaching_object: 0.9494
    Episode_Reward/rotating_object: 0.4576
        Episode_Reward/action_rate: -0.0078
          Episode_Reward/joint_vel: -0.0135
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 4718592
                    Iteration time: 2.04s
                      Time elapsed: 00:02:13
                               ETA: 02:17:13

################################################################################
                      [1m Learning iteration 48/3000 [0m                      

                       Computation: 48535 steps/s (collection: 1.912s, learning 0.114s)
             Mean action noise std: 1.16
          Mean value_function loss: 0.7362
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 48.4537
                       Mean reward: 7.01
               Mean episode length: 235.14
    Episode_Reward/reaching_object: 0.9594
    Episode_Reward/rotating_object: 0.5868
        Episode_Reward/action_rate: -0.0077
          Episode_Reward/joint_vel: -0.0135
      Episode_Termination/time_out: 12.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.3333
--------------------------------------------------------------------------------
                   Total timesteps: 4816896
                    Iteration time: 2.03s
                      Time elapsed: 00:02:15
                               ETA: 02:16:24

################################################################################
                      [1m Learning iteration 49/3000 [0m                      

                       Computation: 47341 steps/s (collection: 1.954s, learning 0.122s)
             Mean action noise std: 1.16
          Mean value_function loss: 0.7900
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 48.5755
                       Mean reward: 9.15
               Mean episode length: 241.80
    Episode_Reward/reaching_object: 0.9866
    Episode_Reward/rotating_object: 0.5724
        Episode_Reward/action_rate: -0.0078
          Episode_Reward/joint_vel: -0.0139
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.7917
--------------------------------------------------------------------------------
                   Total timesteps: 4915200
                    Iteration time: 2.08s
                      Time elapsed: 00:02:17
                               ETA: 02:15:40

################################################################################
                      [1m Learning iteration 50/3000 [0m                      

                       Computation: 48266 steps/s (collection: 1.924s, learning 0.113s)
             Mean action noise std: 1.17
          Mean value_function loss: 1.0620
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 48.7455
                       Mean reward: 6.54
               Mean episode length: 235.25
    Episode_Reward/reaching_object: 0.9678
    Episode_Reward/rotating_object: 0.4433
        Episode_Reward/action_rate: -0.0078
          Episode_Reward/joint_vel: -0.0142
      Episode_Termination/time_out: 13.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.1667
--------------------------------------------------------------------------------
                   Total timesteps: 5013504
                    Iteration time: 2.04s
                      Time elapsed: 00:02:19
                               ETA: 02:14:56

################################################################################
                      [1m Learning iteration 51/3000 [0m                      

                       Computation: 47862 steps/s (collection: 1.939s, learning 0.115s)
             Mean action noise std: 1.17
          Mean value_function loss: 1.4362
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 48.8185
                       Mean reward: 8.21
               Mean episode length: 234.92
    Episode_Reward/reaching_object: 1.0093
    Episode_Reward/rotating_object: 0.6323
        Episode_Reward/action_rate: -0.0079
          Episode_Reward/joint_vel: -0.0144
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.2083
--------------------------------------------------------------------------------
                   Total timesteps: 5111808
                    Iteration time: 2.05s
                      Time elapsed: 00:02:22
                               ETA: 02:14:14

################################################################################
                      [1m Learning iteration 52/3000 [0m                      

                       Computation: 48801 steps/s (collection: 1.903s, learning 0.112s)
             Mean action noise std: 1.17
          Mean value_function loss: 1.7504
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 48.9203
                       Mean reward: 7.88
               Mean episode length: 239.34
    Episode_Reward/reaching_object: 1.0187
    Episode_Reward/rotating_object: 1.0954
        Episode_Reward/action_rate: -0.0081
          Episode_Reward/joint_vel: -0.0150
      Episode_Termination/time_out: 12.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 5210112
                    Iteration time: 2.01s
                      Time elapsed: 00:02:24
                               ETA: 02:13:31

################################################################################
                      [1m Learning iteration 53/3000 [0m                      

                       Computation: 47942 steps/s (collection: 1.933s, learning 0.117s)
             Mean action noise std: 1.18
          Mean value_function loss: 1.8688
               Mean surrogate loss: -0.0011
                 Mean entropy loss: 48.9605
                       Mean reward: 11.52
               Mean episode length: 235.05
    Episode_Reward/reaching_object: 1.0534
    Episode_Reward/rotating_object: 0.9904
        Episode_Reward/action_rate: -0.0080
          Episode_Reward/joint_vel: -0.0150
      Episode_Termination/time_out: 12.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 5308416
                    Iteration time: 2.05s
                      Time elapsed: 00:02:26
                               ETA: 02:12:52

################################################################################
                      [1m Learning iteration 54/3000 [0m                      

                       Computation: 47751 steps/s (collection: 1.946s, learning 0.113s)
             Mean action noise std: 1.18
          Mean value_function loss: 1.3255
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 49.0657
                       Mean reward: 9.19
               Mean episode length: 240.17
    Episode_Reward/reaching_object: 1.0832
    Episode_Reward/rotating_object: 1.1372
        Episode_Reward/action_rate: -0.0082
          Episode_Reward/joint_vel: -0.0153
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 5406720
                    Iteration time: 2.06s
                      Time elapsed: 00:02:28
                               ETA: 02:12:15

################################################################################
                      [1m Learning iteration 55/3000 [0m                      

                       Computation: 48249 steps/s (collection: 1.917s, learning 0.120s)
             Mean action noise std: 1.19
          Mean value_function loss: 1.0940
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 49.2316
                       Mean reward: 11.34
               Mean episode length: 242.09
    Episode_Reward/reaching_object: 1.0981
    Episode_Reward/rotating_object: 1.1202
        Episode_Reward/action_rate: -0.0084
          Episode_Reward/joint_vel: -0.0157
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 5505024
                    Iteration time: 2.04s
                      Time elapsed: 00:02:30
                               ETA: 02:11:38

################################################################################
                      [1m Learning iteration 56/3000 [0m                      

                       Computation: 48525 steps/s (collection: 1.908s, learning 0.118s)
             Mean action noise std: 1.19
          Mean value_function loss: 2.0506
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 49.3243
                       Mean reward: 9.29
               Mean episode length: 246.54
    Episode_Reward/reaching_object: 1.1106
    Episode_Reward/rotating_object: 1.2264
        Episode_Reward/action_rate: -0.0086
          Episode_Reward/joint_vel: -0.0167
      Episode_Termination/time_out: 13.4167
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 5603328
                    Iteration time: 2.03s
                      Time elapsed: 00:02:32
                               ETA: 02:11:01

################################################################################
                      [1m Learning iteration 57/3000 [0m                      

                       Computation: 48194 steps/s (collection: 1.928s, learning 0.112s)
             Mean action noise std: 1.19
          Mean value_function loss: 1.9548
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 49.3892
                       Mean reward: 10.06
               Mean episode length: 240.09
    Episode_Reward/reaching_object: 1.1316
    Episode_Reward/rotating_object: 0.7985
        Episode_Reward/action_rate: -0.0085
          Episode_Reward/joint_vel: -0.0164
      Episode_Termination/time_out: 13.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 5701632
                    Iteration time: 2.04s
                      Time elapsed: 00:02:34
                               ETA: 02:10:26

################################################################################
                      [1m Learning iteration 58/3000 [0m                      

                       Computation: 47965 steps/s (collection: 1.930s, learning 0.119s)
             Mean action noise std: 1.19
          Mean value_function loss: 2.2969
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 49.4474
                       Mean reward: 10.69
               Mean episode length: 240.17
    Episode_Reward/reaching_object: 1.1622
    Episode_Reward/rotating_object: 1.0128
        Episode_Reward/action_rate: -0.0086
          Episode_Reward/joint_vel: -0.0165
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 5799936
                    Iteration time: 2.05s
                      Time elapsed: 00:02:36
                               ETA: 02:09:53

################################################################################
                      [1m Learning iteration 59/3000 [0m                      

                       Computation: 48429 steps/s (collection: 1.919s, learning 0.111s)
             Mean action noise std: 1.20
          Mean value_function loss: 2.4407
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 49.5123
                       Mean reward: 17.54
               Mean episode length: 243.90
    Episode_Reward/reaching_object: 1.1787
    Episode_Reward/rotating_object: 1.4913
        Episode_Reward/action_rate: -0.0087
          Episode_Reward/joint_vel: -0.0168
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 5898240
                    Iteration time: 2.03s
                      Time elapsed: 00:02:38
                               ETA: 02:09:20

################################################################################
                      [1m Learning iteration 60/3000 [0m                      

                       Computation: 48121 steps/s (collection: 1.928s, learning 0.115s)
             Mean action noise std: 1.20
          Mean value_function loss: 1.9080
               Mean surrogate loss: -0.0033
                 Mean entropy loss: 49.6079
                       Mean reward: 11.01
               Mean episode length: 239.47
    Episode_Reward/reaching_object: 1.1464
    Episode_Reward/rotating_object: 1.6430
        Episode_Reward/action_rate: -0.0087
          Episode_Reward/joint_vel: -0.0170
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 5996544
                    Iteration time: 2.04s
                      Time elapsed: 00:02:40
                               ETA: 02:08:49

################################################################################
                      [1m Learning iteration 61/3000 [0m                      

                       Computation: 47618 steps/s (collection: 1.945s, learning 0.119s)
             Mean action noise std: 1.21
          Mean value_function loss: 2.0997
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 49.7211
                       Mean reward: 10.24
               Mean episode length: 245.58
    Episode_Reward/reaching_object: 1.1587
    Episode_Reward/rotating_object: 1.3641
        Episode_Reward/action_rate: -0.0089
          Episode_Reward/joint_vel: -0.0174
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 6094848
                    Iteration time: 2.06s
                      Time elapsed: 00:02:42
                               ETA: 02:08:20

################################################################################
                      [1m Learning iteration 62/3000 [0m                      

                       Computation: 48338 steps/s (collection: 1.920s, learning 0.114s)
             Mean action noise std: 1.21
          Mean value_function loss: 1.8986
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 49.8463
                       Mean reward: 16.30
               Mean episode length: 244.56
    Episode_Reward/reaching_object: 1.1892
    Episode_Reward/rotating_object: 1.6826
        Episode_Reward/action_rate: -0.0089
          Episode_Reward/joint_vel: -0.0174
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 6193152
                    Iteration time: 2.03s
                      Time elapsed: 00:02:44
                               ETA: 02:07:50

################################################################################
                      [1m Learning iteration 63/3000 [0m                      

                       Computation: 48257 steps/s (collection: 1.916s, learning 0.121s)
             Mean action noise std: 1.21
          Mean value_function loss: 2.2731
               Mean surrogate loss: -0.0025
                 Mean entropy loss: 49.9400
                       Mean reward: 12.97
               Mean episode length: 244.09
    Episode_Reward/reaching_object: 1.2005
    Episode_Reward/rotating_object: 1.8322
        Episode_Reward/action_rate: -0.0090
          Episode_Reward/joint_vel: -0.0174
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 6291456
                    Iteration time: 2.04s
                      Time elapsed: 00:02:46
                               ETA: 02:07:21

################################################################################
                      [1m Learning iteration 64/3000 [0m                      

                       Computation: 48181 steps/s (collection: 1.923s, learning 0.117s)
             Mean action noise std: 1.22
          Mean value_function loss: 2.4850
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 50.0568
                       Mean reward: 12.67
               Mean episode length: 245.83
    Episode_Reward/reaching_object: 1.1978
    Episode_Reward/rotating_object: 1.1855
        Episode_Reward/action_rate: -0.0091
          Episode_Reward/joint_vel: -0.0178
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 6389760
                    Iteration time: 2.04s
                      Time elapsed: 00:02:48
                               ETA: 02:06:53

################################################################################
                      [1m Learning iteration 65/3000 [0m                      

                       Computation: 47511 steps/s (collection: 1.954s, learning 0.115s)
             Mean action noise std: 1.22
          Mean value_function loss: 2.2016
               Mean surrogate loss: -0.0004
                 Mean entropy loss: 50.1295
                       Mean reward: 12.41
               Mean episode length: 244.23
    Episode_Reward/reaching_object: 1.1641
    Episode_Reward/rotating_object: 1.4493
        Episode_Reward/action_rate: -0.0091
          Episode_Reward/joint_vel: -0.0180
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 6488064
                    Iteration time: 2.07s
                      Time elapsed: 00:02:50
                               ETA: 02:06:27

################################################################################
                      [1m Learning iteration 66/3000 [0m                      

                       Computation: 48172 steps/s (collection: 1.929s, learning 0.112s)
             Mean action noise std: 1.22
          Mean value_function loss: 2.1053
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 50.1936
                       Mean reward: 13.30
               Mean episode length: 242.08
    Episode_Reward/reaching_object: 1.1746
    Episode_Reward/rotating_object: 2.0401
        Episode_Reward/action_rate: -0.0092
          Episode_Reward/joint_vel: -0.0179
      Episode_Termination/time_out: 13.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 6586368
                    Iteration time: 2.04s
                      Time elapsed: 00:02:52
                               ETA: 02:06:00

################################################################################
                      [1m Learning iteration 67/3000 [0m                      

                       Computation: 48470 steps/s (collection: 1.915s, learning 0.113s)
             Mean action noise std: 1.23
          Mean value_function loss: 1.9156
               Mean surrogate loss: -0.0021
                 Mean entropy loss: 50.2966
                       Mean reward: 9.66
               Mean episode length: 243.09
    Episode_Reward/reaching_object: 1.1744
    Episode_Reward/rotating_object: 1.3922
        Episode_Reward/action_rate: -0.0093
          Episode_Reward/joint_vel: -0.0182
      Episode_Termination/time_out: 13.5417
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 6684672
                    Iteration time: 2.03s
                      Time elapsed: 00:02:54
                               ETA: 02:05:34

################################################################################
                      [1m Learning iteration 68/3000 [0m                      

                       Computation: 48346 steps/s (collection: 1.926s, learning 0.108s)
             Mean action noise std: 1.23
          Mean value_function loss: 1.8189
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 50.3852
                       Mean reward: 10.89
               Mean episode length: 245.24
    Episode_Reward/reaching_object: 1.1660
    Episode_Reward/rotating_object: 1.5268
        Episode_Reward/action_rate: -0.0094
          Episode_Reward/joint_vel: -0.0184
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 6782976
                    Iteration time: 2.03s
                      Time elapsed: 00:02:56
                               ETA: 02:05:09

################################################################################
                      [1m Learning iteration 69/3000 [0m                      

                       Computation: 47584 steps/s (collection: 1.947s, learning 0.119s)
             Mean action noise std: 1.23
          Mean value_function loss: 2.1901
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 50.4515
                       Mean reward: 14.43
               Mean episode length: 245.32
    Episode_Reward/reaching_object: 1.1686
    Episode_Reward/rotating_object: 1.3653
        Episode_Reward/action_rate: -0.0094
          Episode_Reward/joint_vel: -0.0184
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 6881280
                    Iteration time: 2.07s
                      Time elapsed: 00:02:58
                               ETA: 02:04:46

################################################################################
                      [1m Learning iteration 70/3000 [0m                      

                       Computation: 48040 steps/s (collection: 1.921s, learning 0.125s)
             Mean action noise std: 1.24
          Mean value_function loss: 2.5718
               Mean surrogate loss: 0.0058
                 Mean entropy loss: 50.5082
                       Mean reward: 10.44
               Mean episode length: 247.56
    Episode_Reward/reaching_object: 1.2126
    Episode_Reward/rotating_object: 1.6768
        Episode_Reward/action_rate: -0.0096
          Episode_Reward/joint_vel: -0.0186
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 6979584
                    Iteration time: 2.05s
                      Time elapsed: 00:03:00
                               ETA: 02:04:22

################################################################################
                      [1m Learning iteration 71/3000 [0m                      

                       Computation: 48689 steps/s (collection: 1.895s, learning 0.124s)
             Mean action noise std: 1.24
          Mean value_function loss: 2.2377
               Mean surrogate loss: 0.0037
                 Mean entropy loss: 50.5194
                       Mean reward: 11.52
               Mean episode length: 247.91
    Episode_Reward/reaching_object: 1.1432
    Episode_Reward/rotating_object: 1.5110
        Episode_Reward/action_rate: -0.0096
          Episode_Reward/joint_vel: -0.0193
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 7077888
                    Iteration time: 2.02s
                      Time elapsed: 00:03:02
                               ETA: 02:03:58

################################################################################
                      [1m Learning iteration 72/3000 [0m                      

                       Computation: 47772 steps/s (collection: 1.930s, learning 0.128s)
             Mean action noise std: 1.24
          Mean value_function loss: 2.3591
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 50.5329
                       Mean reward: 17.79
               Mean episode length: 245.52
    Episode_Reward/reaching_object: 1.1718
    Episode_Reward/rotating_object: 1.9095
        Episode_Reward/action_rate: -0.0096
          Episode_Reward/joint_vel: -0.0189
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 7176192
                    Iteration time: 2.06s
                      Time elapsed: 00:03:04
                               ETA: 02:03:36

################################################################################
                      [1m Learning iteration 73/3000 [0m                      

                       Computation: 48056 steps/s (collection: 1.925s, learning 0.121s)
             Mean action noise std: 1.24
          Mean value_function loss: 2.4099
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 50.6109
                       Mean reward: 14.46
               Mean episode length: 246.78
    Episode_Reward/reaching_object: 1.2106
    Episode_Reward/rotating_object: 2.0216
        Episode_Reward/action_rate: -0.0097
          Episode_Reward/joint_vel: -0.0192
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 7274496
                    Iteration time: 2.05s
                      Time elapsed: 00:03:06
                               ETA: 02:03:14

################################################################################
                      [1m Learning iteration 74/3000 [0m                      

                       Computation: 47975 steps/s (collection: 1.927s, learning 0.122s)
             Mean action noise std: 1.24
          Mean value_function loss: 3.2863
               Mean surrogate loss: -0.0022
                 Mean entropy loss: 50.6988
                       Mean reward: 13.67
               Mean episode length: 246.34
    Episode_Reward/reaching_object: 1.1540
    Episode_Reward/rotating_object: 1.5260
        Episode_Reward/action_rate: -0.0097
          Episode_Reward/joint_vel: -0.0193
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 7372800
                    Iteration time: 2.05s
                      Time elapsed: 00:03:09
                               ETA: 02:02:53

################################################################################
                      [1m Learning iteration 75/3000 [0m                      

                       Computation: 47379 steps/s (collection: 1.953s, learning 0.122s)
             Mean action noise std: 1.25
          Mean value_function loss: 3.6278
               Mean surrogate loss: 0.0006
                 Mean entropy loss: 50.7622
                       Mean reward: 20.71
               Mean episode length: 244.95
    Episode_Reward/reaching_object: 1.1596
    Episode_Reward/rotating_object: 2.4184
        Episode_Reward/action_rate: -0.0097
          Episode_Reward/joint_vel: -0.0194
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 7471104
                    Iteration time: 2.07s
                      Time elapsed: 00:03:11
                               ETA: 02:02:34

################################################################################
                      [1m Learning iteration 76/3000 [0m                      

                       Computation: 47297 steps/s (collection: 1.949s, learning 0.130s)
             Mean action noise std: 1.25
          Mean value_function loss: 3.4693
               Mean surrogate loss: -0.0001
                 Mean entropy loss: 50.8122
                       Mean reward: 15.30
               Mean episode length: 240.14
    Episode_Reward/reaching_object: 1.1984
    Episode_Reward/rotating_object: 2.0269
        Episode_Reward/action_rate: -0.0097
          Episode_Reward/joint_vel: -0.0193
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 7569408
                    Iteration time: 2.08s
                      Time elapsed: 00:03:13
                               ETA: 02:02:14

################################################################################
                      [1m Learning iteration 77/3000 [0m                      

                       Computation: 48035 steps/s (collection: 1.929s, learning 0.118s)
             Mean action noise std: 1.25
          Mean value_function loss: 3.6700
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 50.8647
                       Mean reward: 15.24
               Mean episode length: 240.70
    Episode_Reward/reaching_object: 1.1891
    Episode_Reward/rotating_object: 2.5992
        Episode_Reward/action_rate: -0.0097
          Episode_Reward/joint_vel: -0.0195
      Episode_Termination/time_out: 13.2500
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 7667712
                    Iteration time: 2.05s
                      Time elapsed: 00:03:15
                               ETA: 02:01:55

################################################################################
                      [1m Learning iteration 78/3000 [0m                      

                       Computation: 47735 steps/s (collection: 1.945s, learning 0.114s)
             Mean action noise std: 1.25
          Mean value_function loss: 3.5025
               Mean surrogate loss: 0.0019
                 Mean entropy loss: 50.9189
                       Mean reward: 17.77
               Mean episode length: 242.59
    Episode_Reward/reaching_object: 1.1799
    Episode_Reward/rotating_object: 2.3836
        Episode_Reward/action_rate: -0.0098
          Episode_Reward/joint_vel: -0.0199
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 7766016
                    Iteration time: 2.06s
                      Time elapsed: 00:03:17
                               ETA: 02:01:36

################################################################################
                      [1m Learning iteration 79/3000 [0m                      

                       Computation: 47676 steps/s (collection: 1.946s, learning 0.116s)
             Mean action noise std: 1.25
          Mean value_function loss: 2.9628
               Mean surrogate loss: -0.0007
                 Mean entropy loss: 50.9380
                       Mean reward: 18.35
               Mean episode length: 244.61
    Episode_Reward/reaching_object: 1.1992
    Episode_Reward/rotating_object: 2.5576
        Episode_Reward/action_rate: -0.0099
          Episode_Reward/joint_vel: -0.0196
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 7864320
                    Iteration time: 2.06s
                      Time elapsed: 00:03:19
                               ETA: 02:01:17

################################################################################
                      [1m Learning iteration 80/3000 [0m                      

                       Computation: 47440 steps/s (collection: 1.959s, learning 0.113s)
             Mean action noise std: 1.26
          Mean value_function loss: 2.8329
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 51.0069
                       Mean reward: 18.06
               Mean episode length: 241.69
    Episode_Reward/reaching_object: 1.1603
    Episode_Reward/rotating_object: 3.1298
        Episode_Reward/action_rate: -0.0099
          Episode_Reward/joint_vel: -0.0199
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 7962624
                    Iteration time: 2.07s
                      Time elapsed: 00:03:21
                               ETA: 02:01:00

################################################################################
                      [1m Learning iteration 81/3000 [0m                      

                       Computation: 47000 steps/s (collection: 1.961s, learning 0.131s)
             Mean action noise std: 1.26
          Mean value_function loss: 2.7210
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 51.0451
                       Mean reward: 20.06
               Mean episode length: 243.24
    Episode_Reward/reaching_object: 1.1769
    Episode_Reward/rotating_object: 2.1358
        Episode_Reward/action_rate: -0.0100
          Episode_Reward/joint_vel: -0.0203
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 8060928
                    Iteration time: 2.09s
                      Time elapsed: 00:03:23
                               ETA: 02:00:43

################################################################################
                      [1m Learning iteration 82/3000 [0m                      

                       Computation: 46678 steps/s (collection: 1.993s, learning 0.113s)
             Mean action noise std: 1.26
          Mean value_function loss: 2.7504
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 51.1085
                       Mean reward: 12.88
               Mean episode length: 245.66
    Episode_Reward/reaching_object: 1.1930
    Episode_Reward/rotating_object: 2.0571
        Episode_Reward/action_rate: -0.0100
          Episode_Reward/joint_vel: -0.0201
      Episode_Termination/time_out: 17.5417
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 8159232
                    Iteration time: 2.11s
                      Time elapsed: 00:03:25
                               ETA: 02:00:28

################################################################################
                      [1m Learning iteration 83/3000 [0m                      

                       Computation: 47477 steps/s (collection: 1.956s, learning 0.115s)
             Mean action noise std: 1.26
          Mean value_function loss: 3.1450
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 51.1836
                       Mean reward: 15.38
               Mean episode length: 245.30
    Episode_Reward/reaching_object: 1.1906
    Episode_Reward/rotating_object: 2.4358
        Episode_Reward/action_rate: -0.0100
          Episode_Reward/joint_vel: -0.0201
      Episode_Termination/time_out: 13.7500
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 8257536
                    Iteration time: 2.07s
                      Time elapsed: 00:03:27
                               ETA: 02:00:11

################################################################################
                      [1m Learning iteration 84/3000 [0m                      

                       Computation: 44511 steps/s (collection: 2.079s, learning 0.129s)
             Mean action noise std: 1.27
          Mean value_function loss: 3.7815
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 51.2959
                       Mean reward: 16.63
               Mean episode length: 244.44
    Episode_Reward/reaching_object: 1.1622
    Episode_Reward/rotating_object: 2.4609
        Episode_Reward/action_rate: -0.0100
          Episode_Reward/joint_vel: -0.0203
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 8355840
                    Iteration time: 2.21s
                      Time elapsed: 00:03:29
                               ETA: 01:59:59

################################################################################
                      [1m Learning iteration 85/3000 [0m                      

                       Computation: 43549 steps/s (collection: 2.085s, learning 0.172s)
             Mean action noise std: 1.27
          Mean value_function loss: 4.2559
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 51.3791
                       Mean reward: 15.79
               Mean episode length: 242.56
    Episode_Reward/reaching_object: 1.1820
    Episode_Reward/rotating_object: 2.2480
        Episode_Reward/action_rate: -0.0101
          Episode_Reward/joint_vel: -0.0204
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 8454144
                    Iteration time: 2.26s
                      Time elapsed: 00:03:32
                               ETA: 01:59:50

################################################################################
                      [1m Learning iteration 86/3000 [0m                      

                       Computation: 37842 steps/s (collection: 2.490s, learning 0.108s)
             Mean action noise std: 1.27
          Mean value_function loss: 4.1888
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 51.4544
                       Mean reward: 17.43
               Mean episode length: 245.59
    Episode_Reward/reaching_object: 1.2015
    Episode_Reward/rotating_object: 2.4405
        Episode_Reward/action_rate: -0.0102
          Episode_Reward/joint_vel: -0.0207
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 8552448
                    Iteration time: 2.60s
                      Time elapsed: 00:03:34
                               ETA: 01:59:52

################################################################################
                      [1m Learning iteration 87/3000 [0m                      

                       Computation: 45414 steps/s (collection: 2.038s, learning 0.126s)
             Mean action noise std: 1.28
          Mean value_function loss: 4.3825
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 51.5417
                       Mean reward: 19.55
               Mean episode length: 243.40
    Episode_Reward/reaching_object: 1.1669
    Episode_Reward/rotating_object: 2.1353
        Episode_Reward/action_rate: -0.0101
          Episode_Reward/joint_vel: -0.0209
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 8650752
                    Iteration time: 2.16s
                      Time elapsed: 00:03:36
                               ETA: 01:59:39

################################################################################
                      [1m Learning iteration 88/3000 [0m                      

                       Computation: 43286 steps/s (collection: 2.126s, learning 0.145s)
             Mean action noise std: 1.28
          Mean value_function loss: 4.8830
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 51.6375
                       Mean reward: 29.33
               Mean episode length: 242.86
    Episode_Reward/reaching_object: 1.1557
    Episode_Reward/rotating_object: 2.6158
        Episode_Reward/action_rate: -0.0101
          Episode_Reward/joint_vel: -0.0209
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 8749056
                    Iteration time: 2.27s
                      Time elapsed: 00:03:39
                               ETA: 01:59:30

################################################################################
                      [1m Learning iteration 89/3000 [0m                      

                       Computation: 37987 steps/s (collection: 2.460s, learning 0.127s)
             Mean action noise std: 1.29
          Mean value_function loss: 4.0780
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 51.7539
                       Mean reward: 22.73
               Mean episode length: 245.66
    Episode_Reward/reaching_object: 1.1783
    Episode_Reward/rotating_object: 3.2519
        Episode_Reward/action_rate: -0.0103
          Episode_Reward/joint_vel: -0.0208
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 8847360
                    Iteration time: 2.59s
                      Time elapsed: 00:03:41
                               ETA: 01:59:32

################################################################################
                      [1m Learning iteration 90/3000 [0m                      

                       Computation: 40318 steps/s (collection: 2.305s, learning 0.134s)
             Mean action noise std: 1.29
          Mean value_function loss: 4.3101
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 51.8400
                       Mean reward: 20.98
               Mean episode length: 244.99
    Episode_Reward/reaching_object: 1.1836
    Episode_Reward/rotating_object: 2.7706
        Episode_Reward/action_rate: -0.0103
          Episode_Reward/joint_vel: -0.0212
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 8945664
                    Iteration time: 2.44s
                      Time elapsed: 00:03:44
                               ETA: 01:59:29

################################################################################
                      [1m Learning iteration 91/3000 [0m                      

                       Computation: 45349 steps/s (collection: 2.052s, learning 0.116s)
             Mean action noise std: 1.30
          Mean value_function loss: 4.8763
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 51.9374
                       Mean reward: 16.38
               Mean episode length: 240.67
    Episode_Reward/reaching_object: 1.1911
    Episode_Reward/rotating_object: 2.8402
        Episode_Reward/action_rate: -0.0103
          Episode_Reward/joint_vel: -0.0210
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 9043968
                    Iteration time: 2.17s
                      Time elapsed: 00:03:46
                               ETA: 01:59:17

################################################################################
                      [1m Learning iteration 92/3000 [0m                      

                       Computation: 47760 steps/s (collection: 1.946s, learning 0.112s)
             Mean action noise std: 1.30
          Mean value_function loss: 5.3465
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 52.0535
                       Mean reward: 17.41
               Mean episode length: 239.73
    Episode_Reward/reaching_object: 1.1743
    Episode_Reward/rotating_object: 3.5767
        Episode_Reward/action_rate: -0.0104
          Episode_Reward/joint_vel: -0.0209
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 9142272
                    Iteration time: 2.06s
                      Time elapsed: 00:03:48
                               ETA: 01:59:02

################################################################################
                      [1m Learning iteration 93/3000 [0m                      

                       Computation: 48267 steps/s (collection: 1.926s, learning 0.111s)
             Mean action noise std: 1.31
          Mean value_function loss: 4.3794
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 52.1687
                       Mean reward: 21.75
               Mean episode length: 235.80
    Episode_Reward/reaching_object: 1.1432
    Episode_Reward/rotating_object: 3.2265
        Episode_Reward/action_rate: -0.0103
          Episode_Reward/joint_vel: -0.0212
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 9240576
                    Iteration time: 2.04s
                      Time elapsed: 00:03:50
                               ETA: 01:58:46

################################################################################
                      [1m Learning iteration 94/3000 [0m                      

                       Computation: 47223 steps/s (collection: 1.968s, learning 0.113s)
             Mean action noise std: 1.31
          Mean value_function loss: 4.7737
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 52.3057
                       Mean reward: 18.12
               Mean episode length: 246.50
    Episode_Reward/reaching_object: 1.1578
    Episode_Reward/rotating_object: 3.0377
        Episode_Reward/action_rate: -0.0106
          Episode_Reward/joint_vel: -0.0216
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 9338880
                    Iteration time: 2.08s
                      Time elapsed: 00:03:52
                               ETA: 01:58:33

################################################################################
                      [1m Learning iteration 95/3000 [0m                      

                       Computation: 47618 steps/s (collection: 1.952s, learning 0.113s)
             Mean action noise std: 1.31
          Mean value_function loss: 4.4738
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 52.3660
                       Mean reward: 20.12
               Mean episode length: 242.42
    Episode_Reward/reaching_object: 1.1816
    Episode_Reward/rotating_object: 3.1138
        Episode_Reward/action_rate: -0.0106
          Episode_Reward/joint_vel: -0.0216
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 9437184
                    Iteration time: 2.06s
                      Time elapsed: 00:03:54
                               ETA: 01:58:19

################################################################################
                      [1m Learning iteration 96/3000 [0m                      

                       Computation: 47388 steps/s (collection: 1.962s, learning 0.112s)
             Mean action noise std: 1.32
          Mean value_function loss: 4.4244
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 52.4523
                       Mean reward: 17.95
               Mean episode length: 244.46
    Episode_Reward/reaching_object: 1.1728
    Episode_Reward/rotating_object: 2.5254
        Episode_Reward/action_rate: -0.0109
          Episode_Reward/joint_vel: -0.0225
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 9535488
                    Iteration time: 2.07s
                      Time elapsed: 00:03:56
                               ETA: 01:58:05

################################################################################
                      [1m Learning iteration 97/3000 [0m                      

                       Computation: 47861 steps/s (collection: 1.952s, learning 0.102s)
             Mean action noise std: 1.32
          Mean value_function loss: 4.7532
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 52.5420
                       Mean reward: 19.93
               Mean episode length: 243.35
    Episode_Reward/reaching_object: 1.1838
    Episode_Reward/rotating_object: 2.4674
        Episode_Reward/action_rate: -0.0109
          Episode_Reward/joint_vel: -0.0222
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 9633792
                    Iteration time: 2.05s
                      Time elapsed: 00:03:58
                               ETA: 01:57:51

################################################################################
                      [1m Learning iteration 98/3000 [0m                      

                       Computation: 48084 steps/s (collection: 1.931s, learning 0.113s)
             Mean action noise std: 1.32
          Mean value_function loss: 5.3935
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 52.6228
                       Mean reward: 20.50
               Mean episode length: 243.31
    Episode_Reward/reaching_object: 1.1683
    Episode_Reward/rotating_object: 2.7167
        Episode_Reward/action_rate: -0.0110
          Episode_Reward/joint_vel: -0.0224
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 9732096
                    Iteration time: 2.04s
                      Time elapsed: 00:04:00
                               ETA: 01:57:37

################################################################################
                      [1m Learning iteration 99/3000 [0m                      

                       Computation: 46804 steps/s (collection: 2.006s, learning 0.094s)
             Mean action noise std: 1.33
          Mean value_function loss: 5.0176
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 52.7085
                       Mean reward: 12.64
               Mean episode length: 247.44
    Episode_Reward/reaching_object: 1.1779
    Episode_Reward/rotating_object: 2.4090
        Episode_Reward/action_rate: -0.0111
          Episode_Reward/joint_vel: -0.0228
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 9830400
                    Iteration time: 2.10s
                      Time elapsed: 00:04:02
                               ETA: 01:57:25

################################################################################
                     [1m Learning iteration 100/3000 [0m                      

                       Computation: 46622 steps/s (collection: 1.987s, learning 0.122s)
             Mean action noise std: 1.33
          Mean value_function loss: 5.0249
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 52.7594
                       Mean reward: 21.21
               Mean episode length: 243.31
    Episode_Reward/reaching_object: 1.1631
    Episode_Reward/rotating_object: 3.0141
        Episode_Reward/action_rate: -0.0112
          Episode_Reward/joint_vel: -0.0229
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 9928704
                    Iteration time: 2.11s
                      Time elapsed: 00:04:04
                               ETA: 01:57:14

################################################################################
                     [1m Learning iteration 101/3000 [0m                      

                       Computation: 46856 steps/s (collection: 1.991s, learning 0.107s)
             Mean action noise std: 1.33
          Mean value_function loss: 4.5673
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 52.8420
                       Mean reward: 18.93
               Mean episode length: 245.83
    Episode_Reward/reaching_object: 1.1627
    Episode_Reward/rotating_object: 2.8946
        Episode_Reward/action_rate: -0.0112
          Episode_Reward/joint_vel: -0.0228
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 10027008
                    Iteration time: 2.10s
                      Time elapsed: 00:04:07
                               ETA: 01:57:02

################################################################################
                     [1m Learning iteration 102/3000 [0m                      

                       Computation: 48017 steps/s (collection: 1.932s, learning 0.115s)
             Mean action noise std: 1.34
          Mean value_function loss: 5.1569
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 52.9422
                       Mean reward: 24.19
               Mean episode length: 243.40
    Episode_Reward/reaching_object: 1.1341
    Episode_Reward/rotating_object: 3.0271
        Episode_Reward/action_rate: -0.0112
          Episode_Reward/joint_vel: -0.0232
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 10125312
                    Iteration time: 2.05s
                      Time elapsed: 00:04:09
                               ETA: 01:56:49

################################################################################
                     [1m Learning iteration 103/3000 [0m                      

                       Computation: 47716 steps/s (collection: 1.932s, learning 0.128s)
             Mean action noise std: 1.34
          Mean value_function loss: 4.2376
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 53.0114
                       Mean reward: 17.78
               Mean episode length: 244.27
    Episode_Reward/reaching_object: 1.1852
    Episode_Reward/rotating_object: 3.1665
        Episode_Reward/action_rate: -0.0115
          Episode_Reward/joint_vel: -0.0239
      Episode_Termination/time_out: 17.4167
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 10223616
                    Iteration time: 2.06s
                      Time elapsed: 00:04:11
                               ETA: 01:56:36

################################################################################
                     [1m Learning iteration 104/3000 [0m                      

                       Computation: 47018 steps/s (collection: 1.957s, learning 0.134s)
             Mean action noise std: 1.34
          Mean value_function loss: 4.9379
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 53.0790
                       Mean reward: 19.36
               Mean episode length: 242.94
    Episode_Reward/reaching_object: 1.1552
    Episode_Reward/rotating_object: 3.2527
        Episode_Reward/action_rate: -0.0113
          Episode_Reward/joint_vel: -0.0236
      Episode_Termination/time_out: 13.1250
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 10321920
                    Iteration time: 2.09s
                      Time elapsed: 00:04:13
                               ETA: 01:56:25

################################################################################
                     [1m Learning iteration 105/3000 [0m                      

                       Computation: 47456 steps/s (collection: 1.950s, learning 0.121s)
             Mean action noise std: 1.35
          Mean value_function loss: 5.3958
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 53.1550
                       Mean reward: 15.98
               Mean episode length: 240.94
    Episode_Reward/reaching_object: 1.1322
    Episode_Reward/rotating_object: 3.1907
        Episode_Reward/action_rate: -0.0114
          Episode_Reward/joint_vel: -0.0236
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 10420224
                    Iteration time: 2.07s
                      Time elapsed: 00:04:15
                               ETA: 01:56:13

################################################################################
                     [1m Learning iteration 106/3000 [0m                      

                       Computation: 47909 steps/s (collection: 1.919s, learning 0.133s)
             Mean action noise std: 1.35
          Mean value_function loss: 5.0414
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 53.1887
                       Mean reward: 17.35
               Mean episode length: 240.60
    Episode_Reward/reaching_object: 1.1348
    Episode_Reward/rotating_object: 2.8672
        Episode_Reward/action_rate: -0.0115
          Episode_Reward/joint_vel: -0.0240
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 10518528
                    Iteration time: 2.05s
                      Time elapsed: 00:04:17
                               ETA: 01:56:01

################################################################################
                     [1m Learning iteration 107/3000 [0m                      

                       Computation: 47250 steps/s (collection: 1.955s, learning 0.125s)
             Mean action noise std: 1.35
          Mean value_function loss: 6.6108
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 53.2544
                       Mean reward: 19.45
               Mean episode length: 244.39
    Episode_Reward/reaching_object: 1.1747
    Episode_Reward/rotating_object: 3.3014
        Episode_Reward/action_rate: -0.0117
          Episode_Reward/joint_vel: -0.0242
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 10616832
                    Iteration time: 2.08s
                      Time elapsed: 00:04:19
                               ETA: 01:55:50

################################################################################
                     [1m Learning iteration 108/3000 [0m                      

                       Computation: 47840 steps/s (collection: 1.958s, learning 0.097s)
             Mean action noise std: 1.35
          Mean value_function loss: 7.1802
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 53.3163
                       Mean reward: 21.55
               Mean episode length: 240.85
    Episode_Reward/reaching_object: 1.1247
    Episode_Reward/rotating_object: 2.6808
        Episode_Reward/action_rate: -0.0115
          Episode_Reward/joint_vel: -0.0242
      Episode_Termination/time_out: 13.5417
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 10715136
                    Iteration time: 2.05s
                      Time elapsed: 00:04:21
                               ETA: 01:55:39

################################################################################
                     [1m Learning iteration 109/3000 [0m                      

                       Computation: 48120 steps/s (collection: 1.932s, learning 0.111s)
             Mean action noise std: 1.36
          Mean value_function loss: 6.9109
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 53.4182
                       Mean reward: 27.97
               Mean episode length: 243.96
    Episode_Reward/reaching_object: 1.1433
    Episode_Reward/rotating_object: 3.3217
        Episode_Reward/action_rate: -0.0117
          Episode_Reward/joint_vel: -0.0245
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 10813440
                    Iteration time: 2.04s
                      Time elapsed: 00:04:23
                               ETA: 01:55:27

################################################################################
                     [1m Learning iteration 110/3000 [0m                      

                       Computation: 47754 steps/s (collection: 1.951s, learning 0.108s)
             Mean action noise std: 1.36
          Mean value_function loss: 5.9483
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 53.5105
                       Mean reward: 21.62
               Mean episode length: 246.94
    Episode_Reward/reaching_object: 1.1872
    Episode_Reward/rotating_object: 3.6299
        Episode_Reward/action_rate: -0.0119
          Episode_Reward/joint_vel: -0.0248
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 10911744
                    Iteration time: 2.06s
                      Time elapsed: 00:04:25
                               ETA: 01:55:16

################################################################################
                     [1m Learning iteration 111/3000 [0m                      

                       Computation: 48291 steps/s (collection: 1.919s, learning 0.117s)
             Mean action noise std: 1.37
          Mean value_function loss: 5.7586
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 53.6046
                       Mean reward: 24.60
               Mean episode length: 244.04
    Episode_Reward/reaching_object: 1.1710
    Episode_Reward/rotating_object: 2.6838
        Episode_Reward/action_rate: -0.0120
          Episode_Reward/joint_vel: -0.0253
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 11010048
                    Iteration time: 2.04s
                      Time elapsed: 00:04:27
                               ETA: 01:55:04

################################################################################
                     [1m Learning iteration 112/3000 [0m                      

                       Computation: 48121 steps/s (collection: 1.926s, learning 0.117s)
             Mean action noise std: 1.37
          Mean value_function loss: 6.4225
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 53.6799
                       Mean reward: 20.47
               Mean episode length: 243.49
    Episode_Reward/reaching_object: 1.1918
    Episode_Reward/rotating_object: 3.4213
        Episode_Reward/action_rate: -0.0121
          Episode_Reward/joint_vel: -0.0253
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 11108352
                    Iteration time: 2.04s
                      Time elapsed: 00:04:29
                               ETA: 01:54:53

################################################################################
                     [1m Learning iteration 113/3000 [0m                      

                       Computation: 47898 steps/s (collection: 1.953s, learning 0.099s)
             Mean action noise std: 1.37
          Mean value_function loss: 6.6466
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 53.7783
                       Mean reward: 33.89
               Mean episode length: 243.12
    Episode_Reward/reaching_object: 1.1759
    Episode_Reward/rotating_object: 4.1356
        Episode_Reward/action_rate: -0.0121
          Episode_Reward/joint_vel: -0.0254
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 11206656
                    Iteration time: 2.05s
                      Time elapsed: 00:04:31
                               ETA: 01:54:42

################################################################################
                     [1m Learning iteration 114/3000 [0m                      

                       Computation: 47665 steps/s (collection: 1.953s, learning 0.109s)
             Mean action noise std: 1.38
          Mean value_function loss: 7.8243
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 53.8751
                       Mean reward: 22.91
               Mean episode length: 240.70
    Episode_Reward/reaching_object: 1.1551
    Episode_Reward/rotating_object: 4.5059
        Episode_Reward/action_rate: -0.0120
          Episode_Reward/joint_vel: -0.0247
      Episode_Termination/time_out: 13.3750
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 11304960
                    Iteration time: 2.06s
                      Time elapsed: 00:04:33
                               ETA: 01:54:31

################################################################################
                     [1m Learning iteration 115/3000 [0m                      

                       Computation: 47590 steps/s (collection: 1.954s, learning 0.112s)
             Mean action noise std: 1.38
          Mean value_function loss: 8.6336
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 53.9702
                       Mean reward: 24.47
               Mean episode length: 243.11
    Episode_Reward/reaching_object: 1.1767
    Episode_Reward/rotating_object: 3.6645
        Episode_Reward/action_rate: -0.0122
          Episode_Reward/joint_vel: -0.0256
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 11403264
                    Iteration time: 2.07s
                      Time elapsed: 00:04:35
                               ETA: 01:54:21

################################################################################
                     [1m Learning iteration 116/3000 [0m                      

                       Computation: 48383 steps/s (collection: 1.940s, learning 0.092s)
             Mean action noise std: 1.39
          Mean value_function loss: 9.7253
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 54.0429
                       Mean reward: 19.45
               Mean episode length: 244.07
    Episode_Reward/reaching_object: 1.1641
    Episode_Reward/rotating_object: 3.2883
        Episode_Reward/action_rate: -0.0123
          Episode_Reward/joint_vel: -0.0259
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 11501568
                    Iteration time: 2.03s
                      Time elapsed: 00:04:37
                               ETA: 01:54:10

################################################################################
                     [1m Learning iteration 117/3000 [0m                      

                       Computation: 47852 steps/s (collection: 1.941s, learning 0.113s)
             Mean action noise std: 1.39
          Mean value_function loss: 8.1579
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 54.1228
                       Mean reward: 29.80
               Mean episode length: 245.40
    Episode_Reward/reaching_object: 1.1792
    Episode_Reward/rotating_object: 3.8182
        Episode_Reward/action_rate: -0.0124
          Episode_Reward/joint_vel: -0.0258
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 11599872
                    Iteration time: 2.05s
                      Time elapsed: 00:04:39
                               ETA: 01:54:00

################################################################################
                     [1m Learning iteration 118/3000 [0m                      

                       Computation: 48025 steps/s (collection: 1.930s, learning 0.117s)
             Mean action noise std: 1.39
          Mean value_function loss: 8.1960
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 54.1874
                       Mean reward: 25.34
               Mean episode length: 242.98
    Episode_Reward/reaching_object: 1.1893
    Episode_Reward/rotating_object: 4.3027
        Episode_Reward/action_rate: -0.0125
          Episode_Reward/joint_vel: -0.0260
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 11698176
                    Iteration time: 2.05s
                      Time elapsed: 00:04:42
                               ETA: 01:53:50

################################################################################
                     [1m Learning iteration 119/3000 [0m                      

                       Computation: 47791 steps/s (collection: 1.942s, learning 0.115s)
             Mean action noise std: 1.40
          Mean value_function loss: 9.8437
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 54.2863
                       Mean reward: 25.63
               Mean episode length: 245.46
    Episode_Reward/reaching_object: 1.1281
    Episode_Reward/rotating_object: 3.2549
        Episode_Reward/action_rate: -0.0126
          Episode_Reward/joint_vel: -0.0269
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 11796480
                    Iteration time: 2.06s
                      Time elapsed: 00:04:44
                               ETA: 01:53:40

################################################################################
                     [1m Learning iteration 120/3000 [0m                      

                       Computation: 48345 steps/s (collection: 1.920s, learning 0.113s)
             Mean action noise std: 1.40
          Mean value_function loss: 9.5031
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 54.3723
                       Mean reward: 43.99
               Mean episode length: 243.03
    Episode_Reward/reaching_object: 1.1615
    Episode_Reward/rotating_object: 5.1052
        Episode_Reward/action_rate: -0.0125
          Episode_Reward/joint_vel: -0.0260
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 11894784
                    Iteration time: 2.03s
                      Time elapsed: 00:04:46
                               ETA: 01:53:30

################################################################################
                     [1m Learning iteration 121/3000 [0m                      

                       Computation: 48159 steps/s (collection: 1.926s, learning 0.115s)
             Mean action noise std: 1.40
          Mean value_function loss: 8.4588
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 54.4639
                       Mean reward: 19.51
               Mean episode length: 241.10
    Episode_Reward/reaching_object: 1.1351
    Episode_Reward/rotating_object: 3.6053
        Episode_Reward/action_rate: -0.0126
          Episode_Reward/joint_vel: -0.0263
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 11993088
                    Iteration time: 2.04s
                      Time elapsed: 00:04:48
                               ETA: 01:53:20

################################################################################
                     [1m Learning iteration 122/3000 [0m                      

                       Computation: 48280 steps/s (collection: 1.925s, learning 0.112s)
             Mean action noise std: 1.41
          Mean value_function loss: 7.8040
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 54.5402
                       Mean reward: 29.03
               Mean episode length: 238.21
    Episode_Reward/reaching_object: 1.1232
    Episode_Reward/rotating_object: 4.9883
        Episode_Reward/action_rate: -0.0126
          Episode_Reward/joint_vel: -0.0265
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 12091392
                    Iteration time: 2.04s
                      Time elapsed: 00:04:50
                               ETA: 01:53:10

################################################################################
                     [1m Learning iteration 123/3000 [0m                      

                       Computation: 47365 steps/s (collection: 1.962s, learning 0.113s)
             Mean action noise std: 1.41
          Mean value_function loss: 7.9367
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 54.6283
                       Mean reward: 18.90
               Mean episode length: 240.01
    Episode_Reward/reaching_object: 1.1344
    Episode_Reward/rotating_object: 3.8698
        Episode_Reward/action_rate: -0.0127
          Episode_Reward/joint_vel: -0.0264
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 12189696
                    Iteration time: 2.08s
                      Time elapsed: 00:04:52
                               ETA: 01:53:01

################################################################################
                     [1m Learning iteration 124/3000 [0m                      

                       Computation: 48056 steps/s (collection: 1.919s, learning 0.126s)
             Mean action noise std: 1.42
          Mean value_function loss: 7.8126
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 54.7031
                       Mean reward: 18.12
               Mean episode length: 235.85
    Episode_Reward/reaching_object: 1.0837
    Episode_Reward/rotating_object: 4.1762
        Episode_Reward/action_rate: -0.0127
          Episode_Reward/joint_vel: -0.0267
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 12288000
                    Iteration time: 2.05s
                      Time elapsed: 00:04:54
                               ETA: 01:52:51

################################################################################
                     [1m Learning iteration 125/3000 [0m                      

                       Computation: 48061 steps/s (collection: 1.938s, learning 0.108s)
             Mean action noise std: 1.42
          Mean value_function loss: 9.1782
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 54.8030
                       Mean reward: 27.86
               Mean episode length: 238.60
    Episode_Reward/reaching_object: 1.0879
    Episode_Reward/rotating_object: 4.5274
        Episode_Reward/action_rate: -0.0127
          Episode_Reward/joint_vel: -0.0265
      Episode_Termination/time_out: 13.5417
Episode_Termination/object_dropping: 0.5833
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 12386304
                    Iteration time: 2.05s
                      Time elapsed: 00:04:56
                               ETA: 01:52:42

################################################################################
                     [1m Learning iteration 126/3000 [0m                      

                       Computation: 47967 steps/s (collection: 1.927s, learning 0.123s)
             Mean action noise std: 1.42
          Mean value_function loss: 8.5458
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 54.8785
                       Mean reward: 14.94
               Mean episode length: 232.42
    Episode_Reward/reaching_object: 1.0182
    Episode_Reward/rotating_object: 3.7087
        Episode_Reward/action_rate: -0.0128
          Episode_Reward/joint_vel: -0.0278
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 12484608
                    Iteration time: 2.05s
                      Time elapsed: 00:04:58
                               ETA: 01:52:33

################################################################################
                     [1m Learning iteration 127/3000 [0m                      

                       Computation: 48139 steps/s (collection: 1.918s, learning 0.124s)
             Mean action noise std: 1.43
          Mean value_function loss: 8.8250
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 54.9645
                       Mean reward: 29.25
               Mean episode length: 236.94
    Episode_Reward/reaching_object: 1.0579
    Episode_Reward/rotating_object: 4.1960
        Episode_Reward/action_rate: -0.0129
          Episode_Reward/joint_vel: -0.0277
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 12582912
                    Iteration time: 2.04s
                      Time elapsed: 00:05:00
                               ETA: 01:52:23

################################################################################
                     [1m Learning iteration 128/3000 [0m                      

                       Computation: 47719 steps/s (collection: 1.930s, learning 0.130s)
             Mean action noise std: 1.43
          Mean value_function loss: 8.5737
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 55.0391
                       Mean reward: 23.93
               Mean episode length: 237.84
    Episode_Reward/reaching_object: 1.0619
    Episode_Reward/rotating_object: 4.4244
        Episode_Reward/action_rate: -0.0129
          Episode_Reward/joint_vel: -0.0273
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 12681216
                    Iteration time: 2.06s
                      Time elapsed: 00:05:02
                               ETA: 01:52:15

################################################################################
                     [1m Learning iteration 129/3000 [0m                      

                       Computation: 48057 steps/s (collection: 1.914s, learning 0.132s)
             Mean action noise std: 1.43
          Mean value_function loss: 9.0588
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 55.0863
                       Mean reward: 24.54
               Mean episode length: 234.94
    Episode_Reward/reaching_object: 1.0355
    Episode_Reward/rotating_object: 3.9192
        Episode_Reward/action_rate: -0.0131
          Episode_Reward/joint_vel: -0.0278
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 12779520
                    Iteration time: 2.05s
                      Time elapsed: 00:05:04
                               ETA: 01:52:06

################################################################################
                     [1m Learning iteration 130/3000 [0m                      

                       Computation: 47624 steps/s (collection: 1.940s, learning 0.124s)
             Mean action noise std: 1.44
          Mean value_function loss: 8.5280
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 55.1393
                       Mean reward: 28.01
               Mean episode length: 232.86
    Episode_Reward/reaching_object: 1.0445
    Episode_Reward/rotating_object: 4.0832
        Episode_Reward/action_rate: -0.0132
          Episode_Reward/joint_vel: -0.0283
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 12877824
                    Iteration time: 2.06s
                      Time elapsed: 00:05:06
                               ETA: 01:51:57

################################################################################
                     [1m Learning iteration 131/3000 [0m                      

                       Computation: 48303 steps/s (collection: 1.925s, learning 0.110s)
             Mean action noise std: 1.44
          Mean value_function loss: 9.1217
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 55.1935
                       Mean reward: 21.26
               Mean episode length: 241.55
    Episode_Reward/reaching_object: 1.0408
    Episode_Reward/rotating_object: 4.1443
        Episode_Reward/action_rate: -0.0133
          Episode_Reward/joint_vel: -0.0279
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 12976128
                    Iteration time: 2.04s
                      Time elapsed: 00:05:08
                               ETA: 01:51:48

################################################################################
                     [1m Learning iteration 132/3000 [0m                      

                       Computation: 47024 steps/s (collection: 1.950s, learning 0.141s)
             Mean action noise std: 1.44
          Mean value_function loss: 9.5733
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 55.2632
                       Mean reward: 23.00
               Mean episode length: 242.66
    Episode_Reward/reaching_object: 1.0435
    Episode_Reward/rotating_object: 3.9221
        Episode_Reward/action_rate: -0.0133
          Episode_Reward/joint_vel: -0.0284
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 13074432
                    Iteration time: 2.09s
                      Time elapsed: 00:05:10
                               ETA: 01:51:40

################################################################################
                     [1m Learning iteration 133/3000 [0m                      

                       Computation: 48409 steps/s (collection: 1.929s, learning 0.102s)
             Mean action noise std: 1.44
          Mean value_function loss: 9.3408
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 55.3168
                       Mean reward: 31.20
               Mean episode length: 237.35
    Episode_Reward/reaching_object: 1.0395
    Episode_Reward/rotating_object: 4.9832
        Episode_Reward/action_rate: -0.0135
          Episode_Reward/joint_vel: -0.0287
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 13172736
                    Iteration time: 2.03s
                      Time elapsed: 00:05:12
                               ETA: 01:51:32

################################################################################
                     [1m Learning iteration 134/3000 [0m                      

                       Computation: 47564 steps/s (collection: 1.970s, learning 0.097s)
             Mean action noise std: 1.45
          Mean value_function loss: 9.1334
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 55.3954
                       Mean reward: 22.88
               Mean episode length: 235.99
    Episode_Reward/reaching_object: 1.0161
    Episode_Reward/rotating_object: 3.7054
        Episode_Reward/action_rate: -0.0136
          Episode_Reward/joint_vel: -0.0299
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.5833
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 13271040
                    Iteration time: 2.07s
                      Time elapsed: 00:05:14
                               ETA: 01:51:24

################################################################################
                     [1m Learning iteration 135/3000 [0m                      

                       Computation: 47769 steps/s (collection: 1.964s, learning 0.094s)
             Mean action noise std: 1.45
          Mean value_function loss: 10.8675
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 55.4706
                       Mean reward: 23.75
               Mean episode length: 238.28
    Episode_Reward/reaching_object: 1.0734
    Episode_Reward/rotating_object: 4.2722
        Episode_Reward/action_rate: -0.0136
          Episode_Reward/joint_vel: -0.0305
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 13369344
                    Iteration time: 2.06s
                      Time elapsed: 00:05:16
                               ETA: 01:51:15

################################################################################
                     [1m Learning iteration 136/3000 [0m                      

                       Computation: 47878 steps/s (collection: 1.950s, learning 0.103s)
             Mean action noise std: 1.46
          Mean value_function loss: 10.1704
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 55.5586
                       Mean reward: 27.02
               Mean episode length: 240.42
    Episode_Reward/reaching_object: 1.0468
    Episode_Reward/rotating_object: 3.5646
        Episode_Reward/action_rate: -0.0136
          Episode_Reward/joint_vel: -0.0302
      Episode_Termination/time_out: 13.3750
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 13467648
                    Iteration time: 2.05s
                      Time elapsed: 00:05:18
                               ETA: 01:51:07

################################################################################
                     [1m Learning iteration 137/3000 [0m                      

                       Computation: 47332 steps/s (collection: 1.966s, learning 0.111s)
             Mean action noise std: 1.46
          Mean value_function loss: 8.9268
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 55.6436
                       Mean reward: 24.12
               Mean episode length: 235.71
    Episode_Reward/reaching_object: 1.0433
    Episode_Reward/rotating_object: 4.4582
        Episode_Reward/action_rate: -0.0138
          Episode_Reward/joint_vel: -0.0306
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 13565952
                    Iteration time: 2.08s
                      Time elapsed: 00:05:21
                               ETA: 01:51:00

################################################################################
                     [1m Learning iteration 138/3000 [0m                      

                       Computation: 48309 steps/s (collection: 1.941s, learning 0.094s)
             Mean action noise std: 1.46
          Mean value_function loss: 7.8708
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 55.7097
                       Mean reward: 40.26
               Mean episode length: 240.80
    Episode_Reward/reaching_object: 1.0572
    Episode_Reward/rotating_object: 6.1690
        Episode_Reward/action_rate: -0.0138
          Episode_Reward/joint_vel: -0.0301
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 13664256
                    Iteration time: 2.03s
                      Time elapsed: 00:05:23
                               ETA: 01:50:51

################################################################################
                     [1m Learning iteration 139/3000 [0m                      

                       Computation: 47944 steps/s (collection: 1.950s, learning 0.101s)
             Mean action noise std: 1.47
          Mean value_function loss: 8.7200
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 55.7747
                       Mean reward: 36.59
               Mean episode length: 242.32
    Episode_Reward/reaching_object: 1.0733
    Episode_Reward/rotating_object: 3.8814
        Episode_Reward/action_rate: -0.0139
          Episode_Reward/joint_vel: -0.0311
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 13762560
                    Iteration time: 2.05s
                      Time elapsed: 00:05:25
                               ETA: 01:50:44

################################################################################
                     [1m Learning iteration 140/3000 [0m                      

                       Computation: 47958 steps/s (collection: 1.951s, learning 0.099s)
             Mean action noise std: 1.47
          Mean value_function loss: 9.0150
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 55.8486
                       Mean reward: 27.51
               Mean episode length: 239.50
    Episode_Reward/reaching_object: 1.0721
    Episode_Reward/rotating_object: 5.2283
        Episode_Reward/action_rate: -0.0139
          Episode_Reward/joint_vel: -0.0312
      Episode_Termination/time_out: 13.5833
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 13860864
                    Iteration time: 2.05s
                      Time elapsed: 00:05:27
                               ETA: 01:50:36

################################################################################
                     [1m Learning iteration 141/3000 [0m                      

                       Computation: 47759 steps/s (collection: 1.954s, learning 0.105s)
             Mean action noise std: 1.47
          Mean value_function loss: 9.1379
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 55.9454
                       Mean reward: 38.40
               Mean episode length: 243.25
    Episode_Reward/reaching_object: 1.1116
    Episode_Reward/rotating_object: 5.3318
        Episode_Reward/action_rate: -0.0143
          Episode_Reward/joint_vel: -0.0317
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 13959168
                    Iteration time: 2.06s
                      Time elapsed: 00:05:29
                               ETA: 01:50:28

################################################################################
                     [1m Learning iteration 142/3000 [0m                      

                       Computation: 47954 steps/s (collection: 1.951s, learning 0.099s)
             Mean action noise std: 1.48
          Mean value_function loss: 10.1728
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 56.0134
                       Mean reward: 37.06
               Mean episode length: 244.32
    Episode_Reward/reaching_object: 1.1030
    Episode_Reward/rotating_object: 4.3397
        Episode_Reward/action_rate: -0.0143
          Episode_Reward/joint_vel: -0.0323
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 14057472
                    Iteration time: 2.05s
                      Time elapsed: 00:05:31
                               ETA: 01:50:20

################################################################################
                     [1m Learning iteration 143/3000 [0m                      

                       Computation: 47977 steps/s (collection: 1.951s, learning 0.098s)
             Mean action noise std: 1.48
          Mean value_function loss: 9.6606
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 56.0867
                       Mean reward: 31.49
               Mean episode length: 239.90
    Episode_Reward/reaching_object: 1.0536
    Episode_Reward/rotating_object: 4.4273
        Episode_Reward/action_rate: -0.0141
          Episode_Reward/joint_vel: -0.0313
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.7500
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 14155776
                    Iteration time: 2.05s
                      Time elapsed: 00:05:33
                               ETA: 01:50:13

################################################################################
                     [1m Learning iteration 144/3000 [0m                      

                       Computation: 48233 steps/s (collection: 1.946s, learning 0.092s)
             Mean action noise std: 1.48
          Mean value_function loss: 8.1607
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 56.1569
                       Mean reward: 18.82
               Mean episode length: 244.07
    Episode_Reward/reaching_object: 1.1031
    Episode_Reward/rotating_object: 4.6148
        Episode_Reward/action_rate: -0.0143
          Episode_Reward/joint_vel: -0.0325
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 14254080
                    Iteration time: 2.04s
                      Time elapsed: 00:05:35
                               ETA: 01:50:05

################################################################################
                     [1m Learning iteration 145/3000 [0m                      

                       Computation: 48464 steps/s (collection: 1.926s, learning 0.103s)
             Mean action noise std: 1.49
          Mean value_function loss: 8.5150
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 56.2377
                       Mean reward: 22.92
               Mean episode length: 241.82
    Episode_Reward/reaching_object: 1.0782
    Episode_Reward/rotating_object: 4.5207
        Episode_Reward/action_rate: -0.0144
          Episode_Reward/joint_vel: -0.0320
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 14352384
                    Iteration time: 2.03s
                      Time elapsed: 00:05:37
                               ETA: 01:49:57

################################################################################
                     [1m Learning iteration 146/3000 [0m                      

                       Computation: 48616 steps/s (collection: 1.920s, learning 0.102s)
             Mean action noise std: 1.49
          Mean value_function loss: 9.2397
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 56.3000
                       Mean reward: 35.94
               Mean episode length: 245.87
    Episode_Reward/reaching_object: 1.0907
    Episode_Reward/rotating_object: 5.1056
        Episode_Reward/action_rate: -0.0144
          Episode_Reward/joint_vel: -0.0325
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.5833
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 14450688
                    Iteration time: 2.02s
                      Time elapsed: 00:05:39
                               ETA: 01:49:49

################################################################################
                     [1m Learning iteration 147/3000 [0m                      

                       Computation: 47775 steps/s (collection: 1.952s, learning 0.106s)
             Mean action noise std: 1.50
          Mean value_function loss: 9.2474
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 56.3935
                       Mean reward: 25.80
               Mean episode length: 241.17
    Episode_Reward/reaching_object: 1.0734
    Episode_Reward/rotating_object: 3.9971
        Episode_Reward/action_rate: -0.0146
          Episode_Reward/joint_vel: -0.0340
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 14548992
                    Iteration time: 2.06s
                      Time elapsed: 00:05:41
                               ETA: 01:49:42

################################################################################
                     [1m Learning iteration 148/3000 [0m                      

                       Computation: 48194 steps/s (collection: 1.915s, learning 0.125s)
             Mean action noise std: 1.50
          Mean value_function loss: 9.8377
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 56.4670
                       Mean reward: 23.88
               Mean episode length: 241.72
    Episode_Reward/reaching_object: 1.0620
    Episode_Reward/rotating_object: 4.4697
        Episode_Reward/action_rate: -0.0148
          Episode_Reward/joint_vel: -0.0338
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 14647296
                    Iteration time: 2.04s
                      Time elapsed: 00:05:43
                               ETA: 01:49:35

################################################################################
                     [1m Learning iteration 149/3000 [0m                      

                       Computation: 47471 steps/s (collection: 1.937s, learning 0.134s)
             Mean action noise std: 1.50
          Mean value_function loss: 10.8288
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 56.5327
                       Mean reward: 30.57
               Mean episode length: 240.72
    Episode_Reward/reaching_object: 1.0858
    Episode_Reward/rotating_object: 5.1506
        Episode_Reward/action_rate: -0.0147
          Episode_Reward/joint_vel: -0.0330
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 14745600
                    Iteration time: 2.07s
                      Time elapsed: 00:05:45
                               ETA: 01:49:28

################################################################################
                     [1m Learning iteration 150/3000 [0m                      

                       Computation: 48192 steps/s (collection: 1.921s, learning 0.119s)
             Mean action noise std: 1.50
          Mean value_function loss: 10.7837
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 56.5976
                       Mean reward: 38.80
               Mean episode length: 244.40
    Episode_Reward/reaching_object: 1.1133
    Episode_Reward/rotating_object: 5.1807
        Episode_Reward/action_rate: -0.0149
          Episode_Reward/joint_vel: -0.0346
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 14843904
                    Iteration time: 2.04s
                      Time elapsed: 00:05:47
                               ETA: 01:49:21

################################################################################
                     [1m Learning iteration 151/3000 [0m                      

                       Computation: 47952 steps/s (collection: 1.922s, learning 0.128s)
             Mean action noise std: 1.51
          Mean value_function loss: 8.9317
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 56.6691
                       Mean reward: 21.39
               Mean episode length: 244.14
    Episode_Reward/reaching_object: 1.0775
    Episode_Reward/rotating_object: 3.4060
        Episode_Reward/action_rate: -0.0149
          Episode_Reward/joint_vel: -0.0342
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.7500
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 14942208
                    Iteration time: 2.05s
                      Time elapsed: 00:05:49
                               ETA: 01:49:14

################################################################################
                     [1m Learning iteration 152/3000 [0m                      

                       Computation: 48598 steps/s (collection: 1.905s, learning 0.117s)
             Mean action noise std: 1.51
          Mean value_function loss: 9.2970
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 56.7492
                       Mean reward: 33.42
               Mean episode length: 243.97
    Episode_Reward/reaching_object: 1.1038
    Episode_Reward/rotating_object: 4.9761
        Episode_Reward/action_rate: -0.0150
          Episode_Reward/joint_vel: -0.0340
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 15040512
                    Iteration time: 2.02s
                      Time elapsed: 00:05:51
                               ETA: 01:49:06

################################################################################
                     [1m Learning iteration 153/3000 [0m                      

                       Computation: 48228 steps/s (collection: 1.929s, learning 0.109s)
             Mean action noise std: 1.52
          Mean value_function loss: 11.0351
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 56.8344
                       Mean reward: 32.23
               Mean episode length: 243.41
    Episode_Reward/reaching_object: 1.0873
    Episode_Reward/rotating_object: 5.3172
        Episode_Reward/action_rate: -0.0152
          Episode_Reward/joint_vel: -0.0351
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 15138816
                    Iteration time: 2.04s
                      Time elapsed: 00:05:53
                               ETA: 01:48:59

################################################################################
                     [1m Learning iteration 154/3000 [0m                      

                       Computation: 47941 steps/s (collection: 1.927s, learning 0.123s)
             Mean action noise std: 1.52
          Mean value_function loss: 10.3360
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 56.9200
                       Mean reward: 36.72
               Mean episode length: 246.97
    Episode_Reward/reaching_object: 1.1101
    Episode_Reward/rotating_object: 4.6413
        Episode_Reward/action_rate: -0.0152
          Episode_Reward/joint_vel: -0.0348
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 15237120
                    Iteration time: 2.05s
                      Time elapsed: 00:05:55
                               ETA: 01:48:52

################################################################################
                     [1m Learning iteration 155/3000 [0m                      

                       Computation: 48741 steps/s (collection: 1.898s, learning 0.119s)
             Mean action noise std: 1.52
          Mean value_function loss: 10.6055
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 56.9743
                       Mean reward: 24.84
               Mean episode length: 239.48
    Episode_Reward/reaching_object: 1.0792
    Episode_Reward/rotating_object: 4.0094
        Episode_Reward/action_rate: -0.0153
          Episode_Reward/joint_vel: -0.0361
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 15335424
                    Iteration time: 2.02s
                      Time elapsed: 00:05:57
                               ETA: 01:48:45

################################################################################
                     [1m Learning iteration 156/3000 [0m                      

                       Computation: 47818 steps/s (collection: 1.943s, learning 0.112s)
             Mean action noise std: 1.53
          Mean value_function loss: 12.1901
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 57.0259
                       Mean reward: 37.32
               Mean episode length: 246.06
    Episode_Reward/reaching_object: 1.0963
    Episode_Reward/rotating_object: 5.8063
        Episode_Reward/action_rate: -0.0154
          Episode_Reward/joint_vel: -0.0357
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 15433728
                    Iteration time: 2.06s
                      Time elapsed: 00:05:59
                               ETA: 01:48:38

################################################################################
                     [1m Learning iteration 157/3000 [0m                      

                       Computation: 48111 steps/s (collection: 1.931s, learning 0.113s)
             Mean action noise std: 1.53
          Mean value_function loss: 9.7199
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 57.0762
                       Mean reward: 28.34
               Mean episode length: 232.93
    Episode_Reward/reaching_object: 1.0454
    Episode_Reward/rotating_object: 4.2151
        Episode_Reward/action_rate: -0.0152
          Episode_Reward/joint_vel: -0.0355
      Episode_Termination/time_out: 13.4583
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 15532032
                    Iteration time: 2.04s
                      Time elapsed: 00:06:01
                               ETA: 01:48:31

################################################################################
                     [1m Learning iteration 158/3000 [0m                      

                       Computation: 48262 steps/s (collection: 1.925s, learning 0.112s)
             Mean action noise std: 1.53
          Mean value_function loss: 10.1910
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 57.1248
                       Mean reward: 25.83
               Mean episode length: 236.48
    Episode_Reward/reaching_object: 1.0873
    Episode_Reward/rotating_object: 4.8009
        Episode_Reward/action_rate: -0.0153
          Episode_Reward/joint_vel: -0.0351
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 15630336
                    Iteration time: 2.04s
                      Time elapsed: 00:06:03
                               ETA: 01:48:25

################################################################################
                     [1m Learning iteration 159/3000 [0m                      

                       Computation: 48014 steps/s (collection: 1.934s, learning 0.113s)
             Mean action noise std: 1.54
          Mean value_function loss: 10.7940
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 57.2078
                       Mean reward: 26.47
               Mean episode length: 234.53
    Episode_Reward/reaching_object: 1.0524
    Episode_Reward/rotating_object: 4.4436
        Episode_Reward/action_rate: -0.0154
          Episode_Reward/joint_vel: -0.0355
      Episode_Termination/time_out: 13.4167
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 15728640
                    Iteration time: 2.05s
                      Time elapsed: 00:06:05
                               ETA: 01:48:18

################################################################################
                     [1m Learning iteration 160/3000 [0m                      

                       Computation: 48146 steps/s (collection: 1.930s, learning 0.111s)
             Mean action noise std: 1.54
          Mean value_function loss: 11.5515
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 57.3015
                       Mean reward: 17.44
               Mean episode length: 238.54
    Episode_Reward/reaching_object: 1.0610
    Episode_Reward/rotating_object: 3.5971
        Episode_Reward/action_rate: -0.0155
          Episode_Reward/joint_vel: -0.0359
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 15826944
                    Iteration time: 2.04s
                      Time elapsed: 00:06:08
                               ETA: 01:48:11

################################################################################
                     [1m Learning iteration 161/3000 [0m                      

                       Computation: 48339 steps/s (collection: 1.924s, learning 0.110s)
             Mean action noise std: 1.54
          Mean value_function loss: 12.0359
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 57.3844
                       Mean reward: 32.25
               Mean episode length: 243.27
    Episode_Reward/reaching_object: 1.0621
    Episode_Reward/rotating_object: 5.3876
        Episode_Reward/action_rate: -0.0157
          Episode_Reward/joint_vel: -0.0364
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 15925248
                    Iteration time: 2.03s
                      Time elapsed: 00:06:10
                               ETA: 01:48:05

################################################################################
                     [1m Learning iteration 162/3000 [0m                      

                       Computation: 47554 steps/s (collection: 1.946s, learning 0.121s)
             Mean action noise std: 1.55
          Mean value_function loss: 11.3093
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 57.4559
                       Mean reward: 28.95
               Mean episode length: 239.86
    Episode_Reward/reaching_object: 1.0738
    Episode_Reward/rotating_object: 4.5602
        Episode_Reward/action_rate: -0.0156
          Episode_Reward/joint_vel: -0.0359
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 16023552
                    Iteration time: 2.07s
                      Time elapsed: 00:06:12
                               ETA: 01:47:59

################################################################################
                     [1m Learning iteration 163/3000 [0m                      

                       Computation: 48513 steps/s (collection: 1.915s, learning 0.112s)
             Mean action noise std: 1.55
          Mean value_function loss: 12.9082
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 57.5089
                       Mean reward: 22.65
               Mean episode length: 233.49
    Episode_Reward/reaching_object: 1.0643
    Episode_Reward/rotating_object: 4.2683
        Episode_Reward/action_rate: -0.0156
          Episode_Reward/joint_vel: -0.0363
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 16121856
                    Iteration time: 2.03s
                      Time elapsed: 00:06:14
                               ETA: 01:47:52

################################################################################
                     [1m Learning iteration 164/3000 [0m                      

                       Computation: 48559 steps/s (collection: 1.908s, learning 0.117s)
             Mean action noise std: 1.55
          Mean value_function loss: 10.9932
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 57.5752
                       Mean reward: 29.08
               Mean episode length: 241.21
    Episode_Reward/reaching_object: 1.0393
    Episode_Reward/rotating_object: 4.1262
        Episode_Reward/action_rate: -0.0158
          Episode_Reward/joint_vel: -0.0368
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 16220160
                    Iteration time: 2.02s
                      Time elapsed: 00:06:16
                               ETA: 01:47:45

################################################################################
                     [1m Learning iteration 165/3000 [0m                      

                       Computation: 48417 steps/s (collection: 1.917s, learning 0.114s)
             Mean action noise std: 1.56
          Mean value_function loss: 12.4577
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 57.6194
                       Mean reward: 26.88
               Mean episode length: 242.05
    Episode_Reward/reaching_object: 1.0683
    Episode_Reward/rotating_object: 4.2710
        Episode_Reward/action_rate: -0.0160
          Episode_Reward/joint_vel: -0.0364
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 16318464
                    Iteration time: 2.03s
                      Time elapsed: 00:06:18
                               ETA: 01:47:39

################################################################################
                     [1m Learning iteration 166/3000 [0m                      

                       Computation: 47458 steps/s (collection: 1.956s, learning 0.116s)
             Mean action noise std: 1.56
          Mean value_function loss: 13.4742
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 57.6826
                       Mean reward: 23.85
               Mean episode length: 237.94
    Episode_Reward/reaching_object: 1.0450
    Episode_Reward/rotating_object: 4.8729
        Episode_Reward/action_rate: -0.0159
          Episode_Reward/joint_vel: -0.0363
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 16416768
                    Iteration time: 2.07s
                      Time elapsed: 00:06:20
                               ETA: 01:47:33

################################################################################
                     [1m Learning iteration 167/3000 [0m                      

                       Computation: 47940 steps/s (collection: 1.938s, learning 0.112s)
             Mean action noise std: 1.56
          Mean value_function loss: 13.4654
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 57.7439
                       Mean reward: 28.58
               Mean episode length: 235.50
    Episode_Reward/reaching_object: 1.0446
    Episode_Reward/rotating_object: 4.9021
        Episode_Reward/action_rate: -0.0160
          Episode_Reward/joint_vel: -0.0365
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 16515072
                    Iteration time: 2.05s
                      Time elapsed: 00:06:22
                               ETA: 01:47:27

################################################################################
                     [1m Learning iteration 168/3000 [0m                      

                       Computation: 48117 steps/s (collection: 1.927s, learning 0.116s)
             Mean action noise std: 1.56
          Mean value_function loss: 12.5448
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 57.7977
                       Mean reward: 30.05
               Mean episode length: 240.70
    Episode_Reward/reaching_object: 1.0570
    Episode_Reward/rotating_object: 5.0251
        Episode_Reward/action_rate: -0.0160
          Episode_Reward/joint_vel: -0.0377
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 16613376
                    Iteration time: 2.04s
                      Time elapsed: 00:06:24
                               ETA: 01:47:21

################################################################################
                     [1m Learning iteration 169/3000 [0m                      

                       Computation: 48024 steps/s (collection: 1.929s, learning 0.118s)
             Mean action noise std: 1.57
          Mean value_function loss: 11.8048
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 57.8518
                       Mean reward: 43.90
               Mean episode length: 236.39
    Episode_Reward/reaching_object: 1.0775
    Episode_Reward/rotating_object: 5.7471
        Episode_Reward/action_rate: -0.0159
          Episode_Reward/joint_vel: -0.0364
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 16711680
                    Iteration time: 2.05s
                      Time elapsed: 00:06:26
                               ETA: 01:47:15

################################################################################
                     [1m Learning iteration 170/3000 [0m                      

                       Computation: 48059 steps/s (collection: 1.932s, learning 0.114s)
             Mean action noise std: 1.57
          Mean value_function loss: 11.9019
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 57.8959
                       Mean reward: 24.03
               Mean episode length: 232.21
    Episode_Reward/reaching_object: 1.0160
    Episode_Reward/rotating_object: 3.8122
        Episode_Reward/action_rate: -0.0160
          Episode_Reward/joint_vel: -0.0370
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 16809984
                    Iteration time: 2.05s
                      Time elapsed: 00:06:28
                               ETA: 01:47:09

################################################################################
                     [1m Learning iteration 171/3000 [0m                      

                       Computation: 48190 steps/s (collection: 1.918s, learning 0.122s)
             Mean action noise std: 1.57
          Mean value_function loss: 12.0982
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 57.9647
                       Mean reward: 30.49
               Mean episode length: 232.19
    Episode_Reward/reaching_object: 1.0831
    Episode_Reward/rotating_object: 5.5966
        Episode_Reward/action_rate: -0.0163
          Episode_Reward/joint_vel: -0.0371
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 16908288
                    Iteration time: 2.04s
                      Time elapsed: 00:06:30
                               ETA: 01:47:02

################################################################################
                     [1m Learning iteration 172/3000 [0m                      

                       Computation: 47868 steps/s (collection: 1.937s, learning 0.117s)
             Mean action noise std: 1.58
          Mean value_function loss: 13.6171
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 58.0204
                       Mean reward: 24.09
               Mean episode length: 229.94
    Episode_Reward/reaching_object: 1.0255
    Episode_Reward/rotating_object: 5.0744
        Episode_Reward/action_rate: -0.0160
          Episode_Reward/joint_vel: -0.0362
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 17006592
                    Iteration time: 2.05s
                      Time elapsed: 00:06:32
                               ETA: 01:46:57

################################################################################
                     [1m Learning iteration 173/3000 [0m                      

                       Computation: 48085 steps/s (collection: 1.926s, learning 0.118s)
             Mean action noise std: 1.58
          Mean value_function loss: 11.7511
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 58.0927
                       Mean reward: 36.03
               Mean episode length: 235.99
    Episode_Reward/reaching_object: 1.0470
    Episode_Reward/rotating_object: 5.4983
        Episode_Reward/action_rate: -0.0164
          Episode_Reward/joint_vel: -0.0373
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 17104896
                    Iteration time: 2.04s
                      Time elapsed: 00:06:34
                               ETA: 01:46:51

################################################################################
                     [1m Learning iteration 174/3000 [0m                      

                       Computation: 47750 steps/s (collection: 1.940s, learning 0.119s)
             Mean action noise std: 1.58
          Mean value_function loss: 12.2383
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 58.1639
                       Mean reward: 22.52
               Mean episode length: 235.93
    Episode_Reward/reaching_object: 1.0262
    Episode_Reward/rotating_object: 4.0820
        Episode_Reward/action_rate: -0.0165
          Episode_Reward/joint_vel: -0.0380
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 17203200
                    Iteration time: 2.06s
                      Time elapsed: 00:06:36
                               ETA: 01:46:45

################################################################################
                     [1m Learning iteration 175/3000 [0m                      

                       Computation: 46600 steps/s (collection: 1.973s, learning 0.137s)
             Mean action noise std: 1.58
          Mean value_function loss: 12.2609
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 58.2113
                       Mean reward: 35.84
               Mean episode length: 235.46
    Episode_Reward/reaching_object: 1.0534
    Episode_Reward/rotating_object: 6.5891
        Episode_Reward/action_rate: -0.0165
          Episode_Reward/joint_vel: -0.0375
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 17301504
                    Iteration time: 2.11s
                      Time elapsed: 00:06:38
                               ETA: 01:46:40

################################################################################
                     [1m Learning iteration 176/3000 [0m                      

                       Computation: 47747 steps/s (collection: 1.933s, learning 0.126s)
             Mean action noise std: 1.59
          Mean value_function loss: 12.3348
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 58.2521
                       Mean reward: 33.43
               Mean episode length: 232.58
    Episode_Reward/reaching_object: 1.0524
    Episode_Reward/rotating_object: 5.6130
        Episode_Reward/action_rate: -0.0166
          Episode_Reward/joint_vel: -0.0383
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 17399808
                    Iteration time: 2.06s
                      Time elapsed: 00:06:40
                               ETA: 01:46:35

################################################################################
                     [1m Learning iteration 177/3000 [0m                      

                       Computation: 47590 steps/s (collection: 1.942s, learning 0.124s)
             Mean action noise std: 1.59
          Mean value_function loss: 10.8210
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 58.3033
                       Mean reward: 23.85
               Mean episode length: 232.79
    Episode_Reward/reaching_object: 0.9846
    Episode_Reward/rotating_object: 4.2352
        Episode_Reward/action_rate: -0.0165
          Episode_Reward/joint_vel: -0.0382
      Episode_Termination/time_out: 12.2500
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 17498112
                    Iteration time: 2.07s
                      Time elapsed: 00:06:42
                               ETA: 01:46:29

################################################################################
                     [1m Learning iteration 178/3000 [0m                      

                       Computation: 46495 steps/s (collection: 1.986s, learning 0.129s)
             Mean action noise std: 1.59
          Mean value_function loss: 12.7801
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 58.3633
                       Mean reward: 30.45
               Mean episode length: 234.94
    Episode_Reward/reaching_object: 1.0744
    Episode_Reward/rotating_object: 5.2217
        Episode_Reward/action_rate: -0.0167
          Episode_Reward/joint_vel: -0.0384
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 17596416
                    Iteration time: 2.11s
                      Time elapsed: 00:06:45
                               ETA: 01:46:25

################################################################################
                     [1m Learning iteration 179/3000 [0m                      

                       Computation: 47432 steps/s (collection: 1.952s, learning 0.121s)
             Mean action noise std: 1.59
          Mean value_function loss: 15.1673
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 58.4032
                       Mean reward: 33.37
               Mean episode length: 232.29
    Episode_Reward/reaching_object: 1.0552
    Episode_Reward/rotating_object: 5.0008
        Episode_Reward/action_rate: -0.0167
          Episode_Reward/joint_vel: -0.0385
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 17694720
                    Iteration time: 2.07s
                      Time elapsed: 00:06:47
                               ETA: 01:46:19

################################################################################
                     [1m Learning iteration 180/3000 [0m                      

                       Computation: 48527 steps/s (collection: 1.915s, learning 0.111s)
             Mean action noise std: 1.60
          Mean value_function loss: 12.9273
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 58.4428
                       Mean reward: 29.60
               Mean episode length: 240.71
    Episode_Reward/reaching_object: 1.0842
    Episode_Reward/rotating_object: 5.7832
        Episode_Reward/action_rate: -0.0169
          Episode_Reward/joint_vel: -0.0385
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 17793024
                    Iteration time: 2.03s
                      Time elapsed: 00:06:49
                               ETA: 01:46:13

################################################################################
                     [1m Learning iteration 181/3000 [0m                      

                       Computation: 48040 steps/s (collection: 1.929s, learning 0.118s)
             Mean action noise std: 1.60
          Mean value_function loss: 13.7936
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 58.4958
                       Mean reward: 24.33
               Mean episode length: 240.12
    Episode_Reward/reaching_object: 1.0752
    Episode_Reward/rotating_object: 5.2195
        Episode_Reward/action_rate: -0.0172
          Episode_Reward/joint_vel: -0.0399
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 17891328
                    Iteration time: 2.05s
                      Time elapsed: 00:06:51
                               ETA: 01:46:08

################################################################################
                     [1m Learning iteration 182/3000 [0m                      

                       Computation: 48399 steps/s (collection: 1.917s, learning 0.114s)
             Mean action noise std: 1.60
          Mean value_function loss: 13.5096
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 58.5393
                       Mean reward: 27.70
               Mean episode length: 233.81
    Episode_Reward/reaching_object: 1.0423
    Episode_Reward/rotating_object: 5.4895
        Episode_Reward/action_rate: -0.0171
          Episode_Reward/joint_vel: -0.0400
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 17989632
                    Iteration time: 2.03s
                      Time elapsed: 00:06:53
                               ETA: 01:46:02

################################################################################
                     [1m Learning iteration 183/3000 [0m                      

                       Computation: 47698 steps/s (collection: 1.943s, learning 0.118s)
             Mean action noise std: 1.61
          Mean value_function loss: 14.8397
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 58.5991
                       Mean reward: 36.06
               Mean episode length: 237.33
    Episode_Reward/reaching_object: 1.0824
    Episode_Reward/rotating_object: 6.6351
        Episode_Reward/action_rate: -0.0171
          Episode_Reward/joint_vel: -0.0395
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 18087936
                    Iteration time: 2.06s
                      Time elapsed: 00:06:55
                               ETA: 01:45:57

################################################################################
                     [1m Learning iteration 184/3000 [0m                      

                       Computation: 48404 steps/s (collection: 1.919s, learning 0.112s)
             Mean action noise std: 1.61
          Mean value_function loss: 14.5026
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 58.6530
                       Mean reward: 35.03
               Mean episode length: 240.54
    Episode_Reward/reaching_object: 1.0960
    Episode_Reward/rotating_object: 5.6678
        Episode_Reward/action_rate: -0.0175
          Episode_Reward/joint_vel: -0.0410
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 18186240
                    Iteration time: 2.03s
                      Time elapsed: 00:06:57
                               ETA: 01:45:51

################################################################################
                     [1m Learning iteration 185/3000 [0m                      

                       Computation: 48028 steps/s (collection: 1.931s, learning 0.116s)
             Mean action noise std: 1.61
          Mean value_function loss: 13.2484
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 58.7196
                       Mean reward: 39.06
               Mean episode length: 242.71
    Episode_Reward/reaching_object: 1.0623
    Episode_Reward/rotating_object: 5.7219
        Episode_Reward/action_rate: -0.0173
          Episode_Reward/joint_vel: -0.0398
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 18284544
                    Iteration time: 2.05s
                      Time elapsed: 00:06:59
                               ETA: 01:45:46

################################################################################
                     [1m Learning iteration 186/3000 [0m                      

                       Computation: 47770 steps/s (collection: 1.943s, learning 0.115s)
             Mean action noise std: 1.61
          Mean value_function loss: 13.6121
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 58.7776
                       Mean reward: 35.47
               Mean episode length: 242.81
    Episode_Reward/reaching_object: 1.0747
    Episode_Reward/rotating_object: 6.1109
        Episode_Reward/action_rate: -0.0176
          Episode_Reward/joint_vel: -0.0410
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 18382848
                    Iteration time: 2.06s
                      Time elapsed: 00:07:01
                               ETA: 01:45:41

################################################################################
                     [1m Learning iteration 187/3000 [0m                      

                       Computation: 48393 steps/s (collection: 1.918s, learning 0.113s)
             Mean action noise std: 1.62
          Mean value_function loss: 13.6693
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 58.8245
                       Mean reward: 31.81
               Mean episode length: 236.05
    Episode_Reward/reaching_object: 1.1232
    Episode_Reward/rotating_object: 5.9152
        Episode_Reward/action_rate: -0.0176
          Episode_Reward/joint_vel: -0.0411
      Episode_Termination/time_out: 13.5000
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 18481152
                    Iteration time: 2.03s
                      Time elapsed: 00:07:03
                               ETA: 01:45:35

################################################################################
                     [1m Learning iteration 188/3000 [0m                      

                       Computation: 48289 steps/s (collection: 1.919s, learning 0.117s)
             Mean action noise std: 1.62
          Mean value_function loss: 11.1991
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 58.8855
                       Mean reward: 31.76
               Mean episode length: 244.92
    Episode_Reward/reaching_object: 1.1008
    Episode_Reward/rotating_object: 5.9273
        Episode_Reward/action_rate: -0.0177
          Episode_Reward/joint_vel: -0.0412
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 18579456
                    Iteration time: 2.04s
                      Time elapsed: 00:07:05
                               ETA: 01:45:29

################################################################################
                     [1m Learning iteration 189/3000 [0m                      

                       Computation: 48542 steps/s (collection: 1.912s, learning 0.114s)
             Mean action noise std: 1.62
          Mean value_function loss: 12.1306
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 58.9310
                       Mean reward: 33.23
               Mean episode length: 236.08
    Episode_Reward/reaching_object: 1.1091
    Episode_Reward/rotating_object: 5.0493
        Episode_Reward/action_rate: -0.0178
          Episode_Reward/joint_vel: -0.0419
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 18677760
                    Iteration time: 2.03s
                      Time elapsed: 00:07:07
                               ETA: 01:45:24

################################################################################
                     [1m Learning iteration 190/3000 [0m                      

                       Computation: 47949 steps/s (collection: 1.934s, learning 0.116s)
             Mean action noise std: 1.63
          Mean value_function loss: 14.1872
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 58.9923
                       Mean reward: 32.50
               Mean episode length: 240.99
    Episode_Reward/reaching_object: 1.1025
    Episode_Reward/rotating_object: 6.3627
        Episode_Reward/action_rate: -0.0178
          Episode_Reward/joint_vel: -0.0418
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 18776064
                    Iteration time: 2.05s
                      Time elapsed: 00:07:09
                               ETA: 01:45:19

################################################################################
                     [1m Learning iteration 191/3000 [0m                      

                       Computation: 48167 steps/s (collection: 1.923s, learning 0.118s)
             Mean action noise std: 1.63
          Mean value_function loss: 13.1557
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 59.0609
                       Mean reward: 34.41
               Mean episode length: 240.26
    Episode_Reward/reaching_object: 1.1040
    Episode_Reward/rotating_object: 6.0276
        Episode_Reward/action_rate: -0.0179
          Episode_Reward/joint_vel: -0.0421
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 18874368
                    Iteration time: 2.04s
                      Time elapsed: 00:07:11
                               ETA: 01:45:13

################################################################################
                     [1m Learning iteration 192/3000 [0m                      

                       Computation: 48520 steps/s (collection: 1.915s, learning 0.111s)
             Mean action noise std: 1.63
          Mean value_function loss: 13.8614
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 59.1098
                       Mean reward: 33.23
               Mean episode length: 243.85
    Episode_Reward/reaching_object: 1.1110
    Episode_Reward/rotating_object: 5.6294
        Episode_Reward/action_rate: -0.0181
          Episode_Reward/joint_vel: -0.0429
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 18972672
                    Iteration time: 2.03s
                      Time elapsed: 00:07:13
                               ETA: 01:45:08

################################################################################
                     [1m Learning iteration 193/3000 [0m                      

                       Computation: 47651 steps/s (collection: 1.948s, learning 0.115s)
             Mean action noise std: 1.64
          Mean value_function loss: 14.0164
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 59.1584
                       Mean reward: 32.49
               Mean episode length: 241.84
    Episode_Reward/reaching_object: 1.1406
    Episode_Reward/rotating_object: 6.8840
        Episode_Reward/action_rate: -0.0179
          Episode_Reward/joint_vel: -0.0423
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.5833
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 19070976
                    Iteration time: 2.06s
                      Time elapsed: 00:07:15
                               ETA: 01:45:03

################################################################################
                     [1m Learning iteration 194/3000 [0m                      

                       Computation: 47819 steps/s (collection: 1.942s, learning 0.114s)
             Mean action noise std: 1.64
          Mean value_function loss: 13.3742
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 59.2278
                       Mean reward: 37.50
               Mean episode length: 234.31
    Episode_Reward/reaching_object: 1.0862
    Episode_Reward/rotating_object: 6.6185
        Episode_Reward/action_rate: -0.0178
          Episode_Reward/joint_vel: -0.0429
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 19169280
                    Iteration time: 2.06s
                      Time elapsed: 00:07:17
                               ETA: 01:44:58

################################################################################
                     [1m Learning iteration 195/3000 [0m                      

                       Computation: 46910 steps/s (collection: 1.973s, learning 0.122s)
             Mean action noise std: 1.64
          Mean value_function loss: 13.9950
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 59.2854
                       Mean reward: 33.90
               Mean episode length: 240.31
    Episode_Reward/reaching_object: 1.1274
    Episode_Reward/rotating_object: 4.9186
        Episode_Reward/action_rate: -0.0181
          Episode_Reward/joint_vel: -0.0441
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 19267584
                    Iteration time: 2.10s
                      Time elapsed: 00:07:19
                               ETA: 01:44:54

################################################################################
                     [1m Learning iteration 196/3000 [0m                      

                       Computation: 47446 steps/s (collection: 1.952s, learning 0.120s)
             Mean action noise std: 1.65
          Mean value_function loss: 14.9844
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 59.3496
                       Mean reward: 32.95
               Mean episode length: 236.16
    Episode_Reward/reaching_object: 1.1335
    Episode_Reward/rotating_object: 5.9722
        Episode_Reward/action_rate: -0.0181
          Episode_Reward/joint_vel: -0.0428
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 19365888
                    Iteration time: 2.07s
                      Time elapsed: 00:07:21
                               ETA: 01:44:49

################################################################################
                     [1m Learning iteration 197/3000 [0m                      

                       Computation: 47729 steps/s (collection: 1.943s, learning 0.117s)
             Mean action noise std: 1.65
          Mean value_function loss: 17.0648
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 59.4245
                       Mean reward: 37.45
               Mean episode length: 234.28
    Episode_Reward/reaching_object: 1.1308
    Episode_Reward/rotating_object: 6.7121
        Episode_Reward/action_rate: -0.0182
          Episode_Reward/joint_vel: -0.0444
      Episode_Termination/time_out: 13.7500
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 19464192
                    Iteration time: 2.06s
                      Time elapsed: 00:07:23
                               ETA: 01:44:44

################################################################################
                     [1m Learning iteration 198/3000 [0m                      

                       Computation: 47319 steps/s (collection: 1.985s, learning 0.093s)
             Mean action noise std: 1.65
          Mean value_function loss: 14.6117
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 59.4752
                       Mean reward: 33.90
               Mean episode length: 241.44
    Episode_Reward/reaching_object: 1.1264
    Episode_Reward/rotating_object: 6.6571
        Episode_Reward/action_rate: -0.0185
          Episode_Reward/joint_vel: -0.0448
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 19562496
                    Iteration time: 2.08s
                      Time elapsed: 00:07:26
                               ETA: 01:44:40

################################################################################
                     [1m Learning iteration 199/3000 [0m                      

                       Computation: 47847 steps/s (collection: 1.956s, learning 0.098s)
             Mean action noise std: 1.65
          Mean value_function loss: 13.9736
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 59.5307
                       Mean reward: 33.07
               Mean episode length: 241.38
    Episode_Reward/reaching_object: 1.1168
    Episode_Reward/rotating_object: 5.3418
        Episode_Reward/action_rate: -0.0185
          Episode_Reward/joint_vel: -0.0443
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 19660800
                    Iteration time: 2.05s
                      Time elapsed: 00:07:28
                               ETA: 01:44:35

################################################################################
                     [1m Learning iteration 200/3000 [0m                      

                       Computation: 46823 steps/s (collection: 1.969s, learning 0.131s)
             Mean action noise std: 1.66
          Mean value_function loss: 15.3811
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 59.5756
                       Mean reward: 44.45
               Mean episode length: 237.82
    Episode_Reward/reaching_object: 1.1671
    Episode_Reward/rotating_object: 6.7951
        Episode_Reward/action_rate: -0.0187
          Episode_Reward/joint_vel: -0.0452
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 19759104
                    Iteration time: 2.10s
                      Time elapsed: 00:07:30
                               ETA: 01:44:31

################################################################################
                     [1m Learning iteration 201/3000 [0m                      

                       Computation: 46631 steps/s (collection: 1.986s, learning 0.122s)
             Mean action noise std: 1.66
          Mean value_function loss: 17.0813
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 59.6404
                       Mean reward: 41.55
               Mean episode length: 243.71
    Episode_Reward/reaching_object: 1.1629
    Episode_Reward/rotating_object: 6.9258
        Episode_Reward/action_rate: -0.0186
          Episode_Reward/joint_vel: -0.0447
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 19857408
                    Iteration time: 2.11s
                      Time elapsed: 00:07:32
                               ETA: 01:44:26

################################################################################
                     [1m Learning iteration 202/3000 [0m                      

                       Computation: 46862 steps/s (collection: 1.975s, learning 0.123s)
             Mean action noise std: 1.66
          Mean value_function loss: 17.2428
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 59.7069
                       Mean reward: 38.79
               Mean episode length: 239.49
    Episode_Reward/reaching_object: 1.1733
    Episode_Reward/rotating_object: 6.4079
        Episode_Reward/action_rate: -0.0187
          Episode_Reward/joint_vel: -0.0446
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 19955712
                    Iteration time: 2.10s
                      Time elapsed: 00:07:34
                               ETA: 01:44:22

################################################################################
                     [1m Learning iteration 203/3000 [0m                      

                       Computation: 47237 steps/s (collection: 1.977s, learning 0.104s)
             Mean action noise std: 1.67
          Mean value_function loss: 18.6490
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 59.7753
                       Mean reward: 38.08
               Mean episode length: 242.10
    Episode_Reward/reaching_object: 1.1298
    Episode_Reward/rotating_object: 6.0015
        Episode_Reward/action_rate: -0.0189
          Episode_Reward/joint_vel: -0.0462
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 20054016
                    Iteration time: 2.08s
                      Time elapsed: 00:07:36
                               ETA: 01:44:18

################################################################################
                     [1m Learning iteration 204/3000 [0m                      

                       Computation: 47289 steps/s (collection: 1.978s, learning 0.101s)
             Mean action noise std: 1.67
          Mean value_function loss: 14.4996
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 59.8334
                       Mean reward: 37.85
               Mean episode length: 242.82
    Episode_Reward/reaching_object: 1.1556
    Episode_Reward/rotating_object: 6.4267
        Episode_Reward/action_rate: -0.0190
          Episode_Reward/joint_vel: -0.0457
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 20152320
                    Iteration time: 2.08s
                      Time elapsed: 00:07:38
                               ETA: 01:44:13

################################################################################
                     [1m Learning iteration 205/3000 [0m                      

                       Computation: 47421 steps/s (collection: 1.970s, learning 0.102s)
             Mean action noise std: 1.67
          Mean value_function loss: 16.9282
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 59.8845
                       Mean reward: 36.41
               Mean episode length: 233.11
    Episode_Reward/reaching_object: 1.1533
    Episode_Reward/rotating_object: 6.4212
        Episode_Reward/action_rate: -0.0189
          Episode_Reward/joint_vel: -0.0457
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 20250624
                    Iteration time: 2.07s
                      Time elapsed: 00:07:40
                               ETA: 01:44:09

################################################################################
                     [1m Learning iteration 206/3000 [0m                      

                       Computation: 39552 steps/s (collection: 2.338s, learning 0.147s)
             Mean action noise std: 1.68
          Mean value_function loss: 17.5735
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 59.9443
                       Mean reward: 38.88
               Mean episode length: 234.88
    Episode_Reward/reaching_object: 1.1648
    Episode_Reward/rotating_object: 7.7106
        Episode_Reward/action_rate: -0.0188
          Episode_Reward/joint_vel: -0.0459
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 20348928
                    Iteration time: 2.49s
                      Time elapsed: 00:07:43
                               ETA: 01:44:10

################################################################################
                     [1m Learning iteration 207/3000 [0m                      

                       Computation: 45661 steps/s (collection: 2.030s, learning 0.123s)
             Mean action noise std: 1.68
          Mean value_function loss: 15.1664
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 59.9921
                       Mean reward: 40.18
               Mean episode length: 237.89
    Episode_Reward/reaching_object: 1.1212
    Episode_Reward/rotating_object: 6.6849
        Episode_Reward/action_rate: -0.0187
          Episode_Reward/joint_vel: -0.0457
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 20447232
                    Iteration time: 2.15s
                      Time elapsed: 00:07:45
                               ETA: 01:44:07

################################################################################
                     [1m Learning iteration 208/3000 [0m                      

                       Computation: 45390 steps/s (collection: 2.049s, learning 0.117s)
             Mean action noise std: 1.68
          Mean value_function loss: 17.7128
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 60.0403
                       Mean reward: 34.54
               Mean episode length: 239.43
    Episode_Reward/reaching_object: 1.1402
    Episode_Reward/rotating_object: 5.7156
        Episode_Reward/action_rate: -0.0188
          Episode_Reward/joint_vel: -0.0467
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 20545536
                    Iteration time: 2.17s
                      Time elapsed: 00:07:47
                               ETA: 01:44:04

################################################################################
                     [1m Learning iteration 209/3000 [0m                      

                       Computation: 46026 steps/s (collection: 2.020s, learning 0.116s)
             Mean action noise std: 1.69
          Mean value_function loss: 16.4885
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 60.0991
                       Mean reward: 32.68
               Mean episode length: 228.82
    Episode_Reward/reaching_object: 1.1155
    Episode_Reward/rotating_object: 5.5208
        Episode_Reward/action_rate: -0.0189
          Episode_Reward/joint_vel: -0.0457
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.5833
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 20643840
                    Iteration time: 2.14s
                      Time elapsed: 00:07:49
                               ETA: 01:44:00

################################################################################
                     [1m Learning iteration 210/3000 [0m                      

                       Computation: 46959 steps/s (collection: 1.971s, learning 0.122s)
             Mean action noise std: 1.69
          Mean value_function loss: 15.7600
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 60.1590
                       Mean reward: 43.73
               Mean episode length: 234.39
    Episode_Reward/reaching_object: 1.1488
    Episode_Reward/rotating_object: 7.1781
        Episode_Reward/action_rate: -0.0192
          Episode_Reward/joint_vel: -0.0461
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 20742144
                    Iteration time: 2.09s
                      Time elapsed: 00:07:51
                               ETA: 01:43:56

################################################################################
                     [1m Learning iteration 211/3000 [0m                      

                       Computation: 46808 steps/s (collection: 1.990s, learning 0.110s)
             Mean action noise std: 1.69
          Mean value_function loss: 17.6798
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 60.1917
                       Mean reward: 47.64
               Mean episode length: 241.64
    Episode_Reward/reaching_object: 1.1656
    Episode_Reward/rotating_object: 7.1211
        Episode_Reward/action_rate: -0.0196
          Episode_Reward/joint_vel: -0.0475
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 20840448
                    Iteration time: 2.10s
                      Time elapsed: 00:07:53
                               ETA: 01:43:52

################################################################################
                     [1m Learning iteration 212/3000 [0m                      

                       Computation: 47486 steps/s (collection: 1.966s, learning 0.104s)
             Mean action noise std: 1.69
          Mean value_function loss: 20.4598
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 60.2332
                       Mean reward: 38.33
               Mean episode length: 240.00
    Episode_Reward/reaching_object: 1.1347
    Episode_Reward/rotating_object: 6.7620
        Episode_Reward/action_rate: -0.0193
          Episode_Reward/joint_vel: -0.0477
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 20938752
                    Iteration time: 2.07s
                      Time elapsed: 00:07:55
                               ETA: 01:43:47

################################################################################
                     [1m Learning iteration 213/3000 [0m                      

                       Computation: 46658 steps/s (collection: 2.000s, learning 0.107s)
             Mean action noise std: 1.70
          Mean value_function loss: 16.9799
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 60.2798
                       Mean reward: 40.77
               Mean episode length: 239.24
    Episode_Reward/reaching_object: 1.1277
    Episode_Reward/rotating_object: 6.8765
        Episode_Reward/action_rate: -0.0196
          Episode_Reward/joint_vel: -0.0474
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 21037056
                    Iteration time: 2.11s
                      Time elapsed: 00:07:57
                               ETA: 01:43:44

################################################################################
                     [1m Learning iteration 214/3000 [0m                      

                       Computation: 46497 steps/s (collection: 1.992s, learning 0.123s)
             Mean action noise std: 1.70
          Mean value_function loss: 18.9459
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 60.3289
                       Mean reward: 30.39
               Mean episode length: 235.30
    Episode_Reward/reaching_object: 1.1509
    Episode_Reward/rotating_object: 5.1386
        Episode_Reward/action_rate: -0.0196
          Episode_Reward/joint_vel: -0.0480
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 21135360
                    Iteration time: 2.11s
                      Time elapsed: 00:08:00
                               ETA: 01:43:40

################################################################################
                     [1m Learning iteration 215/3000 [0m                      

                       Computation: 45647 steps/s (collection: 1.972s, learning 0.181s)
             Mean action noise std: 1.70
          Mean value_function loss: 19.2224
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 60.3847
                       Mean reward: 41.83
               Mean episode length: 234.02
    Episode_Reward/reaching_object: 1.1504
    Episode_Reward/rotating_object: 7.8788
        Episode_Reward/action_rate: -0.0197
          Episode_Reward/joint_vel: -0.0473
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 21233664
                    Iteration time: 2.15s
                      Time elapsed: 00:08:02
                               ETA: 01:43:37

################################################################################
                     [1m Learning iteration 216/3000 [0m                      

                       Computation: 47110 steps/s (collection: 1.970s, learning 0.117s)
             Mean action noise std: 1.70
          Mean value_function loss: 19.4836
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 60.4381
                       Mean reward: 43.71
               Mean episode length: 240.03
    Episode_Reward/reaching_object: 1.1718
    Episode_Reward/rotating_object: 7.2336
        Episode_Reward/action_rate: -0.0201
          Episode_Reward/joint_vel: -0.0490
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 21331968
                    Iteration time: 2.09s
                      Time elapsed: 00:08:04
                               ETA: 01:43:32

################################################################################
                     [1m Learning iteration 217/3000 [0m                      

                       Computation: 46495 steps/s (collection: 1.985s, learning 0.130s)
             Mean action noise std: 1.71
          Mean value_function loss: 17.2167
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 60.4971
                       Mean reward: 46.01
               Mean episode length: 239.90
    Episode_Reward/reaching_object: 1.1820
    Episode_Reward/rotating_object: 7.8442
        Episode_Reward/action_rate: -0.0198
          Episode_Reward/joint_vel: -0.0465
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 21430272
                    Iteration time: 2.11s
                      Time elapsed: 00:08:06
                               ETA: 01:43:29

################################################################################
                     [1m Learning iteration 218/3000 [0m                      

                       Computation: 46797 steps/s (collection: 1.988s, learning 0.112s)
             Mean action noise std: 1.71
          Mean value_function loss: 18.5606
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 60.5421
                       Mean reward: 43.63
               Mean episode length: 231.32
    Episode_Reward/reaching_object: 1.1565
    Episode_Reward/rotating_object: 7.0004
        Episode_Reward/action_rate: -0.0195
          Episode_Reward/joint_vel: -0.0462
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 21528576
                    Iteration time: 2.10s
                      Time elapsed: 00:08:08
                               ETA: 01:43:25

################################################################################
                     [1m Learning iteration 219/3000 [0m                      

                       Computation: 47022 steps/s (collection: 1.985s, learning 0.105s)
             Mean action noise std: 1.71
          Mean value_function loss: 18.0440
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 60.6001
                       Mean reward: 49.76
               Mean episode length: 234.96
    Episode_Reward/reaching_object: 1.1841
    Episode_Reward/rotating_object: 7.7415
        Episode_Reward/action_rate: -0.0199
          Episode_Reward/joint_vel: -0.0463
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 21626880
                    Iteration time: 2.09s
                      Time elapsed: 00:08:10
                               ETA: 01:43:21

################################################################################
                     [1m Learning iteration 220/3000 [0m                      

                       Computation: 47909 steps/s (collection: 1.938s, learning 0.114s)
             Mean action noise std: 1.72
          Mean value_function loss: 18.2326
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 60.6639
                       Mean reward: 70.24
               Mean episode length: 241.26
    Episode_Reward/reaching_object: 1.2016
    Episode_Reward/rotating_object: 8.3298
        Episode_Reward/action_rate: -0.0200
          Episode_Reward/joint_vel: -0.0471
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 21725184
                    Iteration time: 2.05s
                      Time elapsed: 00:08:12
                               ETA: 01:43:16

################################################################################
                     [1m Learning iteration 221/3000 [0m                      

                       Computation: 47130 steps/s (collection: 1.988s, learning 0.098s)
             Mean action noise std: 1.72
          Mean value_function loss: 19.0003
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 60.7221
                       Mean reward: 50.30
               Mean episode length: 239.53
    Episode_Reward/reaching_object: 1.2146
    Episode_Reward/rotating_object: 8.1588
        Episode_Reward/action_rate: -0.0202
          Episode_Reward/joint_vel: -0.0486
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 21823488
                    Iteration time: 2.09s
                      Time elapsed: 00:08:14
                               ETA: 01:43:12

################################################################################
                     [1m Learning iteration 222/3000 [0m                      

                       Computation: 47289 steps/s (collection: 1.962s, learning 0.116s)
             Mean action noise std: 1.72
          Mean value_function loss: 18.3197
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 60.7675
                       Mean reward: 36.18
               Mean episode length: 239.26
    Episode_Reward/reaching_object: 1.1966
    Episode_Reward/rotating_object: 6.9779
        Episode_Reward/action_rate: -0.0202
          Episode_Reward/joint_vel: -0.0477
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 21921792
                    Iteration time: 2.08s
                      Time elapsed: 00:08:16
                               ETA: 01:43:08

################################################################################
                     [1m Learning iteration 223/3000 [0m                      

                       Computation: 45839 steps/s (collection: 2.030s, learning 0.114s)
             Mean action noise std: 1.72
          Mean value_function loss: 18.1928
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 60.8183
                       Mean reward: 28.69
               Mean episode length: 232.61
    Episode_Reward/reaching_object: 1.1566
    Episode_Reward/rotating_object: 6.6591
        Episode_Reward/action_rate: -0.0200
          Episode_Reward/joint_vel: -0.0479
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 22020096
                    Iteration time: 2.14s
                      Time elapsed: 00:08:18
                               ETA: 01:43:05

################################################################################
                     [1m Learning iteration 224/3000 [0m                      

                       Computation: 46944 steps/s (collection: 1.981s, learning 0.113s)
             Mean action noise std: 1.73
          Mean value_function loss: 17.7173
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 60.8614
                       Mean reward: 42.49
               Mean episode length: 238.76
    Episode_Reward/reaching_object: 1.1574
    Episode_Reward/rotating_object: 9.2585
        Episode_Reward/action_rate: -0.0202
          Episode_Reward/joint_vel: -0.0471
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 22118400
                    Iteration time: 2.09s
                      Time elapsed: 00:08:21
                               ETA: 01:43:01

################################################################################
                     [1m Learning iteration 225/3000 [0m                      

                       Computation: 46000 steps/s (collection: 1.978s, learning 0.159s)
             Mean action noise std: 1.73
          Mean value_function loss: 18.0856
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 60.9229
                       Mean reward: 57.35
               Mean episode length: 236.97
    Episode_Reward/reaching_object: 1.2023
    Episode_Reward/rotating_object: 9.0002
        Episode_Reward/action_rate: -0.0205
          Episode_Reward/joint_vel: -0.0467
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 22216704
                    Iteration time: 2.14s
                      Time elapsed: 00:08:23
                               ETA: 01:42:58

################################################################################
                     [1m Learning iteration 226/3000 [0m                      

                       Computation: 46893 steps/s (collection: 1.979s, learning 0.118s)
             Mean action noise std: 1.73
          Mean value_function loss: 19.6212
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 60.9699
                       Mean reward: 27.77
               Mean episode length: 232.69
    Episode_Reward/reaching_object: 1.1325
    Episode_Reward/rotating_object: 7.9213
        Episode_Reward/action_rate: -0.0201
          Episode_Reward/joint_vel: -0.0471
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 22315008
                    Iteration time: 2.10s
                      Time elapsed: 00:08:25
                               ETA: 01:42:54

################################################################################
                     [1m Learning iteration 227/3000 [0m                      

                       Computation: 47763 steps/s (collection: 1.946s, learning 0.112s)
             Mean action noise std: 1.74
          Mean value_function loss: 19.0511
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 61.0235
                       Mean reward: 46.99
               Mean episode length: 241.04
    Episode_Reward/reaching_object: 1.1580
    Episode_Reward/rotating_object: 7.2651
        Episode_Reward/action_rate: -0.0204
          Episode_Reward/joint_vel: -0.0469
      Episode_Termination/time_out: 13.4583
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 22413312
                    Iteration time: 2.06s
                      Time elapsed: 00:08:27
                               ETA: 01:42:50

################################################################################
                     [1m Learning iteration 228/3000 [0m                      

                       Computation: 47954 steps/s (collection: 1.952s, learning 0.098s)
             Mean action noise std: 1.74
          Mean value_function loss: 19.1424
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 61.0609
                       Mean reward: 61.61
               Mean episode length: 237.59
    Episode_Reward/reaching_object: 1.1563
    Episode_Reward/rotating_object: 8.7169
        Episode_Reward/action_rate: -0.0204
          Episode_Reward/joint_vel: -0.0461
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 22511616
                    Iteration time: 2.05s
                      Time elapsed: 00:08:29
                               ETA: 01:42:45

################################################################################
                     [1m Learning iteration 229/3000 [0m                      

                       Computation: 47067 steps/s (collection: 1.968s, learning 0.121s)
             Mean action noise std: 1.74
          Mean value_function loss: 20.9737
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 61.1115
                       Mean reward: 42.15
               Mean episode length: 243.41
    Episode_Reward/reaching_object: 1.1819
    Episode_Reward/rotating_object: 7.0129
        Episode_Reward/action_rate: -0.0208
          Episode_Reward/joint_vel: -0.0481
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 22609920
                    Iteration time: 2.09s
                      Time elapsed: 00:08:31
                               ETA: 01:42:42

################################################################################
                     [1m Learning iteration 230/3000 [0m                      

                       Computation: 46211 steps/s (collection: 1.987s, learning 0.140s)
             Mean action noise std: 1.74
          Mean value_function loss: 21.5777
               Mean surrogate loss: -0.0100
                 Mean entropy loss: 61.1714
                       Mean reward: 37.34
               Mean episode length: 229.06
    Episode_Reward/reaching_object: 1.1720
    Episode_Reward/rotating_object: 8.4911
        Episode_Reward/action_rate: -0.0206
          Episode_Reward/joint_vel: -0.0481
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 22708224
                    Iteration time: 2.13s
                      Time elapsed: 00:08:33
                               ETA: 01:42:38

################################################################################
                     [1m Learning iteration 231/3000 [0m                      

                       Computation: 45910 steps/s (collection: 2.016s, learning 0.125s)
             Mean action noise std: 1.75
          Mean value_function loss: 19.2795
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 61.2139
                       Mean reward: 31.38
               Mean episode length: 234.98
    Episode_Reward/reaching_object: 1.1765
    Episode_Reward/rotating_object: 6.4945
        Episode_Reward/action_rate: -0.0207
          Episode_Reward/joint_vel: -0.0470
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 22806528
                    Iteration time: 2.14s
                      Time elapsed: 00:08:35
                               ETA: 01:42:35

################################################################################
                     [1m Learning iteration 232/3000 [0m                      

                       Computation: 46320 steps/s (collection: 2.013s, learning 0.110s)
             Mean action noise std: 1.75
          Mean value_function loss: 17.4890
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 61.2493
                       Mean reward: 51.90
               Mean episode length: 239.45
    Episode_Reward/reaching_object: 1.1751
    Episode_Reward/rotating_object: 8.0256
        Episode_Reward/action_rate: -0.0207
          Episode_Reward/joint_vel: -0.0482
      Episode_Termination/time_out: 13.8750
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 22904832
                    Iteration time: 2.12s
                      Time elapsed: 00:08:37
                               ETA: 01:42:32

################################################################################
                     [1m Learning iteration 233/3000 [0m                      

                       Computation: 47632 steps/s (collection: 1.964s, learning 0.100s)
             Mean action noise std: 1.75
          Mean value_function loss: 21.0077
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 61.2977
                       Mean reward: 57.00
               Mean episode length: 229.23
    Episode_Reward/reaching_object: 1.1739
    Episode_Reward/rotating_object: 9.7245
        Episode_Reward/action_rate: -0.0206
          Episode_Reward/joint_vel: -0.0461
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 23003136
                    Iteration time: 2.06s
                      Time elapsed: 00:08:39
                               ETA: 01:42:27

################################################################################
                     [1m Learning iteration 234/3000 [0m                      

                       Computation: 46605 steps/s (collection: 2.003s, learning 0.106s)
             Mean action noise std: 1.75
          Mean value_function loss: 19.2733
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 61.3405
                       Mean reward: 47.92
               Mean episode length: 232.48
    Episode_Reward/reaching_object: 1.1802
    Episode_Reward/rotating_object: 7.2851
        Episode_Reward/action_rate: -0.0208
          Episode_Reward/joint_vel: -0.0497
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 23101440
                    Iteration time: 2.11s
                      Time elapsed: 00:08:42
                               ETA: 01:42:24

################################################################################
                     [1m Learning iteration 235/3000 [0m                      

                       Computation: 45754 steps/s (collection: 2.010s, learning 0.139s)
             Mean action noise std: 1.76
          Mean value_function loss: 20.2163
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 61.3940
                       Mean reward: 38.54
               Mean episode length: 231.72
    Episode_Reward/reaching_object: 1.1621
    Episode_Reward/rotating_object: 8.7324
        Episode_Reward/action_rate: -0.0208
          Episode_Reward/joint_vel: -0.0487
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 23199744
                    Iteration time: 2.15s
                      Time elapsed: 00:08:44
                               ETA: 01:42:21

################################################################################
                     [1m Learning iteration 236/3000 [0m                      

                       Computation: 45399 steps/s (collection: 2.031s, learning 0.135s)
             Mean action noise std: 1.76
          Mean value_function loss: 21.8381
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 61.4551
                       Mean reward: 46.10
               Mean episode length: 233.55
    Episode_Reward/reaching_object: 1.1754
    Episode_Reward/rotating_object: 7.4331
        Episode_Reward/action_rate: -0.0207
          Episode_Reward/joint_vel: -0.0479
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 23298048
                    Iteration time: 2.17s
                      Time elapsed: 00:08:46
                               ETA: 01:42:18

################################################################################
                     [1m Learning iteration 237/3000 [0m                      

                       Computation: 45258 steps/s (collection: 2.049s, learning 0.124s)
             Mean action noise std: 1.76
          Mean value_function loss: 21.1221
               Mean surrogate loss: -0.0097
                 Mean entropy loss: 61.5158
                       Mean reward: 32.95
               Mean episode length: 228.76
    Episode_Reward/reaching_object: 1.1457
    Episode_Reward/rotating_object: 6.9261
        Episode_Reward/action_rate: -0.0205
          Episode_Reward/joint_vel: -0.0475
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 23396352
                    Iteration time: 2.17s
                      Time elapsed: 00:08:48
                               ETA: 01:42:15

################################################################################
                     [1m Learning iteration 238/3000 [0m                      

                       Computation: 46234 steps/s (collection: 2.012s, learning 0.114s)
             Mean action noise std: 1.77
          Mean value_function loss: 22.5349
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 61.5636
                       Mean reward: 57.94
               Mean episode length: 230.64
    Episode_Reward/reaching_object: 1.1828
    Episode_Reward/rotating_object: 9.1742
        Episode_Reward/action_rate: -0.0209
          Episode_Reward/joint_vel: -0.0477
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.5833
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 23494656
                    Iteration time: 2.13s
                      Time elapsed: 00:08:50
                               ETA: 01:42:12

################################################################################
                     [1m Learning iteration 239/3000 [0m                      

                       Computation: 46350 steps/s (collection: 1.991s, learning 0.130s)
             Mean action noise std: 1.77
          Mean value_function loss: 18.3426
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 61.6050
                       Mean reward: 56.50
               Mean episode length: 230.69
    Episode_Reward/reaching_object: 1.1645
    Episode_Reward/rotating_object: 8.1279
        Episode_Reward/action_rate: -0.0208
          Episode_Reward/joint_vel: -0.0486
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 23592960
                    Iteration time: 2.12s
                      Time elapsed: 00:08:52
                               ETA: 01:42:08

################################################################################
                     [1m Learning iteration 240/3000 [0m                      

                       Computation: 46279 steps/s (collection: 2.016s, learning 0.109s)
             Mean action noise std: 1.77
          Mean value_function loss: 19.8061
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 61.6507
                       Mean reward: 54.69
               Mean episode length: 243.34
    Episode_Reward/reaching_object: 1.1745
    Episode_Reward/rotating_object: 8.2193
        Episode_Reward/action_rate: -0.0215
          Episode_Reward/joint_vel: -0.0496
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 23691264
                    Iteration time: 2.12s
                      Time elapsed: 00:08:54
                               ETA: 01:42:05

################################################################################
                     [1m Learning iteration 241/3000 [0m                      

                       Computation: 45801 steps/s (collection: 2.024s, learning 0.122s)
             Mean action noise std: 1.77
          Mean value_function loss: 22.5989
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 61.6882
                       Mean reward: 42.12
               Mean episode length: 234.75
    Episode_Reward/reaching_object: 1.1870
    Episode_Reward/rotating_object: 7.4658
        Episode_Reward/action_rate: -0.0209
          Episode_Reward/joint_vel: -0.0475
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 23789568
                    Iteration time: 2.15s
                      Time elapsed: 00:08:57
                               ETA: 01:42:02

################################################################################
                     [1m Learning iteration 242/3000 [0m                      

                       Computation: 45963 steps/s (collection: 2.005s, learning 0.134s)
             Mean action noise std: 1.78
          Mean value_function loss: 24.8563
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 61.7294
                       Mean reward: 46.88
               Mean episode length: 231.30
    Episode_Reward/reaching_object: 1.1788
    Episode_Reward/rotating_object: 9.6344
        Episode_Reward/action_rate: -0.0210
          Episode_Reward/joint_vel: -0.0474
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 23887872
                    Iteration time: 2.14s
                      Time elapsed: 00:08:59
                               ETA: 01:41:59

################################################################################
                     [1m Learning iteration 243/3000 [0m                      

                       Computation: 45037 steps/s (collection: 1.989s, learning 0.194s)
             Mean action noise std: 1.78
          Mean value_function loss: 22.8472
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 61.7744
                       Mean reward: 57.04
               Mean episode length: 227.18
    Episode_Reward/reaching_object: 1.1684
    Episode_Reward/rotating_object: 8.8929
        Episode_Reward/action_rate: -0.0208
          Episode_Reward/joint_vel: -0.0468
      Episode_Termination/time_out: 13.1667
Episode_Termination/object_dropping: 0.8333
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 23986176
                    Iteration time: 2.18s
                      Time elapsed: 00:09:01
                               ETA: 01:41:56

################################################################################
                     [1m Learning iteration 244/3000 [0m                      

                       Computation: 45871 steps/s (collection: 2.008s, learning 0.135s)
             Mean action noise std: 1.78
          Mean value_function loss: 21.6124
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 61.8132
                       Mean reward: 46.72
               Mean episode length: 234.68
    Episode_Reward/reaching_object: 1.2050
    Episode_Reward/rotating_object: 8.1916
        Episode_Reward/action_rate: -0.0214
          Episode_Reward/joint_vel: -0.0468
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 24084480
                    Iteration time: 2.14s
                      Time elapsed: 00:09:03
                               ETA: 01:41:53

################################################################################
                     [1m Learning iteration 245/3000 [0m                      

                       Computation: 46210 steps/s (collection: 2.027s, learning 0.100s)
             Mean action noise std: 1.78
          Mean value_function loss: 24.8849
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 61.8588
                       Mean reward: 41.70
               Mean episode length: 230.85
    Episode_Reward/reaching_object: 1.1991
    Episode_Reward/rotating_object: 8.4059
        Episode_Reward/action_rate: -0.0213
          Episode_Reward/joint_vel: -0.0473
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 24182784
                    Iteration time: 2.13s
                      Time elapsed: 00:09:05
                               ETA: 01:41:50

################################################################################
                     [1m Learning iteration 246/3000 [0m                      

                       Computation: 45323 steps/s (collection: 2.046s, learning 0.123s)
             Mean action noise std: 1.79
          Mean value_function loss: 24.6931
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 61.9019
                       Mean reward: 38.02
               Mean episode length: 229.97
    Episode_Reward/reaching_object: 1.1648
    Episode_Reward/rotating_object: 8.2757
        Episode_Reward/action_rate: -0.0211
          Episode_Reward/joint_vel: -0.0480
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 24281088
                    Iteration time: 2.17s
                      Time elapsed: 00:09:07
                               ETA: 01:41:47

################################################################################
                     [1m Learning iteration 247/3000 [0m                      

                       Computation: 45313 steps/s (collection: 2.061s, learning 0.109s)
             Mean action noise std: 1.79
          Mean value_function loss: 24.0682
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 61.9377
                       Mean reward: 49.10
               Mean episode length: 229.16
    Episode_Reward/reaching_object: 1.1787
    Episode_Reward/rotating_object: 8.5691
        Episode_Reward/action_rate: -0.0215
          Episode_Reward/joint_vel: -0.0490
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 24379392
                    Iteration time: 2.17s
                      Time elapsed: 00:09:09
                               ETA: 01:41:45

################################################################################
                     [1m Learning iteration 248/3000 [0m                      

                       Computation: 46050 steps/s (collection: 2.018s, learning 0.117s)
             Mean action noise std: 1.79
          Mean value_function loss: 28.6821
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 61.9751
                       Mean reward: 53.75
               Mean episode length: 231.08
    Episode_Reward/reaching_object: 1.1853
    Episode_Reward/rotating_object: 8.8656
        Episode_Reward/action_rate: -0.0213
          Episode_Reward/joint_vel: -0.0485
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 24477696
                    Iteration time: 2.13s
                      Time elapsed: 00:09:12
                               ETA: 01:41:41

################################################################################
                     [1m Learning iteration 249/3000 [0m                      

                       Computation: 46692 steps/s (collection: 1.987s, learning 0.118s)
             Mean action noise std: 1.79
          Mean value_function loss: 26.0682
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 62.0116
                       Mean reward: 43.47
               Mean episode length: 238.52
    Episode_Reward/reaching_object: 1.1862
    Episode_Reward/rotating_object: 8.2979
        Episode_Reward/action_rate: -0.0215
          Episode_Reward/joint_vel: -0.0487
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 24576000
                    Iteration time: 2.11s
                      Time elapsed: 00:09:14
                               ETA: 01:41:38

################################################################################
                     [1m Learning iteration 250/3000 [0m                      

                       Computation: 44848 steps/s (collection: 2.009s, learning 0.183s)
             Mean action noise std: 1.80
          Mean value_function loss: 26.6666
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 62.0572
                       Mean reward: 59.10
               Mean episode length: 220.81
    Episode_Reward/reaching_object: 1.1831
    Episode_Reward/rotating_object: 9.8422
        Episode_Reward/action_rate: -0.0212
          Episode_Reward/joint_vel: -0.0476
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 24674304
                    Iteration time: 2.19s
                      Time elapsed: 00:09:16
                               ETA: 01:41:35

################################################################################
                     [1m Learning iteration 251/3000 [0m                      

                       Computation: 44407 steps/s (collection: 2.113s, learning 0.101s)
             Mean action noise std: 1.80
          Mean value_function loss: 29.9376
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 62.1080
                       Mean reward: 43.69
               Mean episode length: 232.82
    Episode_Reward/reaching_object: 1.1984
    Episode_Reward/rotating_object: 9.4469
        Episode_Reward/action_rate: -0.0215
          Episode_Reward/joint_vel: -0.0483
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 24772608
                    Iteration time: 2.21s
                      Time elapsed: 00:09:18
                               ETA: 01:41:33

################################################################################
                     [1m Learning iteration 252/3000 [0m                      

                       Computation: 45373 steps/s (collection: 2.055s, learning 0.112s)
             Mean action noise std: 1.80
          Mean value_function loss: 26.9911
               Mean surrogate loss: -0.0098
                 Mean entropy loss: 62.1449
                       Mean reward: 63.21
               Mean episode length: 231.05
    Episode_Reward/reaching_object: 1.1984
    Episode_Reward/rotating_object: 9.3831
        Episode_Reward/action_rate: -0.0217
          Episode_Reward/joint_vel: -0.0482
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.6250
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 24870912
                    Iteration time: 2.17s
                      Time elapsed: 00:09:20
                               ETA: 01:41:30

################################################################################
                     [1m Learning iteration 253/3000 [0m                      

                       Computation: 45528 steps/s (collection: 2.030s, learning 0.129s)
             Mean action noise std: 1.80
          Mean value_function loss: 24.7277
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 62.1921
                       Mean reward: 61.83
               Mean episode length: 227.96
    Episode_Reward/reaching_object: 1.2030
    Episode_Reward/rotating_object: 9.8474
        Episode_Reward/action_rate: -0.0217
          Episode_Reward/joint_vel: -0.0484
      Episode_Termination/time_out: 13.6250
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 24969216
                    Iteration time: 2.16s
                      Time elapsed: 00:09:22
                               ETA: 01:41:28

################################################################################
                     [1m Learning iteration 254/3000 [0m                      

                       Computation: 45259 steps/s (collection: 2.035s, learning 0.137s)
             Mean action noise std: 1.81
          Mean value_function loss: 30.5205
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 62.2361
                       Mean reward: 53.56
               Mean episode length: 224.05
    Episode_Reward/reaching_object: 1.1711
    Episode_Reward/rotating_object: 8.6867
        Episode_Reward/action_rate: -0.0212
          Episode_Reward/joint_vel: -0.0471
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.5833
     Episode_Termination/robot_out: 4.1250
--------------------------------------------------------------------------------
                   Total timesteps: 25067520
                    Iteration time: 2.17s
                      Time elapsed: 00:09:25
                               ETA: 01:41:25

################################################################################
                     [1m Learning iteration 255/3000 [0m                      

                       Computation: 45728 steps/s (collection: 2.020s, learning 0.130s)
             Mean action noise std: 1.81
          Mean value_function loss: 28.5418
               Mean surrogate loss: -0.0096
                 Mean entropy loss: 62.2813
                       Mean reward: 44.77
               Mean episode length: 223.76
    Episode_Reward/reaching_object: 1.1813
    Episode_Reward/rotating_object: 10.3164
        Episode_Reward/action_rate: -0.0216
          Episode_Reward/joint_vel: -0.0467
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 25165824
                    Iteration time: 2.15s
                      Time elapsed: 00:09:27
                               ETA: 01:41:22

################################################################################
                     [1m Learning iteration 256/3000 [0m                      

                       Computation: 44668 steps/s (collection: 2.002s, learning 0.199s)
             Mean action noise std: 1.81
          Mean value_function loss: 25.3220
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 62.3191
                       Mean reward: 68.22
               Mean episode length: 232.89
    Episode_Reward/reaching_object: 1.2335
    Episode_Reward/rotating_object: 11.1657
        Episode_Reward/action_rate: -0.0221
          Episode_Reward/joint_vel: -0.0472
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 25264128
                    Iteration time: 2.20s
                      Time elapsed: 00:09:29
                               ETA: 01:41:20

################################################################################
                     [1m Learning iteration 257/3000 [0m                      

                       Computation: 45466 steps/s (collection: 2.022s, learning 0.141s)
             Mean action noise std: 1.81
          Mean value_function loss: 23.6747
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 62.3498
                       Mean reward: 51.75
               Mean episode length: 215.91
    Episode_Reward/reaching_object: 1.1889
    Episode_Reward/rotating_object: 9.0067
        Episode_Reward/action_rate: -0.0216
          Episode_Reward/joint_vel: -0.0481
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 25362432
                    Iteration time: 2.16s
                      Time elapsed: 00:09:31
                               ETA: 01:41:17

################################################################################
                     [1m Learning iteration 258/3000 [0m                      

                       Computation: 46527 steps/s (collection: 1.984s, learning 0.129s)
             Mean action noise std: 1.81
          Mean value_function loss: 26.7763
               Mean surrogate loss: -0.0096
                 Mean entropy loss: 62.3851
                       Mean reward: 56.93
               Mean episode length: 229.79
    Episode_Reward/reaching_object: 1.2153
    Episode_Reward/rotating_object: 11.3553
        Episode_Reward/action_rate: -0.0219
          Episode_Reward/joint_vel: -0.0471
      Episode_Termination/time_out: 13.6250
Episode_Termination/object_dropping: 0.5833
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 25460736
                    Iteration time: 2.11s
                      Time elapsed: 00:09:33
                               ETA: 01:41:14

################################################################################
                     [1m Learning iteration 259/3000 [0m                      

                       Computation: 45801 steps/s (collection: 2.038s, learning 0.108s)
             Mean action noise std: 1.82
          Mean value_function loss: 26.8070
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 62.4244
                       Mean reward: 62.96
               Mean episode length: 230.46
    Episode_Reward/reaching_object: 1.1683
    Episode_Reward/rotating_object: 9.9180
        Episode_Reward/action_rate: -0.0216
          Episode_Reward/joint_vel: -0.0458
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 25559040
                    Iteration time: 2.15s
                      Time elapsed: 00:09:35
                               ETA: 01:41:11

################################################################################
                     [1m Learning iteration 260/3000 [0m                      

                       Computation: 46321 steps/s (collection: 1.996s, learning 0.126s)
             Mean action noise std: 1.82
          Mean value_function loss: 23.0880
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 62.4659
                       Mean reward: 64.48
               Mean episode length: 229.94
    Episode_Reward/reaching_object: 1.2279
    Episode_Reward/rotating_object: 9.9875
        Episode_Reward/action_rate: -0.0222
          Episode_Reward/joint_vel: -0.0484
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 25657344
                    Iteration time: 2.12s
                      Time elapsed: 00:09:37
                               ETA: 01:41:07

################################################################################
                     [1m Learning iteration 261/3000 [0m                      

                       Computation: 46423 steps/s (collection: 2.015s, learning 0.103s)
             Mean action noise std: 1.82
          Mean value_function loss: 25.3241
               Mean surrogate loss: -0.0096
                 Mean entropy loss: 62.5078
                       Mean reward: 60.89
               Mean episode length: 232.15
    Episode_Reward/reaching_object: 1.2203
    Episode_Reward/rotating_object: 10.1634
        Episode_Reward/action_rate: -0.0222
          Episode_Reward/joint_vel: -0.0466
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 25755648
                    Iteration time: 2.12s
                      Time elapsed: 00:09:40
                               ETA: 01:41:04

################################################################################
                     [1m Learning iteration 262/3000 [0m                      

                       Computation: 46670 steps/s (collection: 1.995s, learning 0.111s)
             Mean action noise std: 1.82
          Mean value_function loss: 26.2370
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 62.5540
                       Mean reward: 48.56
               Mean episode length: 219.03
    Episode_Reward/reaching_object: 1.2059
    Episode_Reward/rotating_object: 10.4171
        Episode_Reward/action_rate: -0.0219
          Episode_Reward/joint_vel: -0.0467
      Episode_Termination/time_out: 13.4583
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 25853952
                    Iteration time: 2.11s
                      Time elapsed: 00:09:42
                               ETA: 01:41:01

################################################################################
                     [1m Learning iteration 263/3000 [0m                      

                       Computation: 46193 steps/s (collection: 2.016s, learning 0.112s)
             Mean action noise std: 1.83
          Mean value_function loss: 26.1916
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 62.6025
                       Mean reward: 59.24
               Mean episode length: 226.80
    Episode_Reward/reaching_object: 1.2296
    Episode_Reward/rotating_object: 10.5173
        Episode_Reward/action_rate: -0.0225
          Episode_Reward/joint_vel: -0.0481
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 25952256
                    Iteration time: 2.13s
                      Time elapsed: 00:09:44
                               ETA: 01:40:58

################################################################################
                     [1m Learning iteration 264/3000 [0m                      

                       Computation: 43689 steps/s (collection: 2.080s, learning 0.170s)
             Mean action noise std: 1.83
          Mean value_function loss: 28.9422
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 62.6393
                       Mean reward: 52.30
               Mean episode length: 226.09
    Episode_Reward/reaching_object: 1.2662
    Episode_Reward/rotating_object: 10.2093
        Episode_Reward/action_rate: -0.0226
          Episode_Reward/joint_vel: -0.0476
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.5833
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 26050560
                    Iteration time: 2.25s
                      Time elapsed: 00:09:46
                               ETA: 01:40:56

################################################################################
                     [1m Learning iteration 265/3000 [0m                      

                       Computation: 45760 steps/s (collection: 2.020s, learning 0.129s)
             Mean action noise std: 1.83
          Mean value_function loss: 30.5617
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 62.6697
                       Mean reward: 60.20
               Mean episode length: 229.82
    Episode_Reward/reaching_object: 1.2333
    Episode_Reward/rotating_object: 9.9686
        Episode_Reward/action_rate: -0.0223
          Episode_Reward/joint_vel: -0.0482
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 26148864
                    Iteration time: 2.15s
                      Time elapsed: 00:09:48
                               ETA: 01:40:53

################################################################################
                     [1m Learning iteration 266/3000 [0m                      

                       Computation: 44827 steps/s (collection: 2.065s, learning 0.128s)
             Mean action noise std: 1.83
          Mean value_function loss: 30.6617
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 62.7038
                       Mean reward: 34.61
               Mean episode length: 221.31
    Episode_Reward/reaching_object: 1.2366
    Episode_Reward/rotating_object: 9.8294
        Episode_Reward/action_rate: -0.0225
          Episode_Reward/joint_vel: -0.0478
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.7083
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 26247168
                    Iteration time: 2.19s
                      Time elapsed: 00:09:50
                               ETA: 01:40:51

################################################################################
                     [1m Learning iteration 267/3000 [0m                      

                       Computation: 45446 steps/s (collection: 2.039s, learning 0.124s)
             Mean action noise std: 1.84
          Mean value_function loss: 35.9571
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 62.7383
                       Mean reward: 52.08
               Mean episode length: 223.43
    Episode_Reward/reaching_object: 1.1749
    Episode_Reward/rotating_object: 9.8859
        Episode_Reward/action_rate: -0.0217
          Episode_Reward/joint_vel: -0.0467
      Episode_Termination/time_out: 13.1250
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 26345472
                    Iteration time: 2.16s
                      Time elapsed: 00:09:53
                               ETA: 01:40:48

################################################################################
                     [1m Learning iteration 268/3000 [0m                      

                       Computation: 46237 steps/s (collection: 2.028s, learning 0.099s)
             Mean action noise std: 1.84
          Mean value_function loss: 33.8660
               Mean surrogate loss: -0.0098
                 Mean entropy loss: 62.7793
                       Mean reward: 49.13
               Mean episode length: 214.62
    Episode_Reward/reaching_object: 1.2060
    Episode_Reward/rotating_object: 9.3087
        Episode_Reward/action_rate: -0.0218
          Episode_Reward/joint_vel: -0.0472
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.6667
     Episode_Termination/robot_out: 4.1667
--------------------------------------------------------------------------------
                   Total timesteps: 26443776
                    Iteration time: 2.13s
                      Time elapsed: 00:09:55
                               ETA: 01:40:45

################################################################################
                     [1m Learning iteration 269/3000 [0m                      

                       Computation: 45958 steps/s (collection: 2.017s, learning 0.122s)
             Mean action noise std: 1.84
          Mean value_function loss: 32.3174
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 62.8139
                       Mean reward: 50.02
               Mean episode length: 223.36
    Episode_Reward/reaching_object: 1.2193
    Episode_Reward/rotating_object: 9.7625
        Episode_Reward/action_rate: -0.0222
          Episode_Reward/joint_vel: -0.0470
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.5833
     Episode_Termination/robot_out: 3.9583
--------------------------------------------------------------------------------
                   Total timesteps: 26542080
                    Iteration time: 2.14s
                      Time elapsed: 00:09:57
                               ETA: 01:40:42

################################################################################
                     [1m Learning iteration 270/3000 [0m                      

                       Computation: 44862 steps/s (collection: 2.053s, learning 0.138s)
             Mean action noise std: 1.84
          Mean value_function loss: 34.9205
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 62.8480
                       Mean reward: 55.46
               Mean episode length: 218.57
    Episode_Reward/reaching_object: 1.2267
    Episode_Reward/rotating_object: 11.4112
        Episode_Reward/action_rate: -0.0224
          Episode_Reward/joint_vel: -0.0477
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.5833
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 26640384
                    Iteration time: 2.19s
                      Time elapsed: 00:09:59
                               ETA: 01:40:39

################################################################################
                     [1m Learning iteration 271/3000 [0m                      

                       Computation: 45418 steps/s (collection: 2.060s, learning 0.105s)
             Mean action noise std: 1.84
          Mean value_function loss: 36.5077
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 62.8820
                       Mean reward: 49.26
               Mean episode length: 215.05
    Episode_Reward/reaching_object: 1.2076
    Episode_Reward/rotating_object: 10.1181
        Episode_Reward/action_rate: -0.0221
          Episode_Reward/joint_vel: -0.0478
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 26738688
                    Iteration time: 2.16s
                      Time elapsed: 00:10:01
                               ETA: 01:40:37

################################################################################
                     [1m Learning iteration 272/3000 [0m                      

                       Computation: 45383 steps/s (collection: 2.043s, learning 0.124s)
             Mean action noise std: 1.85
          Mean value_function loss: 37.2442
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 62.9161
                       Mean reward: 65.14
               Mean episode length: 229.19
    Episode_Reward/reaching_object: 1.2096
    Episode_Reward/rotating_object: 10.8815
        Episode_Reward/action_rate: -0.0226
          Episode_Reward/joint_vel: -0.0483
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.6250
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 26836992
                    Iteration time: 2.17s
                      Time elapsed: 00:10:03
                               ETA: 01:40:34

################################################################################
                     [1m Learning iteration 273/3000 [0m                      

                       Computation: 45045 steps/s (collection: 2.063s, learning 0.120s)
             Mean action noise std: 1.85
          Mean value_function loss: 39.2031
               Mean surrogate loss: -0.0096
                 Mean entropy loss: 62.9525
                       Mean reward: 74.58
               Mean episode length: 226.21
    Episode_Reward/reaching_object: 1.2489
    Episode_Reward/rotating_object: 10.5345
        Episode_Reward/action_rate: -0.0228
          Episode_Reward/joint_vel: -0.0470
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 26935296
                    Iteration time: 2.18s
                      Time elapsed: 00:10:06
                               ETA: 01:40:31

################################################################################
                     [1m Learning iteration 274/3000 [0m                      

                       Computation: 45921 steps/s (collection: 2.039s, learning 0.102s)
             Mean action noise std: 1.85
          Mean value_function loss: 38.4743
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 62.9862
                       Mean reward: 78.83
               Mean episode length: 231.90
    Episode_Reward/reaching_object: 1.2524
    Episode_Reward/rotating_object: 11.6639
        Episode_Reward/action_rate: -0.0229
          Episode_Reward/joint_vel: -0.0481
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 27033600
                    Iteration time: 2.14s
                      Time elapsed: 00:10:08
                               ETA: 01:40:29

################################################################################
                     [1m Learning iteration 275/3000 [0m                      

                       Computation: 45734 steps/s (collection: 2.027s, learning 0.123s)
             Mean action noise std: 1.85
          Mean value_function loss: 33.5360
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 63.0240
                       Mean reward: 71.31
               Mean episode length: 227.85
    Episode_Reward/reaching_object: 1.2482
    Episode_Reward/rotating_object: 14.0718
        Episode_Reward/action_rate: -0.0228
          Episode_Reward/joint_vel: -0.0474
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 27131904
                    Iteration time: 2.15s
                      Time elapsed: 00:10:10
                               ETA: 01:40:26

################################################################################
                     [1m Learning iteration 276/3000 [0m                      

                       Computation: 45800 steps/s (collection: 2.037s, learning 0.109s)
             Mean action noise std: 1.86
          Mean value_function loss: 36.3375
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 63.0632
                       Mean reward: 58.78
               Mean episode length: 221.02
    Episode_Reward/reaching_object: 1.2135
    Episode_Reward/rotating_object: 12.3487
        Episode_Reward/action_rate: -0.0226
          Episode_Reward/joint_vel: -0.0464
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 4.2083
--------------------------------------------------------------------------------
                   Total timesteps: 27230208
                    Iteration time: 2.15s
                      Time elapsed: 00:10:12
                               ETA: 01:40:23

################################################################################
                     [1m Learning iteration 277/3000 [0m                      

                       Computation: 44933 steps/s (collection: 2.069s, learning 0.119s)
             Mean action noise std: 1.86
          Mean value_function loss: 37.2455
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 63.0957
                       Mean reward: 68.76
               Mean episode length: 229.72
    Episode_Reward/reaching_object: 1.2353
    Episode_Reward/rotating_object: 13.6261
        Episode_Reward/action_rate: -0.0228
          Episode_Reward/joint_vel: -0.0476
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.5833
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 27328512
                    Iteration time: 2.19s
                      Time elapsed: 00:10:14
                               ETA: 01:40:20

################################################################################
                     [1m Learning iteration 278/3000 [0m                      

                       Computation: 45277 steps/s (collection: 2.034s, learning 0.137s)
             Mean action noise std: 1.86
          Mean value_function loss: 34.8771
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 63.1318
                       Mean reward: 63.65
               Mean episode length: 227.50
    Episode_Reward/reaching_object: 1.2378
    Episode_Reward/rotating_object: 14.1423
        Episode_Reward/action_rate: -0.0229
          Episode_Reward/joint_vel: -0.0486
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.6250
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 27426816
                    Iteration time: 2.17s
                      Time elapsed: 00:10:16
                               ETA: 01:40:18

################################################################################
                     [1m Learning iteration 279/3000 [0m                      

                       Computation: 44298 steps/s (collection: 2.111s, learning 0.109s)
             Mean action noise std: 1.86
          Mean value_function loss: 37.4393
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 63.1649
                       Mean reward: 67.46
               Mean episode length: 233.66
    Episode_Reward/reaching_object: 1.2688
    Episode_Reward/rotating_object: 12.4767
        Episode_Reward/action_rate: -0.0233
          Episode_Reward/joint_vel: -0.0482
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 27525120
                    Iteration time: 2.22s
                      Time elapsed: 00:10:19
                               ETA: 01:40:16

################################################################################
                     [1m Learning iteration 280/3000 [0m                      

                       Computation: 44890 steps/s (collection: 2.054s, learning 0.136s)
             Mean action noise std: 1.86
          Mean value_function loss: 40.9414
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 63.1998
                       Mean reward: 63.38
               Mean episode length: 225.83
    Episode_Reward/reaching_object: 1.2629
    Episode_Reward/rotating_object: 12.7656
        Episode_Reward/action_rate: -0.0231
          Episode_Reward/joint_vel: -0.0485
      Episode_Termination/time_out: 13.4167
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 27623424
                    Iteration time: 2.19s
                      Time elapsed: 00:10:21
                               ETA: 01:40:13

################################################################################
                     [1m Learning iteration 281/3000 [0m                      

                       Computation: 44133 steps/s (collection: 2.122s, learning 0.106s)
             Mean action noise std: 1.87
          Mean value_function loss: 36.3571
               Mean surrogate loss: -0.0101
                 Mean entropy loss: 63.2413
                       Mean reward: 61.61
               Mean episode length: 235.36
    Episode_Reward/reaching_object: 1.2744
    Episode_Reward/rotating_object: 14.5684
        Episode_Reward/action_rate: -0.0234
          Episode_Reward/joint_vel: -0.0478
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 27721728
                    Iteration time: 2.23s
                      Time elapsed: 00:10:23
                               ETA: 01:40:11

################################################################################
                     [1m Learning iteration 282/3000 [0m                      

                       Computation: 44949 steps/s (collection: 2.056s, learning 0.131s)
             Mean action noise std: 1.87
          Mean value_function loss: 40.2323
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 63.2794
                       Mean reward: 67.28
               Mean episode length: 233.09
    Episode_Reward/reaching_object: 1.2929
    Episode_Reward/rotating_object: 13.7212
        Episode_Reward/action_rate: -0.0235
          Episode_Reward/joint_vel: -0.0482
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 3.6667
--------------------------------------------------------------------------------
                   Total timesteps: 27820032
                    Iteration time: 2.19s
                      Time elapsed: 00:10:25
                               ETA: 01:40:09

################################################################################
                     [1m Learning iteration 283/3000 [0m                      

                       Computation: 45272 steps/s (collection: 2.040s, learning 0.132s)
             Mean action noise std: 1.87
          Mean value_function loss: 38.5760
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 63.3139
                       Mean reward: 101.98
               Mean episode length: 235.27
    Episode_Reward/reaching_object: 1.2736
    Episode_Reward/rotating_object: 13.9791
        Episode_Reward/action_rate: -0.0235
          Episode_Reward/joint_vel: -0.0487
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.5833
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 27918336
                    Iteration time: 2.17s
                      Time elapsed: 00:10:27
                               ETA: 01:40:06

################################################################################
                     [1m Learning iteration 284/3000 [0m                      

                       Computation: 45940 steps/s (collection: 2.033s, learning 0.107s)
             Mean action noise std: 1.87
          Mean value_function loss: 39.1138
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 63.3480
                       Mean reward: 82.03
               Mean episode length: 222.21
    Episode_Reward/reaching_object: 1.2391
    Episode_Reward/rotating_object: 14.2727
        Episode_Reward/action_rate: -0.0228
          Episode_Reward/joint_vel: -0.0471
      Episode_Termination/time_out: 12.5417
Episode_Termination/object_dropping: 0.6250
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 28016640
                    Iteration time: 2.14s
                      Time elapsed: 00:10:30
                               ETA: 01:40:03

################################################################################
                     [1m Learning iteration 285/3000 [0m                      

                       Computation: 46035 steps/s (collection: 2.030s, learning 0.105s)
             Mean action noise std: 1.87
          Mean value_function loss: 37.1689
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 63.3871
                       Mean reward: 92.14
               Mean episode length: 222.80
    Episode_Reward/reaching_object: 1.3187
    Episode_Reward/rotating_object: 15.6658
        Episode_Reward/action_rate: -0.0236
          Episode_Reward/joint_vel: -0.0484
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.5833
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 28114944
                    Iteration time: 2.14s
                      Time elapsed: 00:10:32
                               ETA: 01:40:00

################################################################################
                     [1m Learning iteration 286/3000 [0m                      

                       Computation: 45941 steps/s (collection: 2.022s, learning 0.118s)
             Mean action noise std: 1.88
          Mean value_function loss: 38.0263
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 63.4195
                       Mean reward: 87.94
               Mean episode length: 226.68
    Episode_Reward/reaching_object: 1.2790
    Episode_Reward/rotating_object: 13.8299
        Episode_Reward/action_rate: -0.0231
          Episode_Reward/joint_vel: -0.0467
      Episode_Termination/time_out: 13.5417
Episode_Termination/object_dropping: 0.7083
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 28213248
                    Iteration time: 2.14s
                      Time elapsed: 00:10:34
                               ETA: 01:39:58

################################################################################
                     [1m Learning iteration 287/3000 [0m                      

                       Computation: 44576 steps/s (collection: 2.076s, learning 0.129s)
             Mean action noise std: 1.88
          Mean value_function loss: 36.5940
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 63.4528
                       Mean reward: 74.89
               Mean episode length: 226.87
    Episode_Reward/reaching_object: 1.2912
    Episode_Reward/rotating_object: 12.8024
        Episode_Reward/action_rate: -0.0235
          Episode_Reward/joint_vel: -0.0471
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 28311552
                    Iteration time: 2.21s
                      Time elapsed: 00:10:36
                               ETA: 01:39:55

################################################################################
                     [1m Learning iteration 288/3000 [0m                      

                       Computation: 45348 steps/s (collection: 2.036s, learning 0.132s)
             Mean action noise std: 1.88
          Mean value_function loss: 40.5272
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 63.4872
                       Mean reward: 66.70
               Mean episode length: 231.18
    Episode_Reward/reaching_object: 1.2946
    Episode_Reward/rotating_object: 11.1202
        Episode_Reward/action_rate: -0.0237
          Episode_Reward/joint_vel: -0.0492
      Episode_Termination/time_out: 13.6250
Episode_Termination/object_dropping: 0.5833
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 28409856
                    Iteration time: 2.17s
                      Time elapsed: 00:10:38
                               ETA: 01:39:53

################################################################################
                     [1m Learning iteration 289/3000 [0m                      

                       Computation: 45189 steps/s (collection: 2.023s, learning 0.152s)
             Mean action noise std: 1.88
          Mean value_function loss: 40.1436
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 63.5281
                       Mean reward: 68.68
               Mean episode length: 223.29
    Episode_Reward/reaching_object: 1.3174
    Episode_Reward/rotating_object: 13.4418
        Episode_Reward/action_rate: -0.0238
          Episode_Reward/joint_vel: -0.0490
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 28508160
                    Iteration time: 2.18s
                      Time elapsed: 00:10:40
                               ETA: 01:39:50

################################################################################
                     [1m Learning iteration 290/3000 [0m                      

                       Computation: 45334 steps/s (collection: 2.057s, learning 0.111s)
             Mean action noise std: 1.89
          Mean value_function loss: 41.6524
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 63.5649
                       Mean reward: 46.91
               Mean episode length: 212.82
    Episode_Reward/reaching_object: 1.2698
    Episode_Reward/rotating_object: 14.0730
        Episode_Reward/action_rate: -0.0233
          Episode_Reward/joint_vel: -0.0470
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.6250
     Episode_Termination/robot_out: 3.8333
--------------------------------------------------------------------------------
                   Total timesteps: 28606464
                    Iteration time: 2.17s
                      Time elapsed: 00:10:42
                               ETA: 01:39:48

################################################################################
                     [1m Learning iteration 291/3000 [0m                      

                       Computation: 45565 steps/s (collection: 2.056s, learning 0.101s)
             Mean action noise std: 1.89
          Mean value_function loss: 36.3949
               Mean surrogate loss: -0.0096
                 Mean entropy loss: 63.5985
                       Mean reward: 75.96
               Mean episode length: 229.52
    Episode_Reward/reaching_object: 1.3017
    Episode_Reward/rotating_object: 13.4317
        Episode_Reward/action_rate: -0.0238
          Episode_Reward/joint_vel: -0.0481
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 28704768
                    Iteration time: 2.16s
                      Time elapsed: 00:10:45
                               ETA: 01:39:45

################################################################################
                     [1m Learning iteration 292/3000 [0m                      

                       Computation: 44847 steps/s (collection: 2.075s, learning 0.117s)
             Mean action noise std: 1.89
          Mean value_function loss: 41.1496
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 63.6353
                       Mean reward: 88.06
               Mean episode length: 228.84
    Episode_Reward/reaching_object: 1.2863
    Episode_Reward/rotating_object: 14.5031
        Episode_Reward/action_rate: -0.0235
          Episode_Reward/joint_vel: -0.0470
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 4.7500
--------------------------------------------------------------------------------
                   Total timesteps: 28803072
                    Iteration time: 2.19s
                      Time elapsed: 00:10:47
                               ETA: 01:39:42

################################################################################
                     [1m Learning iteration 293/3000 [0m                      

                       Computation: 45201 steps/s (collection: 2.071s, learning 0.104s)
             Mean action noise std: 1.89
          Mean value_function loss: 38.6128
               Mean surrogate loss: -0.0096
                 Mean entropy loss: 63.6663
                       Mean reward: 67.23
               Mean episode length: 225.73
    Episode_Reward/reaching_object: 1.2744
    Episode_Reward/rotating_object: 13.3917
        Episode_Reward/action_rate: -0.0234
          Episode_Reward/joint_vel: -0.0470
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 4.1250
--------------------------------------------------------------------------------
                   Total timesteps: 28901376
                    Iteration time: 2.17s
                      Time elapsed: 00:10:49
                               ETA: 01:39:40

################################################################################
                     [1m Learning iteration 294/3000 [0m                      

                       Computation: 43767 steps/s (collection: 2.089s, learning 0.157s)
             Mean action noise std: 1.89
          Mean value_function loss: 39.8147
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 63.6955
                       Mean reward: 73.48
               Mean episode length: 218.19
    Episode_Reward/reaching_object: 1.2820
    Episode_Reward/rotating_object: 13.0241
        Episode_Reward/action_rate: -0.0235
          Episode_Reward/joint_vel: -0.0461
      Episode_Termination/time_out: 13.4583
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 3.8333
--------------------------------------------------------------------------------
                   Total timesteps: 28999680
                    Iteration time: 2.25s
                      Time elapsed: 00:10:51
                               ETA: 01:39:38

################################################################################
                     [1m Learning iteration 295/3000 [0m                      

                       Computation: 45520 steps/s (collection: 2.046s, learning 0.114s)
             Mean action noise std: 1.90
          Mean value_function loss: 44.2411
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 63.7241
                       Mean reward: 89.01
               Mean episode length: 223.89
    Episode_Reward/reaching_object: 1.2798
    Episode_Reward/rotating_object: 14.0292
        Episode_Reward/action_rate: -0.0234
          Episode_Reward/joint_vel: -0.0452
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 29097984
                    Iteration time: 2.16s
                      Time elapsed: 00:10:53
                               ETA: 01:39:35

################################################################################
                     [1m Learning iteration 296/3000 [0m                      

                       Computation: 45727 steps/s (collection: 2.035s, learning 0.115s)
             Mean action noise std: 1.90
          Mean value_function loss: 36.7052
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 63.7557
                       Mean reward: 82.58
               Mean episode length: 222.07
    Episode_Reward/reaching_object: 1.2900
    Episode_Reward/rotating_object: 15.6719
        Episode_Reward/action_rate: -0.0235
          Episode_Reward/joint_vel: -0.0459
      Episode_Termination/time_out: 12.7500
Episode_Termination/object_dropping: 0.7917
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 29196288
                    Iteration time: 2.15s
                      Time elapsed: 00:10:56
                               ETA: 01:39:33

################################################################################
                     [1m Learning iteration 297/3000 [0m                      

                       Computation: 46113 steps/s (collection: 2.029s, learning 0.103s)
             Mean action noise std: 1.90
          Mean value_function loss: 37.8498
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 63.7875
                       Mean reward: 92.83
               Mean episode length: 229.13
    Episode_Reward/reaching_object: 1.3075
    Episode_Reward/rotating_object: 15.0300
        Episode_Reward/action_rate: -0.0241
          Episode_Reward/joint_vel: -0.0468
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.6667
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 29294592
                    Iteration time: 2.13s
                      Time elapsed: 00:10:58
                               ETA: 01:39:30

################################################################################
                     [1m Learning iteration 298/3000 [0m                      

                       Computation: 44356 steps/s (collection: 2.080s, learning 0.136s)
             Mean action noise std: 1.90
          Mean value_function loss: 38.2298
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 63.8249
                       Mean reward: 93.20
               Mean episode length: 232.78
    Episode_Reward/reaching_object: 1.2886
    Episode_Reward/rotating_object: 14.1309
        Episode_Reward/action_rate: -0.0239
          Episode_Reward/joint_vel: -0.0449
      Episode_Termination/time_out: 13.8750
Episode_Termination/object_dropping: 0.7083
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 29392896
                    Iteration time: 2.22s
                      Time elapsed: 00:11:00
                               ETA: 01:39:28

################################################################################
                     [1m Learning iteration 299/3000 [0m                      

                       Computation: 44590 steps/s (collection: 2.087s, learning 0.118s)
             Mean action noise std: 1.90
          Mean value_function loss: 39.1168
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 63.8551
                       Mean reward: 79.37
               Mean episode length: 214.37
    Episode_Reward/reaching_object: 1.2537
    Episode_Reward/rotating_object: 15.3462
        Episode_Reward/action_rate: -0.0236
          Episode_Reward/joint_vel: -0.0444
      Episode_Termination/time_out: 13.2500
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 3.8333
--------------------------------------------------------------------------------
                   Total timesteps: 29491200
                    Iteration time: 2.20s
                      Time elapsed: 00:11:02
                               ETA: 01:39:25

################################################################################
                     [1m Learning iteration 300/3000 [0m                      

                       Computation: 44628 steps/s (collection: 2.088s, learning 0.115s)
             Mean action noise std: 1.91
          Mean value_function loss: 39.5570
               Mean surrogate loss: -0.0097
                 Mean entropy loss: 63.8978
                       Mean reward: 101.37
               Mean episode length: 234.48
    Episode_Reward/reaching_object: 1.3178
    Episode_Reward/rotating_object: 16.6399
        Episode_Reward/action_rate: -0.0246
          Episode_Reward/joint_vel: -0.0455
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 29589504
                    Iteration time: 2.20s
                      Time elapsed: 00:11:04
                               ETA: 01:39:23

################################################################################
                     [1m Learning iteration 301/3000 [0m                      

                       Computation: 44808 steps/s (collection: 2.079s, learning 0.115s)
             Mean action noise std: 1.91
          Mean value_function loss: 36.6293
               Mean surrogate loss: -0.0098
                 Mean entropy loss: 63.9326
                       Mean reward: 90.25
               Mean episode length: 230.48
    Episode_Reward/reaching_object: 1.2753
    Episode_Reward/rotating_object: 15.5058
        Episode_Reward/action_rate: -0.0241
          Episode_Reward/joint_vel: -0.0442
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 3.7500
--------------------------------------------------------------------------------
                   Total timesteps: 29687808
                    Iteration time: 2.19s
                      Time elapsed: 00:11:07
                               ETA: 01:39:21

################################################################################
                     [1m Learning iteration 302/3000 [0m                      

                       Computation: 45401 steps/s (collection: 2.038s, learning 0.128s)
             Mean action noise std: 1.91
          Mean value_function loss: 43.3411
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 63.9677
                       Mean reward: 83.85
               Mean episode length: 234.61
    Episode_Reward/reaching_object: 1.3227
    Episode_Reward/rotating_object: 16.3420
        Episode_Reward/action_rate: -0.0247
          Episode_Reward/joint_vel: -0.0459
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.6250
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 29786112
                    Iteration time: 2.17s
                      Time elapsed: 00:11:09
                               ETA: 01:39:18

################################################################################
                     [1m Learning iteration 303/3000 [0m                      

                       Computation: 45710 steps/s (collection: 2.038s, learning 0.113s)
             Mean action noise std: 1.91
          Mean value_function loss: 37.3539
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 64.0058
                       Mean reward: 78.17
               Mean episode length: 227.03
    Episode_Reward/reaching_object: 1.2924
    Episode_Reward/rotating_object: 15.6960
        Episode_Reward/action_rate: -0.0245
          Episode_Reward/joint_vel: -0.0439
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 29884416
                    Iteration time: 2.15s
                      Time elapsed: 00:11:11
                               ETA: 01:39:15

################################################################################
                     [1m Learning iteration 304/3000 [0m                      

                       Computation: 44418 steps/s (collection: 2.096s, learning 0.117s)
             Mean action noise std: 1.92
          Mean value_function loss: 46.1545
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 64.0379
                       Mean reward: 76.30
               Mean episode length: 229.22
    Episode_Reward/reaching_object: 1.2951
    Episode_Reward/rotating_object: 14.7670
        Episode_Reward/action_rate: -0.0244
          Episode_Reward/joint_vel: -0.0458
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 4.0833
--------------------------------------------------------------------------------
                   Total timesteps: 29982720
                    Iteration time: 2.21s
                      Time elapsed: 00:11:13
                               ETA: 01:39:13

################################################################################
                     [1m Learning iteration 305/3000 [0m                      

                       Computation: 44868 steps/s (collection: 2.083s, learning 0.108s)
             Mean action noise std: 1.92
          Mean value_function loss: 45.3234
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 64.0713
                       Mean reward: 77.67
               Mean episode length: 219.86
    Episode_Reward/reaching_object: 1.2945
    Episode_Reward/rotating_object: 15.8758
        Episode_Reward/action_rate: -0.0241
          Episode_Reward/joint_vel: -0.0456
      Episode_Termination/time_out: 12.7083
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 4.0833
--------------------------------------------------------------------------------
                   Total timesteps: 30081024
                    Iteration time: 2.19s
                      Time elapsed: 00:11:15
                               ETA: 01:39:11

################################################################################
                     [1m Learning iteration 306/3000 [0m                      

                       Computation: 43053 steps/s (collection: 2.137s, learning 0.146s)
             Mean action noise std: 1.92
          Mean value_function loss: 43.4037
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 64.1049
                       Mean reward: 89.99
               Mean episode length: 218.58
    Episode_Reward/reaching_object: 1.2971
    Episode_Reward/rotating_object: 15.4228
        Episode_Reward/action_rate: -0.0243
          Episode_Reward/joint_vel: -0.0458
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.7083
     Episode_Termination/robot_out: 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 30179328
                    Iteration time: 2.28s
                      Time elapsed: 00:11:18
                               ETA: 01:39:09

################################################################################
                     [1m Learning iteration 307/3000 [0m                      

                       Computation: 45382 steps/s (collection: 2.060s, learning 0.107s)
             Mean action noise std: 1.92
          Mean value_function loss: 38.0843
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 64.1364
                       Mean reward: 77.89
               Mean episode length: 223.24
    Episode_Reward/reaching_object: 1.3150
    Episode_Reward/rotating_object: 14.7948
        Episode_Reward/action_rate: -0.0242
          Episode_Reward/joint_vel: -0.0445
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 30277632
                    Iteration time: 2.17s
                      Time elapsed: 00:11:20
                               ETA: 01:39:07

################################################################################
                     [1m Learning iteration 308/3000 [0m                      

                       Computation: 44064 steps/s (collection: 2.111s, learning 0.120s)
             Mean action noise std: 1.92
          Mean value_function loss: 37.8957
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 64.1706
                       Mean reward: 94.00
               Mean episode length: 218.11
    Episode_Reward/reaching_object: 1.2827
    Episode_Reward/rotating_object: 17.0295
        Episode_Reward/action_rate: -0.0236
          Episode_Reward/joint_vel: -0.0429
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.5833
     Episode_Termination/robot_out: 5.1667
--------------------------------------------------------------------------------
                   Total timesteps: 30375936
                    Iteration time: 2.23s
                      Time elapsed: 00:11:22
                               ETA: 01:39:05

################################################################################
                     [1m Learning iteration 309/3000 [0m                      

                       Computation: 44064 steps/s (collection: 2.130s, learning 0.101s)
             Mean action noise std: 1.93
          Mean value_function loss: 38.7201
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 64.2048
                       Mean reward: 76.70
               Mean episode length: 222.93
    Episode_Reward/reaching_object: 1.3161
    Episode_Reward/rotating_object: 15.1108
        Episode_Reward/action_rate: -0.0243
          Episode_Reward/joint_vel: -0.0453
      Episode_Termination/time_out: 13.2917
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 4.0833
--------------------------------------------------------------------------------
                   Total timesteps: 30474240
                    Iteration time: 2.23s
                      Time elapsed: 00:11:24
                               ETA: 01:39:03

################################################################################
                     [1m Learning iteration 310/3000 [0m                      

                       Computation: 44095 steps/s (collection: 2.086s, learning 0.143s)
             Mean action noise std: 1.93
          Mean value_function loss: 35.7977
               Mean surrogate loss: -0.0098
                 Mean entropy loss: 64.2455
                       Mean reward: 98.47
               Mean episode length: 221.99
    Episode_Reward/reaching_object: 1.3142
    Episode_Reward/rotating_object: 15.2821
        Episode_Reward/action_rate: -0.0242
          Episode_Reward/joint_vel: -0.0453
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 4.4167
--------------------------------------------------------------------------------
                   Total timesteps: 30572544
                    Iteration time: 2.23s
                      Time elapsed: 00:11:26
                               ETA: 01:39:01

################################################################################
                     [1m Learning iteration 311/3000 [0m                      

                       Computation: 44002 steps/s (collection: 2.118s, learning 0.116s)
             Mean action noise std: 1.93
          Mean value_function loss: 42.2910
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 64.2805
                       Mean reward: 74.77
               Mean episode length: 214.72
    Episode_Reward/reaching_object: 1.3236
    Episode_Reward/rotating_object: 16.0364
        Episode_Reward/action_rate: -0.0244
          Episode_Reward/joint_vel: -0.0462
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 4.3333
--------------------------------------------------------------------------------
                   Total timesteps: 30670848
                    Iteration time: 2.23s
                      Time elapsed: 00:11:29
                               ETA: 01:38:59

################################################################################
                     [1m Learning iteration 312/3000 [0m                      

                       Computation: 45386 steps/s (collection: 2.063s, learning 0.103s)
             Mean action noise std: 1.93
          Mean value_function loss: 41.2930
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 64.3107
                       Mean reward: 79.62
               Mean episode length: 212.58
    Episode_Reward/reaching_object: 1.2882
    Episode_Reward/rotating_object: 14.3658
        Episode_Reward/action_rate: -0.0241
          Episode_Reward/joint_vel: -0.0463
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 5.2917
--------------------------------------------------------------------------------
                   Total timesteps: 30769152
                    Iteration time: 2.17s
                      Time elapsed: 00:11:31
                               ETA: 01:38:56

################################################################################
                     [1m Learning iteration 313/3000 [0m                      

                       Computation: 44039 steps/s (collection: 2.113s, learning 0.120s)
             Mean action noise std: 1.93
          Mean value_function loss: 43.3381
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 64.3419
                       Mean reward: 72.31
               Mean episode length: 218.87
    Episode_Reward/reaching_object: 1.3157
    Episode_Reward/rotating_object: 14.9874
        Episode_Reward/action_rate: -0.0243
          Episode_Reward/joint_vel: -0.0456
      Episode_Termination/time_out: 13.4167
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 4.5000
--------------------------------------------------------------------------------
                   Total timesteps: 30867456
                    Iteration time: 2.23s
                      Time elapsed: 00:11:33
                               ETA: 01:38:54

################################################################################
                     [1m Learning iteration 314/3000 [0m                      

                       Computation: 45267 steps/s (collection: 2.066s, learning 0.106s)
             Mean action noise std: 1.94
          Mean value_function loss: 41.1302
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 64.3630
                       Mean reward: 78.36
               Mean episode length: 216.53
    Episode_Reward/reaching_object: 1.2789
    Episode_Reward/rotating_object: 16.4016
        Episode_Reward/action_rate: -0.0242
          Episode_Reward/joint_vel: -0.0445
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 4.2500
--------------------------------------------------------------------------------
                   Total timesteps: 30965760
                    Iteration time: 2.17s
                      Time elapsed: 00:11:35
                               ETA: 01:38:52

################################################################################
                     [1m Learning iteration 315/3000 [0m                      

                       Computation: 43923 steps/s (collection: 2.092s, learning 0.146s)
             Mean action noise std: 1.94
          Mean value_function loss: 46.5002
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 64.3927
                       Mean reward: 45.98
               Mean episode length: 207.83
    Episode_Reward/reaching_object: 1.3341
    Episode_Reward/rotating_object: 13.9496
        Episode_Reward/action_rate: -0.0247
          Episode_Reward/joint_vel: -0.0460
      Episode_Termination/time_out: 13.4583
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 31064064
                    Iteration time: 2.24s
                      Time elapsed: 00:11:37
                               ETA: 01:38:50

################################################################################
                     [1m Learning iteration 316/3000 [0m                      

                       Computation: 43710 steps/s (collection: 2.129s, learning 0.120s)
             Mean action noise std: 1.94
          Mean value_function loss: 41.5103
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 64.4236
                       Mean reward: 91.06
               Mean episode length: 228.90
    Episode_Reward/reaching_object: 1.3385
    Episode_Reward/rotating_object: 16.4405
        Episode_Reward/action_rate: -0.0249
          Episode_Reward/joint_vel: -0.0455
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 4.2500
--------------------------------------------------------------------------------
                   Total timesteps: 31162368
                    Iteration time: 2.25s
                      Time elapsed: 00:11:40
                               ETA: 01:38:48

################################################################################
                     [1m Learning iteration 317/3000 [0m                      

                       Computation: 44678 steps/s (collection: 2.087s, learning 0.113s)
             Mean action noise std: 1.94
          Mean value_function loss: 43.0986
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 64.4519
                       Mean reward: 77.18
               Mean episode length: 214.02
    Episode_Reward/reaching_object: 1.3233
    Episode_Reward/rotating_object: 15.4003
        Episode_Reward/action_rate: -0.0245
          Episode_Reward/joint_vel: -0.0451
      Episode_Termination/time_out: 12.8333
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 4.1250
--------------------------------------------------------------------------------
                   Total timesteps: 31260672
                    Iteration time: 2.20s
                      Time elapsed: 00:11:42
                               ETA: 01:38:46

################################################################################
                     [1m Learning iteration 318/3000 [0m                      

                       Computation: 44976 steps/s (collection: 2.080s, learning 0.106s)
             Mean action noise std: 1.94
          Mean value_function loss: 41.9138
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 64.4789
                       Mean reward: 80.80
               Mean episode length: 226.41
    Episode_Reward/reaching_object: 1.3538
    Episode_Reward/rotating_object: 15.1134
        Episode_Reward/action_rate: -0.0250
          Episode_Reward/joint_vel: -0.0451
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.7500
--------------------------------------------------------------------------------
                   Total timesteps: 31358976
                    Iteration time: 2.19s
                      Time elapsed: 00:11:44
                               ETA: 01:38:43

################################################################################
                     [1m Learning iteration 319/3000 [0m                      

                       Computation: 46345 steps/s (collection: 2.020s, learning 0.102s)
             Mean action noise std: 1.94
          Mean value_function loss: 40.9075
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 64.5068
                       Mean reward: 100.11
               Mean episode length: 225.09
    Episode_Reward/reaching_object: 1.3676
    Episode_Reward/rotating_object: 18.3269
        Episode_Reward/action_rate: -0.0252
          Episode_Reward/joint_vel: -0.0448
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 31457280
                    Iteration time: 2.12s
                      Time elapsed: 00:11:46
                               ETA: 01:38:40

################################################################################
                     [1m Learning iteration 320/3000 [0m                      

                       Computation: 45356 steps/s (collection: 2.038s, learning 0.130s)
             Mean action noise std: 1.95
          Mean value_function loss: 38.5768
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 64.5394
                       Mean reward: 88.81
               Mean episode length: 223.34
    Episode_Reward/reaching_object: 1.3319
    Episode_Reward/rotating_object: 16.5845
        Episode_Reward/action_rate: -0.0249
          Episode_Reward/joint_vel: -0.0441
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 4.2083
--------------------------------------------------------------------------------
                   Total timesteps: 31555584
                    Iteration time: 2.17s
                      Time elapsed: 00:11:48
                               ETA: 01:38:38

################################################################################
                     [1m Learning iteration 321/3000 [0m                      

                       Computation: 44227 steps/s (collection: 2.041s, learning 0.182s)
             Mean action noise std: 1.95
          Mean value_function loss: 45.3477
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 64.5751
                       Mean reward: 86.46
               Mean episode length: 212.62
    Episode_Reward/reaching_object: 1.2742
    Episode_Reward/rotating_object: 16.2461
        Episode_Reward/action_rate: -0.0243
          Episode_Reward/joint_vel: -0.0438
      Episode_Termination/time_out: 13.4167
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 5.2083
--------------------------------------------------------------------------------
                   Total timesteps: 31653888
                    Iteration time: 2.22s
                      Time elapsed: 00:11:51
                               ETA: 01:38:36

################################################################################
                     [1m Learning iteration 322/3000 [0m                      

                       Computation: 44792 steps/s (collection: 2.064s, learning 0.131s)
             Mean action noise std: 1.95
          Mean value_function loss: 47.9616
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 64.6077
                       Mean reward: 96.02
               Mean episode length: 227.82
    Episode_Reward/reaching_object: 1.3228
    Episode_Reward/rotating_object: 17.4639
        Episode_Reward/action_rate: -0.0249
          Episode_Reward/joint_vel: -0.0446
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 4.6667
--------------------------------------------------------------------------------
                   Total timesteps: 31752192
                    Iteration time: 2.19s
                      Time elapsed: 00:11:53
                               ETA: 01:38:33

################################################################################
                     [1m Learning iteration 323/3000 [0m                      

                       Computation: 45486 steps/s (collection: 2.046s, learning 0.116s)
             Mean action noise std: 1.95
          Mean value_function loss: 44.0264
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 64.6405
                       Mean reward: 101.51
               Mean episode length: 221.54
    Episode_Reward/reaching_object: 1.3120
    Episode_Reward/rotating_object: 16.6869
        Episode_Reward/action_rate: -0.0249
          Episode_Reward/joint_vel: -0.0443
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.6667
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 31850496
                    Iteration time: 2.16s
                      Time elapsed: 00:11:55
                               ETA: 01:38:31

################################################################################
                     [1m Learning iteration 324/3000 [0m                      

                       Computation: 45400 steps/s (collection: 2.047s, learning 0.119s)
             Mean action noise std: 1.96
          Mean value_function loss: 42.6131
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 64.6761
                       Mean reward: 94.30
               Mean episode length: 208.47
    Episode_Reward/reaching_object: 1.2654
    Episode_Reward/rotating_object: 16.2181
        Episode_Reward/action_rate: -0.0240
          Episode_Reward/joint_vel: -0.0436
      Episode_Termination/time_out: 13.2917
Episode_Termination/object_dropping: 0.5417
     Episode_Termination/robot_out: 5.1250
--------------------------------------------------------------------------------
                   Total timesteps: 31948800
                    Iteration time: 2.17s
                      Time elapsed: 00:11:57
                               ETA: 01:38:28

################################################################################
                     [1m Learning iteration 325/3000 [0m                      

                       Computation: 44986 steps/s (collection: 2.050s, learning 0.135s)
             Mean action noise std: 1.96
          Mean value_function loss: 53.1289
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 64.7037
                       Mean reward: 79.31
               Mean episode length: 212.16
    Episode_Reward/reaching_object: 1.3438
    Episode_Reward/rotating_object: 16.1007
        Episode_Reward/action_rate: -0.0254
          Episode_Reward/joint_vel: -0.0450
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 32047104
                    Iteration time: 2.19s
                      Time elapsed: 00:11:59
                               ETA: 01:38:26

################################################################################
                     [1m Learning iteration 326/3000 [0m                      

                       Computation: 44950 steps/s (collection: 2.045s, learning 0.142s)
             Mean action noise std: 1.96
          Mean value_function loss: 48.2945
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 64.7384
                       Mean reward: 105.25
               Mean episode length: 216.09
    Episode_Reward/reaching_object: 1.2940
    Episode_Reward/rotating_object: 16.2941
        Episode_Reward/action_rate: -0.0246
          Episode_Reward/joint_vel: -0.0429
      Episode_Termination/time_out: 12.7917
Episode_Termination/object_dropping: 0.6667
     Episode_Termination/robot_out: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 32145408
                    Iteration time: 2.19s
                      Time elapsed: 00:12:01
                               ETA: 01:38:23

################################################################################
                     [1m Learning iteration 327/3000 [0m                      

                       Computation: 46430 steps/s (collection: 2.009s, learning 0.109s)
             Mean action noise std: 1.96
          Mean value_function loss: 48.6999
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 64.7749
                       Mean reward: 92.94
               Mean episode length: 210.39
    Episode_Reward/reaching_object: 1.2763
    Episode_Reward/rotating_object: 16.9842
        Episode_Reward/action_rate: -0.0246
          Episode_Reward/joint_vel: -0.0437
      Episode_Termination/time_out: 13.5417
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 4.3333
--------------------------------------------------------------------------------
                   Total timesteps: 32243712
                    Iteration time: 2.12s
                      Time elapsed: 00:12:04
                               ETA: 01:38:20

################################################################################
                     [1m Learning iteration 328/3000 [0m                      

                       Computation: 45565 steps/s (collection: 2.030s, learning 0.127s)
             Mean action noise std: 1.96
          Mean value_function loss: 49.3420
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 64.8006
                       Mean reward: 83.18
               Mean episode length: 228.30
    Episode_Reward/reaching_object: 1.3333
    Episode_Reward/rotating_object: 18.7518
        Episode_Reward/action_rate: -0.0257
          Episode_Reward/joint_vel: -0.0458
      Episode_Termination/time_out: 13.5417
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 32342016
                    Iteration time: 2.16s
                      Time elapsed: 00:12:06
                               ETA: 01:38:18

################################################################################
                     [1m Learning iteration 329/3000 [0m                      

                       Computation: 45990 steps/s (collection: 2.033s, learning 0.104s)
             Mean action noise std: 1.96
          Mean value_function loss: 41.9513
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 64.8266
                       Mean reward: 82.86
               Mean episode length: 223.72
    Episode_Reward/reaching_object: 1.3168
    Episode_Reward/rotating_object: 18.1425
        Episode_Reward/action_rate: -0.0255
          Episode_Reward/joint_vel: -0.0441
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 4.2917
--------------------------------------------------------------------------------
                   Total timesteps: 32440320
                    Iteration time: 2.14s
                      Time elapsed: 00:12:08
                               ETA: 01:38:15

################################################################################
                     [1m Learning iteration 330/3000 [0m                      

                       Computation: 46083 steps/s (collection: 2.030s, learning 0.103s)
             Mean action noise std: 1.97
          Mean value_function loss: 44.3306
               Mean surrogate loss: -0.0098
                 Mean entropy loss: 64.8555
                       Mean reward: 83.74
               Mean episode length: 223.24
    Episode_Reward/reaching_object: 1.2669
    Episode_Reward/rotating_object: 18.2638
        Episode_Reward/action_rate: -0.0249
          Episode_Reward/joint_vel: -0.0439
      Episode_Termination/time_out: 13.1667
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 4.6667
--------------------------------------------------------------------------------
                   Total timesteps: 32538624
                    Iteration time: 2.13s
                      Time elapsed: 00:12:10
                               ETA: 01:38:12

################################################################################
                     [1m Learning iteration 331/3000 [0m                      

                       Computation: 45702 steps/s (collection: 2.052s, learning 0.099s)
             Mean action noise std: 1.97
          Mean value_function loss: 44.2951
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 64.8839
                       Mean reward: 128.42
               Mean episode length: 239.49
    Episode_Reward/reaching_object: 1.3696
    Episode_Reward/rotating_object: 19.1664
        Episode_Reward/action_rate: -0.0262
          Episode_Reward/joint_vel: -0.0459
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 32636928
                    Iteration time: 2.15s
                      Time elapsed: 00:12:12
                               ETA: 01:38:09

################################################################################
                     [1m Learning iteration 332/3000 [0m                      

                       Computation: 45150 steps/s (collection: 2.044s, learning 0.133s)
             Mean action noise std: 1.97
          Mean value_function loss: 46.1523
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 64.9136
                       Mean reward: 100.22
               Mean episode length: 206.97
    Episode_Reward/reaching_object: 1.3165
    Episode_Reward/rotating_object: 18.9965
        Episode_Reward/action_rate: -0.0253
          Episode_Reward/joint_vel: -0.0434
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.6667
     Episode_Termination/robot_out: 4.2917
--------------------------------------------------------------------------------
                   Total timesteps: 32735232
                    Iteration time: 2.18s
                      Time elapsed: 00:12:14
                               ETA: 01:38:07

################################################################################
                     [1m Learning iteration 333/3000 [0m                      

                       Computation: 19854 steps/s (collection: 4.825s, learning 0.127s)
             Mean action noise std: 1.97
          Mean value_function loss: 43.9717
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 64.9405
                       Mean reward: 122.32
               Mean episode length: 228.09
    Episode_Reward/reaching_object: 1.3482
    Episode_Reward/rotating_object: 20.9309
        Episode_Reward/action_rate: -0.0260
          Episode_Reward/joint_vel: -0.0442
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.6667
--------------------------------------------------------------------------------
                   Total timesteps: 32833536
                    Iteration time: 4.95s
                      Time elapsed: 00:12:19
                               ETA: 01:38:27

################################################################################
                     [1m Learning iteration 334/3000 [0m                      

                       Computation: 14528 steps/s (collection: 6.639s, learning 0.127s)
             Mean action noise std: 1.98
          Mean value_function loss: 45.2723
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 64.9823
                       Mean reward: 114.65
               Mean episode length: 220.21
    Episode_Reward/reaching_object: 1.3618
    Episode_Reward/rotating_object: 19.8456
        Episode_Reward/action_rate: -0.0256
          Episode_Reward/joint_vel: -0.0438
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 4.6667
--------------------------------------------------------------------------------
                   Total timesteps: 32931840
                    Iteration time: 6.77s
                      Time elapsed: 00:12:26
                               ETA: 01:39:01

################################################################################
                     [1m Learning iteration 335/3000 [0m                      

                       Computation: 14273 steps/s (collection: 6.741s, learning 0.146s)
             Mean action noise std: 1.98
          Mean value_function loss: 42.5070
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 65.0241
                       Mean reward: 93.33
               Mean episode length: 222.63
    Episode_Reward/reaching_object: 1.3386
    Episode_Reward/rotating_object: 20.3177
        Episode_Reward/action_rate: -0.0256
          Episode_Reward/joint_vel: -0.0439
      Episode_Termination/time_out: 13.7500
Episode_Termination/object_dropping: 0.6667
     Episode_Termination/robot_out: 3.9583
--------------------------------------------------------------------------------
                   Total timesteps: 33030144
                    Iteration time: 6.89s
                      Time elapsed: 00:12:33
                               ETA: 01:39:35

################################################################################
                     [1m Learning iteration 336/3000 [0m                      

                       Computation: 13811 steps/s (collection: 6.951s, learning 0.167s)
             Mean action noise std: 1.98
          Mean value_function loss: 45.5774
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 65.0549
                       Mean reward: 121.77
               Mean episode length: 225.12
    Episode_Reward/reaching_object: 1.3300
    Episode_Reward/rotating_object: 19.1352
        Episode_Reward/action_rate: -0.0256
          Episode_Reward/joint_vel: -0.0440
      Episode_Termination/time_out: 13.4583
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 4.6250
--------------------------------------------------------------------------------
                   Total timesteps: 33128448
                    Iteration time: 7.12s
                      Time elapsed: 00:12:40
                               ETA: 01:40:12

################################################################################
                     [1m Learning iteration 337/3000 [0m                      

                       Computation: 13319 steps/s (collection: 7.244s, learning 0.136s)
             Mean action noise std: 1.98
          Mean value_function loss: 43.0247
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 65.0864
                       Mean reward: 99.24
               Mean episode length: 210.06
    Episode_Reward/reaching_object: 1.3235
    Episode_Reward/rotating_object: 18.0860
        Episode_Reward/action_rate: -0.0253
          Episode_Reward/joint_vel: -0.0426
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 4.5833
--------------------------------------------------------------------------------
                   Total timesteps: 33226752
                    Iteration time: 7.38s
                      Time elapsed: 00:12:47
                               ETA: 01:40:50

################################################################################
                     [1m Learning iteration 338/3000 [0m                      

                       Computation: 14046 steps/s (collection: 6.882s, learning 0.116s)
             Mean action noise std: 1.98
          Mean value_function loss: 44.1829
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 65.1251
                       Mean reward: 107.69
               Mean episode length: 218.60
    Episode_Reward/reaching_object: 1.3088
    Episode_Reward/rotating_object: 17.9887
        Episode_Reward/action_rate: -0.0252
          Episode_Reward/joint_vel: -0.0433
      Episode_Termination/time_out: 12.5000
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 4.5000
--------------------------------------------------------------------------------
                   Total timesteps: 33325056
                    Iteration time: 7.00s
                      Time elapsed: 00:12:54
                               ETA: 01:41:25

################################################################################
                     [1m Learning iteration 339/3000 [0m                      

                       Computation: 13836 steps/s (collection: 6.942s, learning 0.163s)
             Mean action noise std: 1.99
          Mean value_function loss: 42.6974
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 65.1591
                       Mean reward: 100.66
               Mean episode length: 223.91
    Episode_Reward/reaching_object: 1.3056
    Episode_Reward/rotating_object: 18.0699
        Episode_Reward/action_rate: -0.0253
          Episode_Reward/joint_vel: -0.0429
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 5.1667
--------------------------------------------------------------------------------
                   Total timesteps: 33423360
                    Iteration time: 7.10s
                      Time elapsed: 00:13:02
                               ETA: 01:42:00

################################################################################
                     [1m Learning iteration 340/3000 [0m                      

                       Computation: 14014 steps/s (collection: 6.843s, learning 0.171s)
             Mean action noise std: 1.99
          Mean value_function loss: 43.9122
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 65.1902
                       Mean reward: 110.86
               Mean episode length: 216.51
    Episode_Reward/reaching_object: 1.3512
    Episode_Reward/rotating_object: 18.8173
        Episode_Reward/action_rate: -0.0258
          Episode_Reward/joint_vel: -0.0432
      Episode_Termination/time_out: 13.4167
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 4.7083
--------------------------------------------------------------------------------
                   Total timesteps: 33521664
                    Iteration time: 7.01s
                      Time elapsed: 00:13:09
                               ETA: 01:42:35

################################################################################
                     [1m Learning iteration 341/3000 [0m                      

                       Computation: 11986 steps/s (collection: 7.943s, learning 0.258s)
             Mean action noise std: 1.99
          Mean value_function loss: 45.7584
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 65.2154
                       Mean reward: 97.08
               Mean episode length: 221.31
    Episode_Reward/reaching_object: 1.3458
    Episode_Reward/rotating_object: 18.7379
        Episode_Reward/action_rate: -0.0259
          Episode_Reward/joint_vel: -0.0432
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 4.5000
--------------------------------------------------------------------------------
                   Total timesteps: 33619968
                    Iteration time: 8.20s
                      Time elapsed: 00:13:17
                               ETA: 01:43:18

################################################################################
                     [1m Learning iteration 342/3000 [0m                      

                       Computation: 36495 steps/s (collection: 2.522s, learning 0.172s)
             Mean action noise std: 1.99
          Mean value_function loss: 41.7257
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 65.2402
                       Mean reward: 103.13
               Mean episode length: 216.20
    Episode_Reward/reaching_object: 1.3284
    Episode_Reward/rotating_object: 18.2979
        Episode_Reward/action_rate: -0.0255
          Episode_Reward/joint_vel: -0.0420
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 5.2917
--------------------------------------------------------------------------------
                   Total timesteps: 33718272
                    Iteration time: 2.69s
                      Time elapsed: 00:13:19
                               ETA: 01:43:19

################################################################################
                     [1m Learning iteration 343/3000 [0m                      

                       Computation: 43625 steps/s (collection: 2.135s, learning 0.118s)
             Mean action noise std: 1.99
          Mean value_function loss: 45.7446
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 65.2743
                       Mean reward: 123.88
               Mean episode length: 227.46
    Episode_Reward/reaching_object: 1.3626
    Episode_Reward/rotating_object: 22.8217
        Episode_Reward/action_rate: -0.0259
          Episode_Reward/joint_vel: -0.0420
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 4.4167
--------------------------------------------------------------------------------
                   Total timesteps: 33816576
                    Iteration time: 2.25s
                      Time elapsed: 00:13:22
                               ETA: 01:43:16

################################################################################
                     [1m Learning iteration 344/3000 [0m                      

                       Computation: 39727 steps/s (collection: 2.215s, learning 0.259s)
             Mean action noise std: 2.00
          Mean value_function loss: 50.2621
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 65.3104
                       Mean reward: 84.21
               Mean episode length: 211.34
    Episode_Reward/reaching_object: 1.3850
    Episode_Reward/rotating_object: 18.6560
        Episode_Reward/action_rate: -0.0264
          Episode_Reward/joint_vel: -0.0428
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 4.4167
--------------------------------------------------------------------------------
                   Total timesteps: 33914880
                    Iteration time: 2.47s
                      Time elapsed: 00:13:24
                               ETA: 01:43:14

################################################################################
                     [1m Learning iteration 345/3000 [0m                      

                       Computation: 38921 steps/s (collection: 2.342s, learning 0.184s)
             Mean action noise std: 2.00
          Mean value_function loss: 45.4429
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 65.3420
                       Mean reward: 113.99
               Mean episode length: 221.49
    Episode_Reward/reaching_object: 1.3608
    Episode_Reward/rotating_object: 21.1236
        Episode_Reward/action_rate: -0.0258
          Episode_Reward/joint_vel: -0.0422
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 4.5417
--------------------------------------------------------------------------------
                   Total timesteps: 34013184
                    Iteration time: 2.53s
                      Time elapsed: 00:13:27
                               ETA: 01:43:14

################################################################################
                     [1m Learning iteration 346/3000 [0m                      

                       Computation: 40316 steps/s (collection: 2.275s, learning 0.164s)
             Mean action noise std: 2.00
          Mean value_function loss: 56.1907
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 65.3756
                       Mean reward: 95.76
               Mean episode length: 215.56
    Episode_Reward/reaching_object: 1.3753
    Episode_Reward/rotating_object: 18.4393
        Episode_Reward/action_rate: -0.0258
          Episode_Reward/joint_vel: -0.0425
      Episode_Termination/time_out: 13.6250
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 5.0417
--------------------------------------------------------------------------------
                   Total timesteps: 34111488
                    Iteration time: 2.44s
                      Time elapsed: 00:13:29
                               ETA: 01:43:12

################################################################################
                     [1m Learning iteration 347/3000 [0m                      

                       Computation: 42789 steps/s (collection: 2.155s, learning 0.142s)
             Mean action noise std: 2.00
          Mean value_function loss: 46.8858
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 65.4056
                       Mean reward: 95.59
               Mean episode length: 215.70
    Episode_Reward/reaching_object: 1.3154
    Episode_Reward/rotating_object: 16.4461
        Episode_Reward/action_rate: -0.0252
          Episode_Reward/joint_vel: -0.0421
      Episode_Termination/time_out: 12.6667
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 4.9167
--------------------------------------------------------------------------------
                   Total timesteps: 34209792
                    Iteration time: 2.30s
                      Time elapsed: 00:13:31
                               ETA: 01:43:09

################################################################################
                     [1m Learning iteration 348/3000 [0m                      

                       Computation: 44896 steps/s (collection: 2.092s, learning 0.098s)
             Mean action noise std: 2.00
          Mean value_function loss: 45.6852
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 65.4418
                       Mean reward: 86.31
               Mean episode length: 216.58
    Episode_Reward/reaching_object: 1.3796
    Episode_Reward/rotating_object: 18.2332
        Episode_Reward/action_rate: -0.0261
          Episode_Reward/joint_vel: -0.0420
      Episode_Termination/time_out: 13.5000
Episode_Termination/object_dropping: 0.5000
     Episode_Termination/robot_out: 3.9583
--------------------------------------------------------------------------------
                   Total timesteps: 34308096
                    Iteration time: 2.19s
                      Time elapsed: 00:13:34
                               ETA: 01:43:06

################################################################################
                     [1m Learning iteration 349/3000 [0m                      

                       Computation: 45666 steps/s (collection: 2.034s, learning 0.119s)
             Mean action noise std: 2.01
          Mean value_function loss: 51.9428
               Mean surrogate loss: -0.0096
                 Mean entropy loss: 65.4709
                       Mean reward: 110.79
               Mean episode length: 228.97
    Episode_Reward/reaching_object: 1.4298
    Episode_Reward/rotating_object: 21.3626
        Episode_Reward/action_rate: -0.0266
          Episode_Reward/joint_vel: -0.0426
      Episode_Termination/time_out: 13.7500
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.9583
--------------------------------------------------------------------------------
                   Total timesteps: 34406400
                    Iteration time: 2.15s
                      Time elapsed: 00:13:36
                               ETA: 01:43:02

################################################################################
                     [1m Learning iteration 350/3000 [0m                      

                       Computation: 45516 steps/s (collection: 2.049s, learning 0.111s)
             Mean action noise std: 2.01
          Mean value_function loss: 45.0562
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 65.4990
                       Mean reward: 112.56
               Mean episode length: 219.82
    Episode_Reward/reaching_object: 1.3952
    Episode_Reward/rotating_object: 21.1246
        Episode_Reward/action_rate: -0.0263
          Episode_Reward/joint_vel: -0.0428
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 4.9167
--------------------------------------------------------------------------------
                   Total timesteps: 34504704
                    Iteration time: 2.16s
                      Time elapsed: 00:13:38
                               ETA: 01:42:59

################################################################################
                     [1m Learning iteration 351/3000 [0m                      

                       Computation: 44755 steps/s (collection: 2.023s, learning 0.173s)
             Mean action noise std: 2.01
          Mean value_function loss: 46.7071
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 65.5302
                       Mean reward: 128.04
               Mean episode length: 227.73
    Episode_Reward/reaching_object: 1.4300
    Episode_Reward/rotating_object: 21.2738
        Episode_Reward/action_rate: -0.0268
          Episode_Reward/joint_vel: -0.0420
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 34603008
                    Iteration time: 2.20s
                      Time elapsed: 00:13:40
                               ETA: 01:42:55

################################################################################
                     [1m Learning iteration 352/3000 [0m                      

                       Computation: 45175 steps/s (collection: 2.014s, learning 0.162s)
             Mean action noise std: 2.01
          Mean value_function loss: 48.7461
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 65.5584
                       Mean reward: 124.50
               Mean episode length: 218.22
    Episode_Reward/reaching_object: 1.3857
    Episode_Reward/rotating_object: 19.3505
        Episode_Reward/action_rate: -0.0264
          Episode_Reward/joint_vel: -0.0429
      Episode_Termination/time_out: 13.3333
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 4.5833
--------------------------------------------------------------------------------
                   Total timesteps: 34701312
                    Iteration time: 2.18s
                      Time elapsed: 00:13:42
                               ETA: 01:42:52

################################################################################
                     [1m Learning iteration 353/3000 [0m                      

                       Computation: 46877 steps/s (collection: 1.994s, learning 0.104s)
             Mean action noise std: 2.01
          Mean value_function loss: 48.0146
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 65.5833
                       Mean reward: 119.50
               Mean episode length: 230.41
    Episode_Reward/reaching_object: 1.4279
    Episode_Reward/rotating_object: 21.1771
        Episode_Reward/action_rate: -0.0270
          Episode_Reward/joint_vel: -0.0428
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 4.0833
--------------------------------------------------------------------------------
                   Total timesteps: 34799616
                    Iteration time: 2.10s
                      Time elapsed: 00:13:44
                               ETA: 01:42:48

################################################################################
                     [1m Learning iteration 354/3000 [0m                      

                       Computation: 45262 steps/s (collection: 2.063s, learning 0.109s)
             Mean action noise std: 2.02
          Mean value_function loss: 51.0948
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 65.6063
                       Mean reward: 95.56
               Mean episode length: 215.53
    Episode_Reward/reaching_object: 1.3900
    Episode_Reward/rotating_object: 20.5725
        Episode_Reward/action_rate: -0.0265
          Episode_Reward/joint_vel: -0.0431
      Episode_Termination/time_out: 12.7083
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 4.3750
--------------------------------------------------------------------------------
                   Total timesteps: 34897920
                    Iteration time: 2.17s
                      Time elapsed: 00:13:47
                               ETA: 01:42:44

################################################################################
                     [1m Learning iteration 355/3000 [0m                      

                       Computation: 43673 steps/s (collection: 2.153s, learning 0.098s)
             Mean action noise std: 2.02
          Mean value_function loss: 50.9591
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 65.6349
                       Mean reward: 132.67
               Mean episode length: 219.62
    Episode_Reward/reaching_object: 1.3966
    Episode_Reward/rotating_object: 22.3818
        Episode_Reward/action_rate: -0.0267
          Episode_Reward/joint_vel: -0.0427
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 4.2500
--------------------------------------------------------------------------------
                   Total timesteps: 34996224
                    Iteration time: 2.25s
                      Time elapsed: 00:13:49
                               ETA: 01:42:41

################################################################################
                     [1m Learning iteration 356/3000 [0m                      

                       Computation: 46998 steps/s (collection: 1.999s, learning 0.093s)
             Mean action noise std: 2.02
          Mean value_function loss: 47.1519
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 65.6675
                       Mean reward: 112.18
               Mean episode length: 220.27
    Episode_Reward/reaching_object: 1.3768
    Episode_Reward/rotating_object: 20.3864
        Episode_Reward/action_rate: -0.0262
          Episode_Reward/joint_vel: -0.0411
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 5.0833
--------------------------------------------------------------------------------
                   Total timesteps: 35094528
                    Iteration time: 2.09s
                      Time elapsed: 00:13:51
                               ETA: 01:42:37

################################################################################
                     [1m Learning iteration 357/3000 [0m                      

                       Computation: 46225 steps/s (collection: 1.980s, learning 0.147s)
             Mean action noise std: 2.02
          Mean value_function loss: 50.4422
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 65.6968
                       Mean reward: 131.47
               Mean episode length: 215.00
    Episode_Reward/reaching_object: 1.3955
    Episode_Reward/rotating_object: 22.8553
        Episode_Reward/action_rate: -0.0264
          Episode_Reward/joint_vel: -0.0409
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 4.2917
--------------------------------------------------------------------------------
                   Total timesteps: 35192832
                    Iteration time: 2.13s
                      Time elapsed: 00:13:53
                               ETA: 01:42:33

################################################################################
                     [1m Learning iteration 358/3000 [0m                      

                       Computation: 46246 steps/s (collection: 1.936s, learning 0.190s)
             Mean action noise std: 2.02
          Mean value_function loss: 48.9194
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 65.7192
                       Mean reward: 90.06
               Mean episode length: 221.79
    Episode_Reward/reaching_object: 1.4370
    Episode_Reward/rotating_object: 21.0090
        Episode_Reward/action_rate: -0.0273
          Episode_Reward/joint_vel: -0.0430
      Episode_Termination/time_out: 12.9167
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 35291136
                    Iteration time: 2.13s
                      Time elapsed: 00:13:55
                               ETA: 01:42:30

################################################################################
                     [1m Learning iteration 359/3000 [0m                      

                       Computation: 42391 steps/s (collection: 2.211s, learning 0.108s)
             Mean action noise std: 2.02
          Mean value_function loss: 45.7142
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 65.7421
                       Mean reward: 129.68
               Mean episode length: 228.54
    Episode_Reward/reaching_object: 1.3776
    Episode_Reward/rotating_object: 21.5549
        Episode_Reward/action_rate: -0.0265
          Episode_Reward/joint_vel: -0.0420
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 4.0833
--------------------------------------------------------------------------------
                   Total timesteps: 35389440
                    Iteration time: 2.32s
                      Time elapsed: 00:13:57
                               ETA: 01:42:27

################################################################################
                     [1m Learning iteration 360/3000 [0m                      

                       Computation: 46077 steps/s (collection: 2.015s, learning 0.119s)
             Mean action noise std: 2.03
          Mean value_function loss: 45.5374
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 65.7666
                       Mean reward: 122.35
               Mean episode length: 229.21
    Episode_Reward/reaching_object: 1.4050
    Episode_Reward/rotating_object: 23.0354
        Episode_Reward/action_rate: -0.0271
          Episode_Reward/joint_vel: -0.0419
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 35487744
                    Iteration time: 2.13s
                      Time elapsed: 00:14:00
                               ETA: 01:42:23

################################################################################
                     [1m Learning iteration 361/3000 [0m                      

                       Computation: 45923 steps/s (collection: 1.964s, learning 0.177s)
             Mean action noise std: 2.03
          Mean value_function loss: 52.2814
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 65.7976
                       Mean reward: 127.58
               Mean episode length: 227.68
    Episode_Reward/reaching_object: 1.4027
    Episode_Reward/rotating_object: 21.7131
        Episode_Reward/action_rate: -0.0271
          Episode_Reward/joint_vel: -0.0421
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 4.2500
--------------------------------------------------------------------------------
                   Total timesteps: 35586048
                    Iteration time: 2.14s
                      Time elapsed: 00:14:02
                               ETA: 01:42:20

################################################################################
                     [1m Learning iteration 362/3000 [0m                      

                       Computation: 46617 steps/s (collection: 1.988s, learning 0.121s)
             Mean action noise std: 2.03
          Mean value_function loss: 55.0629
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 65.8302
                       Mean reward: 120.60
               Mean episode length: 218.07
    Episode_Reward/reaching_object: 1.3761
    Episode_Reward/rotating_object: 23.1904
        Episode_Reward/action_rate: -0.0269
          Episode_Reward/joint_vel: -0.0410
      Episode_Termination/time_out: 13.4583
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 4.1250
--------------------------------------------------------------------------------
                   Total timesteps: 35684352
                    Iteration time: 2.11s
                      Time elapsed: 00:14:04
                               ETA: 01:42:16

################################################################################
                     [1m Learning iteration 363/3000 [0m                      

                       Computation: 46783 steps/s (collection: 1.996s, learning 0.106s)
             Mean action noise std: 2.03
          Mean value_function loss: 50.6907
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 65.8578
                       Mean reward: 128.32
               Mean episode length: 221.93
    Episode_Reward/reaching_object: 1.4130
    Episode_Reward/rotating_object: 23.8474
        Episode_Reward/action_rate: -0.0275
          Episode_Reward/joint_vel: -0.0424
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 35782656
                    Iteration time: 2.10s
                      Time elapsed: 00:14:06
                               ETA: 01:42:12

################################################################################
                     [1m Learning iteration 364/3000 [0m                      

                       Computation: 41958 steps/s (collection: 2.140s, learning 0.203s)
             Mean action noise std: 2.03
          Mean value_function loss: 50.1026
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 65.8845
                       Mean reward: 119.22
               Mean episode length: 228.63
    Episode_Reward/reaching_object: 1.3842
    Episode_Reward/rotating_object: 23.3763
        Episode_Reward/action_rate: -0.0272
          Episode_Reward/joint_vel: -0.0423
      Episode_Termination/time_out: 13.7500
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 35880960
                    Iteration time: 2.34s
                      Time elapsed: 00:14:08
                               ETA: 01:42:10

################################################################################
                     [1m Learning iteration 365/3000 [0m                      

                       Computation: 46202 steps/s (collection: 2.017s, learning 0.111s)
             Mean action noise std: 2.04
          Mean value_function loss: 52.6496
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 65.9094
                       Mean reward: 123.65
               Mean episode length: 224.23
    Episode_Reward/reaching_object: 1.3850
    Episode_Reward/rotating_object: 23.0824
        Episode_Reward/action_rate: -0.0272
          Episode_Reward/joint_vel: -0.0411
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 4.2083
--------------------------------------------------------------------------------
                   Total timesteps: 35979264
                    Iteration time: 2.13s
                      Time elapsed: 00:14:10
                               ETA: 01:42:06

################################################################################
                     [1m Learning iteration 366/3000 [0m                      

                       Computation: 46545 steps/s (collection: 2.006s, learning 0.106s)
             Mean action noise std: 2.04
          Mean value_function loss: 52.6255
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 65.9365
                       Mean reward: 104.39
               Mean episode length: 220.15
    Episode_Reward/reaching_object: 1.4099
    Episode_Reward/rotating_object: 20.7937
        Episode_Reward/action_rate: -0.0276
          Episode_Reward/joint_vel: -0.0422
      Episode_Termination/time_out: 13.6250
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 4.1667
--------------------------------------------------------------------------------
                   Total timesteps: 36077568
                    Iteration time: 2.11s
                      Time elapsed: 00:14:13
                               ETA: 01:42:02

################################################################################
                     [1m Learning iteration 367/3000 [0m                      

                       Computation: 47657 steps/s (collection: 1.952s, learning 0.111s)
             Mean action noise std: 2.04
          Mean value_function loss: 43.8974
               Mean surrogate loss: -0.0101
                 Mean entropy loss: 65.9626
                       Mean reward: 123.37
               Mean episode length: 215.99
    Episode_Reward/reaching_object: 1.4006
    Episode_Reward/rotating_object: 24.7468
        Episode_Reward/action_rate: -0.0275
          Episode_Reward/joint_vel: -0.0404
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.3750
     Episode_Termination/robot_out: 3.7500
--------------------------------------------------------------------------------
                   Total timesteps: 36175872
                    Iteration time: 2.06s
                      Time elapsed: 00:14:15
                               ETA: 01:41:58

################################################################################
                     [1m Learning iteration 368/3000 [0m                      

                       Computation: 44577 steps/s (collection: 2.018s, learning 0.187s)
             Mean action noise std: 2.04
          Mean value_function loss: 42.1180
               Mean surrogate loss: -0.0096
                 Mean entropy loss: 65.9989
                       Mean reward: 102.28
               Mean episode length: 210.57
    Episode_Reward/reaching_object: 1.3809
    Episode_Reward/rotating_object: 21.4942
        Episode_Reward/action_rate: -0.0271
          Episode_Reward/joint_vel: -0.0409
      Episode_Termination/time_out: 13.3750
Episode_Termination/object_dropping: 0.4583
     Episode_Termination/robot_out: 4.1667
--------------------------------------------------------------------------------
                   Total timesteps: 36274176
                    Iteration time: 2.21s
                      Time elapsed: 00:14:17
                               ETA: 01:41:55

################################################################################
                     [1m Learning iteration 369/3000 [0m                      

                       Computation: 43510 steps/s (collection: 2.120s, learning 0.139s)
             Mean action noise std: 2.04
          Mean value_function loss: 50.0372
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 66.0384
                       Mean reward: 121.77
               Mean episode length: 225.32
    Episode_Reward/reaching_object: 1.3991
    Episode_Reward/rotating_object: 22.2912
        Episode_Reward/action_rate: -0.0273
          Episode_Reward/joint_vel: -0.0418
      Episode_Termination/time_out: 12.7917
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 36372480
                    Iteration time: 2.26s
                      Time elapsed: 00:14:19
                               ETA: 01:41:52

################################################################################
                     [1m Learning iteration 370/3000 [0m                      

                       Computation: 47787 steps/s (collection: 1.947s, learning 0.110s)
             Mean action noise std: 2.05
          Mean value_function loss: 52.7222
               Mean surrogate loss: -0.0095
                 Mean entropy loss: 66.0604
                       Mean reward: 118.48
               Mean episode length: 211.08
    Episode_Reward/reaching_object: 1.3824
    Episode_Reward/rotating_object: 22.6654
        Episode_Reward/action_rate: -0.0270
          Episode_Reward/joint_vel: -0.0404
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 4.8333
--------------------------------------------------------------------------------
                   Total timesteps: 36470784
                    Iteration time: 2.06s
                      Time elapsed: 00:14:21
                               ETA: 01:41:48

################################################################################
                     [1m Learning iteration 371/3000 [0m                      

                       Computation: 44466 steps/s (collection: 2.063s, learning 0.148s)
             Mean action noise std: 2.05
          Mean value_function loss: 51.9376
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 66.0864
                       Mean reward: 112.58
               Mean episode length: 212.09
    Episode_Reward/reaching_object: 1.3997
    Episode_Reward/rotating_object: 24.3164
        Episode_Reward/action_rate: -0.0276
          Episode_Reward/joint_vel: -0.0410
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.5417
--------------------------------------------------------------------------------
                   Total timesteps: 36569088
                    Iteration time: 2.21s
                      Time elapsed: 00:14:23
                               ETA: 01:41:45

################################################################################
                     [1m Learning iteration 372/3000 [0m                      

                       Computation: 46265 steps/s (collection: 2.010s, learning 0.115s)
             Mean action noise std: 2.05
          Mean value_function loss: 51.9690
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 66.1151
                       Mean reward: 116.08
               Mean episode length: 215.36
    Episode_Reward/reaching_object: 1.3681
    Episode_Reward/rotating_object: 21.8846
        Episode_Reward/action_rate: -0.0271
          Episode_Reward/joint_vel: -0.0405
      Episode_Termination/time_out: 13.6250
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 4.1250
--------------------------------------------------------------------------------
                   Total timesteps: 36667392
                    Iteration time: 2.12s
                      Time elapsed: 00:14:25
                               ETA: 01:41:41

################################################################################
                     [1m Learning iteration 373/3000 [0m                      

                       Computation: 44077 steps/s (collection: 2.121s, learning 0.109s)
             Mean action noise std: 2.05
          Mean value_function loss: 52.6932
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 66.1405
                       Mean reward: 122.17
               Mean episode length: 225.27
    Episode_Reward/reaching_object: 1.4104
    Episode_Reward/rotating_object: 20.9609
        Episode_Reward/action_rate: -0.0276
          Episode_Reward/joint_vel: -0.0405
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 36765696
                    Iteration time: 2.23s
                      Time elapsed: 00:14:28
                               ETA: 01:41:38

################################################################################
                     [1m Learning iteration 374/3000 [0m                      

                       Computation: 46866 steps/s (collection: 1.997s, learning 0.100s)
             Mean action noise std: 2.05
          Mean value_function loss: 54.5579
               Mean surrogate loss: -0.0096
                 Mean entropy loss: 66.1706
                       Mean reward: 111.94
               Mean episode length: 223.62
    Episode_Reward/reaching_object: 1.3799
    Episode_Reward/rotating_object: 23.4280
        Episode_Reward/action_rate: -0.0273
          Episode_Reward/joint_vel: -0.0401
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 4.4167
--------------------------------------------------------------------------------
                   Total timesteps: 36864000
                    Iteration time: 2.10s
                      Time elapsed: 00:14:30
                               ETA: 01:41:34

################################################################################
                     [1m Learning iteration 375/3000 [0m                      

                       Computation: 44575 steps/s (collection: 2.034s, learning 0.171s)
             Mean action noise std: 2.06
          Mean value_function loss: 52.7455
               Mean surrogate loss: -0.0096
                 Mean entropy loss: 66.2105
                       Mean reward: 121.29
               Mean episode length: 217.24
    Episode_Reward/reaching_object: 1.4213
    Episode_Reward/rotating_object: 22.9610
        Episode_Reward/action_rate: -0.0277
          Episode_Reward/joint_vel: -0.0411
      Episode_Termination/time_out: 13.0833
Episode_Termination/object_dropping: 0.2083
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 36962304
                    Iteration time: 2.21s
                      Time elapsed: 00:14:32
                               ETA: 01:41:31

################################################################################
                     [1m Learning iteration 376/3000 [0m                      

                       Computation: 44038 steps/s (collection: 2.091s, learning 0.142s)
             Mean action noise std: 2.06
          Mean value_function loss: 55.7299
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 66.2447
                       Mean reward: 126.06
               Mean episode length: 220.61
    Episode_Reward/reaching_object: 1.4445
    Episode_Reward/rotating_object: 25.2288
        Episode_Reward/action_rate: -0.0282
          Episode_Reward/joint_vel: -0.0413
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.4167
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 37060608
                    Iteration time: 2.23s
                      Time elapsed: 00:14:34
                               ETA: 01:41:28

################################################################################
                     [1m Learning iteration 377/3000 [0m                      

                       Computation: 44666 steps/s (collection: 2.055s, learning 0.146s)
             Mean action noise std: 2.06
          Mean value_function loss: 57.4168
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 66.2704
                       Mean reward: 107.11
               Mean episode length: 224.36
    Episode_Reward/reaching_object: 1.4637
    Episode_Reward/rotating_object: 25.3198
        Episode_Reward/action_rate: -0.0286
          Episode_Reward/joint_vel: -0.0408
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 37158912
                    Iteration time: 2.20s
                      Time elapsed: 00:14:36
                               ETA: 01:41:25

################################################################################
                     [1m Learning iteration 378/3000 [0m                      

                       Computation: 40928 steps/s (collection: 2.298s, learning 0.104s)
             Mean action noise std: 2.06
          Mean value_function loss: 60.2153
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 66.2986
                       Mean reward: 147.39
               Mean episode length: 221.14
    Episode_Reward/reaching_object: 1.4271
    Episode_Reward/rotating_object: 24.8617
        Episode_Reward/action_rate: -0.0280
          Episode_Reward/joint_vel: -0.0407
      Episode_Termination/time_out: 13.5417
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 37257216
                    Iteration time: 2.40s
                      Time elapsed: 00:14:39
                               ETA: 01:41:23

################################################################################
                     [1m Learning iteration 379/3000 [0m                      

                       Computation: 46123 steps/s (collection: 2.034s, learning 0.098s)
             Mean action noise std: 2.06
          Mean value_function loss: 63.5855
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 66.3364
                       Mean reward: 140.01
               Mean episode length: 214.02
    Episode_Reward/reaching_object: 1.4411
    Episode_Reward/rotating_object: 25.3577
        Episode_Reward/action_rate: -0.0280
          Episode_Reward/joint_vel: -0.0404
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 4.1250
--------------------------------------------------------------------------------
                   Total timesteps: 37355520
                    Iteration time: 2.13s
                      Time elapsed: 00:14:41
                               ETA: 01:41:19

################################################################################
                     [1m Learning iteration 380/3000 [0m                      

                       Computation: 44453 steps/s (collection: 2.056s, learning 0.156s)
             Mean action noise std: 2.07
          Mean value_function loss: 55.6832
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 66.3769
                       Mean reward: 127.96
               Mean episode length: 213.51
    Episode_Reward/reaching_object: 1.4044
    Episode_Reward/rotating_object: 25.6895
        Episode_Reward/action_rate: -0.0275
          Episode_Reward/joint_vel: -0.0393
      Episode_Termination/time_out: 13.8750
Episode_Termination/object_dropping: 0.3333
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 37453824
                    Iteration time: 2.21s
                      Time elapsed: 00:14:43
                               ETA: 01:41:16

################################################################################
                     [1m Learning iteration 381/3000 [0m                      

                       Computation: 45651 steps/s (collection: 2.002s, learning 0.152s)
             Mean action noise std: 2.07
          Mean value_function loss: 53.7856
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 66.4033
                       Mean reward: 128.21
               Mean episode length: 224.75
    Episode_Reward/reaching_object: 1.4537
    Episode_Reward/rotating_object: 23.2247
        Episode_Reward/action_rate: -0.0285
          Episode_Reward/joint_vel: -0.0407
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 37552128
                    Iteration time: 2.15s
                      Time elapsed: 00:14:45
                               ETA: 01:41:13

################################################################################
                     [1m Learning iteration 382/3000 [0m                      

                       Computation: 44434 steps/s (collection: 2.095s, learning 0.118s)
             Mean action noise std: 2.07
          Mean value_function loss: 62.9222
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 66.4302
                       Mean reward: 153.57
               Mean episode length: 219.53
    Episode_Reward/reaching_object: 1.4153
    Episode_Reward/rotating_object: 26.6036
        Episode_Reward/action_rate: -0.0279
          Episode_Reward/joint_vel: -0.0399
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.2917
     Episode_Termination/robot_out: 4.1667
--------------------------------------------------------------------------------
                   Total timesteps: 37650432
                    Iteration time: 2.21s
                      Time elapsed: 00:14:48
                               ETA: 01:41:10

################################################################################
                     [1m Learning iteration 383/3000 [0m                      

                       Computation: 45334 steps/s (collection: 2.067s, learning 0.102s)
             Mean action noise std: 2.07
          Mean value_function loss: 64.1642
               Mean surrogate loss: -0.0096
                 Mean entropy loss: 66.4532
                       Mean reward: 123.04
               Mean episode length: 219.66
    Episode_Reward/reaching_object: 1.3892
    Episode_Reward/rotating_object: 23.1410
        Episode_Reward/action_rate: -0.0276
          Episode_Reward/joint_vel: -0.0402
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.2500
     Episode_Termination/robot_out: 4.4167
--------------------------------------------------------------------------------
                   Total timesteps: 37748736
                    Iteration time: 2.17s
                      Time elapsed: 00:14:50
                               ETA: 01:41:07

################################################################################
                     [1m Learning iteration 384/3000 [0m                      

                       Computation: 46774 steps/s (collection: 1.992s, learning 0.110s)
             Mean action noise std: 2.07
          Mean value_function loss: 60.6631
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 66.4754
                       Mean reward: 125.56
               Mean episode length: 208.16
    Episode_Reward/reaching_object: 1.4484
    Episode_Reward/rotating_object: 25.2700
        Episode_Reward/action_rate: -0.0282
          Episode_Reward/joint_vel: -0.0400
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.3750
--------------------------------------------------------------------------------
                   Total timesteps: 37847040
                    Iteration time: 2.10s
                      Time elapsed: 00:14:52
                               ETA: 01:41:03

################################################################################
                     [1m Learning iteration 385/3000 [0m                      

                       Computation: 42512 steps/s (collection: 2.197s, learning 0.116s)
             Mean action noise std: 2.08
          Mean value_function loss: 53.9832
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 66.5041
                       Mean reward: 152.65
               Mean episode length: 211.79
    Episode_Reward/reaching_object: 1.4033
    Episode_Reward/rotating_object: 26.8125
        Episode_Reward/action_rate: -0.0278
          Episode_Reward/joint_vel: -0.0393
      Episode_Termination/time_out: 13.4583
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.2083
--------------------------------------------------------------------------------
                   Total timesteps: 37945344
                    Iteration time: 2.31s
                      Time elapsed: 00:14:54
                               ETA: 01:41:00

################################################################################
                     [1m Learning iteration 386/3000 [0m                      

                       Computation: 45584 steps/s (collection: 2.008s, learning 0.148s)
             Mean action noise std: 2.08
          Mean value_function loss: 56.0600
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 66.5260
                       Mean reward: 128.20
               Mean episode length: 227.48
    Episode_Reward/reaching_object: 1.4416
    Episode_Reward/rotating_object: 25.7815
        Episode_Reward/action_rate: -0.0286
          Episode_Reward/joint_vel: -0.0405
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 38043648
                    Iteration time: 2.16s
                      Time elapsed: 00:14:56
                               ETA: 01:40:57

################################################################################
                     [1m Learning iteration 387/3000 [0m                      

                       Computation: 44221 steps/s (collection: 2.054s, learning 0.169s)
             Mean action noise std: 2.08
          Mean value_function loss: 63.9138
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 66.5521
                       Mean reward: 114.43
               Mean episode length: 211.07
    Episode_Reward/reaching_object: 1.4079
    Episode_Reward/rotating_object: 24.9956
        Episode_Reward/action_rate: -0.0282
          Episode_Reward/joint_vel: -0.0400
      Episode_Termination/time_out: 13.3333
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.8333
--------------------------------------------------------------------------------
                   Total timesteps: 38141952
                    Iteration time: 2.22s
                      Time elapsed: 00:14:59
                               ETA: 01:40:54

################################################################################
                     [1m Learning iteration 388/3000 [0m                      

                       Computation: 47134 steps/s (collection: 1.990s, learning 0.096s)
             Mean action noise std: 2.08
          Mean value_function loss: 56.8419
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 66.5805
                       Mean reward: 120.40
               Mean episode length: 230.16
    Episode_Reward/reaching_object: 1.4686
    Episode_Reward/rotating_object: 24.0128
        Episode_Reward/action_rate: -0.0292
          Episode_Reward/joint_vel: -0.0416
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.6667
--------------------------------------------------------------------------------
                   Total timesteps: 38240256
                    Iteration time: 2.09s
                      Time elapsed: 00:15:01
                               ETA: 01:40:50

################################################################################
                     [1m Learning iteration 389/3000 [0m                      

                       Computation: 47014 steps/s (collection: 1.980s, learning 0.111s)
             Mean action noise std: 2.08
          Mean value_function loss: 55.5947
               Mean surrogate loss: -0.0099
                 Mean entropy loss: 66.6159
                       Mean reward: 147.86
               Mean episode length: 221.25
    Episode_Reward/reaching_object: 1.4195
    Episode_Reward/rotating_object: 27.6929
        Episode_Reward/action_rate: -0.0284
          Episode_Reward/joint_vel: -0.0403
      Episode_Termination/time_out: 12.7917
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 38338560
                    Iteration time: 2.09s
                      Time elapsed: 00:15:03
                               ETA: 01:40:46

################################################################################
                     [1m Learning iteration 390/3000 [0m                      

                       Computation: 47390 steps/s (collection: 1.981s, learning 0.094s)
             Mean action noise std: 2.09
          Mean value_function loss: 53.5554
               Mean surrogate loss: -0.0101
                 Mean entropy loss: 66.6504
                       Mean reward: 145.21
               Mean episode length: 225.57
    Episode_Reward/reaching_object: 1.4235
    Episode_Reward/rotating_object: 24.4506
        Episode_Reward/action_rate: -0.0286
          Episode_Reward/joint_vel: -0.0410
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.8333
--------------------------------------------------------------------------------
                   Total timesteps: 38436864
                    Iteration time: 2.07s
                      Time elapsed: 00:15:05
                               ETA: 01:40:42

################################################################################
                     [1m Learning iteration 391/3000 [0m                      

                       Computation: 46574 steps/s (collection: 2.012s, learning 0.099s)
             Mean action noise std: 2.09
          Mean value_function loss: 56.9616
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 66.6754
                       Mean reward: 148.02
               Mean episode length: 226.58
    Episode_Reward/reaching_object: 1.4627
    Episode_Reward/rotating_object: 31.2204
        Episode_Reward/action_rate: -0.0294
          Episode_Reward/joint_vel: -0.0405
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 38535168
                    Iteration time: 2.11s
                      Time elapsed: 00:15:07
                               ETA: 01:40:39

################################################################################
                     [1m Learning iteration 392/3000 [0m                      

                       Computation: 43608 steps/s (collection: 2.161s, learning 0.093s)
             Mean action noise std: 2.09
          Mean value_function loss: 56.9727
               Mean surrogate loss: -0.0099
                 Mean entropy loss: 66.7052
                       Mean reward: 151.36
               Mean episode length: 231.43
    Episode_Reward/reaching_object: 1.4421
    Episode_Reward/rotating_object: 26.3996
        Episode_Reward/action_rate: -0.0290
          Episode_Reward/joint_vel: -0.0399
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 38633472
                    Iteration time: 2.25s
                      Time elapsed: 00:15:09
                               ETA: 01:40:36

################################################################################
                     [1m Learning iteration 393/3000 [0m                      

                       Computation: 46480 steps/s (collection: 1.992s, learning 0.123s)
             Mean action noise std: 2.09
          Mean value_function loss: 57.2451
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 66.7303
                       Mean reward: 138.83
               Mean episode length: 227.53
    Episode_Reward/reaching_object: 1.4358
    Episode_Reward/rotating_object: 25.8560
        Episode_Reward/action_rate: -0.0294
          Episode_Reward/joint_vel: -0.0408
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 38731776
                    Iteration time: 2.11s
                      Time elapsed: 00:15:11
                               ETA: 01:40:32

################################################################################
                     [1m Learning iteration 394/3000 [0m                      

                       Computation: 45082 steps/s (collection: 2.031s, learning 0.150s)
             Mean action noise std: 2.09
          Mean value_function loss: 55.9591
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 66.7582
                       Mean reward: 161.43
               Mean episode length: 225.02
    Episode_Reward/reaching_object: 1.4415
    Episode_Reward/rotating_object: 27.8247
        Episode_Reward/action_rate: -0.0294
          Episode_Reward/joint_vel: -0.0409
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 38830080
                    Iteration time: 2.18s
                      Time elapsed: 00:15:13
                               ETA: 01:40:29

################################################################################
                     [1m Learning iteration 395/3000 [0m                      

                       Computation: 46338 steps/s (collection: 1.978s, learning 0.143s)
             Mean action noise std: 2.09
          Mean value_function loss: 61.4050
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 66.7860
                       Mean reward: 174.64
               Mean episode length: 221.91
    Episode_Reward/reaching_object: 1.4216
    Episode_Reward/rotating_object: 29.0134
        Episode_Reward/action_rate: -0.0291
          Episode_Reward/joint_vel: -0.0404
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 38928384
                    Iteration time: 2.12s
                      Time elapsed: 00:15:16
                               ETA: 01:40:26

################################################################################
                     [1m Learning iteration 396/3000 [0m                      

                       Computation: 42920 steps/s (collection: 2.116s, learning 0.175s)
             Mean action noise std: 2.10
          Mean value_function loss: 62.3331
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 66.8103
                       Mean reward: 169.47
               Mean episode length: 224.10
    Episode_Reward/reaching_object: 1.4277
    Episode_Reward/rotating_object: 29.3330
        Episode_Reward/action_rate: -0.0294
          Episode_Reward/joint_vel: -0.0398
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 39026688
                    Iteration time: 2.29s
                      Time elapsed: 00:15:18
                               ETA: 01:40:23

################################################################################
                     [1m Learning iteration 397/3000 [0m                      

                       Computation: 46698 steps/s (collection: 2.012s, learning 0.093s)
             Mean action noise std: 2.10
          Mean value_function loss: 56.2721
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 66.8371
                       Mean reward: 150.10
               Mean episode length: 229.14
    Episode_Reward/reaching_object: 1.4265
    Episode_Reward/rotating_object: 29.4553
        Episode_Reward/action_rate: -0.0293
          Episode_Reward/joint_vel: -0.0395
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 39124992
                    Iteration time: 2.11s
                      Time elapsed: 00:15:20
                               ETA: 01:40:19

################################################################################
                     [1m Learning iteration 398/3000 [0m                      

                       Computation: 47865 steps/s (collection: 1.957s, learning 0.097s)
             Mean action noise std: 2.10
          Mean value_function loss: 54.2528
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 66.8639
                       Mean reward: 171.42
               Mean episode length: 232.89
    Episode_Reward/reaching_object: 1.4114
    Episode_Reward/rotating_object: 27.1949
        Episode_Reward/action_rate: -0.0294
          Episode_Reward/joint_vel: -0.0417
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 39223296
                    Iteration time: 2.05s
                      Time elapsed: 00:15:22
                               ETA: 01:40:15

################################################################################
                     [1m Learning iteration 399/3000 [0m                      

                       Computation: 44344 steps/s (collection: 2.108s, learning 0.109s)
             Mean action noise std: 2.10
          Mean value_function loss: 55.1496
               Mean surrogate loss: -0.0096
                 Mean entropy loss: 66.8959
                       Mean reward: 159.25
               Mean episode length: 225.93
    Episode_Reward/reaching_object: 1.4032
    Episode_Reward/rotating_object: 28.9298
        Episode_Reward/action_rate: -0.0289
          Episode_Reward/joint_vel: -0.0395
      Episode_Termination/time_out: 13.7500
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.7500
--------------------------------------------------------------------------------
                   Total timesteps: 39321600
                    Iteration time: 2.22s
                      Time elapsed: 00:15:24
                               ETA: 01:40:13

################################################################################
                     [1m Learning iteration 400/3000 [0m                      

                       Computation: 47509 steps/s (collection: 1.976s, learning 0.094s)
             Mean action noise std: 2.10
          Mean value_function loss: 50.8521
               Mean surrogate loss: -0.0095
                 Mean entropy loss: 66.9245
                       Mean reward: 149.67
               Mean episode length: 221.02
    Episode_Reward/reaching_object: 1.3836
    Episode_Reward/rotating_object: 28.7175
        Episode_Reward/action_rate: -0.0287
          Episode_Reward/joint_vel: -0.0390
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.2083
--------------------------------------------------------------------------------
                   Total timesteps: 39419904
                    Iteration time: 2.07s
                      Time elapsed: 00:15:26
                               ETA: 01:40:09

################################################################################
                     [1m Learning iteration 401/3000 [0m                      

                       Computation: 42357 steps/s (collection: 2.178s, learning 0.143s)
             Mean action noise std: 2.11
          Mean value_function loss: 57.1078
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 66.9513
                       Mean reward: 126.09
               Mean episode length: 225.19
    Episode_Reward/reaching_object: 1.4288
    Episode_Reward/rotating_object: 26.1623
        Episode_Reward/action_rate: -0.0296
          Episode_Reward/joint_vel: -0.0410
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.9583
--------------------------------------------------------------------------------
                   Total timesteps: 39518208
                    Iteration time: 2.32s
                      Time elapsed: 00:15:29
                               ETA: 01:40:06

################################################################################
                     [1m Learning iteration 402/3000 [0m                      

                       Computation: 47008 steps/s (collection: 1.990s, learning 0.102s)
             Mean action noise std: 2.11
          Mean value_function loss: 55.5156
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 66.9693
                       Mean reward: 161.10
               Mean episode length: 225.65
    Episode_Reward/reaching_object: 1.4337
    Episode_Reward/rotating_object: 28.0304
        Episode_Reward/action_rate: -0.0295
          Episode_Reward/joint_vel: -0.0404
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 39616512
                    Iteration time: 2.09s
                      Time elapsed: 00:15:31
                               ETA: 01:40:03

################################################################################
                     [1m Learning iteration 403/3000 [0m                      

                       Computation: 45022 steps/s (collection: 2.004s, learning 0.180s)
             Mean action noise std: 2.11
          Mean value_function loss: 59.0513
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 66.9930
                       Mean reward: 182.75
               Mean episode length: 229.39
    Episode_Reward/reaching_object: 1.4332
    Episode_Reward/rotating_object: 31.5443
        Episode_Reward/action_rate: -0.0297
          Episode_Reward/joint_vel: -0.0391
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 39714816
                    Iteration time: 2.18s
                      Time elapsed: 00:15:33
                               ETA: 01:40:00

################################################################################
                     [1m Learning iteration 404/3000 [0m                      

                       Computation: 46232 steps/s (collection: 2.018s, learning 0.108s)
             Mean action noise std: 2.11
          Mean value_function loss: 65.0634
               Mean surrogate loss: -0.0096
                 Mean entropy loss: 67.0281
                       Mean reward: 154.59
               Mean episode length: 219.83
    Episode_Reward/reaching_object: 1.4169
    Episode_Reward/rotating_object: 29.4666
        Episode_Reward/action_rate: -0.0295
          Episode_Reward/joint_vel: -0.0392
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 39813120
                    Iteration time: 2.13s
                      Time elapsed: 00:15:35
                               ETA: 01:39:56

################################################################################
                     [1m Learning iteration 405/3000 [0m                      

                       Computation: 47140 steps/s (collection: 1.994s, learning 0.091s)
             Mean action noise std: 2.11
          Mean value_function loss: 56.3056
               Mean surrogate loss: -0.0095
                 Mean entropy loss: 67.0613
                       Mean reward: 136.28
               Mean episode length: 224.21
    Episode_Reward/reaching_object: 1.4275
    Episode_Reward/rotating_object: 28.6354
        Episode_Reward/action_rate: -0.0296
          Episode_Reward/joint_vel: -0.0390
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 39911424
                    Iteration time: 2.09s
                      Time elapsed: 00:15:37
                               ETA: 01:39:52

################################################################################
                     [1m Learning iteration 406/3000 [0m                      

                       Computation: 46354 steps/s (collection: 2.030s, learning 0.091s)
             Mean action noise std: 2.12
          Mean value_function loss: 63.4909
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 67.0901
                       Mean reward: 127.24
               Mean episode length: 223.94
    Episode_Reward/reaching_object: 1.4371
    Episode_Reward/rotating_object: 28.2316
        Episode_Reward/action_rate: -0.0294
          Episode_Reward/joint_vel: -0.0393
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 40009728
                    Iteration time: 2.12s
                      Time elapsed: 00:15:39
                               ETA: 01:39:49

################################################################################
                     [1m Learning iteration 407/3000 [0m                      

                       Computation: 47033 steps/s (collection: 1.988s, learning 0.102s)
             Mean action noise std: 2.12
          Mean value_function loss: 61.3219
               Mean surrogate loss: -0.0101
                 Mean entropy loss: 67.1148
                       Mean reward: 135.62
               Mean episode length: 227.23
    Episode_Reward/reaching_object: 1.4682
    Episode_Reward/rotating_object: 24.5374
        Episode_Reward/action_rate: -0.0299
          Episode_Reward/joint_vel: -0.0416
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 40108032
                    Iteration time: 2.09s
                      Time elapsed: 00:15:41
                               ETA: 01:39:45

################################################################################
                     [1m Learning iteration 408/3000 [0m                      

                       Computation: 45582 steps/s (collection: 2.030s, learning 0.127s)
             Mean action noise std: 2.12
          Mean value_function loss: 60.3635
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 67.1388
                       Mean reward: 170.57
               Mean episode length: 237.60
    Episode_Reward/reaching_object: 1.4478
    Episode_Reward/rotating_object: 30.3396
        Episode_Reward/action_rate: -0.0297
          Episode_Reward/joint_vel: -0.0392
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 40206336
                    Iteration time: 2.16s
                      Time elapsed: 00:15:43
                               ETA: 01:39:42

################################################################################
                     [1m Learning iteration 409/3000 [0m                      

                       Computation: 45962 steps/s (collection: 2.006s, learning 0.133s)
             Mean action noise std: 2.12
          Mean value_function loss: 58.7980
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 67.1718
                       Mean reward: 160.86
               Mean episode length: 222.84
    Episode_Reward/reaching_object: 1.4916
    Episode_Reward/rotating_object: 29.7284
        Episode_Reward/action_rate: -0.0302
          Episode_Reward/joint_vel: -0.0400
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 40304640
                    Iteration time: 2.14s
                      Time elapsed: 00:15:46
                               ETA: 01:39:38

################################################################################
                     [1m Learning iteration 410/3000 [0m                      

                       Computation: 42208 steps/s (collection: 2.185s, learning 0.144s)
             Mean action noise std: 2.12
          Mean value_function loss: 62.9418
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 67.2122
                       Mean reward: 143.23
               Mean episode length: 219.81
    Episode_Reward/reaching_object: 1.4554
    Episode_Reward/rotating_object: 28.8309
        Episode_Reward/action_rate: -0.0297
          Episode_Reward/joint_vel: -0.0391
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 40402944
                    Iteration time: 2.33s
                      Time elapsed: 00:15:48
                               ETA: 01:39:36

################################################################################
                     [1m Learning iteration 411/3000 [0m                      

                       Computation: 46282 steps/s (collection: 2.019s, learning 0.105s)
             Mean action noise std: 2.13
          Mean value_function loss: 70.2219
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 67.2420
                       Mean reward: 148.42
               Mean episode length: 230.24
    Episode_Reward/reaching_object: 1.4718
    Episode_Reward/rotating_object: 28.5565
        Episode_Reward/action_rate: -0.0299
          Episode_Reward/joint_vel: -0.0401
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 40501248
                    Iteration time: 2.12s
                      Time elapsed: 00:15:50
                               ETA: 01:39:33

################################################################################
                     [1m Learning iteration 412/3000 [0m                      

                       Computation: 47150 steps/s (collection: 1.970s, learning 0.115s)
             Mean action noise std: 2.13
          Mean value_function loss: 63.4505
               Mean surrogate loss: -0.0103
                 Mean entropy loss: 67.2725
                       Mean reward: 153.98
               Mean episode length: 229.06
    Episode_Reward/reaching_object: 1.4622
    Episode_Reward/rotating_object: 25.9879
        Episode_Reward/action_rate: -0.0298
          Episode_Reward/joint_vel: -0.0399
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 40599552
                    Iteration time: 2.08s
                      Time elapsed: 00:15:52
                               ETA: 01:39:29

################################################################################
                     [1m Learning iteration 413/3000 [0m                      

                       Computation: 44672 steps/s (collection: 2.091s, learning 0.109s)
             Mean action noise std: 2.13
          Mean value_function loss: 69.3162
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 67.2993
                       Mean reward: 176.65
               Mean episode length: 220.45
    Episode_Reward/reaching_object: 1.4671
    Episode_Reward/rotating_object: 31.0444
        Episode_Reward/action_rate: -0.0298
          Episode_Reward/joint_vel: -0.0399
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.9583
--------------------------------------------------------------------------------
                   Total timesteps: 40697856
                    Iteration time: 2.20s
                      Time elapsed: 00:15:54
                               ETA: 01:39:26

################################################################################
                     [1m Learning iteration 414/3000 [0m                      

                       Computation: 45937 steps/s (collection: 2.016s, learning 0.124s)
             Mean action noise std: 2.13
          Mean value_function loss: 68.1353
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 67.3229
                       Mean reward: 135.81
               Mean episode length: 196.78
    Episode_Reward/reaching_object: 1.4304
    Episode_Reward/rotating_object: 27.1511
        Episode_Reward/action_rate: -0.0295
          Episode_Reward/joint_vel: -0.0408
      Episode_Termination/time_out: 13.3750
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.1250
--------------------------------------------------------------------------------
                   Total timesteps: 40796160
                    Iteration time: 2.14s
                      Time elapsed: 00:15:56
                               ETA: 01:39:23

################################################################################
                     [1m Learning iteration 415/3000 [0m                      

                       Computation: 43989 steps/s (collection: 2.094s, learning 0.141s)
             Mean action noise std: 2.13
          Mean value_function loss: 69.1000
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 67.3496
                       Mean reward: 151.66
               Mean episode length: 226.00
    Episode_Reward/reaching_object: 1.4937
    Episode_Reward/rotating_object: 30.7116
        Episode_Reward/action_rate: -0.0307
          Episode_Reward/joint_vel: -0.0411
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 40894464
                    Iteration time: 2.23s
                      Time elapsed: 00:15:59
                               ETA: 01:39:20

################################################################################
                     [1m Learning iteration 416/3000 [0m                      

                       Computation: 45954 steps/s (collection: 2.029s, learning 0.110s)
             Mean action noise std: 2.13
          Mean value_function loss: 67.1484
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 67.3742
                       Mean reward: 117.07
               Mean episode length: 216.42
    Episode_Reward/reaching_object: 1.4834
    Episode_Reward/rotating_object: 28.4468
        Episode_Reward/action_rate: -0.0306
          Episode_Reward/joint_vel: -0.0395
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 40992768
                    Iteration time: 2.14s
                      Time elapsed: 00:16:01
                               ETA: 01:39:17

################################################################################
                     [1m Learning iteration 417/3000 [0m                      

                       Computation: 42923 steps/s (collection: 2.119s, learning 0.171s)
             Mean action noise std: 2.14
          Mean value_function loss: 67.8386
               Mean surrogate loss: -0.0095
                 Mean entropy loss: 67.4064
                       Mean reward: 165.82
               Mean episode length: 217.88
    Episode_Reward/reaching_object: 1.4761
    Episode_Reward/rotating_object: 31.7646
        Episode_Reward/action_rate: -0.0306
          Episode_Reward/joint_vel: -0.0408
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 41091072
                    Iteration time: 2.29s
                      Time elapsed: 00:16:03
                               ETA: 01:39:14

################################################################################
                     [1m Learning iteration 418/3000 [0m                      

                       Computation: 45516 steps/s (collection: 2.052s, learning 0.108s)
             Mean action noise std: 2.14
          Mean value_function loss: 69.5661
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 67.4386
                       Mean reward: 158.45
               Mean episode length: 222.19
    Episode_Reward/reaching_object: 1.4963
    Episode_Reward/rotating_object: 30.7819
        Episode_Reward/action_rate: -0.0305
          Episode_Reward/joint_vel: -0.0399
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 41189376
                    Iteration time: 2.16s
                      Time elapsed: 00:16:05
                               ETA: 01:39:11

################################################################################
                     [1m Learning iteration 419/3000 [0m                      

                       Computation: 42329 steps/s (collection: 2.119s, learning 0.204s)
             Mean action noise std: 2.14
          Mean value_function loss: 69.2611
               Mean surrogate loss: -0.0098
                 Mean entropy loss: 67.4740
                       Mean reward: 151.96
               Mean episode length: 217.32
    Episode_Reward/reaching_object: 1.4793
    Episode_Reward/rotating_object: 31.9298
        Episode_Reward/action_rate: -0.0305
          Episode_Reward/joint_vel: -0.0408
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 41287680
                    Iteration time: 2.32s
                      Time elapsed: 00:16:08
                               ETA: 01:39:09

################################################################################
                     [1m Learning iteration 420/3000 [0m                      

                       Computation: 44864 steps/s (collection: 2.074s, learning 0.118s)
             Mean action noise std: 2.14
          Mean value_function loss: 63.3441
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 67.5049
                       Mean reward: 192.02
               Mean episode length: 228.70
    Episode_Reward/reaching_object: 1.4773
    Episode_Reward/rotating_object: 32.3916
        Episode_Reward/action_rate: -0.0303
          Episode_Reward/joint_vel: -0.0396
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 41385984
                    Iteration time: 2.19s
                      Time elapsed: 00:16:10
                               ETA: 01:39:06

################################################################################
                     [1m Learning iteration 421/3000 [0m                      

                       Computation: 47424 steps/s (collection: 1.974s, learning 0.099s)
             Mean action noise std: 2.15
          Mean value_function loss: 69.3951
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 67.5304
                       Mean reward: 134.89
               Mean episode length: 213.88
    Episode_Reward/reaching_object: 1.5041
    Episode_Reward/rotating_object: 32.3020
        Episode_Reward/action_rate: -0.0310
          Episode_Reward/joint_vel: -0.0410
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 41484288
                    Iteration time: 2.07s
                      Time elapsed: 00:16:12
                               ETA: 01:39:02

################################################################################
                     [1m Learning iteration 422/3000 [0m                      

                       Computation: 44102 steps/s (collection: 2.124s, learning 0.105s)
             Mean action noise std: 2.15
          Mean value_function loss: 68.4941
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 67.5527
                       Mean reward: 154.64
               Mean episode length: 228.94
    Episode_Reward/reaching_object: 1.5346
    Episode_Reward/rotating_object: 32.9939
        Episode_Reward/action_rate: -0.0316
          Episode_Reward/joint_vel: -0.0418
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 41582592
                    Iteration time: 2.23s
                      Time elapsed: 00:16:14
                               ETA: 01:38:59

################################################################################
                     [1m Learning iteration 423/3000 [0m                      

                       Computation: 44251 steps/s (collection: 2.097s, learning 0.125s)
             Mean action noise std: 2.15
          Mean value_function loss: 64.0533
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 67.5713
                       Mean reward: 165.46
               Mean episode length: 215.75
    Episode_Reward/reaching_object: 1.4477
    Episode_Reward/rotating_object: 29.2729
        Episode_Reward/action_rate: -0.0301
          Episode_Reward/joint_vel: -0.0399
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.3333
--------------------------------------------------------------------------------
                   Total timesteps: 41680896
                    Iteration time: 2.22s
                      Time elapsed: 00:16:16
                               ETA: 01:38:57

################################################################################
                     [1m Learning iteration 424/3000 [0m                      

                       Computation: 41356 steps/s (collection: 2.259s, learning 0.118s)
             Mean action noise std: 2.15
          Mean value_function loss: 63.9785
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 67.6000
                       Mean reward: 184.14
               Mean episode length: 227.33
    Episode_Reward/reaching_object: 1.4683
    Episode_Reward/rotating_object: 32.9272
        Episode_Reward/action_rate: -0.0308
          Episode_Reward/joint_vel: -0.0399
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 41779200
                    Iteration time: 2.38s
                      Time elapsed: 00:16:19
                               ETA: 01:38:55

################################################################################
                     [1m Learning iteration 425/3000 [0m                      

                       Computation: 44131 steps/s (collection: 2.113s, learning 0.114s)
             Mean action noise std: 2.15
          Mean value_function loss: 67.9100
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 67.6313
                       Mean reward: 138.90
               Mean episode length: 213.56
    Episode_Reward/reaching_object: 1.4015
    Episode_Reward/rotating_object: 27.7511
        Episode_Reward/action_rate: -0.0298
          Episode_Reward/joint_vel: -0.0396
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 5.0833
--------------------------------------------------------------------------------
                   Total timesteps: 41877504
                    Iteration time: 2.23s
                      Time elapsed: 00:16:21
                               ETA: 01:38:52

################################################################################
                     [1m Learning iteration 426/3000 [0m                      

                       Computation: 43969 steps/s (collection: 2.123s, learning 0.113s)
             Mean action noise std: 2.16
          Mean value_function loss: 68.3745
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 67.6620
                       Mean reward: 173.71
               Mean episode length: 223.33
    Episode_Reward/reaching_object: 1.4860
    Episode_Reward/rotating_object: 33.3504
        Episode_Reward/action_rate: -0.0312
          Episode_Reward/joint_vel: -0.0408
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 41975808
                    Iteration time: 2.24s
                      Time elapsed: 00:16:23
                               ETA: 01:38:49

################################################################################
                     [1m Learning iteration 427/3000 [0m                      

                       Computation: 43227 steps/s (collection: 2.158s, learning 0.116s)
             Mean action noise std: 2.16
          Mean value_function loss: 74.2623
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 67.6963
                       Mean reward: 159.14
               Mean episode length: 224.44
    Episode_Reward/reaching_object: 1.4831
    Episode_Reward/rotating_object: 33.0878
        Episode_Reward/action_rate: -0.0311
          Episode_Reward/joint_vel: -0.0399
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 42074112
                    Iteration time: 2.27s
                      Time elapsed: 00:16:25
                               ETA: 01:38:47

################################################################################
                     [1m Learning iteration 428/3000 [0m                      

                       Computation: 44088 steps/s (collection: 2.079s, learning 0.151s)
             Mean action noise std: 2.16
          Mean value_function loss: 62.3486
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 67.7316
                       Mean reward: 132.96
               Mean episode length: 219.58
    Episode_Reward/reaching_object: 1.4744
    Episode_Reward/rotating_object: 30.8598
        Episode_Reward/action_rate: -0.0309
          Episode_Reward/joint_vel: -0.0400
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 42172416
                    Iteration time: 2.23s
                      Time elapsed: 00:16:28
                               ETA: 01:38:44

################################################################################
                     [1m Learning iteration 429/3000 [0m                      

                       Computation: 46313 steps/s (collection: 2.012s, learning 0.111s)
             Mean action noise std: 2.16
          Mean value_function loss: 61.7658
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 67.7654
                       Mean reward: 140.46
               Mean episode length: 211.95
    Episode_Reward/reaching_object: 1.4330
    Episode_Reward/rotating_object: 28.8310
        Episode_Reward/action_rate: -0.0302
          Episode_Reward/joint_vel: -0.0400
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.5417
--------------------------------------------------------------------------------
                   Total timesteps: 42270720
                    Iteration time: 2.12s
                      Time elapsed: 00:16:30
                               ETA: 01:38:41

################################################################################
                     [1m Learning iteration 430/3000 [0m                      

                       Computation: 45763 steps/s (collection: 2.022s, learning 0.126s)
             Mean action noise std: 2.16
          Mean value_function loss: 70.2206
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 67.7925
                       Mean reward: 190.75
               Mean episode length: 224.01
    Episode_Reward/reaching_object: 1.4734
    Episode_Reward/rotating_object: 32.3274
        Episode_Reward/action_rate: -0.0312
          Episode_Reward/joint_vel: -0.0404
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.0833
--------------------------------------------------------------------------------
                   Total timesteps: 42369024
                    Iteration time: 2.15s
                      Time elapsed: 00:16:32
                               ETA: 01:38:37

################################################################################
                     [1m Learning iteration 431/3000 [0m                      

                       Computation: 43099 steps/s (collection: 2.097s, learning 0.184s)
             Mean action noise std: 2.17
          Mean value_function loss: 67.4164
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 67.8201
                       Mean reward: 192.89
               Mean episode length: 231.70
    Episode_Reward/reaching_object: 1.5159
    Episode_Reward/rotating_object: 32.8159
        Episode_Reward/action_rate: -0.0317
          Episode_Reward/joint_vel: -0.0407
      Episode_Termination/time_out: 13.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 42467328
                    Iteration time: 2.28s
                      Time elapsed: 00:16:34
                               ETA: 01:38:35

################################################################################
                     [1m Learning iteration 432/3000 [0m                      

                       Computation: 44362 steps/s (collection: 2.116s, learning 0.100s)
             Mean action noise std: 2.17
          Mean value_function loss: 69.5626
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 67.8437
                       Mean reward: 178.03
               Mean episode length: 224.56
    Episode_Reward/reaching_object: 1.5229
    Episode_Reward/rotating_object: 31.4224
        Episode_Reward/action_rate: -0.0319
          Episode_Reward/joint_vel: -0.0408
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 42565632
                    Iteration time: 2.22s
                      Time elapsed: 00:16:36
                               ETA: 01:38:32

################################################################################
                     [1m Learning iteration 433/3000 [0m                      

                       Computation: 45631 steps/s (collection: 2.006s, learning 0.149s)
             Mean action noise std: 2.17
          Mean value_function loss: 68.8783
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 67.8715
                       Mean reward: 183.98
               Mean episode length: 235.89
    Episode_Reward/reaching_object: 1.5166
    Episode_Reward/rotating_object: 32.0279
        Episode_Reward/action_rate: -0.0318
          Episode_Reward/joint_vel: -0.0415
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.7500
--------------------------------------------------------------------------------
                   Total timesteps: 42663936
                    Iteration time: 2.15s
                      Time elapsed: 00:16:39
                               ETA: 01:38:29

################################################################################
                     [1m Learning iteration 434/3000 [0m                      

                       Computation: 44235 steps/s (collection: 2.081s, learning 0.142s)
             Mean action noise std: 2.17
          Mean value_function loss: 74.0324
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 67.9010
                       Mean reward: 155.76
               Mean episode length: 221.37
    Episode_Reward/reaching_object: 1.4864
    Episode_Reward/rotating_object: 30.3660
        Episode_Reward/action_rate: -0.0313
          Episode_Reward/joint_vel: -0.0410
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.2500
--------------------------------------------------------------------------------
                   Total timesteps: 42762240
                    Iteration time: 2.22s
                      Time elapsed: 00:16:41
                               ETA: 01:38:26

################################################################################
                     [1m Learning iteration 435/3000 [0m                      

                       Computation: 45445 steps/s (collection: 2.040s, learning 0.123s)
             Mean action noise std: 2.17
          Mean value_function loss: 67.8303
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 67.9314
                       Mean reward: 186.24
               Mean episode length: 228.43
    Episode_Reward/reaching_object: 1.5169
    Episode_Reward/rotating_object: 33.5389
        Episode_Reward/action_rate: -0.0320
          Episode_Reward/joint_vel: -0.0413
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.6667
--------------------------------------------------------------------------------
                   Total timesteps: 42860544
                    Iteration time: 2.16s
                      Time elapsed: 00:16:43
                               ETA: 01:38:23

################################################################################
                     [1m Learning iteration 436/3000 [0m                      

                       Computation: 44335 steps/s (collection: 2.088s, learning 0.130s)
             Mean action noise std: 2.18
          Mean value_function loss: 69.1668
               Mean surrogate loss: -0.0098
                 Mean entropy loss: 67.9664
                       Mean reward: 165.92
               Mean episode length: 223.89
    Episode_Reward/reaching_object: 1.5229
    Episode_Reward/rotating_object: 31.9917
        Episode_Reward/action_rate: -0.0318
          Episode_Reward/joint_vel: -0.0398
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 42958848
                    Iteration time: 2.22s
                      Time elapsed: 00:16:45
                               ETA: 01:38:20

################################################################################
                     [1m Learning iteration 437/3000 [0m                      

                       Computation: 44676 steps/s (collection: 2.102s, learning 0.099s)
             Mean action noise std: 2.18
          Mean value_function loss: 70.1628
               Mean surrogate loss: -0.0099
                 Mean entropy loss: 67.9973
                       Mean reward: 143.35
               Mean episode length: 214.61
    Episode_Reward/reaching_object: 1.4673
    Episode_Reward/rotating_object: 31.9578
        Episode_Reward/action_rate: -0.0310
          Episode_Reward/joint_vel: -0.0391
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.1667
--------------------------------------------------------------------------------
                   Total timesteps: 43057152
                    Iteration time: 2.20s
                      Time elapsed: 00:16:47
                               ETA: 01:38:17

################################################################################
                     [1m Learning iteration 438/3000 [0m                      

                       Computation: 44814 steps/s (collection: 2.053s, learning 0.141s)
             Mean action noise std: 2.18
          Mean value_function loss: 74.9345
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 68.0175
                       Mean reward: 176.27
               Mean episode length: 226.71
    Episode_Reward/reaching_object: 1.5227
    Episode_Reward/rotating_object: 32.2601
        Episode_Reward/action_rate: -0.0319
          Episode_Reward/joint_vel: -0.0413
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 43155456
                    Iteration time: 2.19s
                      Time elapsed: 00:16:50
                               ETA: 01:38:14

################################################################################
                     [1m Learning iteration 439/3000 [0m                      

                       Computation: 43817 steps/s (collection: 2.129s, learning 0.114s)
             Mean action noise std: 2.18
          Mean value_function loss: 70.2145
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 68.0395
                       Mean reward: 186.62
               Mean episode length: 222.72
    Episode_Reward/reaching_object: 1.4954
    Episode_Reward/rotating_object: 32.1217
        Episode_Reward/action_rate: -0.0319
          Episode_Reward/joint_vel: -0.0417
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.3333
--------------------------------------------------------------------------------
                   Total timesteps: 43253760
                    Iteration time: 2.24s
                      Time elapsed: 00:16:52
                               ETA: 01:38:12

################################################################################
                     [1m Learning iteration 440/3000 [0m                      

                       Computation: 46170 steps/s (collection: 2.028s, learning 0.102s)
             Mean action noise std: 2.18
          Mean value_function loss: 65.2228
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 68.0689
                       Mean reward: 174.85
               Mean episode length: 224.48
    Episode_Reward/reaching_object: 1.4954
    Episode_Reward/rotating_object: 31.3181
        Episode_Reward/action_rate: -0.0315
          Episode_Reward/joint_vel: -0.0399
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.2500
--------------------------------------------------------------------------------
                   Total timesteps: 43352064
                    Iteration time: 2.13s
                      Time elapsed: 00:16:54
                               ETA: 01:38:09

################################################################################
                     [1m Learning iteration 441/3000 [0m                      

                       Computation: 40859 steps/s (collection: 2.244s, learning 0.162s)
             Mean action noise std: 2.19
          Mean value_function loss: 68.7671
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 68.0945
                       Mean reward: 139.52
               Mean episode length: 217.86
    Episode_Reward/reaching_object: 1.5121
    Episode_Reward/rotating_object: 30.6970
        Episode_Reward/action_rate: -0.0320
          Episode_Reward/joint_vel: -0.0406
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 43450368
                    Iteration time: 2.41s
                      Time elapsed: 00:16:56
                               ETA: 01:38:07

################################################################################
                     [1m Learning iteration 442/3000 [0m                      

                       Computation: 40298 steps/s (collection: 2.303s, learning 0.137s)
             Mean action noise std: 2.19
          Mean value_function loss: 67.4419
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 68.1207
                       Mean reward: 184.97
               Mean episode length: 219.12
    Episode_Reward/reaching_object: 1.4572
    Episode_Reward/rotating_object: 32.6303
        Episode_Reward/action_rate: -0.0312
          Episode_Reward/joint_vel: -0.0402
      Episode_Termination/time_out: 12.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.9583
--------------------------------------------------------------------------------
                   Total timesteps: 43548672
                    Iteration time: 2.44s
                      Time elapsed: 00:16:59
                               ETA: 01:38:05

################################################################################
                     [1m Learning iteration 443/3000 [0m                      

                       Computation: 45073 steps/s (collection: 2.077s, learning 0.104s)
             Mean action noise std: 2.19
          Mean value_function loss: 65.6416
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 68.1443
                       Mean reward: 153.54
               Mean episode length: 217.41
    Episode_Reward/reaching_object: 1.4933
    Episode_Reward/rotating_object: 32.2956
        Episode_Reward/action_rate: -0.0319
          Episode_Reward/joint_vel: -0.0397
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.1250
--------------------------------------------------------------------------------
                   Total timesteps: 43646976
                    Iteration time: 2.18s
                      Time elapsed: 00:17:01
                               ETA: 01:38:02

################################################################################
                     [1m Learning iteration 444/3000 [0m                      

                       Computation: 42837 steps/s (collection: 2.169s, learning 0.126s)
             Mean action noise std: 2.19
          Mean value_function loss: 67.8987
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 68.1748
                       Mean reward: 150.64
               Mean episode length: 221.75
    Episode_Reward/reaching_object: 1.4947
    Episode_Reward/rotating_object: 30.2635
        Episode_Reward/action_rate: -0.0319
          Episode_Reward/joint_vel: -0.0401
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 43745280
                    Iteration time: 2.29s
                      Time elapsed: 00:17:03
                               ETA: 01:38:00

################################################################################
                     [1m Learning iteration 445/3000 [0m                      

                       Computation: 43813 steps/s (collection: 2.094s, learning 0.150s)
             Mean action noise std: 2.19
          Mean value_function loss: 70.6066
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 68.2040
                       Mean reward: 176.04
               Mean episode length: 226.08
    Episode_Reward/reaching_object: 1.5249
    Episode_Reward/rotating_object: 34.4860
        Episode_Reward/action_rate: -0.0327
          Episode_Reward/joint_vel: -0.0402
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 3.6667
--------------------------------------------------------------------------------
                   Total timesteps: 43843584
                    Iteration time: 2.24s
                      Time elapsed: 00:17:06
                               ETA: 01:37:57

################################################################################
                     [1m Learning iteration 446/3000 [0m                      

                       Computation: 41908 steps/s (collection: 2.147s, learning 0.199s)
             Mean action noise std: 2.20
          Mean value_function loss: 66.1892
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 68.2356
                       Mean reward: 174.66
               Mean episode length: 215.74
    Episode_Reward/reaching_object: 1.4880
    Episode_Reward/rotating_object: 33.7488
        Episode_Reward/action_rate: -0.0321
          Episode_Reward/joint_vel: -0.0413
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 43941888
                    Iteration time: 2.35s
                      Time elapsed: 00:17:08
                               ETA: 01:37:55

################################################################################
                     [1m Learning iteration 447/3000 [0m                      

                       Computation: 45586 steps/s (collection: 2.061s, learning 0.095s)
             Mean action noise std: 2.20
          Mean value_function loss: 71.8349
               Mean surrogate loss: -0.0099
                 Mean entropy loss: 68.2713
                       Mean reward: 159.54
               Mean episode length: 227.79
    Episode_Reward/reaching_object: 1.4729
    Episode_Reward/rotating_object: 31.3955
        Episode_Reward/action_rate: -0.0317
          Episode_Reward/joint_vel: -0.0398
      Episode_Termination/time_out: 13.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.2917
--------------------------------------------------------------------------------
                   Total timesteps: 44040192
                    Iteration time: 2.16s
                      Time elapsed: 00:17:10
                               ETA: 01:37:52

################################################################################
                     [1m Learning iteration 448/3000 [0m                      

                       Computation: 46231 steps/s (collection: 2.031s, learning 0.095s)
             Mean action noise std: 2.20
          Mean value_function loss: 65.6111
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 68.2994
                       Mean reward: 183.72
               Mean episode length: 218.58
    Episode_Reward/reaching_object: 1.5342
    Episode_Reward/rotating_object: 32.6543
        Episode_Reward/action_rate: -0.0331
          Episode_Reward/joint_vel: -0.0414
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 44138496
                    Iteration time: 2.13s
                      Time elapsed: 00:17:12
                               ETA: 01:37:49

################################################################################
                     [1m Learning iteration 449/3000 [0m                      

                       Computation: 46273 steps/s (collection: 2.017s, learning 0.108s)
             Mean action noise std: 2.20
          Mean value_function loss: 62.7569
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 68.3264
                       Mean reward: 173.48
               Mean episode length: 236.31
    Episode_Reward/reaching_object: 1.5300
    Episode_Reward/rotating_object: 32.3210
        Episode_Reward/action_rate: -0.0330
          Episode_Reward/joint_vel: -0.0411
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 44236800
                    Iteration time: 2.12s
                      Time elapsed: 00:17:14
                               ETA: 01:37:46

################################################################################
                     [1m Learning iteration 450/3000 [0m                      

                       Computation: 37800 steps/s (collection: 2.373s, learning 0.227s)
             Mean action noise std: 2.20
          Mean value_function loss: 71.7150
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 68.3539
                       Mean reward: 172.61
               Mean episode length: 230.34
    Episode_Reward/reaching_object: 1.5460
    Episode_Reward/rotating_object: 32.5551
        Episode_Reward/action_rate: -0.0333
          Episode_Reward/joint_vel: -0.0410
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 44335104
                    Iteration time: 2.60s
                      Time elapsed: 00:17:17
                               ETA: 01:37:45

################################################################################
                     [1m Learning iteration 451/3000 [0m                      

                       Computation: 37318 steps/s (collection: 2.486s, learning 0.148s)
             Mean action noise std: 2.21
          Mean value_function loss: 77.2806
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 68.3785
                       Mean reward: 162.33
               Mean episode length: 228.20
    Episode_Reward/reaching_object: 1.4848
    Episode_Reward/rotating_object: 32.2530
        Episode_Reward/action_rate: -0.0325
          Episode_Reward/joint_vel: -0.0403
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.9583
--------------------------------------------------------------------------------
                   Total timesteps: 44433408
                    Iteration time: 2.63s
                      Time elapsed: 00:17:20
                               ETA: 01:37:45

################################################################################
                     [1m Learning iteration 452/3000 [0m                      

                       Computation: 40657 steps/s (collection: 2.200s, learning 0.218s)
             Mean action noise std: 2.21
          Mean value_function loss: 70.5882
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 68.4017
                       Mean reward: 173.94
               Mean episode length: 215.72
    Episode_Reward/reaching_object: 1.4630
    Episode_Reward/rotating_object: 28.7259
        Episode_Reward/action_rate: -0.0320
          Episode_Reward/joint_vel: -0.0404
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.5417
--------------------------------------------------------------------------------
                   Total timesteps: 44531712
                    Iteration time: 2.42s
                      Time elapsed: 00:17:22
                               ETA: 01:37:43

################################################################################
                     [1m Learning iteration 453/3000 [0m                      

                       Computation: 39907 steps/s (collection: 2.307s, learning 0.156s)
             Mean action noise std: 2.21
          Mean value_function loss: 71.5746
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 68.4218
                       Mean reward: 212.49
               Mean episode length: 219.98
    Episode_Reward/reaching_object: 1.4659
    Episode_Reward/rotating_object: 34.7822
        Episode_Reward/action_rate: -0.0324
          Episode_Reward/joint_vel: -0.0410
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.3750
--------------------------------------------------------------------------------
                   Total timesteps: 44630016
                    Iteration time: 2.46s
                      Time elapsed: 00:17:24
                               ETA: 01:37:42

################################################################################
                     [1m Learning iteration 454/3000 [0m                      

                       Computation: 43919 steps/s (collection: 2.138s, learning 0.100s)
             Mean action noise std: 2.21
          Mean value_function loss: 73.0894
               Mean surrogate loss: -0.0095
                 Mean entropy loss: 68.4510
                       Mean reward: 194.49
               Mean episode length: 239.35
    Episode_Reward/reaching_object: 1.5329
    Episode_Reward/rotating_object: 35.1974
        Episode_Reward/action_rate: -0.0332
          Episode_Reward/joint_vel: -0.0407
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 44728320
                    Iteration time: 2.24s
                      Time elapsed: 00:17:27
                               ETA: 01:37:39

################################################################################
                     [1m Learning iteration 455/3000 [0m                      

                       Computation: 44106 steps/s (collection: 2.136s, learning 0.093s)
             Mean action noise std: 2.21
          Mean value_function loss: 64.6733
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 68.4798
                       Mean reward: 186.57
               Mean episode length: 216.55
    Episode_Reward/reaching_object: 1.4967
    Episode_Reward/rotating_object: 36.5738
        Episode_Reward/action_rate: -0.0328
          Episode_Reward/joint_vel: -0.0400
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.4583
--------------------------------------------------------------------------------
                   Total timesteps: 44826624
                    Iteration time: 2.23s
                      Time elapsed: 00:17:29
                               ETA: 01:37:36

################################################################################
                     [1m Learning iteration 456/3000 [0m                      

                       Computation: 44404 steps/s (collection: 2.072s, learning 0.142s)
             Mean action noise std: 2.22
          Mean value_function loss: 72.5195
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 68.5141
                       Mean reward: 187.30
               Mean episode length: 222.90
    Episode_Reward/reaching_object: 1.5291
    Episode_Reward/rotating_object: 35.8648
        Episode_Reward/action_rate: -0.0333
          Episode_Reward/joint_vel: -0.0403
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 44924928
                    Iteration time: 2.21s
                      Time elapsed: 00:17:31
                               ETA: 01:37:33

################################################################################
                     [1m Learning iteration 457/3000 [0m                      

                       Computation: 44308 steps/s (collection: 2.096s, learning 0.123s)
             Mean action noise std: 2.22
          Mean value_function loss: 77.6095
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 68.5484
                       Mean reward: 133.83
               Mean episode length: 218.73
    Episode_Reward/reaching_object: 1.4526
    Episode_Reward/rotating_object: 26.4510
        Episode_Reward/action_rate: -0.0318
          Episode_Reward/joint_vel: -0.0403
      Episode_Termination/time_out: 13.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.5000
--------------------------------------------------------------------------------
                   Total timesteps: 45023232
                    Iteration time: 2.22s
                      Time elapsed: 00:17:33
                               ETA: 01:37:31

################################################################################
                     [1m Learning iteration 458/3000 [0m                      

                       Computation: 44188 steps/s (collection: 2.124s, learning 0.101s)
             Mean action noise std: 2.22
          Mean value_function loss: 73.6586
               Mean surrogate loss: -0.0099
                 Mean entropy loss: 68.5732
                       Mean reward: 184.69
               Mean episode length: 213.27
    Episode_Reward/reaching_object: 1.5113
    Episode_Reward/rotating_object: 34.0273
        Episode_Reward/action_rate: -0.0332
          Episode_Reward/joint_vel: -0.0412
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.0833
--------------------------------------------------------------------------------
                   Total timesteps: 45121536
                    Iteration time: 2.22s
                      Time elapsed: 00:17:36
                               ETA: 01:37:28

################################################################################
                     [1m Learning iteration 459/3000 [0m                      

                       Computation: 42090 steps/s (collection: 2.160s, learning 0.175s)
             Mean action noise std: 2.22
          Mean value_function loss: 65.6891
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 68.6046
                       Mean reward: 165.78
               Mean episode length: 217.65
    Episode_Reward/reaching_object: 1.4691
    Episode_Reward/rotating_object: 32.8456
        Episode_Reward/action_rate: -0.0323
          Episode_Reward/joint_vel: -0.0403
      Episode_Termination/time_out: 13.5417
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 45219840
                    Iteration time: 2.34s
                      Time elapsed: 00:17:38
                               ETA: 01:37:26

################################################################################
                     [1m Learning iteration 460/3000 [0m                      

                       Computation: 44355 steps/s (collection: 2.107s, learning 0.109s)
             Mean action noise std: 2.23
          Mean value_function loss: 69.3292
               Mean surrogate loss: -0.0098
                 Mean entropy loss: 68.6376
                       Mean reward: 179.68
               Mean episode length: 210.13
    Episode_Reward/reaching_object: 1.4686
    Episode_Reward/rotating_object: 35.4309
        Episode_Reward/action_rate: -0.0326
          Episode_Reward/joint_vel: -0.0403
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.2500
--------------------------------------------------------------------------------
                   Total timesteps: 45318144
                    Iteration time: 2.22s
                      Time elapsed: 00:17:40
                               ETA: 01:37:23

################################################################################
                     [1m Learning iteration 461/3000 [0m                      

                       Computation: 43156 steps/s (collection: 2.105s, learning 0.173s)
             Mean action noise std: 2.23
          Mean value_function loss: 68.3849
               Mean surrogate loss: -0.0098
                 Mean entropy loss: 68.6685
                       Mean reward: 157.23
               Mean episode length: 217.11
    Episode_Reward/reaching_object: 1.4769
    Episode_Reward/rotating_object: 32.1879
        Episode_Reward/action_rate: -0.0330
          Episode_Reward/joint_vel: -0.0409
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.1667
     Episode_Termination/robot_out: 4.5833
--------------------------------------------------------------------------------
                   Total timesteps: 45416448
                    Iteration time: 2.28s
                      Time elapsed: 00:17:42
                               ETA: 01:37:21

################################################################################
                     [1m Learning iteration 462/3000 [0m                      

                       Computation: 45896 steps/s (collection: 2.042s, learning 0.100s)
             Mean action noise std: 2.23
          Mean value_function loss: 71.8625
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 68.6983
                       Mean reward: 174.82
               Mean episode length: 231.57
    Episode_Reward/reaching_object: 1.5089
    Episode_Reward/rotating_object: 34.9382
        Episode_Reward/action_rate: -0.0334
          Episode_Reward/joint_vel: -0.0411
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 45514752
                    Iteration time: 2.14s
                      Time elapsed: 00:17:45
                               ETA: 01:37:17

################################################################################
                     [1m Learning iteration 463/3000 [0m                      

                       Computation: 44895 steps/s (collection: 2.086s, learning 0.104s)
             Mean action noise std: 2.23
          Mean value_function loss: 70.8029
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 68.7252
                       Mean reward: 187.31
               Mean episode length: 225.06
    Episode_Reward/reaching_object: 1.4826
    Episode_Reward/rotating_object: 34.4109
        Episode_Reward/action_rate: -0.0329
          Episode_Reward/joint_vel: -0.0406
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 45613056
                    Iteration time: 2.19s
                      Time elapsed: 00:17:47
                               ETA: 01:37:15

################################################################################
                     [1m Learning iteration 464/3000 [0m                      

                       Computation: 44366 steps/s (collection: 2.112s, learning 0.104s)
             Mean action noise std: 2.23
          Mean value_function loss: 66.8763
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 68.7561
                       Mean reward: 197.41
               Mean episode length: 236.58
    Episode_Reward/reaching_object: 1.5290
    Episode_Reward/rotating_object: 33.1505
        Episode_Reward/action_rate: -0.0340
          Episode_Reward/joint_vel: -0.0424
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 45711360
                    Iteration time: 2.22s
                      Time elapsed: 00:17:49
                               ETA: 01:37:12

################################################################################
                     [1m Learning iteration 465/3000 [0m                      

                       Computation: 42919 steps/s (collection: 2.179s, learning 0.112s)
             Mean action noise std: 2.24
          Mean value_function loss: 69.9515
               Mean surrogate loss: -0.0102
                 Mean entropy loss: 68.7833
                       Mean reward: 193.07
               Mean episode length: 218.97
    Episode_Reward/reaching_object: 1.5104
    Episode_Reward/rotating_object: 33.8244
        Episode_Reward/action_rate: -0.0335
          Episode_Reward/joint_vel: -0.0407
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.7500
--------------------------------------------------------------------------------
                   Total timesteps: 45809664
                    Iteration time: 2.29s
                      Time elapsed: 00:17:51
                               ETA: 01:37:09

################################################################################
                     [1m Learning iteration 466/3000 [0m                      

                       Computation: 42085 steps/s (collection: 2.225s, learning 0.111s)
             Mean action noise std: 2.24
          Mean value_function loss: 63.3483
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 68.8120
                       Mean reward: 163.94
               Mean episode length: 217.14
    Episode_Reward/reaching_object: 1.4740
    Episode_Reward/rotating_object: 35.5342
        Episode_Reward/action_rate: -0.0333
          Episode_Reward/joint_vel: -0.0401
      Episode_Termination/time_out: 13.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 45907968
                    Iteration time: 2.34s
                      Time elapsed: 00:17:54
                               ETA: 01:37:07

################################################################################
                     [1m Learning iteration 467/3000 [0m                      

                       Computation: 44151 steps/s (collection: 2.094s, learning 0.132s)
             Mean action noise std: 2.24
          Mean value_function loss: 67.1419
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 68.8383
                       Mean reward: 156.62
               Mean episode length: 212.92
    Episode_Reward/reaching_object: 1.4687
    Episode_Reward/rotating_object: 31.8484
        Episode_Reward/action_rate: -0.0331
          Episode_Reward/joint_vel: -0.0410
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.4167
--------------------------------------------------------------------------------
                   Total timesteps: 46006272
                    Iteration time: 2.23s
                      Time elapsed: 00:17:56
                               ETA: 01:37:05

################################################################################
                     [1m Learning iteration 468/3000 [0m                      

                       Computation: 43353 steps/s (collection: 2.124s, learning 0.144s)
             Mean action noise std: 2.24
          Mean value_function loss: 74.7852
               Mean surrogate loss: -0.0106
                 Mean entropy loss: 68.8677
                       Mean reward: 205.00
               Mean episode length: 223.30
    Episode_Reward/reaching_object: 1.5151
    Episode_Reward/rotating_object: 35.1256
        Episode_Reward/action_rate: -0.0339
          Episode_Reward/joint_vel: -0.0394
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 46104576
                    Iteration time: 2.27s
                      Time elapsed: 00:17:58
                               ETA: 01:37:02

################################################################################
                     [1m Learning iteration 469/3000 [0m                      

                       Computation: 43750 steps/s (collection: 2.071s, learning 0.176s)
             Mean action noise std: 2.25
          Mean value_function loss: 76.5536
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 68.9011
                       Mean reward: 197.09
               Mean episode length: 226.50
    Episode_Reward/reaching_object: 1.4790
    Episode_Reward/rotating_object: 36.5866
        Episode_Reward/action_rate: -0.0338
          Episode_Reward/joint_vel: -0.0403
      Episode_Termination/time_out: 13.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 46202880
                    Iteration time: 2.25s
                      Time elapsed: 00:18:00
                               ETA: 01:37:00

################################################################################
                     [1m Learning iteration 470/3000 [0m                      

                       Computation: 46037 steps/s (collection: 2.038s, learning 0.097s)
             Mean action noise std: 2.25
          Mean value_function loss: 77.2195
               Mean surrogate loss: -0.0100
                 Mean entropy loss: 68.9441
                       Mean reward: 189.97
               Mean episode length: 226.49
    Episode_Reward/reaching_object: 1.5303
    Episode_Reward/rotating_object: 36.0552
        Episode_Reward/action_rate: -0.0347
          Episode_Reward/joint_vel: -0.0425
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 46301184
                    Iteration time: 2.14s
                      Time elapsed: 00:18:02
                               ETA: 01:36:56

################################################################################
                     [1m Learning iteration 471/3000 [0m                      

                       Computation: 46583 steps/s (collection: 2.010s, learning 0.101s)
             Mean action noise std: 2.25
          Mean value_function loss: 73.3325
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 68.9880
                       Mean reward: 227.22
               Mean episode length: 231.98
    Episode_Reward/reaching_object: 1.5052
    Episode_Reward/rotating_object: 37.1921
        Episode_Reward/action_rate: -0.0342
          Episode_Reward/joint_vel: -0.0409
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 46399488
                    Iteration time: 2.11s
                      Time elapsed: 00:18:05
                               ETA: 01:36:53

################################################################################
                     [1m Learning iteration 472/3000 [0m                      

                       Computation: 43714 steps/s (collection: 2.085s, learning 0.163s)
             Mean action noise std: 2.25
          Mean value_function loss: 82.2096
               Mean surrogate loss: -0.0099
                 Mean entropy loss: 69.0174
                       Mean reward: 185.60
               Mean episode length: 225.47
    Episode_Reward/reaching_object: 1.4948
    Episode_Reward/rotating_object: 35.1288
        Episode_Reward/action_rate: -0.0340
          Episode_Reward/joint_vel: -0.0410
      Episode_Termination/time_out: 13.4167
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 46497792
                    Iteration time: 2.25s
                      Time elapsed: 00:18:07
                               ETA: 01:36:51

################################################################################
                     [1m Learning iteration 473/3000 [0m                      

                       Computation: 41501 steps/s (collection: 2.273s, learning 0.096s)
             Mean action noise std: 2.26
          Mean value_function loss: 82.2878
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 69.0518
                       Mean reward: 197.23
               Mean episode length: 228.10
    Episode_Reward/reaching_object: 1.5501
    Episode_Reward/rotating_object: 36.9625
        Episode_Reward/action_rate: -0.0351
          Episode_Reward/joint_vel: -0.0429
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 46596096
                    Iteration time: 2.37s
                      Time elapsed: 00:18:09
                               ETA: 01:36:49

################################################################################
                     [1m Learning iteration 474/3000 [0m                      

                       Computation: 43112 steps/s (collection: 2.129s, learning 0.152s)
             Mean action noise std: 2.26
          Mean value_function loss: 72.8964
               Mean surrogate loss: -0.0098
                 Mean entropy loss: 69.0795
                       Mean reward: 207.36
               Mean episode length: 228.67
    Episode_Reward/reaching_object: 1.5291
    Episode_Reward/rotating_object: 36.7887
        Episode_Reward/action_rate: -0.0347
          Episode_Reward/joint_vel: -0.0416
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.7500
--------------------------------------------------------------------------------
                   Total timesteps: 46694400
                    Iteration time: 2.28s
                      Time elapsed: 00:18:11
                               ETA: 01:36:46

################################################################################
                     [1m Learning iteration 475/3000 [0m                      

                       Computation: 41011 steps/s (collection: 2.258s, learning 0.139s)
             Mean action noise std: 2.26
          Mean value_function loss: 80.2869
               Mean surrogate loss: -0.0097
                 Mean entropy loss: 69.1064
                       Mean reward: 152.51
               Mean episode length: 215.43
    Episode_Reward/reaching_object: 1.5091
    Episode_Reward/rotating_object: 31.2262
        Episode_Reward/action_rate: -0.0343
          Episode_Reward/joint_vel: -0.0418
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 46792704
                    Iteration time: 2.40s
                      Time elapsed: 00:18:14
                               ETA: 01:36:44

################################################################################
                     [1m Learning iteration 476/3000 [0m                      

                       Computation: 41867 steps/s (collection: 2.193s, learning 0.155s)
             Mean action noise std: 2.26
          Mean value_function loss: 77.4784
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 69.1323
                       Mean reward: 172.16
               Mean episode length: 219.90
    Episode_Reward/reaching_object: 1.5088
    Episode_Reward/rotating_object: 35.3776
        Episode_Reward/action_rate: -0.0343
          Episode_Reward/joint_vel: -0.0412
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 46891008
                    Iteration time: 2.35s
                      Time elapsed: 00:18:16
                               ETA: 01:36:42

################################################################################
                     [1m Learning iteration 477/3000 [0m                      

                       Computation: 43962 steps/s (collection: 2.125s, learning 0.111s)
             Mean action noise std: 2.26
          Mean value_function loss: 77.2865
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 69.1565
                       Mean reward: 187.30
               Mean episode length: 223.73
    Episode_Reward/reaching_object: 1.5386
    Episode_Reward/rotating_object: 37.5223
        Episode_Reward/action_rate: -0.0351
          Episode_Reward/joint_vel: -0.0420
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 46989312
                    Iteration time: 2.24s
                      Time elapsed: 00:18:18
                               ETA: 01:36:40

################################################################################
                     [1m Learning iteration 478/3000 [0m                      

                       Computation: 44839 steps/s (collection: 2.067s, learning 0.125s)
             Mean action noise std: 2.27
          Mean value_function loss: 79.4432
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 69.1791
                       Mean reward: 203.88
               Mean episode length: 218.24
    Episode_Reward/reaching_object: 1.5153
    Episode_Reward/rotating_object: 38.0769
        Episode_Reward/action_rate: -0.0346
          Episode_Reward/joint_vel: -0.0414
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 47087616
                    Iteration time: 2.19s
                      Time elapsed: 00:18:21
                               ETA: 01:36:37

################################################################################
                     [1m Learning iteration 479/3000 [0m                      

                       Computation: 44520 steps/s (collection: 2.070s, learning 0.138s)
             Mean action noise std: 2.27
          Mean value_function loss: 79.5252
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 69.2115
                       Mean reward: 197.10
               Mean episode length: 230.91
    Episode_Reward/reaching_object: 1.5313
    Episode_Reward/rotating_object: 37.3830
        Episode_Reward/action_rate: -0.0350
          Episode_Reward/joint_vel: -0.0421
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 47185920
                    Iteration time: 2.21s
                      Time elapsed: 00:18:23
                               ETA: 01:36:34

################################################################################
                     [1m Learning iteration 480/3000 [0m                      

                       Computation: 43248 steps/s (collection: 2.098s, learning 0.175s)
             Mean action noise std: 2.27
          Mean value_function loss: 75.9724
               Mean surrogate loss: -0.0100
                 Mean entropy loss: 69.2361
                       Mean reward: 197.08
               Mean episode length: 225.47
    Episode_Reward/reaching_object: 1.5008
    Episode_Reward/rotating_object: 34.8896
        Episode_Reward/action_rate: -0.0345
          Episode_Reward/joint_vel: -0.0422
      Episode_Termination/time_out: 13.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 47284224
                    Iteration time: 2.27s
                      Time elapsed: 00:18:25
                               ETA: 01:36:32

################################################################################
                     [1m Learning iteration 481/3000 [0m                      

                       Computation: 44332 steps/s (collection: 2.106s, learning 0.112s)
             Mean action noise std: 2.27
          Mean value_function loss: 80.3972
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 69.2588
                       Mean reward: 203.99
               Mean episode length: 233.64
    Episode_Reward/reaching_object: 1.5557
    Episode_Reward/rotating_object: 36.6783
        Episode_Reward/action_rate: -0.0355
          Episode_Reward/joint_vel: -0.0419
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 47382528
                    Iteration time: 2.22s
                      Time elapsed: 00:18:27
                               ETA: 01:36:29

################################################################################
                     [1m Learning iteration 482/3000 [0m                      

                       Computation: 44646 steps/s (collection: 2.057s, learning 0.145s)
             Mean action noise std: 2.27
          Mean value_function loss: 79.1875
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 69.2846
                       Mean reward: 174.87
               Mean episode length: 222.60
    Episode_Reward/reaching_object: 1.5358
    Episode_Reward/rotating_object: 38.1977
        Episode_Reward/action_rate: -0.0356
          Episode_Reward/joint_vel: -0.0424
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 47480832
                    Iteration time: 2.20s
                      Time elapsed: 00:18:29
                               ETA: 01:36:26

################################################################################
                     [1m Learning iteration 483/3000 [0m                      

                       Computation: 44924 steps/s (collection: 2.086s, learning 0.102s)
             Mean action noise std: 2.27
          Mean value_function loss: 78.4706
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 69.2983
                       Mean reward: 190.12
               Mean episode length: 219.24
    Episode_Reward/reaching_object: 1.5052
    Episode_Reward/rotating_object: 37.3369
        Episode_Reward/action_rate: -0.0349
          Episode_Reward/joint_vel: -0.0414
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 47579136
                    Iteration time: 2.19s
                      Time elapsed: 00:18:32
                               ETA: 01:36:23

################################################################################
                     [1m Learning iteration 484/3000 [0m                      

                       Computation: 45654 steps/s (collection: 2.027s, learning 0.126s)
             Mean action noise std: 2.28
          Mean value_function loss: 71.8631
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 69.3205
                       Mean reward: 181.10
               Mean episode length: 220.34
    Episode_Reward/reaching_object: 1.5139
    Episode_Reward/rotating_object: 36.6717
        Episode_Reward/action_rate: -0.0350
          Episode_Reward/joint_vel: -0.0412
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 47677440
                    Iteration time: 2.15s
                      Time elapsed: 00:18:34
                               ETA: 01:36:20

################################################################################
                     [1m Learning iteration 485/3000 [0m                      

                       Computation: 42002 steps/s (collection: 2.215s, learning 0.125s)
             Mean action noise std: 2.28
          Mean value_function loss: 78.7733
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 69.3547
                       Mean reward: 181.24
               Mean episode length: 224.97
    Episode_Reward/reaching_object: 1.5320
    Episode_Reward/rotating_object: 35.7678
        Episode_Reward/action_rate: -0.0357
          Episode_Reward/joint_vel: -0.0422
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 47775744
                    Iteration time: 2.34s
                      Time elapsed: 00:18:36
                               ETA: 01:36:18

################################################################################
                     [1m Learning iteration 486/3000 [0m                      

                       Computation: 38423 steps/s (collection: 2.439s, learning 0.120s)
             Mean action noise std: 2.28
          Mean value_function loss: 78.2316
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 69.3873
                       Mean reward: 208.97
               Mean episode length: 220.04
    Episode_Reward/reaching_object: 1.5107
    Episode_Reward/rotating_object: 36.9459
        Episode_Reward/action_rate: -0.0352
          Episode_Reward/joint_vel: -0.0414
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 47874048
                    Iteration time: 2.56s
                      Time elapsed: 00:18:39
                               ETA: 01:36:17

################################################################################
                     [1m Learning iteration 487/3000 [0m                      

                       Computation: 41507 steps/s (collection: 2.219s, learning 0.150s)
             Mean action noise std: 2.28
          Mean value_function loss: 77.9541
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 69.4111
                       Mean reward: 204.31
               Mean episode length: 218.86
    Episode_Reward/reaching_object: 1.4981
    Episode_Reward/rotating_object: 38.1472
        Episode_Reward/action_rate: -0.0351
          Episode_Reward/joint_vel: -0.0415
      Episode_Termination/time_out: 13.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 47972352
                    Iteration time: 2.37s
                      Time elapsed: 00:18:41
                               ETA: 01:36:15

################################################################################
                     [1m Learning iteration 488/3000 [0m                      

                       Computation: 44505 steps/s (collection: 2.066s, learning 0.143s)
             Mean action noise std: 2.28
          Mean value_function loss: 78.8920
               Mean surrogate loss: -0.0099
                 Mean entropy loss: 69.4388
                       Mean reward: 216.96
               Mean episode length: 226.68
    Episode_Reward/reaching_object: 1.5214
    Episode_Reward/rotating_object: 39.7510
        Episode_Reward/action_rate: -0.0358
          Episode_Reward/joint_vel: -0.0418
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 48070656
                    Iteration time: 2.21s
                      Time elapsed: 00:18:43
                               ETA: 01:36:13

################################################################################
                     [1m Learning iteration 489/3000 [0m                      

                       Computation: 44816 steps/s (collection: 2.065s, learning 0.129s)
             Mean action noise std: 2.29
          Mean value_function loss: 80.3254
               Mean surrogate loss: -0.0096
                 Mean entropy loss: 69.4702
                       Mean reward: 198.98
               Mean episode length: 219.54
    Episode_Reward/reaching_object: 1.5194
    Episode_Reward/rotating_object: 39.0235
        Episode_Reward/action_rate: -0.0356
          Episode_Reward/joint_vel: -0.0407
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.7083
--------------------------------------------------------------------------------
                   Total timesteps: 48168960
                    Iteration time: 2.19s
                      Time elapsed: 00:18:46
                               ETA: 01:36:10

################################################################################
                     [1m Learning iteration 490/3000 [0m                      

                       Computation: 42198 steps/s (collection: 2.223s, learning 0.106s)
             Mean action noise std: 2.29
          Mean value_function loss: 70.1040
               Mean surrogate loss: -0.0106
                 Mean entropy loss: 69.5004
                       Mean reward: 221.18
               Mean episode length: 218.70
    Episode_Reward/reaching_object: 1.5023
    Episode_Reward/rotating_object: 40.9587
        Episode_Reward/action_rate: -0.0354
          Episode_Reward/joint_vel: -0.0403
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 48267264
                    Iteration time: 2.33s
                      Time elapsed: 00:18:48
                               ETA: 01:36:08

################################################################################
                     [1m Learning iteration 491/3000 [0m                      

                       Computation: 39692 steps/s (collection: 2.200s, learning 0.277s)
             Mean action noise std: 2.29
          Mean value_function loss: 68.4956
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 69.5323
                       Mean reward: 192.92
               Mean episode length: 226.80
    Episode_Reward/reaching_object: 1.5368
    Episode_Reward/rotating_object: 35.5036
        Episode_Reward/action_rate: -0.0359
          Episode_Reward/joint_vel: -0.0421
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 48365568
                    Iteration time: 2.48s
                      Time elapsed: 00:18:50
                               ETA: 01:36:06

################################################################################
                     [1m Learning iteration 492/3000 [0m                      

                       Computation: 37744 steps/s (collection: 2.440s, learning 0.164s)
             Mean action noise std: 2.29
          Mean value_function loss: 69.4103
               Mean surrogate loss: -0.0102
                 Mean entropy loss: 69.5678
                       Mean reward: 228.20
               Mean episode length: 223.77
    Episode_Reward/reaching_object: 1.5002
    Episode_Reward/rotating_object: 39.7547
        Episode_Reward/action_rate: -0.0357
          Episode_Reward/joint_vel: -0.0411
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 48463872
                    Iteration time: 2.60s
                      Time elapsed: 00:18:53
                               ETA: 01:36:05

################################################################################
                     [1m Learning iteration 493/3000 [0m                      

                       Computation: 40290 steps/s (collection: 2.208s, learning 0.232s)
             Mean action noise std: 2.30
          Mean value_function loss: 73.1791
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 69.6030
                       Mean reward: 203.68
               Mean episode length: 227.68
    Episode_Reward/reaching_object: 1.4732
    Episode_Reward/rotating_object: 37.1838
        Episode_Reward/action_rate: -0.0351
          Episode_Reward/joint_vel: -0.0410
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 48562176
                    Iteration time: 2.44s
                      Time elapsed: 00:18:55
                               ETA: 01:36:04

################################################################################
                     [1m Learning iteration 494/3000 [0m                      

                       Computation: 43585 steps/s (collection: 2.136s, learning 0.119s)
             Mean action noise std: 2.30
          Mean value_function loss: 78.8149
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 69.6374
                       Mean reward: 201.47
               Mean episode length: 221.07
    Episode_Reward/reaching_object: 1.4868
    Episode_Reward/rotating_object: 37.4049
        Episode_Reward/action_rate: -0.0354
          Episode_Reward/joint_vel: -0.0407
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 48660480
                    Iteration time: 2.26s
                      Time elapsed: 00:18:58
                               ETA: 01:36:01

################################################################################
                     [1m Learning iteration 495/3000 [0m                      

                       Computation: 43260 steps/s (collection: 2.122s, learning 0.150s)
             Mean action noise std: 2.30
          Mean value_function loss: 70.6903
               Mean surrogate loss: -0.0102
                 Mean entropy loss: 69.6684
                       Mean reward: 219.55
               Mean episode length: 229.67
    Episode_Reward/reaching_object: 1.5122
    Episode_Reward/rotating_object: 38.1347
        Episode_Reward/action_rate: -0.0357
          Episode_Reward/joint_vel: -0.0400
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 48758784
                    Iteration time: 2.27s
                      Time elapsed: 00:19:00
                               ETA: 01:35:59

################################################################################
                     [1m Learning iteration 496/3000 [0m                      

                       Computation: 44591 steps/s (collection: 2.051s, learning 0.153s)
             Mean action noise std: 2.30
          Mean value_function loss: 75.3799
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 69.6965
                       Mean reward: 197.47
               Mean episode length: 217.13
    Episode_Reward/reaching_object: 1.4641
    Episode_Reward/rotating_object: 36.2941
        Episode_Reward/action_rate: -0.0350
          Episode_Reward/joint_vel: -0.0411
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.0833
--------------------------------------------------------------------------------
                   Total timesteps: 48857088
                    Iteration time: 2.20s
                      Time elapsed: 00:19:02
                               ETA: 01:35:56

################################################################################
                     [1m Learning iteration 497/3000 [0m                      

                       Computation: 44252 steps/s (collection: 2.071s, learning 0.150s)
             Mean action noise std: 2.31
          Mean value_function loss: 77.8670
               Mean surrogate loss: -0.0095
                 Mean entropy loss: 69.7338
                       Mean reward: 212.86
               Mean episode length: 228.21
    Episode_Reward/reaching_object: 1.5056
    Episode_Reward/rotating_object: 39.7326
        Episode_Reward/action_rate: -0.0359
          Episode_Reward/joint_vel: -0.0405
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.9583
--------------------------------------------------------------------------------
                   Total timesteps: 48955392
                    Iteration time: 2.22s
                      Time elapsed: 00:19:04
                               ETA: 01:35:53

################################################################################
                     [1m Learning iteration 498/3000 [0m                      

                       Computation: 41490 steps/s (collection: 2.169s, learning 0.201s)
             Mean action noise std: 2.31
          Mean value_function loss: 77.6890
               Mean surrogate loss: -0.0097
                 Mean entropy loss: 69.7697
                       Mean reward: 181.48
               Mean episode length: 216.84
    Episode_Reward/reaching_object: 1.4812
    Episode_Reward/rotating_object: 38.3666
        Episode_Reward/action_rate: -0.0352
          Episode_Reward/joint_vel: -0.0400
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.2083
--------------------------------------------------------------------------------
                   Total timesteps: 49053696
                    Iteration time: 2.37s
                      Time elapsed: 00:19:07
                               ETA: 01:35:52

################################################################################
                     [1m Learning iteration 499/3000 [0m                      

                       Computation: 42090 steps/s (collection: 2.226s, learning 0.110s)
             Mean action noise std: 2.31
          Mean value_function loss: 77.7196
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 69.7991
                       Mean reward: 220.15
               Mean episode length: 220.53
    Episode_Reward/reaching_object: 1.4600
    Episode_Reward/rotating_object: 39.3688
        Episode_Reward/action_rate: -0.0351
          Episode_Reward/joint_vel: -0.0386
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.1250
--------------------------------------------------------------------------------
                   Total timesteps: 49152000
                    Iteration time: 2.34s
                      Time elapsed: 00:19:09
                               ETA: 01:35:49

################################################################################
                     [1m Learning iteration 500/3000 [0m                      

                       Computation: 43616 steps/s (collection: 2.136s, learning 0.118s)
             Mean action noise std: 2.31
          Mean value_function loss: 63.1265
               Mean surrogate loss: -0.0098
                 Mean entropy loss: 69.8256
                       Mean reward: 208.95
               Mean episode length: 217.38
    Episode_Reward/reaching_object: 1.5196
    Episode_Reward/rotating_object: 36.9130
        Episode_Reward/action_rate: -0.0361
          Episode_Reward/joint_vel: -0.0412
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 49250304
                    Iteration time: 2.25s
                      Time elapsed: 00:19:11
                               ETA: 01:35:47

################################################################################
                     [1m Learning iteration 501/3000 [0m                      

                       Computation: 41766 steps/s (collection: 2.217s, learning 0.137s)
             Mean action noise std: 2.32
          Mean value_function loss: 73.3844
               Mean surrogate loss: -0.0097
                 Mean entropy loss: 69.8505
                       Mean reward: 197.01
               Mean episode length: 228.29
    Episode_Reward/reaching_object: 1.5346
    Episode_Reward/rotating_object: 39.7935
        Episode_Reward/action_rate: -0.0367
          Episode_Reward/joint_vel: -0.0417
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 49348608
                    Iteration time: 2.35s
                      Time elapsed: 00:19:14
                               ETA: 01:35:45

################################################################################
                     [1m Learning iteration 502/3000 [0m                      

                       Computation: 42463 steps/s (collection: 2.200s, learning 0.115s)
             Mean action noise std: 2.32
          Mean value_function loss: 74.1817
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 69.8834
                       Mean reward: 175.01
               Mean episode length: 229.81
    Episode_Reward/reaching_object: 1.5057
    Episode_Reward/rotating_object: 35.5594
        Episode_Reward/action_rate: -0.0364
          Episode_Reward/joint_vel: -0.0419
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.7500
--------------------------------------------------------------------------------
                   Total timesteps: 49446912
                    Iteration time: 2.31s
                      Time elapsed: 00:19:16
                               ETA: 01:35:43

################################################################################
                     [1m Learning iteration 503/3000 [0m                      

                       Computation: 42888 steps/s (collection: 2.181s, learning 0.111s)
             Mean action noise std: 2.32
          Mean value_function loss: 76.3948
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 69.9084
                       Mean reward: 233.10
               Mean episode length: 215.58
    Episode_Reward/reaching_object: 1.5141
    Episode_Reward/rotating_object: 41.2713
        Episode_Reward/action_rate: -0.0366
          Episode_Reward/joint_vel: -0.0398
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 49545216
                    Iteration time: 2.29s
                      Time elapsed: 00:19:18
                               ETA: 01:35:40

################################################################################
                     [1m Learning iteration 504/3000 [0m                      

                       Computation: 44768 steps/s (collection: 2.089s, learning 0.107s)
             Mean action noise std: 2.32
          Mean value_function loss: 77.2077
               Mean surrogate loss: -0.0098
                 Mean entropy loss: 69.9433
                       Mean reward: 182.37
               Mean episode length: 227.77
    Episode_Reward/reaching_object: 1.5292
    Episode_Reward/rotating_object: 39.0113
        Episode_Reward/action_rate: -0.0371
          Episode_Reward/joint_vel: -0.0411
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 49643520
                    Iteration time: 2.20s
                      Time elapsed: 00:19:20
                               ETA: 01:35:37

################################################################################
                     [1m Learning iteration 505/3000 [0m                      

                       Computation: 43122 steps/s (collection: 2.133s, learning 0.147s)
             Mean action noise std: 2.32
          Mean value_function loss: 77.6569
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 69.9754
                       Mean reward: 217.24
               Mean episode length: 228.04
    Episode_Reward/reaching_object: 1.5010
    Episode_Reward/rotating_object: 42.4720
        Episode_Reward/action_rate: -0.0367
          Episode_Reward/joint_vel: -0.0407
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.9583
--------------------------------------------------------------------------------
                   Total timesteps: 49741824
                    Iteration time: 2.28s
                      Time elapsed: 00:19:23
                               ETA: 01:35:35

################################################################################
                     [1m Learning iteration 506/3000 [0m                      

                       Computation: 43614 steps/s (collection: 2.153s, learning 0.101s)
             Mean action noise std: 2.33
          Mean value_function loss: 80.8312
               Mean surrogate loss: -0.0098
                 Mean entropy loss: 69.9994
                       Mean reward: 210.24
               Mean episode length: 213.90
    Episode_Reward/reaching_object: 1.4616
    Episode_Reward/rotating_object: 40.2120
        Episode_Reward/action_rate: -0.0361
          Episode_Reward/joint_vel: -0.0414
      Episode_Termination/time_out: 13.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 49840128
                    Iteration time: 2.25s
                      Time elapsed: 00:19:25
                               ETA: 01:35:33

################################################################################
                     [1m Learning iteration 507/3000 [0m                      

                       Computation: 40766 steps/s (collection: 2.236s, learning 0.176s)
             Mean action noise std: 2.33
          Mean value_function loss: 83.5448
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 70.0350
                       Mean reward: 216.25
               Mean episode length: 224.99
    Episode_Reward/reaching_object: 1.5121
    Episode_Reward/rotating_object: 40.0233
        Episode_Reward/action_rate: -0.0372
          Episode_Reward/joint_vel: -0.0415
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.7500
--------------------------------------------------------------------------------
                   Total timesteps: 49938432
                    Iteration time: 2.41s
                      Time elapsed: 00:19:27
                               ETA: 01:35:31

################################################################################
                     [1m Learning iteration 508/3000 [0m                      

                       Computation: 44071 steps/s (collection: 2.100s, learning 0.131s)
             Mean action noise std: 2.33
          Mean value_function loss: 77.9900
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 70.0628
                       Mean reward: 205.70
               Mean episode length: 223.90
    Episode_Reward/reaching_object: 1.4987
    Episode_Reward/rotating_object: 39.2704
        Episode_Reward/action_rate: -0.0371
          Episode_Reward/joint_vel: -0.0422
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 50036736
                    Iteration time: 2.23s
                      Time elapsed: 00:19:30
                               ETA: 01:35:28

################################################################################
                     [1m Learning iteration 509/3000 [0m                      

                       Computation: 43087 steps/s (collection: 2.150s, learning 0.131s)
             Mean action noise std: 2.33
          Mean value_function loss: 79.5724
               Mean surrogate loss: -0.0099
                 Mean entropy loss: 70.0856
                       Mean reward: 201.24
               Mean episode length: 225.94
    Episode_Reward/reaching_object: 1.5308
    Episode_Reward/rotating_object: 37.7668
        Episode_Reward/action_rate: -0.0374
          Episode_Reward/joint_vel: -0.0426
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 50135040
                    Iteration time: 2.28s
                      Time elapsed: 00:19:32
                               ETA: 01:35:26

################################################################################
                     [1m Learning iteration 510/3000 [0m                      

                       Computation: 42524 steps/s (collection: 2.151s, learning 0.161s)
             Mean action noise std: 2.34
          Mean value_function loss: 74.9125
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 70.1151
                       Mean reward: 245.15
               Mean episode length: 233.36
    Episode_Reward/reaching_object: 1.5354
    Episode_Reward/rotating_object: 40.6107
        Episode_Reward/action_rate: -0.0378
          Episode_Reward/joint_vel: -0.0427
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 50233344
                    Iteration time: 2.31s
                      Time elapsed: 00:19:34
                               ETA: 01:35:24

################################################################################
                     [1m Learning iteration 511/3000 [0m                      

                       Computation: 42700 steps/s (collection: 2.115s, learning 0.187s)
             Mean action noise std: 2.34
          Mean value_function loss: 73.8335
               Mean surrogate loss: -0.0099
                 Mean entropy loss: 70.1504
                       Mean reward: 208.12
               Mean episode length: 219.19
    Episode_Reward/reaching_object: 1.5007
    Episode_Reward/rotating_object: 38.4483
        Episode_Reward/action_rate: -0.0369
          Episode_Reward/joint_vel: -0.0413
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.1667
--------------------------------------------------------------------------------
                   Total timesteps: 50331648
                    Iteration time: 2.30s
                      Time elapsed: 00:19:36
                               ETA: 01:35:21

################################################################################
                     [1m Learning iteration 512/3000 [0m                      

                       Computation: 44301 steps/s (collection: 2.110s, learning 0.109s)
             Mean action noise std: 2.34
          Mean value_function loss: 74.5366
               Mean surrogate loss: -0.0098
                 Mean entropy loss: 70.1816
                       Mean reward: 199.94
               Mean episode length: 225.95
    Episode_Reward/reaching_object: 1.5225
    Episode_Reward/rotating_object: 41.0504
        Episode_Reward/action_rate: -0.0377
          Episode_Reward/joint_vel: -0.0420
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 50429952
                    Iteration time: 2.22s
                      Time elapsed: 00:19:39
                               ETA: 01:35:19

################################################################################
                     [1m Learning iteration 513/3000 [0m                      

                       Computation: 43679 steps/s (collection: 2.139s, learning 0.112s)
             Mean action noise std: 2.34
          Mean value_function loss: 82.9650
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 70.2143
                       Mean reward: 184.72
               Mean episode length: 225.52
    Episode_Reward/reaching_object: 1.5273
    Episode_Reward/rotating_object: 39.1209
        Episode_Reward/action_rate: -0.0378
          Episode_Reward/joint_vel: -0.0418
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 50528256
                    Iteration time: 2.25s
                      Time elapsed: 00:19:41
                               ETA: 01:35:16

################################################################################
                     [1m Learning iteration 514/3000 [0m                      

                       Computation: 43335 steps/s (collection: 2.109s, learning 0.159s)
             Mean action noise std: 2.35
          Mean value_function loss: 80.0560
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 70.2530
                       Mean reward: 202.11
               Mean episode length: 211.78
    Episode_Reward/reaching_object: 1.5092
    Episode_Reward/rotating_object: 41.1687
        Episode_Reward/action_rate: -0.0377
          Episode_Reward/joint_vel: -0.0420
      Episode_Termination/time_out: 13.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 50626560
                    Iteration time: 2.27s
                      Time elapsed: 00:19:43
                               ETA: 01:35:14

################################################################################
                     [1m Learning iteration 515/3000 [0m                      

                       Computation: 44310 steps/s (collection: 2.079s, learning 0.140s)
             Mean action noise std: 2.35
          Mean value_function loss: 78.1001
               Mean surrogate loss: -0.0100
                 Mean entropy loss: 70.2868
                       Mean reward: 201.62
               Mean episode length: 230.39
    Episode_Reward/reaching_object: 1.5148
    Episode_Reward/rotating_object: 39.3203
        Episode_Reward/action_rate: -0.0381
          Episode_Reward/joint_vel: -0.0420
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 50724864
                    Iteration time: 2.22s
                      Time elapsed: 00:19:45
                               ETA: 01:35:11

################################################################################
                     [1m Learning iteration 516/3000 [0m                      

                       Computation: 44302 steps/s (collection: 2.089s, learning 0.130s)
             Mean action noise std: 2.35
          Mean value_function loss: 83.3416
               Mean surrogate loss: -0.0096
                 Mean entropy loss: 70.3151
                       Mean reward: 166.50
               Mean episode length: 216.19
    Episode_Reward/reaching_object: 1.4869
    Episode_Reward/rotating_object: 38.3748
        Episode_Reward/action_rate: -0.0372
          Episode_Reward/joint_vel: -0.0411
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.0833
--------------------------------------------------------------------------------
                   Total timesteps: 50823168
                    Iteration time: 2.22s
                      Time elapsed: 00:19:48
                               ETA: 01:35:08

################################################################################
                     [1m Learning iteration 517/3000 [0m                      

                       Computation: 45038 steps/s (collection: 2.037s, learning 0.146s)
             Mean action noise std: 2.35
          Mean value_function loss: 83.0091
               Mean surrogate loss: -0.0101
                 Mean entropy loss: 70.3485
                       Mean reward: 201.86
               Mean episode length: 218.63
    Episode_Reward/reaching_object: 1.4557
    Episode_Reward/rotating_object: 39.9737
        Episode_Reward/action_rate: -0.0369
          Episode_Reward/joint_vel: -0.0395
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 4.0833
--------------------------------------------------------------------------------
                   Total timesteps: 50921472
                    Iteration time: 2.18s
                      Time elapsed: 00:19:50
                               ETA: 01:35:05

################################################################################
                     [1m Learning iteration 518/3000 [0m                      

                       Computation: 44948 steps/s (collection: 2.069s, learning 0.118s)
             Mean action noise std: 2.36
          Mean value_function loss: 73.3775
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 70.3813
                       Mean reward: 179.82
               Mean episode length: 218.29
    Episode_Reward/reaching_object: 1.4937
    Episode_Reward/rotating_object: 38.0441
        Episode_Reward/action_rate: -0.0376
          Episode_Reward/joint_vel: -0.0408
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 51019776
                    Iteration time: 2.19s
                      Time elapsed: 00:19:52
                               ETA: 01:35:03

################################################################################
                     [1m Learning iteration 519/3000 [0m                      

                       Computation: 44114 steps/s (collection: 2.093s, learning 0.135s)
             Mean action noise std: 2.36
          Mean value_function loss: 90.9375
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 70.4062
                       Mean reward: 210.96
               Mean episode length: 214.59
    Episode_Reward/reaching_object: 1.4709
    Episode_Reward/rotating_object: 39.4495
        Episode_Reward/action_rate: -0.0373
          Episode_Reward/joint_vel: -0.0403
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.9583
--------------------------------------------------------------------------------
                   Total timesteps: 51118080
                    Iteration time: 2.23s
                      Time elapsed: 00:19:54
                               ETA: 01:35:00

################################################################################
                     [1m Learning iteration 520/3000 [0m                      

                       Computation: 42304 steps/s (collection: 2.152s, learning 0.172s)
             Mean action noise std: 2.36
          Mean value_function loss: 78.9368
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 70.4294
                       Mean reward: 200.26
               Mean episode length: 212.96
    Episode_Reward/reaching_object: 1.4598
    Episode_Reward/rotating_object: 40.6687
        Episode_Reward/action_rate: -0.0372
          Episode_Reward/joint_vel: -0.0404
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.0833
--------------------------------------------------------------------------------
                   Total timesteps: 51216384
                    Iteration time: 2.32s
                      Time elapsed: 00:19:57
                               ETA: 01:34:58

################################################################################
                     [1m Learning iteration 521/3000 [0m                      

                       Computation: 43948 steps/s (collection: 2.127s, learning 0.110s)
             Mean action noise std: 2.36
          Mean value_function loss: 85.8962
               Mean surrogate loss: -0.0100
                 Mean entropy loss: 70.4610
                       Mean reward: 202.79
               Mean episode length: 221.20
    Episode_Reward/reaching_object: 1.4903
    Episode_Reward/rotating_object: 42.7210
        Episode_Reward/action_rate: -0.0376
          Episode_Reward/joint_vel: -0.0397
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 51314688
                    Iteration time: 2.24s
                      Time elapsed: 00:19:59
                               ETA: 01:34:55

################################################################################
                     [1m Learning iteration 522/3000 [0m                      

                       Computation: 43537 steps/s (collection: 2.112s, learning 0.146s)
             Mean action noise std: 2.37
          Mean value_function loss: 86.6435
               Mean surrogate loss: -0.0099
                 Mean entropy loss: 70.4969
                       Mean reward: 210.63
               Mean episode length: 216.51
    Episode_Reward/reaching_object: 1.5028
    Episode_Reward/rotating_object: 43.5198
        Episode_Reward/action_rate: -0.0381
          Episode_Reward/joint_vel: -0.0412
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 51412992
                    Iteration time: 2.26s
                      Time elapsed: 00:20:01
                               ETA: 01:34:53

################################################################################
                     [1m Learning iteration 523/3000 [0m                      

                       Computation: 40433 steps/s (collection: 2.315s, learning 0.117s)
             Mean action noise std: 2.37
          Mean value_function loss: 80.4301
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 70.5301
                       Mean reward: 219.38
               Mean episode length: 232.07
    Episode_Reward/reaching_object: 1.4904
    Episode_Reward/rotating_object: 40.1853
        Episode_Reward/action_rate: -0.0381
          Episode_Reward/joint_vel: -0.0408
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.1250
--------------------------------------------------------------------------------
                   Total timesteps: 51511296
                    Iteration time: 2.43s
                      Time elapsed: 00:20:04
                               ETA: 01:34:51

################################################################################
                     [1m Learning iteration 524/3000 [0m                      

                       Computation: 43613 steps/s (collection: 2.142s, learning 0.112s)
             Mean action noise std: 2.37
          Mean value_function loss: 83.2423
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 70.5556
                       Mean reward: 211.63
               Mean episode length: 217.78
    Episode_Reward/reaching_object: 1.4839
    Episode_Reward/rotating_object: 41.6385
        Episode_Reward/action_rate: -0.0379
          Episode_Reward/joint_vel: -0.0410
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 51609600
                    Iteration time: 2.25s
                      Time elapsed: 00:20:06
                               ETA: 01:34:49

################################################################################
                     [1m Learning iteration 525/3000 [0m                      

                       Computation: 41771 steps/s (collection: 2.177s, learning 0.177s)
             Mean action noise std: 2.37
          Mean value_function loss: 79.1123
               Mean surrogate loss: -0.0104
                 Mean entropy loss: 70.5913
                       Mean reward: 168.22
               Mean episode length: 218.62
    Episode_Reward/reaching_object: 1.4898
    Episode_Reward/rotating_object: 34.5458
        Episode_Reward/action_rate: -0.0379
          Episode_Reward/joint_vel: -0.0417
      Episode_Termination/time_out: 12.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 51707904
                    Iteration time: 2.35s
                      Time elapsed: 00:20:08
                               ETA: 01:34:46

################################################################################
                     [1m Learning iteration 526/3000 [0m                      

                       Computation: 43898 steps/s (collection: 2.025s, learning 0.214s)
             Mean action noise std: 2.38
          Mean value_function loss: 72.5869
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 70.6287
                       Mean reward: 204.44
               Mean episode length: 224.20
    Episode_Reward/reaching_object: 1.4811
    Episode_Reward/rotating_object: 38.1520
        Episode_Reward/action_rate: -0.0378
          Episode_Reward/joint_vel: -0.0408
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.3333
--------------------------------------------------------------------------------
                   Total timesteps: 51806208
                    Iteration time: 2.24s
                      Time elapsed: 00:20:10
                               ETA: 01:34:44

################################################################################
                     [1m Learning iteration 527/3000 [0m                      

                       Computation: 42182 steps/s (collection: 2.196s, learning 0.134s)
             Mean action noise std: 2.38
          Mean value_function loss: 81.9458
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 70.6617
                       Mean reward: 222.27
               Mean episode length: 227.39
    Episode_Reward/reaching_object: 1.4835
    Episode_Reward/rotating_object: 39.2943
        Episode_Reward/action_rate: -0.0378
          Episode_Reward/joint_vel: -0.0398
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 51904512
                    Iteration time: 2.33s
                      Time elapsed: 00:20:13
                               ETA: 01:34:42

################################################################################
                     [1m Learning iteration 528/3000 [0m                      

                       Computation: 43129 steps/s (collection: 2.159s, learning 0.120s)
             Mean action noise std: 2.38
          Mean value_function loss: 80.1964
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 70.6917
                       Mean reward: 207.89
               Mean episode length: 222.86
    Episode_Reward/reaching_object: 1.4915
    Episode_Reward/rotating_object: 42.4753
        Episode_Reward/action_rate: -0.0382
          Episode_Reward/joint_vel: -0.0407
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.3750
--------------------------------------------------------------------------------
                   Total timesteps: 52002816
                    Iteration time: 2.28s
                      Time elapsed: 00:20:15
                               ETA: 01:34:39

################################################################################
                     [1m Learning iteration 529/3000 [0m                      

                       Computation: 42854 steps/s (collection: 2.173s, learning 0.121s)
             Mean action noise std: 2.38
          Mean value_function loss: 85.3186
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 70.7272
                       Mean reward: 220.34
               Mean episode length: 226.56
    Episode_Reward/reaching_object: 1.4769
    Episode_Reward/rotating_object: 41.0024
        Episode_Reward/action_rate: -0.0381
          Episode_Reward/joint_vel: -0.0402
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.7500
--------------------------------------------------------------------------------
                   Total timesteps: 52101120
                    Iteration time: 2.29s
                      Time elapsed: 00:20:17
                               ETA: 01:34:37

################################################################################
                     [1m Learning iteration 530/3000 [0m                      

                       Computation: 44905 steps/s (collection: 2.089s, learning 0.100s)
             Mean action noise std: 2.39
          Mean value_function loss: 81.3957
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 70.7652
                       Mean reward: 219.05
               Mean episode length: 211.82
    Episode_Reward/reaching_object: 1.4447
    Episode_Reward/rotating_object: 40.4180
        Episode_Reward/action_rate: -0.0374
          Episode_Reward/joint_vel: -0.0403
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.5833
--------------------------------------------------------------------------------
                   Total timesteps: 52199424
                    Iteration time: 2.19s
                      Time elapsed: 00:20:19
                               ETA: 01:34:34

################################################################################
                     [1m Learning iteration 531/3000 [0m                      

                       Computation: 44806 steps/s (collection: 2.069s, learning 0.125s)
             Mean action noise std: 2.39
          Mean value_function loss: 81.7830
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 70.7962
                       Mean reward: 227.78
               Mean episode length: 226.85
    Episode_Reward/reaching_object: 1.4533
    Episode_Reward/rotating_object: 40.9668
        Episode_Reward/action_rate: -0.0378
          Episode_Reward/joint_vel: -0.0407
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.5417
--------------------------------------------------------------------------------
                   Total timesteps: 52297728
                    Iteration time: 2.19s
                      Time elapsed: 00:20:22
                               ETA: 01:34:32

################################################################################
                     [1m Learning iteration 532/3000 [0m                      

                       Computation: 43186 steps/s (collection: 2.168s, learning 0.109s)
             Mean action noise std: 2.39
          Mean value_function loss: 85.2767
               Mean surrogate loss: -0.0104
                 Mean entropy loss: 70.8300
                       Mean reward: 216.27
               Mean episode length: 212.52
    Episode_Reward/reaching_object: 1.4649
    Episode_Reward/rotating_object: 38.6678
        Episode_Reward/action_rate: -0.0379
          Episode_Reward/joint_vel: -0.0405
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.5000
--------------------------------------------------------------------------------
                   Total timesteps: 52396032
                    Iteration time: 2.28s
                      Time elapsed: 00:20:24
                               ETA: 01:34:29

################################################################################
                     [1m Learning iteration 533/3000 [0m                      

                       Computation: 43831 steps/s (collection: 2.141s, learning 0.102s)
             Mean action noise std: 2.39
          Mean value_function loss: 90.1189
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 70.8616
                       Mean reward: 216.92
               Mean episode length: 222.69
    Episode_Reward/reaching_object: 1.4381
    Episode_Reward/rotating_object: 37.1074
        Episode_Reward/action_rate: -0.0375
          Episode_Reward/joint_vel: -0.0415
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.3750
--------------------------------------------------------------------------------
                   Total timesteps: 52494336
                    Iteration time: 2.24s
                      Time elapsed: 00:20:26
                               ETA: 01:34:27

################################################################################
                     [1m Learning iteration 534/3000 [0m                      

                       Computation: 42170 steps/s (collection: 2.212s, learning 0.120s)
             Mean action noise std: 2.40
          Mean value_function loss: 90.5903
               Mean surrogate loss: -0.0103
                 Mean entropy loss: 70.8996
                       Mean reward: 185.56
               Mean episode length: 214.62
    Episode_Reward/reaching_object: 1.4912
    Episode_Reward/rotating_object: 39.7422
        Episode_Reward/action_rate: -0.0384
          Episode_Reward/joint_vel: -0.0415
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.5417
--------------------------------------------------------------------------------
                   Total timesteps: 52592640
                    Iteration time: 2.33s
                      Time elapsed: 00:20:29
                               ETA: 01:34:24

################################################################################
                     [1m Learning iteration 535/3000 [0m                      

                       Computation: 44658 steps/s (collection: 2.085s, learning 0.116s)
             Mean action noise std: 2.40
          Mean value_function loss: 97.4420
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 70.9383
                       Mean reward: 184.83
               Mean episode length: 222.29
    Episode_Reward/reaching_object: 1.4655
    Episode_Reward/rotating_object: 38.8293
        Episode_Reward/action_rate: -0.0381
          Episode_Reward/joint_vel: -0.0418
      Episode_Termination/time_out: 12.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.0833
--------------------------------------------------------------------------------
                   Total timesteps: 52690944
                    Iteration time: 2.20s
                      Time elapsed: 00:20:31
                               ETA: 01:34:22

################################################################################
                     [1m Learning iteration 536/3000 [0m                      

                       Computation: 43691 steps/s (collection: 2.125s, learning 0.125s)
             Mean action noise std: 2.40
          Mean value_function loss: 99.0472
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 70.9618
                       Mean reward: 199.26
               Mean episode length: 222.74
    Episode_Reward/reaching_object: 1.5081
    Episode_Reward/rotating_object: 38.7780
        Episode_Reward/action_rate: -0.0389
          Episode_Reward/joint_vel: -0.0421
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.3333
--------------------------------------------------------------------------------
                   Total timesteps: 52789248
                    Iteration time: 2.25s
                      Time elapsed: 00:20:33
                               ETA: 01:34:19

################################################################################
                     [1m Learning iteration 537/3000 [0m                      

                       Computation: 43391 steps/s (collection: 2.160s, learning 0.106s)
             Mean action noise std: 2.40
          Mean value_function loss: 100.0160
               Mean surrogate loss: -0.0105
                 Mean entropy loss: 70.9931
                       Mean reward: 207.01
               Mean episode length: 216.11
    Episode_Reward/reaching_object: 1.4963
    Episode_Reward/rotating_object: 40.0800
        Episode_Reward/action_rate: -0.0387
          Episode_Reward/joint_vel: -0.0410
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.1667
--------------------------------------------------------------------------------
                   Total timesteps: 52887552
                    Iteration time: 2.27s
                      Time elapsed: 00:20:35
                               ETA: 01:34:17

################################################################################
                     [1m Learning iteration 538/3000 [0m                      

                       Computation: 43174 steps/s (collection: 2.152s, learning 0.125s)
             Mean action noise std: 2.41
          Mean value_function loss: 97.1653
               Mean surrogate loss: -0.0097
                 Mean entropy loss: 71.0260
                       Mean reward: 228.25
               Mean episode length: 211.23
    Episode_Reward/reaching_object: 1.4614
    Episode_Reward/rotating_object: 42.0490
        Episode_Reward/action_rate: -0.0383
          Episode_Reward/joint_vel: -0.0414
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.6667
--------------------------------------------------------------------------------
                   Total timesteps: 52985856
                    Iteration time: 2.28s
                      Time elapsed: 00:20:38
                               ETA: 01:34:14

################################################################################
                     [1m Learning iteration 539/3000 [0m                      

                       Computation: 44042 steps/s (collection: 2.113s, learning 0.119s)
             Mean action noise std: 2.41
          Mean value_function loss: 100.5335
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 71.0558
                       Mean reward: 210.79
               Mean episode length: 209.46
    Episode_Reward/reaching_object: 1.4832
    Episode_Reward/rotating_object: 40.3956
        Episode_Reward/action_rate: -0.0388
          Episode_Reward/joint_vel: -0.0414
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.4583
--------------------------------------------------------------------------------
                   Total timesteps: 53084160
                    Iteration time: 2.23s
                      Time elapsed: 00:20:40
                               ETA: 01:34:12

################################################################################
                     [1m Learning iteration 540/3000 [0m                      

                       Computation: 44277 steps/s (collection: 2.118s, learning 0.103s)
             Mean action noise std: 2.41
          Mean value_function loss: 99.7194
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 71.0843
                       Mean reward: 197.12
               Mean episode length: 216.15
    Episode_Reward/reaching_object: 1.4817
    Episode_Reward/rotating_object: 39.9695
        Episode_Reward/action_rate: -0.0388
          Episode_Reward/joint_vel: -0.0422
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.7917
--------------------------------------------------------------------------------
                   Total timesteps: 53182464
                    Iteration time: 2.22s
                      Time elapsed: 00:20:42
                               ETA: 01:34:09

################################################################################
                     [1m Learning iteration 541/3000 [0m                      

                       Computation: 42518 steps/s (collection: 2.192s, learning 0.120s)
             Mean action noise std: 2.41
          Mean value_function loss: 96.3152
               Mean surrogate loss: -0.0096
                 Mean entropy loss: 71.1158
                       Mean reward: 212.94
               Mean episode length: 228.74
    Episode_Reward/reaching_object: 1.5006
    Episode_Reward/rotating_object: 42.7712
        Episode_Reward/action_rate: -0.0391
          Episode_Reward/joint_vel: -0.0417
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.2083
--------------------------------------------------------------------------------
                   Total timesteps: 53280768
                    Iteration time: 2.31s
                      Time elapsed: 00:20:44
                               ETA: 01:34:07

################################################################################
                     [1m Learning iteration 542/3000 [0m                      

                       Computation: 38718 steps/s (collection: 2.392s, learning 0.147s)
             Mean action noise std: 2.42
          Mean value_function loss: 104.7059
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 71.1508
                       Mean reward: 192.53
               Mean episode length: 219.92
    Episode_Reward/reaching_object: 1.4489
    Episode_Reward/rotating_object: 41.9087
        Episode_Reward/action_rate: -0.0383
          Episode_Reward/joint_vel: -0.0425
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.9583
--------------------------------------------------------------------------------
                   Total timesteps: 53379072
                    Iteration time: 2.54s
                      Time elapsed: 00:20:47
                               ETA: 01:34:06

################################################################################
                     [1m Learning iteration 543/3000 [0m                      

                       Computation: 42769 steps/s (collection: 2.193s, learning 0.106s)
             Mean action noise std: 2.42
          Mean value_function loss: 93.7132
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 71.1803
                       Mean reward: 230.69
               Mean episode length: 218.58
    Episode_Reward/reaching_object: 1.4678
    Episode_Reward/rotating_object: 39.1224
        Episode_Reward/action_rate: -0.0386
          Episode_Reward/joint_vel: -0.0425
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.1667
--------------------------------------------------------------------------------
                   Total timesteps: 53477376
                    Iteration time: 2.30s
                      Time elapsed: 00:20:49
                               ETA: 01:34:03

################################################################################
                     [1m Learning iteration 544/3000 [0m                      

                       Computation: 44490 steps/s (collection: 2.088s, learning 0.122s)
             Mean action noise std: 2.42
          Mean value_function loss: 99.2421
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 71.2052
                       Mean reward: 231.50
               Mean episode length: 224.37
    Episode_Reward/reaching_object: 1.4913
    Episode_Reward/rotating_object: 44.0087
        Episode_Reward/action_rate: -0.0393
          Episode_Reward/joint_vel: -0.0421
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.6667
--------------------------------------------------------------------------------
                   Total timesteps: 53575680
                    Iteration time: 2.21s
                      Time elapsed: 00:20:51
                               ETA: 01:34:01

################################################################################
                     [1m Learning iteration 545/3000 [0m                      

                       Computation: 45011 steps/s (collection: 2.040s, learning 0.144s)
             Mean action noise std: 2.42
          Mean value_function loss: 103.8936
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 71.2342
                       Mean reward: 209.67
               Mean episode length: 207.14
    Episode_Reward/reaching_object: 1.4921
    Episode_Reward/rotating_object: 41.3770
        Episode_Reward/action_rate: -0.0392
          Episode_Reward/joint_vel: -0.0427
      Episode_Termination/time_out: 13.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 53673984
                    Iteration time: 2.18s
                      Time elapsed: 00:20:53
                               ETA: 01:33:58

################################################################################
                     [1m Learning iteration 546/3000 [0m                      

                       Computation: 43999 steps/s (collection: 2.129s, learning 0.105s)
             Mean action noise std: 2.43
          Mean value_function loss: 100.2376
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 71.2663
                       Mean reward: 223.50
               Mean episode length: 211.82
    Episode_Reward/reaching_object: 1.4808
    Episode_Reward/rotating_object: 42.1620
        Episode_Reward/action_rate: -0.0391
          Episode_Reward/joint_vel: -0.0425
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.7500
--------------------------------------------------------------------------------
                   Total timesteps: 53772288
                    Iteration time: 2.23s
                      Time elapsed: 00:20:56
                               ETA: 01:33:55

################################################################################
                     [1m Learning iteration 547/3000 [0m                      

                       Computation: 45945 steps/s (collection: 2.028s, learning 0.111s)
             Mean action noise std: 2.43
          Mean value_function loss: 95.9115
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 71.2919
                       Mean reward: 220.29
               Mean episode length: 221.93
    Episode_Reward/reaching_object: 1.5174
    Episode_Reward/rotating_object: 40.4697
        Episode_Reward/action_rate: -0.0399
          Episode_Reward/joint_vel: -0.0437
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.2083
--------------------------------------------------------------------------------
                   Total timesteps: 53870592
                    Iteration time: 2.14s
                      Time elapsed: 00:20:58
                               ETA: 01:33:52

################################################################################
                     [1m Learning iteration 548/3000 [0m                      

                       Computation: 45836 steps/s (collection: 2.044s, learning 0.101s)
             Mean action noise std: 2.43
          Mean value_function loss: 103.8001
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 71.3142
                       Mean reward: 252.29
               Mean episode length: 225.11
    Episode_Reward/reaching_object: 1.5417
    Episode_Reward/rotating_object: 43.5949
        Episode_Reward/action_rate: -0.0409
          Episode_Reward/joint_vel: -0.0445
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.7500
--------------------------------------------------------------------------------
                   Total timesteps: 53968896
                    Iteration time: 2.14s
                      Time elapsed: 00:21:00
                               ETA: 01:33:49

################################################################################
                     [1m Learning iteration 549/3000 [0m                      

                       Computation: 45821 steps/s (collection: 2.025s, learning 0.121s)
             Mean action noise std: 2.43
          Mean value_function loss: 88.4366
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 71.3467
                       Mean reward: 229.92
               Mean episode length: 228.22
    Episode_Reward/reaching_object: 1.5049
    Episode_Reward/rotating_object: 42.8503
        Episode_Reward/action_rate: -0.0397
          Episode_Reward/joint_vel: -0.0434
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.9167
--------------------------------------------------------------------------------
                   Total timesteps: 54067200
                    Iteration time: 2.15s
                      Time elapsed: 00:21:02
                               ETA: 01:33:46

################################################################################
                     [1m Learning iteration 550/3000 [0m                      

                       Computation: 44700 steps/s (collection: 2.061s, learning 0.138s)
             Mean action noise std: 2.44
          Mean value_function loss: 90.9590
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 71.3890
                       Mean reward: 271.76
               Mean episode length: 226.10
    Episode_Reward/reaching_object: 1.4715
    Episode_Reward/rotating_object: 45.5082
        Episode_Reward/action_rate: -0.0395
          Episode_Reward/joint_vel: -0.0417
      Episode_Termination/time_out: 12.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.2917
--------------------------------------------------------------------------------
                   Total timesteps: 54165504
                    Iteration time: 2.20s
                      Time elapsed: 00:21:04
                               ETA: 01:33:44

################################################################################
                     [1m Learning iteration 551/3000 [0m                      

                       Computation: 44038 steps/s (collection: 2.136s, learning 0.097s)
             Mean action noise std: 2.44
          Mean value_function loss: 89.7251
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 71.4223
                       Mean reward: 206.08
               Mean episode length: 205.17
    Episode_Reward/reaching_object: 1.4857
    Episode_Reward/rotating_object: 46.7666
        Episode_Reward/action_rate: -0.0398
          Episode_Reward/joint_vel: -0.0416
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.2917
--------------------------------------------------------------------------------
                   Total timesteps: 54263808
                    Iteration time: 2.23s
                      Time elapsed: 00:21:07
                               ETA: 01:33:41

################################################################################
                     [1m Learning iteration 552/3000 [0m                      

                       Computation: 44732 steps/s (collection: 2.066s, learning 0.132s)
             Mean action noise std: 2.44
          Mean value_function loss: 94.9765
               Mean surrogate loss: -0.0095
                 Mean entropy loss: 71.4495
                       Mean reward: 245.45
               Mean episode length: 223.04
    Episode_Reward/reaching_object: 1.5076
    Episode_Reward/rotating_object: 44.7502
        Episode_Reward/action_rate: -0.0407
          Episode_Reward/joint_vel: -0.0426
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.5417
--------------------------------------------------------------------------------
                   Total timesteps: 54362112
                    Iteration time: 2.20s
                      Time elapsed: 00:21:09
                               ETA: 01:33:38

################################################################################
                     [1m Learning iteration 553/3000 [0m                      

                       Computation: 41135 steps/s (collection: 2.247s, learning 0.143s)
             Mean action noise std: 2.44
          Mean value_function loss: 89.2078
               Mean surrogate loss: -0.0103
                 Mean entropy loss: 71.4786
                       Mean reward: 221.14
               Mean episode length: 226.51
    Episode_Reward/reaching_object: 1.5058
    Episode_Reward/rotating_object: 48.1558
        Episode_Reward/action_rate: -0.0406
          Episode_Reward/joint_vel: -0.0417
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 54460416
                    Iteration time: 2.39s
                      Time elapsed: 00:21:11
                               ETA: 01:33:36

################################################################################
                     [1m Learning iteration 554/3000 [0m                      

                       Computation: 36740 steps/s (collection: 2.419s, learning 0.257s)
             Mean action noise std: 2.45
          Mean value_function loss: 91.0439
               Mean surrogate loss: -0.0105
                 Mean entropy loss: 71.5152
                       Mean reward: 231.65
               Mean episode length: 209.38
    Episode_Reward/reaching_object: 1.4652
    Episode_Reward/rotating_object: 46.4723
        Episode_Reward/action_rate: -0.0396
          Episode_Reward/joint_vel: -0.0401
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 5.0833
--------------------------------------------------------------------------------
                   Total timesteps: 54558720
                    Iteration time: 2.68s
                      Time elapsed: 00:21:14
                               ETA: 01:33:36

################################################################################
                     [1m Learning iteration 555/3000 [0m                      

                       Computation: 41169 steps/s (collection: 2.289s, learning 0.099s)
             Mean action noise std: 2.45
          Mean value_function loss: 90.8752
               Mean surrogate loss: -0.0097
                 Mean entropy loss: 71.5506
                       Mean reward: 229.11
               Mean episode length: 210.64
    Episode_Reward/reaching_object: 1.4409
    Episode_Reward/rotating_object: 43.3616
        Episode_Reward/action_rate: -0.0397
          Episode_Reward/joint_vel: -0.0415
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.6667
--------------------------------------------------------------------------------
                   Total timesteps: 54657024
                    Iteration time: 2.39s
                      Time elapsed: 00:21:16
                               ETA: 01:33:34

################################################################################
                     [1m Learning iteration 556/3000 [0m                      

                       Computation: 43298 steps/s (collection: 2.096s, learning 0.175s)
             Mean action noise std: 2.45
          Mean value_function loss: 97.1432
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 71.5731
                       Mean reward: 247.69
               Mean episode length: 218.91
    Episode_Reward/reaching_object: 1.4583
    Episode_Reward/rotating_object: 44.3201
        Episode_Reward/action_rate: -0.0398
          Episode_Reward/joint_vel: -0.0414
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.2500
--------------------------------------------------------------------------------
                   Total timesteps: 54755328
                    Iteration time: 2.27s
                      Time elapsed: 00:21:19
                               ETA: 01:33:32

################################################################################
                     [1m Learning iteration 557/3000 [0m                      

                       Computation: 40315 steps/s (collection: 2.280s, learning 0.159s)
             Mean action noise std: 2.45
          Mean value_function loss: 87.3134
               Mean surrogate loss: -0.0101
                 Mean entropy loss: 71.5985
                       Mean reward: 209.44
               Mean episode length: 222.78
    Episode_Reward/reaching_object: 1.4674
    Episode_Reward/rotating_object: 43.1395
        Episode_Reward/action_rate: -0.0402
          Episode_Reward/joint_vel: -0.0412
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.6667
--------------------------------------------------------------------------------
                   Total timesteps: 54853632
                    Iteration time: 2.44s
                      Time elapsed: 00:21:21
                               ETA: 01:33:30

################################################################################
                     [1m Learning iteration 558/3000 [0m                      

                       Computation: 42105 steps/s (collection: 2.200s, learning 0.135s)
             Mean action noise std: 2.46
          Mean value_function loss: 85.2538
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 71.6322
                       Mean reward: 212.40
               Mean episode length: 206.77
    Episode_Reward/reaching_object: 1.4057
    Episode_Reward/rotating_object: 43.2127
        Episode_Reward/action_rate: -0.0390
          Episode_Reward/joint_vel: -0.0404
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.0833
--------------------------------------------------------------------------------
                   Total timesteps: 54951936
                    Iteration time: 2.33s
                      Time elapsed: 00:21:23
                               ETA: 01:33:28

################################################################################
                     [1m Learning iteration 559/3000 [0m                      

                       Computation: 40911 steps/s (collection: 2.268s, learning 0.134s)
             Mean action noise std: 2.46
          Mean value_function loss: 90.3808
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 71.6628
                       Mean reward: 236.47
               Mean episode length: 206.29
    Episode_Reward/reaching_object: 1.4933
    Episode_Reward/rotating_object: 45.0261
        Episode_Reward/action_rate: -0.0410
          Episode_Reward/joint_vel: -0.0426
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.2500
--------------------------------------------------------------------------------
                   Total timesteps: 55050240
                    Iteration time: 2.40s
                      Time elapsed: 00:21:26
                               ETA: 01:33:26

################################################################################
                     [1m Learning iteration 560/3000 [0m                      

                       Computation: 44619 steps/s (collection: 2.098s, learning 0.106s)
             Mean action noise std: 2.46
          Mean value_function loss: 91.0906
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 71.6920
                       Mean reward: 235.97
               Mean episode length: 214.89
    Episode_Reward/reaching_object: 1.4219
    Episode_Reward/rotating_object: 42.5745
        Episode_Reward/action_rate: -0.0395
          Episode_Reward/joint_vel: -0.0411
      Episode_Termination/time_out: 12.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.6250
--------------------------------------------------------------------------------
                   Total timesteps: 55148544
                    Iteration time: 2.20s
                      Time elapsed: 00:21:28
                               ETA: 01:33:23

################################################################################
                     [1m Learning iteration 561/3000 [0m                      

                       Computation: 44568 steps/s (collection: 2.101s, learning 0.105s)
             Mean action noise std: 2.46
          Mean value_function loss: 88.2854
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 71.7197
                       Mean reward: 242.42
               Mean episode length: 224.46
    Episode_Reward/reaching_object: 1.4678
    Episode_Reward/rotating_object: 43.4198
        Episode_Reward/action_rate: -0.0407
          Episode_Reward/joint_vel: -0.0416
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.8333
--------------------------------------------------------------------------------
                   Total timesteps: 55246848
                    Iteration time: 2.21s
                      Time elapsed: 00:21:30
                               ETA: 01:33:21

################################################################################
                     [1m Learning iteration 562/3000 [0m                      

                       Computation: 44663 steps/s (collection: 2.084s, learning 0.117s)
             Mean action noise std: 2.47
          Mean value_function loss: 90.2638
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 71.7500
                       Mean reward: 253.52
               Mean episode length: 219.01
    Episode_Reward/reaching_object: 1.4809
    Episode_Reward/rotating_object: 48.1814
        Episode_Reward/action_rate: -0.0413
          Episode_Reward/joint_vel: -0.0420
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 55345152
                    Iteration time: 2.20s
                      Time elapsed: 00:21:32
                               ETA: 01:33:18

################################################################################
                     [1m Learning iteration 563/3000 [0m                      

                       Computation: 44368 steps/s (collection: 2.078s, learning 0.137s)
             Mean action noise std: 2.47
          Mean value_function loss: 90.0038
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 71.7842
                       Mean reward: 238.61
               Mean episode length: 207.82
    Episode_Reward/reaching_object: 1.4421
    Episode_Reward/rotating_object: 46.4770
        Episode_Reward/action_rate: -0.0405
          Episode_Reward/joint_vel: -0.0412
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.3750
--------------------------------------------------------------------------------
                   Total timesteps: 55443456
                    Iteration time: 2.22s
                      Time elapsed: 00:21:35
                               ETA: 01:33:15

################################################################################
                     [1m Learning iteration 564/3000 [0m                      

                       Computation: 40356 steps/s (collection: 2.237s, learning 0.199s)
             Mean action noise std: 2.47
          Mean value_function loss: 84.0109
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 71.8066
                       Mean reward: 236.28
               Mean episode length: 216.41
    Episode_Reward/reaching_object: 1.4450
    Episode_Reward/rotating_object: 44.5492
        Episode_Reward/action_rate: -0.0406
          Episode_Reward/joint_vel: -0.0423
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.2917
--------------------------------------------------------------------------------
                   Total timesteps: 55541760
                    Iteration time: 2.44s
                      Time elapsed: 00:21:37
                               ETA: 01:33:13

################################################################################
                     [1m Learning iteration 565/3000 [0m                      

                       Computation: 44681 steps/s (collection: 2.085s, learning 0.115s)
             Mean action noise std: 2.47
          Mean value_function loss: 88.8562
               Mean surrogate loss: -0.0100
                 Mean entropy loss: 71.8385
                       Mean reward: 227.77
               Mean episode length: 209.16
    Episode_Reward/reaching_object: 1.4687
    Episode_Reward/rotating_object: 47.1704
        Episode_Reward/action_rate: -0.0411
          Episode_Reward/joint_vel: -0.0413
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.4167
--------------------------------------------------------------------------------
                   Total timesteps: 55640064
                    Iteration time: 2.20s
                      Time elapsed: 00:21:39
                               ETA: 01:33:11

################################################################################
                     [1m Learning iteration 566/3000 [0m                      

                       Computation: 45246 steps/s (collection: 2.057s, learning 0.116s)
             Mean action noise std: 2.48
          Mean value_function loss: 97.7958
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 71.8760
                       Mean reward: 206.05
               Mean episode length: 204.38
    Episode_Reward/reaching_object: 1.3860
    Episode_Reward/rotating_object: 42.4254
        Episode_Reward/action_rate: -0.0394
          Episode_Reward/joint_vel: -0.0405
      Episode_Termination/time_out: 13.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 5.5000
--------------------------------------------------------------------------------
                   Total timesteps: 55738368
                    Iteration time: 2.17s
                      Time elapsed: 00:21:41
                               ETA: 01:33:08

################################################################################
                     [1m Learning iteration 567/3000 [0m                      

                       Computation: 45242 steps/s (collection: 2.055s, learning 0.118s)
             Mean action noise std: 2.48
          Mean value_function loss: 90.1146
               Mean surrogate loss: -0.0097
                 Mean entropy loss: 71.9070
                       Mean reward: 245.43
               Mean episode length: 217.58
    Episode_Reward/reaching_object: 1.4660
    Episode_Reward/rotating_object: 47.1742
        Episode_Reward/action_rate: -0.0413
          Episode_Reward/joint_vel: -0.0414
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.5417
--------------------------------------------------------------------------------
                   Total timesteps: 55836672
                    Iteration time: 2.17s
                      Time elapsed: 00:21:43
                               ETA: 01:33:05

################################################################################
                     [1m Learning iteration 568/3000 [0m                      

                       Computation: 43963 steps/s (collection: 2.093s, learning 0.143s)
             Mean action noise std: 2.48
          Mean value_function loss: 91.6511
               Mean surrogate loss: -0.0100
                 Mean entropy loss: 71.9412
                       Mean reward: 239.04
               Mean episode length: 215.10
    Episode_Reward/reaching_object: 1.4559
    Episode_Reward/rotating_object: 46.3199
        Episode_Reward/action_rate: -0.0412
          Episode_Reward/joint_vel: -0.0425
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.8333
--------------------------------------------------------------------------------
                   Total timesteps: 55934976
                    Iteration time: 2.24s
                      Time elapsed: 00:21:46
                               ETA: 01:33:03

################################################################################
                     [1m Learning iteration 569/3000 [0m                      

                       Computation: 44166 steps/s (collection: 2.097s, learning 0.129s)
             Mean action noise std: 2.48
          Mean value_function loss: 91.9399
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 71.9750
                       Mean reward: 257.27
               Mean episode length: 215.07
    Episode_Reward/reaching_object: 1.4388
    Episode_Reward/rotating_object: 45.1711
        Episode_Reward/action_rate: -0.0410
          Episode_Reward/joint_vel: -0.0417
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.0833
--------------------------------------------------------------------------------
                   Total timesteps: 56033280
                    Iteration time: 2.23s
                      Time elapsed: 00:21:48
                               ETA: 01:33:00

################################################################################
                     [1m Learning iteration 570/3000 [0m                      

                       Computation: 45067 steps/s (collection: 2.068s, learning 0.113s)
             Mean action noise std: 2.49
          Mean value_function loss: 101.8341
               Mean surrogate loss: -0.0098
                 Mean entropy loss: 71.9988
                       Mean reward: 260.38
               Mean episode length: 218.17
    Episode_Reward/reaching_object: 1.4650
    Episode_Reward/rotating_object: 47.9346
        Episode_Reward/action_rate: -0.0417
          Episode_Reward/joint_vel: -0.0417
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.3333
--------------------------------------------------------------------------------
                   Total timesteps: 56131584
                    Iteration time: 2.18s
                      Time elapsed: 00:21:50
                               ETA: 01:32:57

################################################################################
                     [1m Learning iteration 571/3000 [0m                      

                       Computation: 45657 steps/s (collection: 2.055s, learning 0.099s)
             Mean action noise std: 2.49
          Mean value_function loss: 93.4787
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 72.0246
                       Mean reward: 237.36
               Mean episode length: 208.66
    Episode_Reward/reaching_object: 1.4058
    Episode_Reward/rotating_object: 45.5094
        Episode_Reward/action_rate: -0.0402
          Episode_Reward/joint_vel: -0.0405
      Episode_Termination/time_out: 12.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.2083
--------------------------------------------------------------------------------
                   Total timesteps: 56229888
                    Iteration time: 2.15s
                      Time elapsed: 00:21:52
                               ETA: 01:32:54

################################################################################
                     [1m Learning iteration 572/3000 [0m                      

                       Computation: 45124 steps/s (collection: 2.066s, learning 0.113s)
             Mean action noise std: 2.49
          Mean value_function loss: 92.1907
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 72.0525
                       Mean reward: 231.70
               Mean episode length: 205.10
    Episode_Reward/reaching_object: 1.4629
    Episode_Reward/rotating_object: 46.1717
        Episode_Reward/action_rate: -0.0417
          Episode_Reward/joint_vel: -0.0429
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.0833
--------------------------------------------------------------------------------
                   Total timesteps: 56328192
                    Iteration time: 2.18s
                      Time elapsed: 00:21:54
                               ETA: 01:32:51

################################################################################
                     [1m Learning iteration 573/3000 [0m                      

                       Computation: 42811 steps/s (collection: 2.144s, learning 0.153s)
             Mean action noise std: 2.49
          Mean value_function loss: 99.0698
               Mean surrogate loss: -0.0098
                 Mean entropy loss: 72.0741
                       Mean reward: 276.95
               Mean episode length: 226.76
    Episode_Reward/reaching_object: 1.4446
    Episode_Reward/rotating_object: 48.3616
        Episode_Reward/action_rate: -0.0416
          Episode_Reward/joint_vel: -0.0416
      Episode_Termination/time_out: 13.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.3333
--------------------------------------------------------------------------------
                   Total timesteps: 56426496
                    Iteration time: 2.30s
                      Time elapsed: 00:21:57
                               ETA: 01:32:49

################################################################################
                     [1m Learning iteration 574/3000 [0m                      

                       Computation: 44261 steps/s (collection: 2.085s, learning 0.136s)
             Mean action noise std: 2.49
          Mean value_function loss: 97.0907
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 72.0956
                       Mean reward: 243.59
               Mean episode length: 219.65
    Episode_Reward/reaching_object: 1.4682
    Episode_Reward/rotating_object: 47.4499
        Episode_Reward/action_rate: -0.0419
          Episode_Reward/joint_vel: -0.0419
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.7917
--------------------------------------------------------------------------------
                   Total timesteps: 56524800
                    Iteration time: 2.22s
                      Time elapsed: 00:21:59
                               ETA: 01:32:47

################################################################################
                     [1m Learning iteration 575/3000 [0m                      

                       Computation: 45306 steps/s (collection: 2.053s, learning 0.117s)
             Mean action noise std: 2.50
          Mean value_function loss: 94.7989
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 72.1210
                       Mean reward: 237.22
               Mean episode length: 216.02
    Episode_Reward/reaching_object: 1.4783
    Episode_Reward/rotating_object: 48.1652
        Episode_Reward/action_rate: -0.0423
          Episode_Reward/joint_vel: -0.0412
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.8750
--------------------------------------------------------------------------------
                   Total timesteps: 56623104
                    Iteration time: 2.17s
                      Time elapsed: 00:22:01
                               ETA: 01:32:44

################################################################################
                     [1m Learning iteration 576/3000 [0m                      

                       Computation: 44344 steps/s (collection: 2.097s, learning 0.120s)
             Mean action noise std: 2.50
          Mean value_function loss: 97.4324
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 72.1498
                       Mean reward: 211.27
               Mean episode length: 207.69
    Episode_Reward/reaching_object: 1.3914
    Episode_Reward/rotating_object: 46.1714
        Episode_Reward/action_rate: -0.0403
          Episode_Reward/joint_vel: -0.0399
      Episode_Termination/time_out: 13.5000
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 5.4583
--------------------------------------------------------------------------------
                   Total timesteps: 56721408
                    Iteration time: 2.22s
                      Time elapsed: 00:22:03
                               ETA: 01:32:41

################################################################################
                     [1m Learning iteration 577/3000 [0m                      

                       Computation: 43399 steps/s (collection: 2.129s, learning 0.136s)
             Mean action noise std: 2.50
          Mean value_function loss: 100.7123
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 72.1781
                       Mean reward: 283.46
               Mean episode length: 214.68
    Episode_Reward/reaching_object: 1.4501
    Episode_Reward/rotating_object: 53.1702
        Episode_Reward/action_rate: -0.0422
          Episode_Reward/joint_vel: -0.0412
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.3333
--------------------------------------------------------------------------------
                   Total timesteps: 56819712
                    Iteration time: 2.27s
                      Time elapsed: 00:22:06
                               ETA: 01:32:39

################################################################################
                     [1m Learning iteration 578/3000 [0m                      

                       Computation: 43076 steps/s (collection: 2.150s, learning 0.132s)
             Mean action noise std: 2.50
          Mean value_function loss: 100.7777
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 72.2049
                       Mean reward: 235.38
               Mean episode length: 204.66
    Episode_Reward/reaching_object: 1.4398
    Episode_Reward/rotating_object: 46.9647
        Episode_Reward/action_rate: -0.0416
          Episode_Reward/joint_vel: -0.0414
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.7500
--------------------------------------------------------------------------------
                   Total timesteps: 56918016
                    Iteration time: 2.28s
                      Time elapsed: 00:22:08
                               ETA: 01:32:36

################################################################################
                     [1m Learning iteration 579/3000 [0m                      

                       Computation: 45211 steps/s (collection: 2.064s, learning 0.111s)
             Mean action noise std: 2.51
          Mean value_function loss: 93.2009
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 72.2343
                       Mean reward: 274.10
               Mean episode length: 215.46
    Episode_Reward/reaching_object: 1.4504
    Episode_Reward/rotating_object: 52.3663
        Episode_Reward/action_rate: -0.0420
          Episode_Reward/joint_vel: -0.0406
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.2917
--------------------------------------------------------------------------------
                   Total timesteps: 57016320
                    Iteration time: 2.17s
                      Time elapsed: 00:22:10
                               ETA: 01:32:34

################################################################################
                     [1m Learning iteration 580/3000 [0m                      

                       Computation: 45550 steps/s (collection: 2.052s, learning 0.107s)
             Mean action noise std: 2.51
          Mean value_function loss: 91.0122
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 72.2663
                       Mean reward: 256.63
               Mean episode length: 222.49
    Episode_Reward/reaching_object: 1.4756
    Episode_Reward/rotating_object: 48.2377
        Episode_Reward/action_rate: -0.0426
          Episode_Reward/joint_vel: -0.0419
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.5833
--------------------------------------------------------------------------------
                   Total timesteps: 57114624
                    Iteration time: 2.16s
                      Time elapsed: 00:22:12
                               ETA: 01:32:31

################################################################################
                     [1m Learning iteration 581/3000 [0m                      

                       Computation: 41457 steps/s (collection: 2.171s, learning 0.201s)
             Mean action noise std: 2.51
          Mean value_function loss: 85.6496
               Mean surrogate loss: -0.0098
                 Mean entropy loss: 72.3050
                       Mean reward: 238.35
               Mean episode length: 199.48
    Episode_Reward/reaching_object: 1.3601
    Episode_Reward/rotating_object: 43.5998
        Episode_Reward/action_rate: -0.0398
          Episode_Reward/joint_vel: -0.0400
      Episode_Termination/time_out: 13.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 6.1667
--------------------------------------------------------------------------------
                   Total timesteps: 57212928
                    Iteration time: 2.37s
                      Time elapsed: 00:22:15
                               ETA: 01:32:29

################################################################################
                     [1m Learning iteration 582/3000 [0m                      

                       Computation: 42793 steps/s (collection: 2.123s, learning 0.175s)
             Mean action noise std: 2.51
          Mean value_function loss: 95.1806
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 72.3334
                       Mean reward: 253.70
               Mean episode length: 215.48
    Episode_Reward/reaching_object: 1.4155
    Episode_Reward/rotating_object: 46.6516
        Episode_Reward/action_rate: -0.0415
          Episode_Reward/joint_vel: -0.0413
      Episode_Termination/time_out: 13.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.7083
--------------------------------------------------------------------------------
                   Total timesteps: 57311232
                    Iteration time: 2.30s
                      Time elapsed: 00:22:17
                               ETA: 01:32:26

################################################################################
                     [1m Learning iteration 583/3000 [0m                      

                       Computation: 45077 steps/s (collection: 2.060s, learning 0.121s)
             Mean action noise std: 2.51
          Mean value_function loss: 87.3245
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 72.3492
                       Mean reward: 255.96
               Mean episode length: 208.36
    Episode_Reward/reaching_object: 1.3630
    Episode_Reward/rotating_object: 47.5675
        Episode_Reward/action_rate: -0.0407
          Episode_Reward/joint_vel: -0.0405
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 5.7083
--------------------------------------------------------------------------------
                   Total timesteps: 57409536
                    Iteration time: 2.18s
                      Time elapsed: 00:22:19
                               ETA: 01:32:24

################################################################################
                     [1m Learning iteration 584/3000 [0m                      

                       Computation: 44479 steps/s (collection: 2.094s, learning 0.117s)
             Mean action noise std: 2.52
          Mean value_function loss: 94.1526
               Mean surrogate loss: -0.0096
                 Mean entropy loss: 72.3700
                       Mean reward: 239.99
               Mean episode length: 208.49
    Episode_Reward/reaching_object: 1.3542
    Episode_Reward/rotating_object: 46.9956
        Episode_Reward/action_rate: -0.0402
          Episode_Reward/joint_vel: -0.0394
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 5.4583
--------------------------------------------------------------------------------
                   Total timesteps: 57507840
                    Iteration time: 2.21s
                      Time elapsed: 00:22:21
                               ETA: 01:32:21

################################################################################
                     [1m Learning iteration 585/3000 [0m                      

                       Computation: 40670 steps/s (collection: 2.171s, learning 0.246s)
             Mean action noise std: 2.52
          Mean value_function loss: 102.7152
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 72.4006
                       Mean reward: 270.48
               Mean episode length: 215.02
    Episode_Reward/reaching_object: 1.3927
    Episode_Reward/rotating_object: 51.9291
        Episode_Reward/action_rate: -0.0417
          Episode_Reward/joint_vel: -0.0401
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.1667
--------------------------------------------------------------------------------
                   Total timesteps: 57606144
                    Iteration time: 2.42s
                      Time elapsed: 00:22:24
                               ETA: 01:32:19

################################################################################
                     [1m Learning iteration 586/3000 [0m                      

                       Computation: 39350 steps/s (collection: 2.341s, learning 0.157s)
             Mean action noise std: 2.52
          Mean value_function loss: 99.2058
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 72.4297
                       Mean reward: 257.84
               Mean episode length: 208.99
    Episode_Reward/reaching_object: 1.3917
    Episode_Reward/rotating_object: 50.2931
        Episode_Reward/action_rate: -0.0419
          Episode_Reward/joint_vel: -0.0409
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.7917
--------------------------------------------------------------------------------
                   Total timesteps: 57704448
                    Iteration time: 2.50s
                      Time elapsed: 00:22:26
                               ETA: 01:32:18

################################################################################
                     [1m Learning iteration 587/3000 [0m                      

                       Computation: 44724 steps/s (collection: 2.066s, learning 0.132s)
             Mean action noise std: 2.52
          Mean value_function loss: 97.1496
               Mean surrogate loss: -0.0095
                 Mean entropy loss: 72.4597
                       Mean reward: 254.92
               Mean episode length: 215.78
    Episode_Reward/reaching_object: 1.4265
    Episode_Reward/rotating_object: 50.2179
        Episode_Reward/action_rate: -0.0426
          Episode_Reward/joint_vel: -0.0414
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.6667
--------------------------------------------------------------------------------
                   Total timesteps: 57802752
                    Iteration time: 2.20s
                      Time elapsed: 00:22:28
                               ETA: 01:32:15

################################################################################
                     [1m Learning iteration 588/3000 [0m                      

                       Computation: 44617 steps/s (collection: 2.089s, learning 0.114s)
             Mean action noise std: 2.53
          Mean value_function loss: 99.1460
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 72.4970
                       Mean reward: 184.15
               Mean episode length: 195.89
    Episode_Reward/reaching_object: 1.3930
    Episode_Reward/rotating_object: 47.7668
        Episode_Reward/action_rate: -0.0417
          Episode_Reward/joint_vel: -0.0410
      Episode_Termination/time_out: 13.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 5.0417
--------------------------------------------------------------------------------
                   Total timesteps: 57901056
                    Iteration time: 2.20s
                      Time elapsed: 00:22:31
                               ETA: 01:32:12

################################################################################
                     [1m Learning iteration 589/3000 [0m                      

                       Computation: 44384 steps/s (collection: 2.068s, learning 0.147s)
             Mean action noise std: 2.53
          Mean value_function loss: 99.0312
               Mean surrogate loss: -0.0095
                 Mean entropy loss: 72.5353
                       Mean reward: 241.60
               Mean episode length: 208.36
    Episode_Reward/reaching_object: 1.3924
    Episode_Reward/rotating_object: 48.2809
        Episode_Reward/action_rate: -0.0417
          Episode_Reward/joint_vel: -0.0418
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.5417
--------------------------------------------------------------------------------
                   Total timesteps: 57999360
                    Iteration time: 2.21s
                      Time elapsed: 00:22:33
                               ETA: 01:32:10

################################################################################
                     [1m Learning iteration 590/3000 [0m                      

                       Computation: 44192 steps/s (collection: 2.126s, learning 0.098s)
             Mean action noise std: 2.53
          Mean value_function loss: 91.4499
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 72.5693
                       Mean reward: 196.41
               Mean episode length: 197.05
    Episode_Reward/reaching_object: 1.3955
    Episode_Reward/rotating_object: 46.6701
        Episode_Reward/action_rate: -0.0420
          Episode_Reward/joint_vel: -0.0417
      Episode_Termination/time_out: 13.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 5.2500
--------------------------------------------------------------------------------
                   Total timesteps: 58097664
                    Iteration time: 2.22s
                      Time elapsed: 00:22:35
                               ETA: 01:32:07

################################################################################
                     [1m Learning iteration 591/3000 [0m                      

                       Computation: 42114 steps/s (collection: 2.211s, learning 0.123s)
             Mean action noise std: 2.54
          Mean value_function loss: 96.8788
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 72.5968
                       Mean reward: 230.49
               Mean episode length: 197.92
    Episode_Reward/reaching_object: 1.3640
    Episode_Reward/rotating_object: 49.0551
        Episode_Reward/action_rate: -0.0410
          Episode_Reward/joint_vel: -0.0403
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.6250
--------------------------------------------------------------------------------
                   Total timesteps: 58195968
                    Iteration time: 2.33s
                      Time elapsed: 00:22:37
                               ETA: 01:32:05

################################################################################
                     [1m Learning iteration 592/3000 [0m                      

                       Computation: 44539 steps/s (collection: 2.089s, learning 0.119s)
             Mean action noise std: 2.54
          Mean value_function loss: 92.7328
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 72.6157
                       Mean reward: 270.02
               Mean episode length: 206.15
    Episode_Reward/reaching_object: 1.3944
    Episode_Reward/rotating_object: 51.7064
        Episode_Reward/action_rate: -0.0421
          Episode_Reward/joint_vel: -0.0408
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.0417
--------------------------------------------------------------------------------
                   Total timesteps: 58294272
                    Iteration time: 2.21s
                      Time elapsed: 00:22:40
                               ETA: 01:32:03

################################################################################
                     [1m Learning iteration 593/3000 [0m                      

                       Computation: 43831 steps/s (collection: 2.119s, learning 0.124s)
             Mean action noise std: 2.54
          Mean value_function loss: 106.0196
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 72.6311
                       Mean reward: 227.44
               Mean episode length: 203.83
    Episode_Reward/reaching_object: 1.4118
    Episode_Reward/rotating_object: 49.0027
        Episode_Reward/action_rate: -0.0424
          Episode_Reward/joint_vel: -0.0416
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.7083
--------------------------------------------------------------------------------
                   Total timesteps: 58392576
                    Iteration time: 2.24s
                      Time elapsed: 00:22:42
                               ETA: 01:32:00

################################################################################
                     [1m Learning iteration 594/3000 [0m                      

                       Computation: 43811 steps/s (collection: 2.117s, learning 0.127s)
             Mean action noise std: 2.54
          Mean value_function loss: 97.5183
               Mean surrogate loss: -0.0098
                 Mean entropy loss: 72.6480
                       Mean reward: 261.96
               Mean episode length: 205.70
    Episode_Reward/reaching_object: 1.3654
    Episode_Reward/rotating_object: 48.4784
        Episode_Reward/action_rate: -0.0415
          Episode_Reward/joint_vel: -0.0409
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 6.0000
--------------------------------------------------------------------------------
                   Total timesteps: 58490880
                    Iteration time: 2.24s
                      Time elapsed: 00:22:44
                               ETA: 01:31:58

################################################################################
                     [1m Learning iteration 595/3000 [0m                      

                       Computation: 43706 steps/s (collection: 2.139s, learning 0.110s)
             Mean action noise std: 2.54
          Mean value_function loss: 104.3645
               Mean surrogate loss: -0.0095
                 Mean entropy loss: 72.6674
                       Mean reward: 303.32
               Mean episode length: 207.78
    Episode_Reward/reaching_object: 1.4027
    Episode_Reward/rotating_object: 51.0396
        Episode_Reward/action_rate: -0.0423
          Episode_Reward/joint_vel: -0.0404
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.5833
--------------------------------------------------------------------------------
                   Total timesteps: 58589184
                    Iteration time: 2.25s
                      Time elapsed: 00:22:46
                               ETA: 01:31:55

################################################################################
                     [1m Learning iteration 596/3000 [0m                      

                       Computation: 44888 steps/s (collection: 2.078s, learning 0.112s)
             Mean action noise std: 2.54
          Mean value_function loss: 97.9544
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 72.6925
                       Mean reward: 223.21
               Mean episode length: 193.83
    Episode_Reward/reaching_object: 1.3408
    Episode_Reward/rotating_object: 45.5164
        Episode_Reward/action_rate: -0.0407
          Episode_Reward/joint_vel: -0.0402
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 6.1250
--------------------------------------------------------------------------------
                   Total timesteps: 58687488
                    Iteration time: 2.19s
                      Time elapsed: 00:22:49
                               ETA: 01:31:52

################################################################################
                     [1m Learning iteration 597/3000 [0m                      

                       Computation: 44385 steps/s (collection: 2.089s, learning 0.126s)
             Mean action noise std: 2.55
          Mean value_function loss: 89.8099
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 72.7244
                       Mean reward: 249.79
               Mean episode length: 208.68
    Episode_Reward/reaching_object: 1.4035
    Episode_Reward/rotating_object: 50.4633
        Episode_Reward/action_rate: -0.0424
          Episode_Reward/joint_vel: -0.0412
      Episode_Termination/time_out: 13.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.9167
--------------------------------------------------------------------------------
                   Total timesteps: 58785792
                    Iteration time: 2.21s
                      Time elapsed: 00:22:51
                               ETA: 01:31:50

################################################################################
                     [1m Learning iteration 598/3000 [0m                      

                       Computation: 44430 steps/s (collection: 2.091s, learning 0.121s)
             Mean action noise std: 2.55
          Mean value_function loss: 95.4124
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 72.7601
                       Mean reward: 252.97
               Mean episode length: 198.63
    Episode_Reward/reaching_object: 1.3477
    Episode_Reward/rotating_object: 46.5574
        Episode_Reward/action_rate: -0.0412
          Episode_Reward/joint_vel: -0.0412
      Episode_Termination/time_out: 12.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.8750
--------------------------------------------------------------------------------
                   Total timesteps: 58884096
                    Iteration time: 2.21s
                      Time elapsed: 00:22:53
                               ETA: 01:31:47

################################################################################
                     [1m Learning iteration 599/3000 [0m                      

                       Computation: 43010 steps/s (collection: 2.148s, learning 0.137s)
             Mean action noise std: 2.55
          Mean value_function loss: 92.2697
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 72.7963
                       Mean reward: 317.38
               Mean episode length: 216.84
    Episode_Reward/reaching_object: 1.4075
    Episode_Reward/rotating_object: 53.9598
        Episode_Reward/action_rate: -0.0430
          Episode_Reward/joint_vel: -0.0407
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.8750
--------------------------------------------------------------------------------
                   Total timesteps: 58982400
                    Iteration time: 2.29s
                      Time elapsed: 00:22:55
                               ETA: 01:31:45

################################################################################
                     [1m Learning iteration 600/3000 [0m                      

                       Computation: 42129 steps/s (collection: 2.234s, learning 0.099s)
             Mean action noise std: 2.56
          Mean value_function loss: 87.4906
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 72.8277
                       Mean reward: 279.23
               Mean episode length: 209.32
    Episode_Reward/reaching_object: 1.4127
    Episode_Reward/rotating_object: 51.0506
        Episode_Reward/action_rate: -0.0431
          Episode_Reward/joint_vel: -0.0408
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.8750
--------------------------------------------------------------------------------
                   Total timesteps: 59080704
                    Iteration time: 2.33s
                      Time elapsed: 00:22:58
                               ETA: 01:31:43

################################################################################
                     [1m Learning iteration 601/3000 [0m                      

                       Computation: 43049 steps/s (collection: 2.062s, learning 0.222s)
             Mean action noise std: 2.56
          Mean value_function loss: 100.3321
               Mean surrogate loss: -0.0099
                 Mean entropy loss: 72.8664
                       Mean reward: 302.43
               Mean episode length: 214.32
    Episode_Reward/reaching_object: 1.4130
    Episode_Reward/rotating_object: 53.5570
        Episode_Reward/action_rate: -0.0435
          Episode_Reward/joint_vel: -0.0416
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.8750
--------------------------------------------------------------------------------
                   Total timesteps: 59179008
                    Iteration time: 2.28s
                      Time elapsed: 00:23:00
                               ETA: 01:31:40

################################################################################
                     [1m Learning iteration 602/3000 [0m                      

                       Computation: 45301 steps/s (collection: 2.042s, learning 0.128s)
             Mean action noise std: 2.56
          Mean value_function loss: 91.5187
               Mean surrogate loss: -0.0102
                 Mean entropy loss: 72.8980
                       Mean reward: 273.56
               Mean episode length: 204.23
    Episode_Reward/reaching_object: 1.3567
    Episode_Reward/rotating_object: 52.7273
        Episode_Reward/action_rate: -0.0422
          Episode_Reward/joint_vel: -0.0405
      Episode_Termination/time_out: 13.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.3333
--------------------------------------------------------------------------------
                   Total timesteps: 59277312
                    Iteration time: 2.17s
                      Time elapsed: 00:23:02
                               ETA: 01:31:38

################################################################################
                     [1m Learning iteration 603/3000 [0m                      

                       Computation: 45795 steps/s (collection: 2.019s, learning 0.128s)
             Mean action noise std: 2.57
          Mean value_function loss: 92.2695
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 72.9336
                       Mean reward: 263.55
               Mean episode length: 203.49
    Episode_Reward/reaching_object: 1.3222
    Episode_Reward/rotating_object: 48.4240
        Episode_Reward/action_rate: -0.0410
          Episode_Reward/joint_vel: -0.0391
      Episode_Termination/time_out: 13.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 6.3333
--------------------------------------------------------------------------------
                   Total timesteps: 59375616
                    Iteration time: 2.15s
                      Time elapsed: 00:23:04
                               ETA: 01:31:35

################################################################################
                     [1m Learning iteration 604/3000 [0m                      

                       Computation: 45627 steps/s (collection: 2.026s, learning 0.129s)
             Mean action noise std: 2.57
          Mean value_function loss: 94.4746
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 72.9634
                       Mean reward: 275.38
               Mean episode length: 206.42
    Episode_Reward/reaching_object: 1.3512
    Episode_Reward/rotating_object: 54.7022
        Episode_Reward/action_rate: -0.0425
          Episode_Reward/joint_vel: -0.0398
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 5.3333
--------------------------------------------------------------------------------
                   Total timesteps: 59473920
                    Iteration time: 2.15s
                      Time elapsed: 00:23:06
                               ETA: 01:31:32

################################################################################
                     [1m Learning iteration 605/3000 [0m                      

                       Computation: 46528 steps/s (collection: 2.012s, learning 0.101s)
             Mean action noise std: 2.57
          Mean value_function loss: 88.3455
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 72.9838
                       Mean reward: 295.64
               Mean episode length: 215.86
    Episode_Reward/reaching_object: 1.3655
    Episode_Reward/rotating_object: 52.0998
        Episode_Reward/action_rate: -0.0426
          Episode_Reward/joint_vel: -0.0410
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 5.9583
--------------------------------------------------------------------------------
                   Total timesteps: 59572224
                    Iteration time: 2.11s
                      Time elapsed: 00:23:08
                               ETA: 01:31:29

################################################################################
                     [1m Learning iteration 606/3000 [0m                      

                       Computation: 44454 steps/s (collection: 2.099s, learning 0.112s)
             Mean action noise std: 2.57
          Mean value_function loss: 97.8488
               Mean surrogate loss: -0.0098
                 Mean entropy loss: 73.0027
                       Mean reward: 314.59
               Mean episode length: 220.89
    Episode_Reward/reaching_object: 1.3789
    Episode_Reward/rotating_object: 54.6562
        Episode_Reward/action_rate: -0.0430
          Episode_Reward/joint_vel: -0.0410
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 5.7917
--------------------------------------------------------------------------------
                   Total timesteps: 59670528
                    Iteration time: 2.21s
                      Time elapsed: 00:23:11
                               ETA: 01:31:26

################################################################################
                     [1m Learning iteration 607/3000 [0m                      

                       Computation: 45943 steps/s (collection: 2.036s, learning 0.104s)
             Mean action noise std: 2.57
          Mean value_function loss: 93.8245
               Mean surrogate loss: -0.0101
                 Mean entropy loss: 73.0281
                       Mean reward: 290.26
               Mean episode length: 207.13
    Episode_Reward/reaching_object: 1.3316
    Episode_Reward/rotating_object: 52.6860
        Episode_Reward/action_rate: -0.0421
          Episode_Reward/joint_vel: -0.0402
      Episode_Termination/time_out: 13.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.9583
--------------------------------------------------------------------------------
                   Total timesteps: 59768832
                    Iteration time: 2.14s
                      Time elapsed: 00:23:13
                               ETA: 01:31:23

################################################################################
                     [1m Learning iteration 608/3000 [0m                      

                       Computation: 44493 steps/s (collection: 2.107s, learning 0.102s)
             Mean action noise std: 2.57
          Mean value_function loss: 95.9389
               Mean surrogate loss: -0.0100
                 Mean entropy loss: 73.0480
                       Mean reward: 261.18
               Mean episode length: 206.01
    Episode_Reward/reaching_object: 1.3171
    Episode_Reward/rotating_object: 49.2212
        Episode_Reward/action_rate: -0.0414
          Episode_Reward/joint_vel: -0.0412
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 6.6250
--------------------------------------------------------------------------------
                   Total timesteps: 59867136
                    Iteration time: 2.21s
                      Time elapsed: 00:23:15
                               ETA: 01:31:21

################################################################################
                     [1m Learning iteration 609/3000 [0m                      

                       Computation: 46490 steps/s (collection: 2.012s, learning 0.103s)
             Mean action noise std: 2.58
          Mean value_function loss: 94.6662
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 73.0755
                       Mean reward: 262.82
               Mean episode length: 205.28
    Episode_Reward/reaching_object: 1.3366
    Episode_Reward/rotating_object: 51.3185
        Episode_Reward/action_rate: -0.0421
          Episode_Reward/joint_vel: -0.0417
      Episode_Termination/time_out: 12.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.6250
--------------------------------------------------------------------------------
                   Total timesteps: 59965440
                    Iteration time: 2.11s
                      Time elapsed: 00:23:17
                               ETA: 01:31:18

################################################################################
                     [1m Learning iteration 610/3000 [0m                      

                       Computation: 45476 steps/s (collection: 2.038s, learning 0.124s)
             Mean action noise std: 2.58
          Mean value_function loss: 92.2584
               Mean surrogate loss: -0.0095
                 Mean entropy loss: 73.1032
                       Mean reward: 286.78
               Mean episode length: 210.41
    Episode_Reward/reaching_object: 1.3782
    Episode_Reward/rotating_object: 55.6954
        Episode_Reward/action_rate: -0.0438
          Episode_Reward/joint_vel: -0.0417
      Episode_Termination/time_out: 13.2083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.4167
--------------------------------------------------------------------------------
                   Total timesteps: 60063744
                    Iteration time: 2.16s
                      Time elapsed: 00:23:19
                               ETA: 01:31:15

################################################################################
                     [1m Learning iteration 611/3000 [0m                      

                       Computation: 45735 steps/s (collection: 2.027s, learning 0.123s)
             Mean action noise std: 2.58
          Mean value_function loss: 97.6534
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 73.1240
                       Mean reward: 291.88
               Mean episode length: 215.71
    Episode_Reward/reaching_object: 1.3711
    Episode_Reward/rotating_object: 54.1098
        Episode_Reward/action_rate: -0.0432
          Episode_Reward/joint_vel: -0.0411
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.3333
--------------------------------------------------------------------------------
                   Total timesteps: 60162048
                    Iteration time: 2.15s
                      Time elapsed: 00:23:21
                               ETA: 01:31:12

################################################################################
                     [1m Learning iteration 612/3000 [0m                      

                       Computation: 45025 steps/s (collection: 2.059s, learning 0.125s)
             Mean action noise std: 2.58
          Mean value_function loss: 97.1590
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 73.1503
                       Mean reward: 270.18
               Mean episode length: 196.41
    Episode_Reward/reaching_object: 1.3760
    Episode_Reward/rotating_object: 53.1479
        Episode_Reward/action_rate: -0.0435
          Episode_Reward/joint_vel: -0.0412
      Episode_Termination/time_out: 13.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.0000
--------------------------------------------------------------------------------
                   Total timesteps: 60260352
                    Iteration time: 2.18s
                      Time elapsed: 00:23:24
                               ETA: 01:31:09

################################################################################
                     [1m Learning iteration 613/3000 [0m                      

                       Computation: 44561 steps/s (collection: 2.104s, learning 0.102s)
             Mean action noise std: 2.59
          Mean value_function loss: 101.0040
               Mean surrogate loss: -0.0095
                 Mean entropy loss: 73.1783
                       Mean reward: 259.54
               Mean episode length: 214.77
    Episode_Reward/reaching_object: 1.4072
    Episode_Reward/rotating_object: 54.1159
        Episode_Reward/action_rate: -0.0444
          Episode_Reward/joint_vel: -0.0424
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.0833
--------------------------------------------------------------------------------
                   Total timesteps: 60358656
                    Iteration time: 2.21s
                      Time elapsed: 00:23:26
                               ETA: 01:31:07

################################################################################
                     [1m Learning iteration 614/3000 [0m                      

                       Computation: 45606 steps/s (collection: 2.038s, learning 0.118s)
             Mean action noise std: 2.59
          Mean value_function loss: 101.7954
               Mean surrogate loss: -0.0106
                 Mean entropy loss: 73.2043
                       Mean reward: 265.89
               Mean episode length: 203.49
    Episode_Reward/reaching_object: 1.3851
    Episode_Reward/rotating_object: 53.9870
        Episode_Reward/action_rate: -0.0439
          Episode_Reward/joint_vel: -0.0422
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.4167
--------------------------------------------------------------------------------
                   Total timesteps: 60456960
                    Iteration time: 2.16s
                      Time elapsed: 00:23:28
                               ETA: 01:31:04

################################################################################
                     [1m Learning iteration 615/3000 [0m                      

                       Computation: 46252 steps/s (collection: 2.019s, learning 0.107s)
             Mean action noise std: 2.59
          Mean value_function loss: 90.5991
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 73.2326
                       Mean reward: 287.18
               Mean episode length: 212.09
    Episode_Reward/reaching_object: 1.3666
    Episode_Reward/rotating_object: 54.4231
        Episode_Reward/action_rate: -0.0436
          Episode_Reward/joint_vel: -0.0428
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 6.2083
--------------------------------------------------------------------------------
                   Total timesteps: 60555264
                    Iteration time: 2.13s
                      Time elapsed: 00:23:30
                               ETA: 01:31:01

################################################################################
                     [1m Learning iteration 616/3000 [0m                      

                       Computation: 45478 steps/s (collection: 2.041s, learning 0.121s)
             Mean action noise std: 2.59
          Mean value_function loss: 104.7809
               Mean surrogate loss: -0.0104
                 Mean entropy loss: 73.2536
                       Mean reward: 284.17
               Mean episode length: 207.59
    Episode_Reward/reaching_object: 1.3825
    Episode_Reward/rotating_object: 56.6651
        Episode_Reward/action_rate: -0.0442
          Episode_Reward/joint_vel: -0.0421
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.2917
--------------------------------------------------------------------------------
                   Total timesteps: 60653568
                    Iteration time: 2.16s
                      Time elapsed: 00:23:32
                               ETA: 01:30:58

################################################################################
                     [1m Learning iteration 617/3000 [0m                      

                       Computation: 45552 steps/s (collection: 2.049s, learning 0.110s)
             Mean action noise std: 2.60
          Mean value_function loss: 99.6938
               Mean surrogate loss: -0.0099
                 Mean entropy loss: 73.2745
                       Mean reward: 232.18
               Mean episode length: 193.69
    Episode_Reward/reaching_object: 1.3560
    Episode_Reward/rotating_object: 52.7399
        Episode_Reward/action_rate: -0.0433
          Episode_Reward/joint_vel: -0.0413
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.7083
--------------------------------------------------------------------------------
                   Total timesteps: 60751872
                    Iteration time: 2.16s
                      Time elapsed: 00:23:34
                               ETA: 01:30:55

################################################################################
                     [1m Learning iteration 618/3000 [0m                      

                       Computation: 45631 steps/s (collection: 2.050s, learning 0.105s)
             Mean action noise std: 2.60
          Mean value_function loss: 103.6540
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 73.3035
                       Mean reward: 245.66
               Mean episode length: 189.74
    Episode_Reward/reaching_object: 1.3616
    Episode_Reward/rotating_object: 56.5173
        Episode_Reward/action_rate: -0.0438
          Episode_Reward/joint_vel: -0.0412
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.9167
--------------------------------------------------------------------------------
                   Total timesteps: 60850176
                    Iteration time: 2.15s
                      Time elapsed: 00:23:37
                               ETA: 01:30:53

################################################################################
                     [1m Learning iteration 619/3000 [0m                      

                       Computation: 46135 steps/s (collection: 2.008s, learning 0.123s)
             Mean action noise std: 2.60
          Mean value_function loss: 96.9808
               Mean surrogate loss: -0.0099
                 Mean entropy loss: 73.3324
                       Mean reward: 287.98
               Mean episode length: 210.09
    Episode_Reward/reaching_object: 1.3749
    Episode_Reward/rotating_object: 56.0274
        Episode_Reward/action_rate: -0.0444
          Episode_Reward/joint_vel: -0.0413
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 5.4167
--------------------------------------------------------------------------------
                   Total timesteps: 60948480
                    Iteration time: 2.13s
                      Time elapsed: 00:23:39
                               ETA: 01:30:50

################################################################################
                     [1m Learning iteration 620/3000 [0m                      

                       Computation: 46069 steps/s (collection: 2.009s, learning 0.125s)
             Mean action noise std: 2.60
          Mean value_function loss: 102.2645
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 73.3603
                       Mean reward: 261.95
               Mean episode length: 199.29
    Episode_Reward/reaching_object: 1.3274
    Episode_Reward/rotating_object: 52.5342
        Episode_Reward/action_rate: -0.0430
          Episode_Reward/joint_vel: -0.0414
      Episode_Termination/time_out: 13.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 6.2500
--------------------------------------------------------------------------------
                   Total timesteps: 61046784
                    Iteration time: 2.13s
                      Time elapsed: 00:23:41
                               ETA: 01:30:47

################################################################################
                     [1m Learning iteration 621/3000 [0m                      

                       Computation: 45327 steps/s (collection: 2.034s, learning 0.135s)
             Mean action noise std: 2.60
          Mean value_function loss: 104.2789
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 73.3773
                       Mean reward: 296.88
               Mean episode length: 214.24
    Episode_Reward/reaching_object: 1.3798
    Episode_Reward/rotating_object: 57.7377
        Episode_Reward/action_rate: -0.0446
          Episode_Reward/joint_vel: -0.0414
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.2083
--------------------------------------------------------------------------------
                   Total timesteps: 61145088
                    Iteration time: 2.17s
                      Time elapsed: 00:23:43
                               ETA: 01:30:44

################################################################################
                     [1m Learning iteration 622/3000 [0m                      

                       Computation: 44984 steps/s (collection: 2.050s, learning 0.135s)
             Mean action noise std: 2.61
          Mean value_function loss: 102.7149
               Mean surrogate loss: -0.0098
                 Mean entropy loss: 73.4071
                       Mean reward: 265.01
               Mean episode length: 206.51
    Episode_Reward/reaching_object: 1.3659
    Episode_Reward/rotating_object: 53.8293
        Episode_Reward/action_rate: -0.0438
          Episode_Reward/joint_vel: -0.0428
      Episode_Termination/time_out: 13.2917
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 5.3333
--------------------------------------------------------------------------------
                   Total timesteps: 61243392
                    Iteration time: 2.19s
                      Time elapsed: 00:23:45
                               ETA: 01:30:41

################################################################################
                     [1m Learning iteration 623/3000 [0m                      

                       Computation: 45668 steps/s (collection: 2.023s, learning 0.130s)
             Mean action noise std: 2.61
          Mean value_function loss: 100.7060
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 73.4398
                       Mean reward: 291.52
               Mean episode length: 215.13
    Episode_Reward/reaching_object: 1.3942
    Episode_Reward/rotating_object: 53.8424
        Episode_Reward/action_rate: -0.0448
          Episode_Reward/joint_vel: -0.0429
      Episode_Termination/time_out: 13.4167
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 5.0000
--------------------------------------------------------------------------------
                   Total timesteps: 61341696
                    Iteration time: 2.15s
                      Time elapsed: 00:23:47
                               ETA: 01:30:39

################################################################################
                     [1m Learning iteration 624/3000 [0m                      

                       Computation: 45799 steps/s (collection: 2.017s, learning 0.130s)
             Mean action noise std: 2.61
          Mean value_function loss: 109.5701
               Mean surrogate loss: -0.0096
                 Mean entropy loss: 73.4722
                       Mean reward: 307.16
               Mean episode length: 218.25
    Episode_Reward/reaching_object: 1.4044
    Episode_Reward/rotating_object: 61.2598
        Episode_Reward/action_rate: -0.0455
          Episode_Reward/joint_vel: -0.0426
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.7917
--------------------------------------------------------------------------------
                   Total timesteps: 61440000
                    Iteration time: 2.15s
                      Time elapsed: 00:23:49
                               ETA: 01:30:36

################################################################################
                     [1m Learning iteration 625/3000 [0m                      

                       Computation: 45740 steps/s (collection: 2.037s, learning 0.113s)
             Mean action noise std: 2.62
          Mean value_function loss: 101.0243
               Mean surrogate loss: -0.0101
                 Mean entropy loss: 73.5054
                       Mean reward: 289.86
               Mean episode length: 207.57
    Episode_Reward/reaching_object: 1.3015
    Episode_Reward/rotating_object: 53.1453
        Episode_Reward/action_rate: -0.0429
          Episode_Reward/joint_vel: -0.0416
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 6.5833
--------------------------------------------------------------------------------
                   Total timesteps: 61538304
                    Iteration time: 2.15s
                      Time elapsed: 00:23:52
                               ETA: 01:30:33

################################################################################
                     [1m Learning iteration 626/3000 [0m                      

                       Computation: 45900 steps/s (collection: 2.026s, learning 0.115s)
             Mean action noise std: 2.62
          Mean value_function loss: 99.7563
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 73.5367
                       Mean reward: 304.78
               Mean episode length: 208.98
    Episode_Reward/reaching_object: 1.3818
    Episode_Reward/rotating_object: 60.4217
        Episode_Reward/action_rate: -0.0451
          Episode_Reward/joint_vel: -0.0412
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.2083
--------------------------------------------------------------------------------
                   Total timesteps: 61636608
                    Iteration time: 2.14s
                      Time elapsed: 00:23:54
                               ETA: 01:30:30

################################################################################
                     [1m Learning iteration 627/3000 [0m                      

                       Computation: 45985 steps/s (collection: 2.028s, learning 0.110s)
             Mean action noise std: 2.62
          Mean value_function loss: 101.4096
               Mean surrogate loss: -0.0095
                 Mean entropy loss: 73.5673
                       Mean reward: 320.29
               Mean episode length: 218.20
    Episode_Reward/reaching_object: 1.3917
    Episode_Reward/rotating_object: 58.3602
        Episode_Reward/action_rate: -0.0454
          Episode_Reward/joint_vel: -0.0425
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 5.5833
--------------------------------------------------------------------------------
                   Total timesteps: 61734912
                    Iteration time: 2.14s
                      Time elapsed: 00:23:56
                               ETA: 01:30:27

################################################################################
                     [1m Learning iteration 628/3000 [0m                      

                       Computation: 45696 steps/s (collection: 2.023s, learning 0.128s)
             Mean action noise std: 2.62
          Mean value_function loss: 107.4032
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 73.6027
                       Mean reward: 250.92
               Mean episode length: 194.36
    Episode_Reward/reaching_object: 1.3312
    Episode_Reward/rotating_object: 54.4054
        Episode_Reward/action_rate: -0.0437
          Episode_Reward/joint_vel: -0.0416
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 5.7917
--------------------------------------------------------------------------------
                   Total timesteps: 61833216
                    Iteration time: 2.15s
                      Time elapsed: 00:23:58
                               ETA: 01:30:24

################################################################################
                     [1m Learning iteration 629/3000 [0m                      

                       Computation: 45814 steps/s (collection: 2.012s, learning 0.134s)
             Mean action noise std: 2.63
          Mean value_function loss: 97.2321
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 73.6338
                       Mean reward: 267.33
               Mean episode length: 191.45
    Episode_Reward/reaching_object: 1.3290
    Episode_Reward/rotating_object: 59.5876
        Episode_Reward/action_rate: -0.0439
          Episode_Reward/joint_vel: -0.0393
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.9583
--------------------------------------------------------------------------------
                   Total timesteps: 61931520
                    Iteration time: 2.15s
                      Time elapsed: 00:24:00
                               ETA: 01:30:22

################################################################################
                     [1m Learning iteration 630/3000 [0m                      

                       Computation: 45927 steps/s (collection: 2.012s, learning 0.128s)
             Mean action noise std: 2.63
          Mean value_function loss: 103.7636
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 73.6613
                       Mean reward: 260.89
               Mean episode length: 206.49
    Episode_Reward/reaching_object: 1.3668
    Episode_Reward/rotating_object: 55.5995
        Episode_Reward/action_rate: -0.0452
          Episode_Reward/joint_vel: -0.0425
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.3333
--------------------------------------------------------------------------------
                   Total timesteps: 62029824
                    Iteration time: 2.14s
                      Time elapsed: 00:24:02
                               ETA: 01:30:19

################################################################################
                     [1m Learning iteration 631/3000 [0m                      

                       Computation: 46111 steps/s (collection: 2.017s, learning 0.115s)
             Mean action noise std: 2.63
          Mean value_function loss: 108.0701
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 73.6805
                       Mean reward: 277.22
               Mean episode length: 192.55
    Episode_Reward/reaching_object: 1.3477
    Episode_Reward/rotating_object: 59.2005
        Episode_Reward/action_rate: -0.0452
          Episode_Reward/joint_vel: -0.0425
      Episode_Termination/time_out: 13.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.1250
--------------------------------------------------------------------------------
                   Total timesteps: 62128128
                    Iteration time: 2.13s
                      Time elapsed: 00:24:04
                               ETA: 01:30:16

################################################################################
                     [1m Learning iteration 632/3000 [0m                      

                       Computation: 45699 steps/s (collection: 2.026s, learning 0.125s)
             Mean action noise std: 2.63
          Mean value_function loss: 96.8416
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 73.7038
                       Mean reward: 286.27
               Mean episode length: 208.88
    Episode_Reward/reaching_object: 1.3207
    Episode_Reward/rotating_object: 58.2146
        Episode_Reward/action_rate: -0.0445
          Episode_Reward/joint_vel: -0.0415
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.6250
--------------------------------------------------------------------------------
                   Total timesteps: 62226432
                    Iteration time: 2.15s
                      Time elapsed: 00:24:07
                               ETA: 01:30:13

################################################################################
                     [1m Learning iteration 633/3000 [0m                      

                       Computation: 45822 steps/s (collection: 2.024s, learning 0.121s)
             Mean action noise std: 2.64
          Mean value_function loss: 103.3216
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 73.7264
                       Mean reward: 303.73
               Mean episode length: 205.82
    Episode_Reward/reaching_object: 1.3351
    Episode_Reward/rotating_object: 60.4850
        Episode_Reward/action_rate: -0.0452
          Episode_Reward/joint_vel: -0.0421
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 5.0833
--------------------------------------------------------------------------------
                   Total timesteps: 62324736
                    Iteration time: 2.15s
                      Time elapsed: 00:24:09
                               ETA: 01:30:10

################################################################################
                     [1m Learning iteration 634/3000 [0m                      

                       Computation: 46049 steps/s (collection: 2.007s, learning 0.128s)
             Mean action noise std: 2.64
          Mean value_function loss: 100.8092
               Mean surrogate loss: -0.0100
                 Mean entropy loss: 73.7537
                       Mean reward: 286.46
               Mean episode length: 205.83
    Episode_Reward/reaching_object: 1.3614
    Episode_Reward/rotating_object: 57.2517
        Episode_Reward/action_rate: -0.0460
          Episode_Reward/joint_vel: -0.0430
      Episode_Termination/time_out: 13.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.0833
--------------------------------------------------------------------------------
                   Total timesteps: 62423040
                    Iteration time: 2.13s
                      Time elapsed: 00:24:11
                               ETA: 01:30:07

################################################################################
                     [1m Learning iteration 635/3000 [0m                      

                       Computation: 45918 steps/s (collection: 2.015s, learning 0.126s)
             Mean action noise std: 2.64
          Mean value_function loss: 100.3133
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 73.7846
                       Mean reward: 299.09
               Mean episode length: 207.95
    Episode_Reward/reaching_object: 1.3831
    Episode_Reward/rotating_object: 60.1150
        Episode_Reward/action_rate: -0.0464
          Episode_Reward/joint_vel: -0.0429
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 4.9583
--------------------------------------------------------------------------------
                   Total timesteps: 62521344
                    Iteration time: 2.14s
                      Time elapsed: 00:24:13
                               ETA: 01:30:05

################################################################################
                     [1m Learning iteration 636/3000 [0m                      

                       Computation: 45063 steps/s (collection: 2.052s, learning 0.130s)
             Mean action noise std: 2.64
          Mean value_function loss: 100.7497
               Mean surrogate loss: -0.0100
                 Mean entropy loss: 73.8161
                       Mean reward: 247.28
               Mean episode length: 199.29
    Episode_Reward/reaching_object: 1.4042
    Episode_Reward/rotating_object: 58.2896
        Episode_Reward/action_rate: -0.0470
          Episode_Reward/joint_vel: -0.0436
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.6667
--------------------------------------------------------------------------------
                   Total timesteps: 62619648
                    Iteration time: 2.18s
                      Time elapsed: 00:24:15
                               ETA: 01:30:02

################################################################################
                     [1m Learning iteration 637/3000 [0m                      

                       Computation: 46349 steps/s (collection: 2.003s, learning 0.118s)
             Mean action noise std: 2.65
          Mean value_function loss: 105.9189
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 73.8423
                       Mean reward: 291.24
               Mean episode length: 216.89
    Episode_Reward/reaching_object: 1.3346
    Episode_Reward/rotating_object: 58.6519
        Episode_Reward/action_rate: -0.0452
          Episode_Reward/joint_vel: -0.0418
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 6.1667
--------------------------------------------------------------------------------
                   Total timesteps: 62717952
                    Iteration time: 2.12s
                      Time elapsed: 00:24:17
                               ETA: 01:29:59

################################################################################
                     [1m Learning iteration 638/3000 [0m                      

                       Computation: 45912 steps/s (collection: 2.022s, learning 0.119s)
             Mean action noise std: 2.65
          Mean value_function loss: 107.5227
               Mean surrogate loss: -0.0100
                 Mean entropy loss: 73.8767
                       Mean reward: 298.93
               Mean episode length: 214.55
    Episode_Reward/reaching_object: 1.3787
    Episode_Reward/rotating_object: 58.8656
        Episode_Reward/action_rate: -0.0465
          Episode_Reward/joint_vel: -0.0435
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.7083
--------------------------------------------------------------------------------
                   Total timesteps: 62816256
                    Iteration time: 2.14s
                      Time elapsed: 00:24:20
                               ETA: 01:29:56

################################################################################
                     [1m Learning iteration 639/3000 [0m                      

                       Computation: 46491 steps/s (collection: 1.997s, learning 0.118s)
             Mean action noise std: 2.65
          Mean value_function loss: 102.2768
               Mean surrogate loss: -0.0099
                 Mean entropy loss: 73.9059
                       Mean reward: 290.77
               Mean episode length: 209.32
    Episode_Reward/reaching_object: 1.3812
    Episode_Reward/rotating_object: 57.3650
        Episode_Reward/action_rate: -0.0463
          Episode_Reward/joint_vel: -0.0425
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.2083
--------------------------------------------------------------------------------
                   Total timesteps: 62914560
                    Iteration time: 2.11s
                      Time elapsed: 00:24:22
                               ETA: 01:29:53

################################################################################
                     [1m Learning iteration 640/3000 [0m                      

                       Computation: 46004 steps/s (collection: 2.016s, learning 0.121s)
             Mean action noise std: 2.65
          Mean value_function loss: 110.0731
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 73.9316
                       Mean reward: 330.32
               Mean episode length: 208.71
    Episode_Reward/reaching_object: 1.3242
    Episode_Reward/rotating_object: 61.7411
        Episode_Reward/action_rate: -0.0452
          Episode_Reward/joint_vel: -0.0405
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 5.4583
--------------------------------------------------------------------------------
                   Total timesteps: 63012864
                    Iteration time: 2.14s
                      Time elapsed: 00:24:24
                               ETA: 01:29:51

################################################################################
                     [1m Learning iteration 641/3000 [0m                      

                       Computation: 44879 steps/s (collection: 2.075s, learning 0.115s)
             Mean action noise std: 2.66
          Mean value_function loss: 102.6692
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 73.9562
                       Mean reward: 316.88
               Mean episode length: 214.71
    Episode_Reward/reaching_object: 1.3445
    Episode_Reward/rotating_object: 58.9053
        Episode_Reward/action_rate: -0.0457
          Episode_Reward/joint_vel: -0.0412
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.5833
--------------------------------------------------------------------------------
                   Total timesteps: 63111168
                    Iteration time: 2.19s
                      Time elapsed: 00:24:26
                               ETA: 01:29:48

################################################################################
                     [1m Learning iteration 642/3000 [0m                      

                       Computation: 46293 steps/s (collection: 2.009s, learning 0.115s)
             Mean action noise std: 2.66
          Mean value_function loss: 104.2462
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 73.9781
                       Mean reward: 297.29
               Mean episode length: 194.16
    Episode_Reward/reaching_object: 1.3387
    Episode_Reward/rotating_object: 60.1116
        Episode_Reward/action_rate: -0.0457
          Episode_Reward/joint_vel: -0.0414
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 5.3333
--------------------------------------------------------------------------------
                   Total timesteps: 63209472
                    Iteration time: 2.12s
                      Time elapsed: 00:24:28
                               ETA: 01:29:45

################################################################################
                     [1m Learning iteration 643/3000 [0m                      

                       Computation: 45724 steps/s (collection: 2.009s, learning 0.141s)
             Mean action noise std: 2.66
          Mean value_function loss: 109.4389
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 73.9979
                       Mean reward: 285.03
               Mean episode length: 206.30
    Episode_Reward/reaching_object: 1.2927
    Episode_Reward/rotating_object: 56.5241
        Episode_Reward/action_rate: -0.0442
          Episode_Reward/joint_vel: -0.0399
      Episode_Termination/time_out: 13.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 6.3750
--------------------------------------------------------------------------------
                   Total timesteps: 63307776
                    Iteration time: 2.15s
                      Time elapsed: 00:24:30
                               ETA: 01:29:42

################################################################################
                     [1m Learning iteration 644/3000 [0m                      

                       Computation: 46205 steps/s (collection: 1.992s, learning 0.136s)
             Mean action noise std: 2.66
          Mean value_function loss: 102.1491
               Mean surrogate loss: -0.0097
                 Mean entropy loss: 74.0207
                       Mean reward: 313.80
               Mean episode length: 216.92
    Episode_Reward/reaching_object: 1.3460
    Episode_Reward/rotating_object: 59.5892
        Episode_Reward/action_rate: -0.0464
          Episode_Reward/joint_vel: -0.0417
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.1667
--------------------------------------------------------------------------------
                   Total timesteps: 63406080
                    Iteration time: 2.13s
                      Time elapsed: 00:24:32
                               ETA: 01:29:39

################################################################################
                     [1m Learning iteration 645/3000 [0m                      

                       Computation: 45778 steps/s (collection: 2.023s, learning 0.125s)
             Mean action noise std: 2.67
          Mean value_function loss: 97.4778
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 74.0458
                       Mean reward: 316.05
               Mean episode length: 207.74
    Episode_Reward/reaching_object: 1.3771
    Episode_Reward/rotating_object: 61.8390
        Episode_Reward/action_rate: -0.0470
          Episode_Reward/joint_vel: -0.0414
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.7917
--------------------------------------------------------------------------------
                   Total timesteps: 63504384
                    Iteration time: 2.15s
                      Time elapsed: 00:24:34
                               ETA: 01:29:37

################################################################################
                     [1m Learning iteration 646/3000 [0m                      

                       Computation: 45994 steps/s (collection: 2.022s, learning 0.116s)
             Mean action noise std: 2.67
          Mean value_function loss: 101.6536
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 74.0761
                       Mean reward: 261.86
               Mean episode length: 187.51
    Episode_Reward/reaching_object: 1.3365
    Episode_Reward/rotating_object: 59.6552
        Episode_Reward/action_rate: -0.0460
          Episode_Reward/joint_vel: -0.0407
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 5.6250
--------------------------------------------------------------------------------
                   Total timesteps: 63602688
                    Iteration time: 2.14s
                      Time elapsed: 00:24:37
                               ETA: 01:29:34

################################################################################
                     [1m Learning iteration 647/3000 [0m                      

                       Computation: 46444 steps/s (collection: 1.998s, learning 0.119s)
             Mean action noise std: 2.67
          Mean value_function loss: 102.6397
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 74.1087
                       Mean reward: 272.55
               Mean episode length: 196.34
    Episode_Reward/reaching_object: 1.3643
    Episode_Reward/rotating_object: 61.0170
        Episode_Reward/action_rate: -0.0469
          Episode_Reward/joint_vel: -0.0401
      Episode_Termination/time_out: 13.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.1667
--------------------------------------------------------------------------------
                   Total timesteps: 63700992
                    Iteration time: 2.12s
                      Time elapsed: 00:24:39
                               ETA: 01:29:31

################################################################################
                     [1m Learning iteration 648/3000 [0m                      

                       Computation: 46646 steps/s (collection: 2.005s, learning 0.103s)
             Mean action noise std: 2.67
          Mean value_function loss: 105.0449
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 74.1418
                       Mean reward: 307.53
               Mean episode length: 195.98
    Episode_Reward/reaching_object: 1.3383
    Episode_Reward/rotating_object: 62.5024
        Episode_Reward/action_rate: -0.0465
          Episode_Reward/joint_vel: -0.0409
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.2500
--------------------------------------------------------------------------------
                   Total timesteps: 63799296
                    Iteration time: 2.11s
                      Time elapsed: 00:24:41
                               ETA: 01:29:28

################################################################################
                     [1m Learning iteration 649/3000 [0m                      

                       Computation: 46311 steps/s (collection: 2.014s, learning 0.109s)
             Mean action noise std: 2.68
          Mean value_function loss: 111.1945
               Mean surrogate loss: -0.0102
                 Mean entropy loss: 74.1738
                       Mean reward: 299.79
               Mean episode length: 205.52
    Episode_Reward/reaching_object: 1.3465
    Episode_Reward/rotating_object: 61.9482
        Episode_Reward/action_rate: -0.0466
          Episode_Reward/joint_vel: -0.0405
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.7917
--------------------------------------------------------------------------------
                   Total timesteps: 63897600
                    Iteration time: 2.12s
                      Time elapsed: 00:24:43
                               ETA: 01:29:25

################################################################################
                     [1m Learning iteration 650/3000 [0m                      

                       Computation: 45713 steps/s (collection: 2.032s, learning 0.119s)
             Mean action noise std: 2.68
          Mean value_function loss: 110.4301
               Mean surrogate loss: -0.0103
                 Mean entropy loss: 74.1976
                       Mean reward: 328.79
               Mean episode length: 214.88
    Episode_Reward/reaching_object: 1.3748
    Episode_Reward/rotating_object: 63.1670
        Episode_Reward/action_rate: -0.0473
          Episode_Reward/joint_vel: -0.0409
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.6250
--------------------------------------------------------------------------------
                   Total timesteps: 63995904
                    Iteration time: 2.15s
                      Time elapsed: 00:24:45
                               ETA: 01:29:22

################################################################################
                     [1m Learning iteration 651/3000 [0m                      

                       Computation: 39365 steps/s (collection: 2.368s, learning 0.130s)
             Mean action noise std: 2.68
          Mean value_function loss: 105.8114
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 74.2135
                       Mean reward: 337.67
               Mean episode length: 224.75
    Episode_Reward/reaching_object: 1.3612
    Episode_Reward/rotating_object: 61.4587
        Episode_Reward/action_rate: -0.0470
          Episode_Reward/joint_vel: -0.0406
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 5.2917
--------------------------------------------------------------------------------
                   Total timesteps: 64094208
                    Iteration time: 2.50s
                      Time elapsed: 00:24:48
                               ETA: 01:29:21

################################################################################
                     [1m Learning iteration 652/3000 [0m                      

                       Computation: 43665 steps/s (collection: 2.106s, learning 0.146s)
             Mean action noise std: 2.68
          Mean value_function loss: 116.0124
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 74.2306
                       Mean reward: 307.13
               Mean episode length: 203.49
    Episode_Reward/reaching_object: 1.3094
    Episode_Reward/rotating_object: 60.7254
        Episode_Reward/action_rate: -0.0455
          Episode_Reward/joint_vel: -0.0401
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.7917
--------------------------------------------------------------------------------
                   Total timesteps: 64192512
                    Iteration time: 2.25s
                      Time elapsed: 00:24:50
                               ETA: 01:29:18

################################################################################
                     [1m Learning iteration 653/3000 [0m                      

                       Computation: 43890 steps/s (collection: 2.120s, learning 0.120s)
             Mean action noise std: 2.68
          Mean value_function loss: 107.7715
               Mean surrogate loss: -0.0097
                 Mean entropy loss: 74.2512
                       Mean reward: 304.60
               Mean episode length: 197.89
    Episode_Reward/reaching_object: 1.2955
    Episode_Reward/rotating_object: 60.7612
        Episode_Reward/action_rate: -0.0452
          Episode_Reward/joint_vel: -0.0389
      Episode_Termination/time_out: 13.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 6.1250
--------------------------------------------------------------------------------
                   Total timesteps: 64290816
                    Iteration time: 2.24s
                      Time elapsed: 00:24:52
                               ETA: 01:29:16

################################################################################
                     [1m Learning iteration 654/3000 [0m                      

                       Computation: 44748 steps/s (collection: 2.066s, learning 0.131s)
             Mean action noise std: 2.69
          Mean value_function loss: 106.4457
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 74.2855
                       Mean reward: 309.35
               Mean episode length: 199.92
    Episode_Reward/reaching_object: 1.3276
    Episode_Reward/rotating_object: 63.2786
        Episode_Reward/action_rate: -0.0462
          Episode_Reward/joint_vel: -0.0390
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.5000
--------------------------------------------------------------------------------
                   Total timesteps: 64389120
                    Iteration time: 2.20s
                      Time elapsed: 00:24:54
                               ETA: 01:29:13

################################################################################
                     [1m Learning iteration 655/3000 [0m                      

                       Computation: 43041 steps/s (collection: 2.169s, learning 0.115s)
             Mean action noise std: 2.69
          Mean value_function loss: 105.8760
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 74.3213
                       Mean reward: 318.62
               Mean episode length: 198.50
    Episode_Reward/reaching_object: 1.3119
    Episode_Reward/rotating_object: 63.8136
        Episode_Reward/action_rate: -0.0460
          Episode_Reward/joint_vel: -0.0393
      Episode_Termination/time_out: 13.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.5000
--------------------------------------------------------------------------------
                   Total timesteps: 64487424
                    Iteration time: 2.28s
                      Time elapsed: 00:24:57
                               ETA: 01:29:11

################################################################################
                     [1m Learning iteration 656/3000 [0m                      

                       Computation: 43890 steps/s (collection: 2.117s, learning 0.123s)
             Mean action noise std: 2.69
          Mean value_function loss: 103.0770
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 74.3476
                       Mean reward: 339.46
               Mean episode length: 203.90
    Episode_Reward/reaching_object: 1.3531
    Episode_Reward/rotating_object: 65.9235
        Episode_Reward/action_rate: -0.0476
          Episode_Reward/joint_vel: -0.0412
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.8750
--------------------------------------------------------------------------------
                   Total timesteps: 64585728
                    Iteration time: 2.24s
                      Time elapsed: 00:24:59
                               ETA: 01:29:09

################################################################################
                     [1m Learning iteration 657/3000 [0m                      

                       Computation: 44960 steps/s (collection: 2.065s, learning 0.122s)
             Mean action noise std: 2.70
          Mean value_function loss: 110.7540
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 74.3758
                       Mean reward: 311.74
               Mean episode length: 211.65
    Episode_Reward/reaching_object: 1.3477
    Episode_Reward/rotating_object: 63.7719
        Episode_Reward/action_rate: -0.0473
          Episode_Reward/joint_vel: -0.0400
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 5.4167
--------------------------------------------------------------------------------
                   Total timesteps: 64684032
                    Iteration time: 2.19s
                      Time elapsed: 00:25:01
                               ETA: 01:29:06

################################################################################
                     [1m Learning iteration 658/3000 [0m                      

                       Computation: 45253 steps/s (collection: 2.059s, learning 0.113s)
             Mean action noise std: 2.70
          Mean value_function loss: 106.7449
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 74.4102
                       Mean reward: 342.57
               Mean episode length: 214.07
    Episode_Reward/reaching_object: 1.3476
    Episode_Reward/rotating_object: 66.4263
        Episode_Reward/action_rate: -0.0475
          Episode_Reward/joint_vel: -0.0398
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.0000
--------------------------------------------------------------------------------
                   Total timesteps: 64782336
                    Iteration time: 2.17s
                      Time elapsed: 00:25:03
                               ETA: 01:29:03

################################################################################
                     [1m Learning iteration 659/3000 [0m                      

                       Computation: 43031 steps/s (collection: 2.116s, learning 0.169s)
             Mean action noise std: 2.70
          Mean value_function loss: 101.6676
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 74.4552
                       Mean reward: 298.94
               Mean episode length: 193.54
    Episode_Reward/reaching_object: 1.3134
    Episode_Reward/rotating_object: 64.6386
        Episode_Reward/action_rate: -0.0469
          Episode_Reward/joint_vel: -0.0393
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 5.4167
--------------------------------------------------------------------------------
                   Total timesteps: 64880640
                    Iteration time: 2.28s
                      Time elapsed: 00:25:05
                               ETA: 01:29:01

################################################################################
                     [1m Learning iteration 660/3000 [0m                      

                       Computation: 44903 steps/s (collection: 2.073s, learning 0.117s)
             Mean action noise std: 2.71
          Mean value_function loss: 108.9553
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 74.4906
                       Mean reward: 342.42
               Mean episode length: 214.49
    Episode_Reward/reaching_object: 1.3338
    Episode_Reward/rotating_object: 62.6691
        Episode_Reward/action_rate: -0.0471
          Episode_Reward/joint_vel: -0.0406
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.8750
--------------------------------------------------------------------------------
                   Total timesteps: 64978944
                    Iteration time: 2.19s
                      Time elapsed: 00:25:08
                               ETA: 01:28:59

################################################################################
                     [1m Learning iteration 661/3000 [0m                      

                       Computation: 44783 steps/s (collection: 2.087s, learning 0.108s)
             Mean action noise std: 2.71
          Mean value_function loss: 112.8420
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 74.5142
                       Mean reward: 349.04
               Mean episode length: 211.03
    Episode_Reward/reaching_object: 1.3715
    Episode_Reward/rotating_object: 67.7496
        Episode_Reward/action_rate: -0.0483
          Episode_Reward/joint_vel: -0.0403
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.5417
--------------------------------------------------------------------------------
                   Total timesteps: 65077248
                    Iteration time: 2.20s
                      Time elapsed: 00:25:10
                               ETA: 01:28:56

################################################################################
                     [1m Learning iteration 662/3000 [0m                      

                       Computation: 44224 steps/s (collection: 2.109s, learning 0.114s)
             Mean action noise std: 2.71
          Mean value_function loss: 112.2007
               Mean surrogate loss: -0.0097
                 Mean entropy loss: 74.5481
                       Mean reward: 310.38
               Mean episode length: 203.72
    Episode_Reward/reaching_object: 1.3184
    Episode_Reward/rotating_object: 60.9167
        Episode_Reward/action_rate: -0.0464
          Episode_Reward/joint_vel: -0.0384
      Episode_Termination/time_out: 13.5833
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 5.9167
--------------------------------------------------------------------------------
                   Total timesteps: 65175552
                    Iteration time: 2.22s
                      Time elapsed: 00:25:12
                               ETA: 01:28:54

################################################################################
                     [1m Learning iteration 663/3000 [0m                      

                       Computation: 38780 steps/s (collection: 2.345s, learning 0.190s)
             Mean action noise std: 2.71
          Mean value_function loss: 114.0052
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 74.5749
                       Mean reward: 339.28
               Mean episode length: 213.01
    Episode_Reward/reaching_object: 1.3664
    Episode_Reward/rotating_object: 63.9466
        Episode_Reward/action_rate: -0.0481
          Episode_Reward/joint_vel: -0.0409
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.5833
--------------------------------------------------------------------------------
                   Total timesteps: 65273856
                    Iteration time: 2.53s
                      Time elapsed: 00:25:15
                               ETA: 01:28:52

################################################################################
                     [1m Learning iteration 664/3000 [0m                      

                       Computation: 44122 steps/s (collection: 2.122s, learning 0.106s)
             Mean action noise std: 2.72
          Mean value_function loss: 110.9352
               Mean surrogate loss: -0.0100
                 Mean entropy loss: 74.6083
                       Mean reward: 396.32
               Mean episode length: 222.66
    Episode_Reward/reaching_object: 1.3694
    Episode_Reward/rotating_object: 67.9881
        Episode_Reward/action_rate: -0.0480
          Episode_Reward/joint_vel: -0.0396
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.1667
--------------------------------------------------------------------------------
                   Total timesteps: 65372160
                    Iteration time: 2.23s
                      Time elapsed: 00:25:17
                               ETA: 01:28:50

################################################################################
                     [1m Learning iteration 665/3000 [0m                      

                       Computation: 42308 steps/s (collection: 2.170s, learning 0.153s)
             Mean action noise std: 2.72
          Mean value_function loss: 118.0173
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 74.6451
                       Mean reward: 336.36
               Mean episode length: 212.76
    Episode_Reward/reaching_object: 1.3607
    Episode_Reward/rotating_object: 64.1314
        Episode_Reward/action_rate: -0.0479
          Episode_Reward/joint_vel: -0.0414
      Episode_Termination/time_out: 13.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 5.4167
--------------------------------------------------------------------------------
                   Total timesteps: 65470464
                    Iteration time: 2.32s
                      Time elapsed: 00:25:19
                               ETA: 01:28:48

################################################################################
                     [1m Learning iteration 666/3000 [0m                      

                       Computation: 26805 steps/s (collection: 3.549s, learning 0.119s)
             Mean action noise std: 2.72
          Mean value_function loss: 115.3481
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 74.6698
                       Mean reward: 298.58
               Mean episode length: 195.27
    Episode_Reward/reaching_object: 1.3588
    Episode_Reward/rotating_object: 63.9266
        Episode_Reward/action_rate: -0.0482
          Episode_Reward/joint_vel: -0.0404
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.5000
--------------------------------------------------------------------------------
                   Total timesteps: 65568768
                    Iteration time: 3.67s
                      Time elapsed: 00:25:23
                               ETA: 01:28:50

################################################################################
                     [1m Learning iteration 667/3000 [0m                      

                       Computation: 14537 steps/s (collection: 6.623s, learning 0.139s)
             Mean action noise std: 2.72
          Mean value_function loss: 109.7188
               Mean surrogate loss: -0.0100
                 Mean entropy loss: 74.6854
                       Mean reward: 345.26
               Mean episode length: 203.85
    Episode_Reward/reaching_object: 1.3405
    Episode_Reward/rotating_object: 66.6556
        Episode_Reward/action_rate: -0.0479
          Episode_Reward/joint_vel: -0.0393
      Episode_Termination/time_out: 13.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 5.2083
--------------------------------------------------------------------------------
                   Total timesteps: 65667072
                    Iteration time: 6.76s
                      Time elapsed: 00:25:30
                               ETA: 01:29:03

################################################################################
                     [1m Learning iteration 668/3000 [0m                      

                       Computation: 12985 steps/s (collection: 7.460s, learning 0.110s)
             Mean action noise std: 2.73
          Mean value_function loss: 100.6129
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 74.7103
                       Mean reward: 364.75
               Mean episode length: 213.22
    Episode_Reward/reaching_object: 1.3724
    Episode_Reward/rotating_object: 66.8358
        Episode_Reward/action_rate: -0.0487
          Episode_Reward/joint_vel: -0.0412
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.6250
--------------------------------------------------------------------------------
                   Total timesteps: 65765376
                    Iteration time: 7.57s
                      Time elapsed: 00:25:37
                               ETA: 01:29:20

################################################################################
                     [1m Learning iteration 669/3000 [0m                      

                       Computation: 13805 steps/s (collection: 6.969s, learning 0.152s)
             Mean action noise std: 2.73
          Mean value_function loss: 108.3045
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 74.7295
                       Mean reward: 327.39
               Mean episode length: 195.54
    Episode_Reward/reaching_object: 1.2714
    Episode_Reward/rotating_object: 58.6140
        Episode_Reward/action_rate: -0.0457
          Episode_Reward/joint_vel: -0.0387
      Episode_Termination/time_out: 12.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 6.0833
--------------------------------------------------------------------------------
                   Total timesteps: 65863680
                    Iteration time: 7.12s
                      Time elapsed: 00:25:44
                               ETA: 01:29:34

################################################################################
                     [1m Learning iteration 670/3000 [0m                      

                       Computation: 14116 steps/s (collection: 6.819s, learning 0.145s)
             Mean action noise std: 2.73
          Mean value_function loss: 110.4711
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 74.7529
                       Mean reward: 367.54
               Mean episode length: 215.23
    Episode_Reward/reaching_object: 1.3874
    Episode_Reward/rotating_object: 69.7485
        Episode_Reward/action_rate: -0.0488
          Episode_Reward/joint_vel: -0.0384
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.8333
--------------------------------------------------------------------------------
                   Total timesteps: 65961984
                    Iteration time: 6.96s
                      Time elapsed: 00:25:51
                               ETA: 01:29:48

################################################################################
                     [1m Learning iteration 671/3000 [0m                      

                       Computation: 14352 steps/s (collection: 6.732s, learning 0.117s)
             Mean action noise std: 2.73
          Mean value_function loss: 113.2846
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 74.7799
                       Mean reward: 348.04
               Mean episode length: 208.00
    Episode_Reward/reaching_object: 1.3838
    Episode_Reward/rotating_object: 69.7685
        Episode_Reward/action_rate: -0.0493
          Episode_Reward/joint_vel: -0.0408
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.8333
--------------------------------------------------------------------------------
                   Total timesteps: 66060288
                    Iteration time: 6.85s
                      Time elapsed: 00:25:58
                               ETA: 01:30:01

################################################################################
                     [1m Learning iteration 672/3000 [0m                      

                       Computation: 13984 steps/s (collection: 6.846s, learning 0.184s)
             Mean action noise std: 2.74
          Mean value_function loss: 112.9336
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 74.8134
                       Mean reward: 307.22
               Mean episode length: 197.37
    Episode_Reward/reaching_object: 1.3913
    Episode_Reward/rotating_object: 64.9938
        Episode_Reward/action_rate: -0.0493
          Episode_Reward/joint_vel: -0.0409
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.4167
--------------------------------------------------------------------------------
                   Total timesteps: 66158592
                    Iteration time: 7.03s
                      Time elapsed: 00:26:05
                               ETA: 01:30:15

################################################################################
                     [1m Learning iteration 673/3000 [0m                      

                       Computation: 14211 steps/s (collection: 6.769s, learning 0.149s)
             Mean action noise std: 2.74
          Mean value_function loss: 116.2275
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 74.8414
                       Mean reward: 349.23
               Mean episode length: 207.76
    Episode_Reward/reaching_object: 1.3994
    Episode_Reward/rotating_object: 68.8315
        Episode_Reward/action_rate: -0.0495
          Episode_Reward/joint_vel: -0.0402
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.8333
--------------------------------------------------------------------------------
                   Total timesteps: 66256896
                    Iteration time: 6.92s
                      Time elapsed: 00:26:12
                               ETA: 01:30:29

################################################################################
                     [1m Learning iteration 674/3000 [0m                      

                       Computation: 14034 steps/s (collection: 6.873s, learning 0.131s)
             Mean action noise std: 2.74
          Mean value_function loss: 110.2408
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 74.8672
                       Mean reward: 327.07
               Mean episode length: 197.62
    Episode_Reward/reaching_object: 1.3576
    Episode_Reward/rotating_object: 68.6134
        Episode_Reward/action_rate: -0.0484
          Episode_Reward/joint_vel: -0.0392
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.2917
--------------------------------------------------------------------------------
                   Total timesteps: 66355200
                    Iteration time: 7.00s
                      Time elapsed: 00:26:19
                               ETA: 01:30:43

################################################################################
                     [1m Learning iteration 675/3000 [0m                      

                       Computation: 20988 steps/s (collection: 4.525s, learning 0.159s)
             Mean action noise std: 2.75
          Mean value_function loss: 118.4736
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 74.8966
                       Mean reward: 383.21
               Mean episode length: 215.72
    Episode_Reward/reaching_object: 1.3872
    Episode_Reward/rotating_object: 72.3879
        Episode_Reward/action_rate: -0.0497
          Episode_Reward/joint_vel: -0.0393
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.5417
--------------------------------------------------------------------------------
                   Total timesteps: 66453504
                    Iteration time: 4.68s
                      Time elapsed: 00:26:24
                               ETA: 01:30:48

################################################################################
                     [1m Learning iteration 676/3000 [0m                      

                       Computation: 45771 steps/s (collection: 2.033s, learning 0.115s)
             Mean action noise std: 2.75
          Mean value_function loss: 118.8975
               Mean surrogate loss: -0.0095
                 Mean entropy loss: 74.9243
                       Mean reward: 324.29
               Mean episode length: 195.72
    Episode_Reward/reaching_object: 1.3528
    Episode_Reward/rotating_object: 68.4574
        Episode_Reward/action_rate: -0.0486
          Episode_Reward/joint_vel: -0.0399
      Episode_Termination/time_out: 13.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.1667
--------------------------------------------------------------------------------
                   Total timesteps: 66551808
                    Iteration time: 2.15s
                      Time elapsed: 00:26:26
                               ETA: 01:30:45

################################################################################
                     [1m Learning iteration 677/3000 [0m                      

                       Computation: 47727 steps/s (collection: 1.925s, learning 0.135s)
             Mean action noise std: 2.75
          Mean value_function loss: 103.2028
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 74.9461
                       Mean reward: 363.86
               Mean episode length: 204.78
    Episode_Reward/reaching_object: 1.3627
    Episode_Reward/rotating_object: 69.9286
        Episode_Reward/action_rate: -0.0489
          Episode_Reward/joint_vel: -0.0387
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.9583
--------------------------------------------------------------------------------
                   Total timesteps: 66650112
                    Iteration time: 2.06s
                      Time elapsed: 00:26:28
                               ETA: 01:30:42

################################################################################
                     [1m Learning iteration 678/3000 [0m                      

                       Computation: 44878 steps/s (collection: 2.049s, learning 0.142s)
             Mean action noise std: 2.75
          Mean value_function loss: 105.7483
               Mean surrogate loss: -0.0099
                 Mean entropy loss: 74.9666
                       Mean reward: 366.46
               Mean episode length: 216.67
    Episode_Reward/reaching_object: 1.4069
    Episode_Reward/rotating_object: 70.1334
        Episode_Reward/action_rate: -0.0506
          Episode_Reward/joint_vel: -0.0410
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.6250
--------------------------------------------------------------------------------
                   Total timesteps: 66748416
                    Iteration time: 2.19s
                      Time elapsed: 00:26:30
                               ETA: 01:30:39

################################################################################
                     [1m Learning iteration 679/3000 [0m                      

                       Computation: 44429 steps/s (collection: 2.100s, learning 0.113s)
             Mean action noise std: 2.76
          Mean value_function loss: 104.5113
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 74.9988
                       Mean reward: 389.65
               Mean episode length: 220.41
    Episode_Reward/reaching_object: 1.4239
    Episode_Reward/rotating_object: 72.7502
        Episode_Reward/action_rate: -0.0510
          Episode_Reward/joint_vel: -0.0395
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.2917
--------------------------------------------------------------------------------
                   Total timesteps: 66846720
                    Iteration time: 2.21s
                      Time elapsed: 00:26:32
                               ETA: 01:30:36

################################################################################
                     [1m Learning iteration 680/3000 [0m                      

                       Computation: 47091 steps/s (collection: 1.993s, learning 0.095s)
             Mean action noise std: 2.76
          Mean value_function loss: 101.5147
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 75.0293
                       Mean reward: 374.73
               Mean episode length: 212.78
    Episode_Reward/reaching_object: 1.4395
    Episode_Reward/rotating_object: 72.9701
        Episode_Reward/action_rate: -0.0518
          Episode_Reward/joint_vel: -0.0422
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.3333
--------------------------------------------------------------------------------
                   Total timesteps: 66945024
                    Iteration time: 2.09s
                      Time elapsed: 00:26:34
                               ETA: 01:30:33

################################################################################
                     [1m Learning iteration 681/3000 [0m                      

                       Computation: 46654 steps/s (collection: 1.946s, learning 0.161s)
             Mean action noise std: 2.76
          Mean value_function loss: 113.3169
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 75.0634
                       Mean reward: 395.80
               Mean episode length: 211.53
    Episode_Reward/reaching_object: 1.3896
    Episode_Reward/rotating_object: 74.0518
        Episode_Reward/action_rate: -0.0506
          Episode_Reward/joint_vel: -0.0395
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.5417
--------------------------------------------------------------------------------
                   Total timesteps: 67043328
                    Iteration time: 2.11s
                      Time elapsed: 00:26:37
                               ETA: 01:30:30

################################################################################
                     [1m Learning iteration 682/3000 [0m                      

                       Computation: 44845 steps/s (collection: 2.083s, learning 0.109s)
             Mean action noise std: 2.76
          Mean value_function loss: 112.8702
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 75.0969
                       Mean reward: 331.35
               Mean episode length: 199.94
    Episode_Reward/reaching_object: 1.3537
    Episode_Reward/rotating_object: 70.0591
        Episode_Reward/action_rate: -0.0492
          Episode_Reward/joint_vel: -0.0392
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.4167
--------------------------------------------------------------------------------
                   Total timesteps: 67141632
                    Iteration time: 2.19s
                      Time elapsed: 00:26:39
                               ETA: 01:30:27

################################################################################
                     [1m Learning iteration 683/3000 [0m                      

                       Computation: 47495 steps/s (collection: 1.928s, learning 0.142s)
             Mean action noise std: 2.77
          Mean value_function loss: 110.5791
               Mean surrogate loss: -0.0099
                 Mean entropy loss: 75.1274
                       Mean reward: 387.05
               Mean episode length: 210.51
    Episode_Reward/reaching_object: 1.3799
    Episode_Reward/rotating_object: 69.6869
        Episode_Reward/action_rate: -0.0503
          Episode_Reward/joint_vel: -0.0409
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 5.1667
--------------------------------------------------------------------------------
                   Total timesteps: 67239936
                    Iteration time: 2.07s
                      Time elapsed: 00:26:41
                               ETA: 01:30:24

################################################################################
                     [1m Learning iteration 684/3000 [0m                      

                       Computation: 47494 steps/s (collection: 1.928s, learning 0.142s)
             Mean action noise std: 2.77
          Mean value_function loss: 127.1452
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 75.1619
                       Mean reward: 332.45
               Mean episode length: 203.78
    Episode_Reward/reaching_object: 1.3709
    Episode_Reward/rotating_object: 68.4980
        Episode_Reward/action_rate: -0.0501
          Episode_Reward/joint_vel: -0.0410
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.9167
--------------------------------------------------------------------------------
                   Total timesteps: 67338240
                    Iteration time: 2.07s
                      Time elapsed: 00:26:43
                               ETA: 01:30:21

################################################################################
                     [1m Learning iteration 685/3000 [0m                      

                       Computation: 44130 steps/s (collection: 2.037s, learning 0.190s)
             Mean action noise std: 2.77
          Mean value_function loss: 118.3068
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 75.1930
                       Mean reward: 326.74
               Mean episode length: 203.81
    Episode_Reward/reaching_object: 1.3894
    Episode_Reward/rotating_object: 70.8087
        Episode_Reward/action_rate: -0.0508
          Episode_Reward/joint_vel: -0.0410
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.9583
--------------------------------------------------------------------------------
                   Total timesteps: 67436544
                    Iteration time: 2.23s
                      Time elapsed: 00:26:45
                               ETA: 01:30:18

################################################################################
                     [1m Learning iteration 686/3000 [0m                      

                       Computation: 47726 steps/s (collection: 1.960s, learning 0.100s)
             Mean action noise std: 2.77
          Mean value_function loss: 110.9397
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 75.2131
                       Mean reward: 380.04
               Mean episode length: 203.90
    Episode_Reward/reaching_object: 1.3485
    Episode_Reward/rotating_object: 71.5781
        Episode_Reward/action_rate: -0.0494
          Episode_Reward/joint_vel: -0.0389
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.2500
--------------------------------------------------------------------------------
                   Total timesteps: 67534848
                    Iteration time: 2.06s
                      Time elapsed: 00:26:47
                               ETA: 01:30:15

################################################################################
                     [1m Learning iteration 687/3000 [0m                      

                       Computation: 48249 steps/s (collection: 1.930s, learning 0.107s)
             Mean action noise std: 2.78
          Mean value_function loss: 110.0548
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 75.2290
                       Mean reward: 393.94
               Mean episode length: 218.07
    Episode_Reward/reaching_object: 1.4065
    Episode_Reward/rotating_object: 72.6023
        Episode_Reward/action_rate: -0.0516
          Episode_Reward/joint_vel: -0.0413
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.1250
--------------------------------------------------------------------------------
                   Total timesteps: 67633152
                    Iteration time: 2.04s
                      Time elapsed: 00:26:49
                               ETA: 01:30:11

################################################################################
                     [1m Learning iteration 688/3000 [0m                      

                       Computation: 47586 steps/s (collection: 1.963s, learning 0.103s)
             Mean action noise std: 2.78
          Mean value_function loss: 111.8919
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 75.2470
                       Mean reward: 381.72
               Mean episode length: 207.12
    Episode_Reward/reaching_object: 1.3589
    Episode_Reward/rotating_object: 71.4503
        Episode_Reward/action_rate: -0.0501
          Episode_Reward/joint_vel: -0.0401
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 5.2500
--------------------------------------------------------------------------------
                   Total timesteps: 67731456
                    Iteration time: 2.07s
                      Time elapsed: 00:26:51
                               ETA: 01:30:08

################################################################################
                     [1m Learning iteration 689/3000 [0m                      

                       Computation: 48651 steps/s (collection: 1.929s, learning 0.092s)
             Mean action noise std: 2.78
          Mean value_function loss: 107.4187
               Mean surrogate loss: -0.0097
                 Mean entropy loss: 75.2647
                       Mean reward: 360.61
               Mean episode length: 222.45
    Episode_Reward/reaching_object: 1.4402
    Episode_Reward/rotating_object: 72.2952
        Episode_Reward/action_rate: -0.0530
          Episode_Reward/joint_vel: -0.0437
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.6667
--------------------------------------------------------------------------------
                   Total timesteps: 67829760
                    Iteration time: 2.02s
                      Time elapsed: 00:26:53
                               ETA: 01:30:05

################################################################################
                     [1m Learning iteration 690/3000 [0m                      

                       Computation: 46817 steps/s (collection: 1.992s, learning 0.108s)
             Mean action noise std: 2.78
          Mean value_function loss: 110.4763
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 75.2888
                       Mean reward: 338.42
               Mean episode length: 196.04
    Episode_Reward/reaching_object: 1.3056
    Episode_Reward/rotating_object: 68.0797
        Episode_Reward/action_rate: -0.0486
          Episode_Reward/joint_vel: -0.0403
      Episode_Termination/time_out: 13.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.7500
--------------------------------------------------------------------------------
                   Total timesteps: 67928064
                    Iteration time: 2.10s
                      Time elapsed: 00:26:55
                               ETA: 01:30:01

################################################################################
                     [1m Learning iteration 691/3000 [0m                      

                       Computation: 47450 steps/s (collection: 1.968s, learning 0.104s)
             Mean action noise std: 2.79
          Mean value_function loss: 112.5856
               Mean surrogate loss: -0.0098
                 Mean entropy loss: 75.3125
                       Mean reward: 375.15
               Mean episode length: 198.02
    Episode_Reward/reaching_object: 1.3586
    Episode_Reward/rotating_object: 72.2218
        Episode_Reward/action_rate: -0.0506
          Episode_Reward/joint_vel: -0.0411
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.4583
--------------------------------------------------------------------------------
                   Total timesteps: 68026368
                    Iteration time: 2.07s
                      Time elapsed: 00:26:57
                               ETA: 01:29:58

################################################################################
                     [1m Learning iteration 692/3000 [0m                      

                       Computation: 46272 steps/s (collection: 2.011s, learning 0.114s)
             Mean action noise std: 2.79
          Mean value_function loss: 118.1804
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 75.3414
                       Mean reward: 344.10
               Mean episode length: 200.52
    Episode_Reward/reaching_object: 1.3171
    Episode_Reward/rotating_object: 70.6951
        Episode_Reward/action_rate: -0.0492
          Episode_Reward/joint_vel: -0.0393
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.6667
--------------------------------------------------------------------------------
                   Total timesteps: 68124672
                    Iteration time: 2.12s
                      Time elapsed: 00:27:00
                               ETA: 01:29:55

################################################################################
                     [1m Learning iteration 693/3000 [0m                      

                       Computation: 47069 steps/s (collection: 1.968s, learning 0.121s)
             Mean action noise std: 2.79
          Mean value_function loss: 120.6901
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 75.3719
                       Mean reward: 349.97
               Mean episode length: 199.02
    Episode_Reward/reaching_object: 1.4082
    Episode_Reward/rotating_object: 74.6021
        Episode_Reward/action_rate: -0.0526
          Episode_Reward/joint_vel: -0.0412
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.6667
--------------------------------------------------------------------------------
                   Total timesteps: 68222976
                    Iteration time: 2.09s
                      Time elapsed: 00:27:02
                               ETA: 01:29:52

################################################################################
                     [1m Learning iteration 694/3000 [0m                      

                       Computation: 47646 steps/s (collection: 1.961s, learning 0.102s)
             Mean action noise std: 2.79
          Mean value_function loss: 113.4306
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 75.4078
                       Mean reward: 358.44
               Mean episode length: 200.86
    Episode_Reward/reaching_object: 1.3318
    Episode_Reward/rotating_object: 73.6236
        Episode_Reward/action_rate: -0.0504
          Episode_Reward/joint_vel: -0.0389
      Episode_Termination/time_out: 13.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.9583
--------------------------------------------------------------------------------
                   Total timesteps: 68321280
                    Iteration time: 2.06s
                      Time elapsed: 00:27:04
                               ETA: 01:29:49

################################################################################
                     [1m Learning iteration 695/3000 [0m                      

                       Computation: 45035 steps/s (collection: 2.030s, learning 0.153s)
             Mean action noise std: 2.80
          Mean value_function loss: 112.5935
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 75.4317
                       Mean reward: 397.12
               Mean episode length: 205.00
    Episode_Reward/reaching_object: 1.3359
    Episode_Reward/rotating_object: 70.8122
        Episode_Reward/action_rate: -0.0504
          Episode_Reward/joint_vel: -0.0405
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.5417
--------------------------------------------------------------------------------
                   Total timesteps: 68419584
                    Iteration time: 2.18s
                      Time elapsed: 00:27:06
                               ETA: 01:29:46

################################################################################
                     [1m Learning iteration 696/3000 [0m                      

                       Computation: 47334 steps/s (collection: 1.969s, learning 0.108s)
             Mean action noise std: 2.80
          Mean value_function loss: 112.1294
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 75.4592
                       Mean reward: 395.67
               Mean episode length: 215.76
    Episode_Reward/reaching_object: 1.3553
    Episode_Reward/rotating_object: 74.3207
        Episode_Reward/action_rate: -0.0513
          Episode_Reward/joint_vel: -0.0403
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.7500
--------------------------------------------------------------------------------
                   Total timesteps: 68517888
                    Iteration time: 2.08s
                      Time elapsed: 00:27:08
                               ETA: 01:29:43

################################################################################
                     [1m Learning iteration 697/3000 [0m                      

                       Computation: 47068 steps/s (collection: 1.995s, learning 0.093s)
             Mean action noise std: 2.80
          Mean value_function loss: 110.4690
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 75.4793
                       Mean reward: 382.12
               Mean episode length: 214.24
    Episode_Reward/reaching_object: 1.3548
    Episode_Reward/rotating_object: 71.9420
        Episode_Reward/action_rate: -0.0513
          Episode_Reward/joint_vel: -0.0403
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.6667
--------------------------------------------------------------------------------
                   Total timesteps: 68616192
                    Iteration time: 2.09s
                      Time elapsed: 00:27:10
                               ETA: 01:29:40

################################################################################
                     [1m Learning iteration 698/3000 [0m                      

                       Computation: 47624 steps/s (collection: 1.958s, learning 0.106s)
             Mean action noise std: 2.80
          Mean value_function loss: 114.2964
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 75.4994
                       Mean reward: 386.87
               Mean episode length: 220.81
    Episode_Reward/reaching_object: 1.3285
    Episode_Reward/rotating_object: 70.5043
        Episode_Reward/action_rate: -0.0507
          Episode_Reward/joint_vel: -0.0417
      Episode_Termination/time_out: 13.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.5833
--------------------------------------------------------------------------------
                   Total timesteps: 68714496
                    Iteration time: 2.06s
                      Time elapsed: 00:27:12
                               ETA: 01:29:36

################################################################################
                     [1m Learning iteration 699/3000 [0m                      

                       Computation: 46334 steps/s (collection: 2.026s, learning 0.096s)
             Mean action noise std: 2.81
          Mean value_function loss: 110.8706
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 75.5150
                       Mean reward: 347.96
               Mean episode length: 203.05
    Episode_Reward/reaching_object: 1.4053
    Episode_Reward/rotating_object: 74.3805
        Episode_Reward/action_rate: -0.0531
          Episode_Reward/joint_vel: -0.0418
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.6667
--------------------------------------------------------------------------------
                   Total timesteps: 68812800
                    Iteration time: 2.12s
                      Time elapsed: 00:27:14
                               ETA: 01:29:33

################################################################################
                     [1m Learning iteration 700/3000 [0m                      

                       Computation: 47585 steps/s (collection: 1.971s, learning 0.095s)
             Mean action noise std: 2.81
          Mean value_function loss: 111.9110
               Mean surrogate loss: -0.0098
                 Mean entropy loss: 75.5385
                       Mean reward: 404.95
               Mean episode length: 205.56
    Episode_Reward/reaching_object: 1.3748
    Episode_Reward/rotating_object: 77.7071
        Episode_Reward/action_rate: -0.0524
          Episode_Reward/joint_vel: -0.0402
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.1250
--------------------------------------------------------------------------------
                   Total timesteps: 68911104
                    Iteration time: 2.07s
                      Time elapsed: 00:27:16
                               ETA: 01:29:30

################################################################################
                     [1m Learning iteration 701/3000 [0m                      

                       Computation: 47529 steps/s (collection: 1.976s, learning 0.093s)
             Mean action noise std: 2.81
          Mean value_function loss: 108.8671
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 75.5668
                       Mean reward: 404.90
               Mean episode length: 217.24
    Episode_Reward/reaching_object: 1.4036
    Episode_Reward/rotating_object: 76.3049
        Episode_Reward/action_rate: -0.0533
          Episode_Reward/joint_vel: -0.0420
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.4167
--------------------------------------------------------------------------------
                   Total timesteps: 69009408
                    Iteration time: 2.07s
                      Time elapsed: 00:27:18
                               ETA: 01:29:27

################################################################################
                     [1m Learning iteration 702/3000 [0m                      

                       Computation: 48070 steps/s (collection: 1.952s, learning 0.093s)
             Mean action noise std: 2.82
          Mean value_function loss: 110.8067
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 75.6040
                       Mean reward: 389.13
               Mean episode length: 202.06
    Episode_Reward/reaching_object: 1.3749
    Episode_Reward/rotating_object: 77.5386
        Episode_Reward/action_rate: -0.0524
          Episode_Reward/joint_vel: -0.0407
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.0000
--------------------------------------------------------------------------------
                   Total timesteps: 69107712
                    Iteration time: 2.05s
                      Time elapsed: 00:27:20
                               ETA: 01:29:24

################################################################################
                     [1m Learning iteration 703/3000 [0m                      

                       Computation: 46258 steps/s (collection: 2.017s, learning 0.108s)
             Mean action noise std: 2.82
          Mean value_function loss: 111.1169
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 75.6471
                       Mean reward: 392.11
               Mean episode length: 217.19
    Episode_Reward/reaching_object: 1.3813
    Episode_Reward/rotating_object: 75.9495
        Episode_Reward/action_rate: -0.0524
          Episode_Reward/joint_vel: -0.0404
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.2917
--------------------------------------------------------------------------------
                   Total timesteps: 69206016
                    Iteration time: 2.13s
                      Time elapsed: 00:27:23
                               ETA: 01:29:21

################################################################################
                     [1m Learning iteration 704/3000 [0m                      

                       Computation: 46638 steps/s (collection: 1.997s, learning 0.111s)
             Mean action noise std: 2.82
          Mean value_function loss: 121.5613
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 75.6849
                       Mean reward: 393.96
               Mean episode length: 208.75
    Episode_Reward/reaching_object: 1.4192
    Episode_Reward/rotating_object: 78.4247
        Episode_Reward/action_rate: -0.0537
          Episode_Reward/joint_vel: -0.0410
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.6667
--------------------------------------------------------------------------------
                   Total timesteps: 69304320
                    Iteration time: 2.11s
                      Time elapsed: 00:27:25
                               ETA: 01:29:17

################################################################################
                     [1m Learning iteration 705/3000 [0m                      

                       Computation: 46823 steps/s (collection: 1.993s, learning 0.107s)
             Mean action noise std: 2.83
          Mean value_function loss: 115.5291
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 75.7115
                       Mean reward: 435.06
               Mean episode length: 227.08
    Episode_Reward/reaching_object: 1.3696
    Episode_Reward/rotating_object: 75.3324
        Episode_Reward/action_rate: -0.0521
          Episode_Reward/joint_vel: -0.0406
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.3333
--------------------------------------------------------------------------------
                   Total timesteps: 69402624
                    Iteration time: 2.10s
                      Time elapsed: 00:27:27
                               ETA: 01:29:14

################################################################################
                     [1m Learning iteration 706/3000 [0m                      

                       Computation: 48376 steps/s (collection: 1.917s, learning 0.115s)
             Mean action noise std: 2.83
          Mean value_function loss: 115.4150
               Mean surrogate loss: -0.0096
                 Mean entropy loss: 75.7336
                       Mean reward: 392.88
               Mean episode length: 207.33
    Episode_Reward/reaching_object: 1.4305
    Episode_Reward/rotating_object: 81.2403
        Episode_Reward/action_rate: -0.0542
          Episode_Reward/joint_vel: -0.0405
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.7500
--------------------------------------------------------------------------------
                   Total timesteps: 69500928
                    Iteration time: 2.03s
                      Time elapsed: 00:27:29
                               ETA: 01:29:11

################################################################################
                     [1m Learning iteration 707/3000 [0m                      

                       Computation: 49058 steps/s (collection: 1.911s, learning 0.093s)
             Mean action noise std: 2.83
          Mean value_function loss: 114.7670
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 75.7607
                       Mean reward: 415.68
               Mean episode length: 219.09
    Episode_Reward/reaching_object: 1.3589
    Episode_Reward/rotating_object: 76.0065
        Episode_Reward/action_rate: -0.0519
          Episode_Reward/joint_vel: -0.0402
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.7500
--------------------------------------------------------------------------------
                   Total timesteps: 69599232
                    Iteration time: 2.00s
                      Time elapsed: 00:27:31
                               ETA: 01:29:08

################################################################################
                     [1m Learning iteration 708/3000 [0m                      

                       Computation: 48211 steps/s (collection: 1.948s, learning 0.091s)
             Mean action noise std: 2.83
          Mean value_function loss: 112.7349
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 75.7800
                       Mean reward: 392.70
               Mean episode length: 211.73
    Episode_Reward/reaching_object: 1.4106
    Episode_Reward/rotating_object: 78.2190
        Episode_Reward/action_rate: -0.0539
          Episode_Reward/joint_vel: -0.0413
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.2083
--------------------------------------------------------------------------------
                   Total timesteps: 69697536
                    Iteration time: 2.04s
                      Time elapsed: 00:27:33
                               ETA: 01:29:04

################################################################################
                     [1m Learning iteration 709/3000 [0m                      

                       Computation: 46481 steps/s (collection: 1.975s, learning 0.140s)
             Mean action noise std: 2.83
          Mean value_function loss: 113.9144
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 75.7970
                       Mean reward: 409.78
               Mean episode length: 216.91
    Episode_Reward/reaching_object: 1.3920
    Episode_Reward/rotating_object: 78.0790
        Episode_Reward/action_rate: -0.0533
          Episode_Reward/joint_vel: -0.0397
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.2083
--------------------------------------------------------------------------------
                   Total timesteps: 69795840
                    Iteration time: 2.11s
                      Time elapsed: 00:27:35
                               ETA: 01:29:01

################################################################################
                     [1m Learning iteration 710/3000 [0m                      

                       Computation: 46038 steps/s (collection: 1.954s, learning 0.181s)
             Mean action noise std: 2.84
          Mean value_function loss: 109.0412
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 75.8122
                       Mean reward: 371.24
               Mean episode length: 201.82
    Episode_Reward/reaching_object: 1.4031
    Episode_Reward/rotating_object: 78.0807
        Episode_Reward/action_rate: -0.0539
          Episode_Reward/joint_vel: -0.0408
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.3750
--------------------------------------------------------------------------------
                   Total timesteps: 69894144
                    Iteration time: 2.14s
                      Time elapsed: 00:27:37
                               ETA: 01:28:58

################################################################################
                     [1m Learning iteration 711/3000 [0m                      

                       Computation: 46720 steps/s (collection: 1.955s, learning 0.149s)
             Mean action noise std: 2.84
          Mean value_function loss: 116.9598
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 75.8362
                       Mean reward: 413.44
               Mean episode length: 217.25
    Episode_Reward/reaching_object: 1.3850
    Episode_Reward/rotating_object: 77.9975
        Episode_Reward/action_rate: -0.0538
          Episode_Reward/joint_vel: -0.0406
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.5417
--------------------------------------------------------------------------------
                   Total timesteps: 69992448
                    Iteration time: 2.10s
                      Time elapsed: 00:27:39
                               ETA: 01:28:55

################################################################################
                     [1m Learning iteration 712/3000 [0m                      

                       Computation: 48414 steps/s (collection: 1.914s, learning 0.116s)
             Mean action noise std: 2.84
          Mean value_function loss: 106.4444
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 75.8567
                       Mean reward: 428.65
               Mean episode length: 215.17
    Episode_Reward/reaching_object: 1.3904
    Episode_Reward/rotating_object: 76.9753
        Episode_Reward/action_rate: -0.0539
          Episode_Reward/joint_vel: -0.0409
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.7083
--------------------------------------------------------------------------------
                   Total timesteps: 70090752
                    Iteration time: 2.03s
                      Time elapsed: 00:27:41
                               ETA: 01:28:52

################################################################################
                     [1m Learning iteration 713/3000 [0m                      

                       Computation: 46559 steps/s (collection: 1.999s, learning 0.113s)
             Mean action noise std: 2.84
          Mean value_function loss: 112.6371
               Mean surrogate loss: -0.0098
                 Mean entropy loss: 75.8821
                       Mean reward: 393.17
               Mean episode length: 217.37
    Episode_Reward/reaching_object: 1.3641
    Episode_Reward/rotating_object: 75.0478
        Episode_Reward/action_rate: -0.0529
          Episode_Reward/joint_vel: -0.0407
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.8750
--------------------------------------------------------------------------------
                   Total timesteps: 70189056
                    Iteration time: 2.11s
                      Time elapsed: 00:27:43
                               ETA: 01:28:49

################################################################################
                     [1m Learning iteration 714/3000 [0m                      

                       Computation: 44682 steps/s (collection: 2.103s, learning 0.097s)
             Mean action noise std: 2.85
          Mean value_function loss: 112.6212
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 75.9060
                       Mean reward: 408.72
               Mean episode length: 207.94
    Episode_Reward/reaching_object: 1.3797
    Episode_Reward/rotating_object: 77.3309
        Episode_Reward/action_rate: -0.0539
          Episode_Reward/joint_vel: -0.0408
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.9167
--------------------------------------------------------------------------------
                   Total timesteps: 70287360
                    Iteration time: 2.20s
                      Time elapsed: 00:27:46
                               ETA: 01:28:46

################################################################################
                     [1m Learning iteration 715/3000 [0m                      

                       Computation: 47725 steps/s (collection: 1.958s, learning 0.102s)
             Mean action noise std: 2.85
          Mean value_function loss: 106.2204
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 75.9191
                       Mean reward: 391.14
               Mean episode length: 212.96
    Episode_Reward/reaching_object: 1.3785
    Episode_Reward/rotating_object: 76.8810
        Episode_Reward/action_rate: -0.0535
          Episode_Reward/joint_vel: -0.0411
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.7083
--------------------------------------------------------------------------------
                   Total timesteps: 70385664
                    Iteration time: 2.06s
                      Time elapsed: 00:27:48
                               ETA: 01:28:43

################################################################################
                     [1m Learning iteration 716/3000 [0m                      

                       Computation: 47458 steps/s (collection: 1.959s, learning 0.112s)
             Mean action noise std: 2.85
          Mean value_function loss: 118.1382
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 75.9348
                       Mean reward: 379.29
               Mean episode length: 204.82
    Episode_Reward/reaching_object: 1.3608
    Episode_Reward/rotating_object: 76.0908
        Episode_Reward/action_rate: -0.0529
          Episode_Reward/joint_vel: -0.0395
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 5.1667
--------------------------------------------------------------------------------
                   Total timesteps: 70483968
                    Iteration time: 2.07s
                      Time elapsed: 00:27:50
                               ETA: 01:28:40

################################################################################
                     [1m Learning iteration 717/3000 [0m                      

                       Computation: 47854 steps/s (collection: 1.952s, learning 0.102s)
             Mean action noise std: 2.85
          Mean value_function loss: 121.8961
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 75.9580
                       Mean reward: 376.31
               Mean episode length: 205.23
    Episode_Reward/reaching_object: 1.4070
    Episode_Reward/rotating_object: 80.2299
        Episode_Reward/action_rate: -0.0544
          Episode_Reward/joint_vel: -0.0399
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.0833
--------------------------------------------------------------------------------
                   Total timesteps: 70582272
                    Iteration time: 2.05s
                      Time elapsed: 00:27:52
                               ETA: 01:28:37

################################################################################
                     [1m Learning iteration 718/3000 [0m                      

                       Computation: 47349 steps/s (collection: 1.969s, learning 0.107s)
             Mean action noise std: 2.85
          Mean value_function loss: 113.8095
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 75.9710
                       Mean reward: 408.05
               Mean episode length: 216.15
    Episode_Reward/reaching_object: 1.4172
    Episode_Reward/rotating_object: 81.4936
        Episode_Reward/action_rate: -0.0549
          Episode_Reward/joint_vel: -0.0399
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.2083
--------------------------------------------------------------------------------
                   Total timesteps: 70680576
                    Iteration time: 2.08s
                      Time elapsed: 00:27:54
                               ETA: 01:28:34

################################################################################
                     [1m Learning iteration 719/3000 [0m                      

                       Computation: 46879 steps/s (collection: 1.978s, learning 0.119s)
             Mean action noise std: 2.85
          Mean value_function loss: 114.6186
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 75.9822
                       Mean reward: 409.26
               Mean episode length: 214.02
    Episode_Reward/reaching_object: 1.3909
    Episode_Reward/rotating_object: 80.0571
        Episode_Reward/action_rate: -0.0541
          Episode_Reward/joint_vel: -0.0399
      Episode_Termination/time_out: 12.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 70778880
                    Iteration time: 2.10s
                      Time elapsed: 00:27:56
                               ETA: 01:28:30

################################################################################
                     [1m Learning iteration 720/3000 [0m                      

                       Computation: 46940 steps/s (collection: 1.968s, learning 0.127s)
             Mean action noise std: 2.86
          Mean value_function loss: 115.9359
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 76.0013
                       Mean reward: 398.38
               Mean episode length: 212.13
    Episode_Reward/reaching_object: 1.4214
    Episode_Reward/rotating_object: 82.9710
        Episode_Reward/action_rate: -0.0548
          Episode_Reward/joint_vel: -0.0391
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.1250
--------------------------------------------------------------------------------
                   Total timesteps: 70877184
                    Iteration time: 2.09s
                      Time elapsed: 00:27:58
                               ETA: 01:28:27

################################################################################
                     [1m Learning iteration 721/3000 [0m                      

                       Computation: 46478 steps/s (collection: 1.978s, learning 0.137s)
             Mean action noise std: 2.86
          Mean value_function loss: 104.9546
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 76.0333
                       Mean reward: 435.23
               Mean episode length: 217.20
    Episode_Reward/reaching_object: 1.4117
    Episode_Reward/rotating_object: 81.2072
        Episode_Reward/action_rate: -0.0546
          Episode_Reward/joint_vel: -0.0388
      Episode_Termination/time_out: 13.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.1250
--------------------------------------------------------------------------------
                   Total timesteps: 70975488
                    Iteration time: 2.12s
                      Time elapsed: 00:28:00
                               ETA: 01:28:24

################################################################################
                     [1m Learning iteration 722/3000 [0m                      

                       Computation: 46905 steps/s (collection: 1.953s, learning 0.143s)
             Mean action noise std: 2.86
          Mean value_function loss: 106.5410
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 76.0679
                       Mean reward: 414.22
               Mean episode length: 217.66
    Episode_Reward/reaching_object: 1.3862
    Episode_Reward/rotating_object: 81.5342
        Episode_Reward/action_rate: -0.0540
          Episode_Reward/joint_vel: -0.0381
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.7917
--------------------------------------------------------------------------------
                   Total timesteps: 71073792
                    Iteration time: 2.10s
                      Time elapsed: 00:28:02
                               ETA: 01:28:21

################################################################################
                     [1m Learning iteration 723/3000 [0m                      

                       Computation: 46878 steps/s (collection: 1.970s, learning 0.127s)
             Mean action noise std: 2.87
          Mean value_function loss: 111.2838
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 76.0861
                       Mean reward: 379.61
               Mean episode length: 213.45
    Episode_Reward/reaching_object: 1.4270
    Episode_Reward/rotating_object: 84.0731
        Episode_Reward/action_rate: -0.0554
          Episode_Reward/joint_vel: -0.0387
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.7500
--------------------------------------------------------------------------------
                   Total timesteps: 71172096
                    Iteration time: 2.10s
                      Time elapsed: 00:28:04
                               ETA: 01:28:18

################################################################################
                     [1m Learning iteration 724/3000 [0m                      

                       Computation: 46647 steps/s (collection: 2.000s, learning 0.107s)
             Mean action noise std: 2.87
          Mean value_function loss: 120.0027
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 76.1028
                       Mean reward: 449.34
               Mean episode length: 216.96
    Episode_Reward/reaching_object: 1.3975
    Episode_Reward/rotating_object: 82.8016
        Episode_Reward/action_rate: -0.0547
          Episode_Reward/joint_vel: -0.0392
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.3750
--------------------------------------------------------------------------------
                   Total timesteps: 71270400
                    Iteration time: 2.11s
                      Time elapsed: 00:28:06
                               ETA: 01:28:15

################################################################################
                     [1m Learning iteration 725/3000 [0m                      

                       Computation: 46593 steps/s (collection: 1.992s, learning 0.118s)
             Mean action noise std: 2.87
          Mean value_function loss: 121.0050
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 76.1242
                       Mean reward: 395.45
               Mean episode length: 204.54
    Episode_Reward/reaching_object: 1.3894
    Episode_Reward/rotating_object: 82.0546
        Episode_Reward/action_rate: -0.0541
          Episode_Reward/joint_vel: -0.0378
      Episode_Termination/time_out: 13.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 71368704
                    Iteration time: 2.11s
                      Time elapsed: 00:28:09
                               ETA: 01:28:12

################################################################################
                     [1m Learning iteration 726/3000 [0m                      

                       Computation: 47576 steps/s (collection: 1.950s, learning 0.117s)
             Mean action noise std: 2.87
          Mean value_function loss: 104.8053
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 76.1629
                       Mean reward: 468.04
               Mean episode length: 222.37
    Episode_Reward/reaching_object: 1.3927
    Episode_Reward/rotating_object: 85.4456
        Episode_Reward/action_rate: -0.0548
          Episode_Reward/joint_vel: -0.0381
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.1667
--------------------------------------------------------------------------------
                   Total timesteps: 71467008
                    Iteration time: 2.07s
                      Time elapsed: 00:28:11
                               ETA: 01:28:09

################################################################################
                     [1m Learning iteration 727/3000 [0m                      

                       Computation: 45044 steps/s (collection: 2.023s, learning 0.159s)
             Mean action noise std: 2.88
          Mean value_function loss: 102.3355
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 76.2050
                       Mean reward: 405.99
               Mean episode length: 206.88
    Episode_Reward/reaching_object: 1.3885
    Episode_Reward/rotating_object: 82.5582
        Episode_Reward/action_rate: -0.0549
          Episode_Reward/joint_vel: -0.0398
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.1667
--------------------------------------------------------------------------------
                   Total timesteps: 71565312
                    Iteration time: 2.18s
                      Time elapsed: 00:28:13
                               ETA: 01:28:06

################################################################################
                     [1m Learning iteration 728/3000 [0m                      

                       Computation: 45547 steps/s (collection: 2.066s, learning 0.093s)
             Mean action noise std: 2.88
          Mean value_function loss: 109.6484
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 76.2304
                       Mean reward: 425.01
               Mean episode length: 208.31
    Episode_Reward/reaching_object: 1.3852
    Episode_Reward/rotating_object: 81.2279
        Episode_Reward/action_rate: -0.0547
          Episode_Reward/joint_vel: -0.0400
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.6667
--------------------------------------------------------------------------------
                   Total timesteps: 71663616
                    Iteration time: 2.16s
                      Time elapsed: 00:28:15
                               ETA: 01:28:04

################################################################################
                     [1m Learning iteration 729/3000 [0m                      

                       Computation: 47240 steps/s (collection: 1.982s, learning 0.099s)
             Mean action noise std: 2.88
          Mean value_function loss: 118.8170
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 76.2515
                       Mean reward: 411.73
               Mean episode length: 208.19
    Episode_Reward/reaching_object: 1.4191
    Episode_Reward/rotating_object: 81.6467
        Episode_Reward/action_rate: -0.0557
          Episode_Reward/joint_vel: -0.0400
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.9583
--------------------------------------------------------------------------------
                   Total timesteps: 71761920
                    Iteration time: 2.08s
                      Time elapsed: 00:28:17
                               ETA: 01:28:00

################################################################################
                     [1m Learning iteration 730/3000 [0m                      

                       Computation: 46275 steps/s (collection: 2.004s, learning 0.120s)
             Mean action noise std: 2.88
          Mean value_function loss: 111.8952
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 76.2705
                       Mean reward: 426.34
               Mean episode length: 225.21
    Episode_Reward/reaching_object: 1.3946
    Episode_Reward/rotating_object: 82.5781
        Episode_Reward/action_rate: -0.0555
          Episode_Reward/joint_vel: -0.0401
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.3333
--------------------------------------------------------------------------------
                   Total timesteps: 71860224
                    Iteration time: 2.12s
                      Time elapsed: 00:28:19
                               ETA: 01:27:57

################################################################################
                     [1m Learning iteration 731/3000 [0m                      

                       Computation: 46526 steps/s (collection: 1.966s, learning 0.147s)
             Mean action noise std: 2.89
          Mean value_function loss: 110.2373
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 76.2883
                       Mean reward: 430.51
               Mean episode length: 207.91
    Episode_Reward/reaching_object: 1.4390
    Episode_Reward/rotating_object: 88.2076
        Episode_Reward/action_rate: -0.0567
          Episode_Reward/joint_vel: -0.0388
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.7500
--------------------------------------------------------------------------------
                   Total timesteps: 71958528
                    Iteration time: 2.11s
                      Time elapsed: 00:28:21
                               ETA: 01:27:54

################################################################################
                     [1m Learning iteration 732/3000 [0m                      

                       Computation: 44457 steps/s (collection: 2.047s, learning 0.164s)
             Mean action noise std: 2.89
          Mean value_function loss: 106.9189
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 76.3056
                       Mean reward: 430.36
               Mean episode length: 215.28
    Episode_Reward/reaching_object: 1.4405
    Episode_Reward/rotating_object: 87.5425
        Episode_Reward/action_rate: -0.0567
          Episode_Reward/joint_vel: -0.0396
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 72056832
                    Iteration time: 2.21s
                      Time elapsed: 00:28:23
                               ETA: 01:27:52

################################################################################
                     [1m Learning iteration 733/3000 [0m                      

                       Computation: 44191 steps/s (collection: 2.125s, learning 0.100s)
             Mean action noise std: 2.89
          Mean value_function loss: 116.9759
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 76.3098
                       Mean reward: 437.10
               Mean episode length: 215.17
    Episode_Reward/reaching_object: 1.3758
    Episode_Reward/rotating_object: 81.8394
        Episode_Reward/action_rate: -0.0546
          Episode_Reward/joint_vel: -0.0389
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.2917
--------------------------------------------------------------------------------
                   Total timesteps: 72155136
                    Iteration time: 2.22s
                      Time elapsed: 00:28:26
                               ETA: 01:27:49

################################################################################
                     [1m Learning iteration 734/3000 [0m                      

                       Computation: 48371 steps/s (collection: 1.941s, learning 0.092s)
             Mean action noise std: 2.89
          Mean value_function loss: 104.3145
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 76.3282
                       Mean reward: 458.50
               Mean episode length: 221.27
    Episode_Reward/reaching_object: 1.4154
    Episode_Reward/rotating_object: 87.4649
        Episode_Reward/action_rate: -0.0561
          Episode_Reward/joint_vel: -0.0377
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.6667
--------------------------------------------------------------------------------
                   Total timesteps: 72253440
                    Iteration time: 2.03s
                      Time elapsed: 00:28:28
                               ETA: 01:27:46

################################################################################
                     [1m Learning iteration 735/3000 [0m                      

                       Computation: 48551 steps/s (collection: 1.930s, learning 0.095s)
             Mean action noise std: 2.89
          Mean value_function loss: 107.3297
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 76.3474
                       Mean reward: 431.66
               Mean episode length: 202.53
    Episode_Reward/reaching_object: 1.3822
    Episode_Reward/rotating_object: 84.5652
        Episode_Reward/action_rate: -0.0552
          Episode_Reward/joint_vel: -0.0379
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.3750
--------------------------------------------------------------------------------
                   Total timesteps: 72351744
                    Iteration time: 2.02s
                      Time elapsed: 00:28:30
                               ETA: 01:27:43

################################################################################
                     [1m Learning iteration 736/3000 [0m                      

                       Computation: 47437 steps/s (collection: 1.956s, learning 0.117s)
             Mean action noise std: 2.90
          Mean value_function loss: 106.4182
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 76.3631
                       Mean reward: 429.60
               Mean episode length: 207.46
    Episode_Reward/reaching_object: 1.3821
    Episode_Reward/rotating_object: 84.6036
        Episode_Reward/action_rate: -0.0554
          Episode_Reward/joint_vel: -0.0378
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.9583
--------------------------------------------------------------------------------
                   Total timesteps: 72450048
                    Iteration time: 2.07s
                      Time elapsed: 00:28:32
                               ETA: 01:27:40

################################################################################
                     [1m Learning iteration 737/3000 [0m                      

                       Computation: 47192 steps/s (collection: 1.979s, learning 0.104s)
             Mean action noise std: 2.90
          Mean value_function loss: 108.3893
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 76.3816
                       Mean reward: 433.48
               Mean episode length: 213.60
    Episode_Reward/reaching_object: 1.4276
    Episode_Reward/rotating_object: 86.7139
        Episode_Reward/action_rate: -0.0570
          Episode_Reward/joint_vel: -0.0392
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 72548352
                    Iteration time: 2.08s
                      Time elapsed: 00:28:34
                               ETA: 01:27:37

################################################################################
                     [1m Learning iteration 738/3000 [0m                      

                       Computation: 47457 steps/s (collection: 1.974s, learning 0.098s)
             Mean action noise std: 2.90
          Mean value_function loss: 109.2137
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 76.4010
                       Mean reward: 449.93
               Mean episode length: 220.45
    Episode_Reward/reaching_object: 1.4338
    Episode_Reward/rotating_object: 88.7678
        Episode_Reward/action_rate: -0.0572
          Episode_Reward/joint_vel: -0.0393
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 72646656
                    Iteration time: 2.07s
                      Time elapsed: 00:28:36
                               ETA: 01:27:33

################################################################################
                     [1m Learning iteration 739/3000 [0m                      

                       Computation: 47815 steps/s (collection: 1.954s, learning 0.102s)
             Mean action noise std: 2.90
          Mean value_function loss: 113.8872
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 76.4279
                       Mean reward: 466.02
               Mean episode length: 218.73
    Episode_Reward/reaching_object: 1.4506
    Episode_Reward/rotating_object: 92.8506
        Episode_Reward/action_rate: -0.0578
          Episode_Reward/joint_vel: -0.0376
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 72744960
                    Iteration time: 2.06s
                      Time elapsed: 00:28:38
                               ETA: 01:27:30

################################################################################
                     [1m Learning iteration 740/3000 [0m                      

                       Computation: 47945 steps/s (collection: 1.936s, learning 0.115s)
             Mean action noise std: 2.90
          Mean value_function loss: 106.8246
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 76.4492
                       Mean reward: 476.32
               Mean episode length: 225.38
    Episode_Reward/reaching_object: 1.4157
    Episode_Reward/rotating_object: 84.8961
        Episode_Reward/action_rate: -0.0572
          Episode_Reward/joint_vel: -0.0395
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.6667
--------------------------------------------------------------------------------
                   Total timesteps: 72843264
                    Iteration time: 2.05s
                      Time elapsed: 00:28:40
                               ETA: 01:27:27

################################################################################
                     [1m Learning iteration 741/3000 [0m                      

                       Computation: 44290 steps/s (collection: 2.029s, learning 0.191s)
             Mean action noise std: 2.91
          Mean value_function loss: 108.6479
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 76.4748
                       Mean reward: 451.24
               Mean episode length: 212.25
    Episode_Reward/reaching_object: 1.3765
    Episode_Reward/rotating_object: 85.0165
        Episode_Reward/action_rate: -0.0557
          Episode_Reward/joint_vel: -0.0382
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.0833
--------------------------------------------------------------------------------
                   Total timesteps: 72941568
                    Iteration time: 2.22s
                      Time elapsed: 00:28:42
                               ETA: 01:27:25

################################################################################
                     [1m Learning iteration 742/3000 [0m                      

                       Computation: 44851 steps/s (collection: 2.029s, learning 0.163s)
             Mean action noise std: 2.91
          Mean value_function loss: 104.1291
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 76.5042
                       Mean reward: 456.85
               Mean episode length: 225.50
    Episode_Reward/reaching_object: 1.4079
    Episode_Reward/rotating_object: 89.2470
        Episode_Reward/action_rate: -0.0570
          Episode_Reward/joint_vel: -0.0382
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 73039872
                    Iteration time: 2.19s
                      Time elapsed: 00:28:44
                               ETA: 01:27:22

################################################################################
                     [1m Learning iteration 743/3000 [0m                      

                       Computation: 47171 steps/s (collection: 1.962s, learning 0.122s)
             Mean action noise std: 2.91
          Mean value_function loss: 99.2022
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 76.5264
                       Mean reward: 427.08
               Mean episode length: 209.65
    Episode_Reward/reaching_object: 1.3766
    Episode_Reward/rotating_object: 85.6913
        Episode_Reward/action_rate: -0.0561
          Episode_Reward/joint_vel: -0.0384
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.0417
--------------------------------------------------------------------------------
                   Total timesteps: 73138176
                    Iteration time: 2.08s
                      Time elapsed: 00:28:47
                               ETA: 01:27:19

################################################################################
                     [1m Learning iteration 744/3000 [0m                      

                       Computation: 48036 steps/s (collection: 1.930s, learning 0.117s)
             Mean action noise std: 2.92
          Mean value_function loss: 112.4163
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 76.5580
                       Mean reward: 438.38
               Mean episode length: 218.83
    Episode_Reward/reaching_object: 1.3999
    Episode_Reward/rotating_object: 88.8884
        Episode_Reward/action_rate: -0.0570
          Episode_Reward/joint_vel: -0.0373
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.7500
--------------------------------------------------------------------------------
                   Total timesteps: 73236480
                    Iteration time: 2.05s
                      Time elapsed: 00:28:49
                               ETA: 01:27:16

################################################################################
                     [1m Learning iteration 745/3000 [0m                      

                       Computation: 48259 steps/s (collection: 1.926s, learning 0.111s)
             Mean action noise std: 2.92
          Mean value_function loss: 104.2208
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 76.5864
                       Mean reward: 489.46
               Mean episode length: 224.61
    Episode_Reward/reaching_object: 1.4236
    Episode_Reward/rotating_object: 88.3552
        Episode_Reward/action_rate: -0.0578
          Episode_Reward/joint_vel: -0.0382
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 73334784
                    Iteration time: 2.04s
                      Time elapsed: 00:28:51
                               ETA: 01:27:12

################################################################################
                     [1m Learning iteration 746/3000 [0m                      

                       Computation: 47513 steps/s (collection: 1.973s, learning 0.096s)
             Mean action noise std: 2.92
          Mean value_function loss: 118.8545
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 76.6058
                       Mean reward: 415.84
               Mean episode length: 198.24
    Episode_Reward/reaching_object: 1.3310
    Episode_Reward/rotating_object: 85.1701
        Episode_Reward/action_rate: -0.0549
          Episode_Reward/joint_vel: -0.0369
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.6250
--------------------------------------------------------------------------------
                   Total timesteps: 73433088
                    Iteration time: 2.07s
                      Time elapsed: 00:28:53
                               ETA: 01:27:09

################################################################################
                     [1m Learning iteration 747/3000 [0m                      

                       Computation: 46480 steps/s (collection: 2.021s, learning 0.094s)
             Mean action noise std: 2.92
          Mean value_function loss: 110.7632
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 76.6175
                       Mean reward: 456.80
               Mean episode length: 222.52
    Episode_Reward/reaching_object: 1.3954
    Episode_Reward/rotating_object: 89.0243
        Episode_Reward/action_rate: -0.0573
          Episode_Reward/joint_vel: -0.0379
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.1667
--------------------------------------------------------------------------------
                   Total timesteps: 73531392
                    Iteration time: 2.11s
                      Time elapsed: 00:28:55
                               ETA: 01:27:06

################################################################################
                     [1m Learning iteration 748/3000 [0m                      

                       Computation: 47158 steps/s (collection: 1.983s, learning 0.102s)
             Mean action noise std: 2.93
          Mean value_function loss: 120.2903
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 76.6396
                       Mean reward: 450.99
               Mean episode length: 212.43
    Episode_Reward/reaching_object: 1.3705
    Episode_Reward/rotating_object: 88.8611
        Episode_Reward/action_rate: -0.0562
          Episode_Reward/joint_vel: -0.0372
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.3750
--------------------------------------------------------------------------------
                   Total timesteps: 73629696
                    Iteration time: 2.08s
                      Time elapsed: 00:28:57
                               ETA: 01:27:03

################################################################################
                     [1m Learning iteration 749/3000 [0m                      

                       Computation: 48473 steps/s (collection: 1.932s, learning 0.096s)
             Mean action noise std: 2.93
          Mean value_function loss: 120.4570
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 76.6650
                       Mean reward: 466.22
               Mean episode length: 218.28
    Episode_Reward/reaching_object: 1.3524
    Episode_Reward/rotating_object: 85.7113
        Episode_Reward/action_rate: -0.0559
          Episode_Reward/joint_vel: -0.0383
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.6250
--------------------------------------------------------------------------------
                   Total timesteps: 73728000
                    Iteration time: 2.03s
                      Time elapsed: 00:28:59
                               ETA: 01:27:00

################################################################################
                     [1m Learning iteration 750/3000 [0m                      

                       Computation: 47224 steps/s (collection: 1.963s, learning 0.118s)
             Mean action noise std: 2.93
          Mean value_function loss: 116.4616
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 76.6963
                       Mean reward: 430.02
               Mean episode length: 202.78
    Episode_Reward/reaching_object: 1.3607
    Episode_Reward/rotating_object: 87.6897
        Episode_Reward/action_rate: -0.0560
          Episode_Reward/joint_vel: -0.0371
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.6667
--------------------------------------------------------------------------------
                   Total timesteps: 73826304
                    Iteration time: 2.08s
                      Time elapsed: 00:29:01
                               ETA: 01:26:57

################################################################################
                     [1m Learning iteration 751/3000 [0m                      

                       Computation: 47720 steps/s (collection: 1.941s, learning 0.119s)
             Mean action noise std: 2.93
          Mean value_function loss: 121.6029
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 76.7279
                       Mean reward: 421.08
               Mean episode length: 206.80
    Episode_Reward/reaching_object: 1.3625
    Episode_Reward/rotating_object: 84.1658
        Episode_Reward/action_rate: -0.0562
          Episode_Reward/joint_vel: -0.0384
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.9167
--------------------------------------------------------------------------------
                   Total timesteps: 73924608
                    Iteration time: 2.06s
                      Time elapsed: 00:29:03
                               ETA: 01:26:54

################################################################################
                     [1m Learning iteration 752/3000 [0m                      

                       Computation: 45788 steps/s (collection: 2.051s, learning 0.096s)
             Mean action noise std: 2.94
          Mean value_function loss: 110.6500
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 76.7621
                       Mean reward: 464.93
               Mean episode length: 221.14
    Episode_Reward/reaching_object: 1.3579
    Episode_Reward/rotating_object: 87.7976
        Episode_Reward/action_rate: -0.0557
          Episode_Reward/joint_vel: -0.0371
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.2083
--------------------------------------------------------------------------------
                   Total timesteps: 74022912
                    Iteration time: 2.15s
                      Time elapsed: 00:29:05
                               ETA: 01:26:51

################################################################################
                     [1m Learning iteration 753/3000 [0m                      

                       Computation: 47577 steps/s (collection: 1.947s, learning 0.120s)
             Mean action noise std: 2.94
          Mean value_function loss: 112.6269
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 76.7977
                       Mean reward: 468.27
               Mean episode length: 213.44
    Episode_Reward/reaching_object: 1.4553
    Episode_Reward/rotating_object: 94.3095
        Episode_Reward/action_rate: -0.0594
          Episode_Reward/joint_vel: -0.0378
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 74121216
                    Iteration time: 2.07s
                      Time elapsed: 00:29:07
                               ETA: 01:26:48

################################################################################
                     [1m Learning iteration 754/3000 [0m                      

                       Computation: 46558 steps/s (collection: 2.003s, learning 0.108s)
             Mean action noise std: 2.94
          Mean value_function loss: 115.0000
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 76.8206
                       Mean reward: 473.86
               Mean episode length: 214.91
    Episode_Reward/reaching_object: 1.3815
    Episode_Reward/rotating_object: 86.7984
        Episode_Reward/action_rate: -0.0572
          Episode_Reward/joint_vel: -0.0382
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.5417
--------------------------------------------------------------------------------
                   Total timesteps: 74219520
                    Iteration time: 2.11s
                      Time elapsed: 00:29:09
                               ETA: 01:26:45

################################################################################
                     [1m Learning iteration 755/3000 [0m                      

                       Computation: 47549 steps/s (collection: 1.956s, learning 0.111s)
             Mean action noise std: 2.95
          Mean value_function loss: 114.4376
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 76.8432
                       Mean reward: 409.23
               Mean episode length: 208.39
    Episode_Reward/reaching_object: 1.3838
    Episode_Reward/rotating_object: 88.3221
        Episode_Reward/action_rate: -0.0575
          Episode_Reward/joint_vel: -0.0388
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.2083
--------------------------------------------------------------------------------
                   Total timesteps: 74317824
                    Iteration time: 2.07s
                      Time elapsed: 00:29:11
                               ETA: 01:26:42

################################################################################
                     [1m Learning iteration 756/3000 [0m                      

                       Computation: 46517 steps/s (collection: 1.994s, learning 0.119s)
             Mean action noise std: 2.95
          Mean value_function loss: 116.3695
               Mean surrogate loss: -0.0094
                 Mean entropy loss: 76.8677
                       Mean reward: 498.32
               Mean episode length: 223.10
    Episode_Reward/reaching_object: 1.4131
    Episode_Reward/rotating_object: 91.2277
        Episode_Reward/action_rate: -0.0584
          Episode_Reward/joint_vel: -0.0377
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.0000
--------------------------------------------------------------------------------
                   Total timesteps: 74416128
                    Iteration time: 2.11s
                      Time elapsed: 00:29:14
                               ETA: 01:26:39

################################################################################
                     [1m Learning iteration 757/3000 [0m                      

                       Computation: 47518 steps/s (collection: 1.970s, learning 0.099s)
             Mean action noise std: 2.95
          Mean value_function loss: 108.5874
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 76.8881
                       Mean reward: 485.24
               Mean episode length: 227.59
    Episode_Reward/reaching_object: 1.4229
    Episode_Reward/rotating_object: 89.9186
        Episode_Reward/action_rate: -0.0589
          Episode_Reward/joint_vel: -0.0388
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 74514432
                    Iteration time: 2.07s
                      Time elapsed: 00:29:16
                               ETA: 01:26:36

################################################################################
                     [1m Learning iteration 758/3000 [0m                      

                       Computation: 47392 steps/s (collection: 1.981s, learning 0.093s)
             Mean action noise std: 2.95
          Mean value_function loss: 114.6732
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 76.9097
                       Mean reward: 465.38
               Mean episode length: 211.84
    Episode_Reward/reaching_object: 1.3900
    Episode_Reward/rotating_object: 91.5303
        Episode_Reward/action_rate: -0.0578
          Episode_Reward/joint_vel: -0.0361
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.9583
--------------------------------------------------------------------------------
                   Total timesteps: 74612736
                    Iteration time: 2.07s
                      Time elapsed: 00:29:18
                               ETA: 01:26:33

################################################################################
                     [1m Learning iteration 759/3000 [0m                      

                       Computation: 48219 steps/s (collection: 1.944s, learning 0.095s)
             Mean action noise std: 2.96
          Mean value_function loss: 118.6108
               Mean surrogate loss: -0.0092
                 Mean entropy loss: 76.9369
                       Mean reward: 433.61
               Mean episode length: 201.97
    Episode_Reward/reaching_object: 1.4041
    Episode_Reward/rotating_object: 93.3337
        Episode_Reward/action_rate: -0.0584
          Episode_Reward/joint_vel: -0.0373
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.0833
--------------------------------------------------------------------------------
                   Total timesteps: 74711040
                    Iteration time: 2.04s
                      Time elapsed: 00:29:20
                               ETA: 01:26:30

################################################################################
                     [1m Learning iteration 760/3000 [0m                      

                       Computation: 47987 steps/s (collection: 1.952s, learning 0.097s)
             Mean action noise std: 2.96
          Mean value_function loss: 121.6361
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 76.9720
                       Mean reward: 473.17
               Mean episode length: 210.61
    Episode_Reward/reaching_object: 1.4006
    Episode_Reward/rotating_object: 91.2073
        Episode_Reward/action_rate: -0.0581
          Episode_Reward/joint_vel: -0.0385
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.1667
--------------------------------------------------------------------------------
                   Total timesteps: 74809344
                    Iteration time: 2.05s
                      Time elapsed: 00:29:22
                               ETA: 01:26:27

################################################################################
                     [1m Learning iteration 761/3000 [0m                      

                       Computation: 46375 steps/s (collection: 2.006s, learning 0.113s)
             Mean action noise std: 2.97
          Mean value_function loss: 115.6154
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 77.0078
                       Mean reward: 449.97
               Mean episode length: 211.12
    Episode_Reward/reaching_object: 1.3577
    Episode_Reward/rotating_object: 87.3330
        Episode_Reward/action_rate: -0.0567
          Episode_Reward/joint_vel: -0.0373
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.9167
--------------------------------------------------------------------------------
                   Total timesteps: 74907648
                    Iteration time: 2.12s
                      Time elapsed: 00:29:24
                               ETA: 01:26:24

################################################################################
                     [1m Learning iteration 762/3000 [0m                      

                       Computation: 46724 steps/s (collection: 2.001s, learning 0.103s)
             Mean action noise std: 2.97
          Mean value_function loss: 118.3444
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 77.0382
                       Mean reward: 488.12
               Mean episode length: 215.74
    Episode_Reward/reaching_object: 1.3938
    Episode_Reward/rotating_object: 93.8135
        Episode_Reward/action_rate: -0.0582
          Episode_Reward/joint_vel: -0.0367
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.8333
--------------------------------------------------------------------------------
                   Total timesteps: 75005952
                    Iteration time: 2.10s
                      Time elapsed: 00:29:26
                               ETA: 01:26:21

################################################################################
                     [1m Learning iteration 763/3000 [0m                      

                       Computation: 48383 steps/s (collection: 1.933s, learning 0.099s)
             Mean action noise std: 2.97
          Mean value_function loss: 112.2173
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 77.0728
                       Mean reward: 512.46
               Mean episode length: 225.28
    Episode_Reward/reaching_object: 1.4106
    Episode_Reward/rotating_object: 95.2169
        Episode_Reward/action_rate: -0.0594
          Episode_Reward/joint_vel: -0.0373
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 75104256
                    Iteration time: 2.03s
                      Time elapsed: 00:29:28
                               ETA: 01:26:18

################################################################################
                     [1m Learning iteration 764/3000 [0m                      

                       Computation: 47675 steps/s (collection: 1.955s, learning 0.107s)
             Mean action noise std: 2.97
          Mean value_function loss: 110.4210
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 77.0973
                       Mean reward: 475.87
               Mean episode length: 210.06
    Episode_Reward/reaching_object: 1.4139
    Episode_Reward/rotating_object: 92.8605
        Episode_Reward/action_rate: -0.0591
          Episode_Reward/joint_vel: -0.0369
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.8333
--------------------------------------------------------------------------------
                   Total timesteps: 75202560
                    Iteration time: 2.06s
                      Time elapsed: 00:29:30
                               ETA: 01:26:15

################################################################################
                     [1m Learning iteration 765/3000 [0m                      

                       Computation: 47873 steps/s (collection: 1.954s, learning 0.099s)
             Mean action noise std: 2.98
          Mean value_function loss: 105.1503
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 77.1230
                       Mean reward: 461.71
               Mean episode length: 208.98
    Episode_Reward/reaching_object: 1.4044
    Episode_Reward/rotating_object: 94.7660
        Episode_Reward/action_rate: -0.0594
          Episode_Reward/joint_vel: -0.0383
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.8333
--------------------------------------------------------------------------------
                   Total timesteps: 75300864
                    Iteration time: 2.05s
                      Time elapsed: 00:29:32
                               ETA: 01:26:12

################################################################################
                     [1m Learning iteration 766/3000 [0m                      

                       Computation: 45328 steps/s (collection: 2.034s, learning 0.135s)
             Mean action noise std: 2.98
          Mean value_function loss: 116.3770
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 77.1510
                       Mean reward: 495.34
               Mean episode length: 219.11
    Episode_Reward/reaching_object: 1.4152
    Episode_Reward/rotating_object: 95.5570
        Episode_Reward/action_rate: -0.0600
          Episode_Reward/joint_vel: -0.0371
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.7500
--------------------------------------------------------------------------------
                   Total timesteps: 75399168
                    Iteration time: 2.17s
                      Time elapsed: 00:29:34
                               ETA: 01:26:09

################################################################################
                     [1m Learning iteration 767/3000 [0m                      

                       Computation: 47300 steps/s (collection: 1.966s, learning 0.113s)
             Mean action noise std: 2.98
          Mean value_function loss: 117.3275
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 77.1783
                       Mean reward: 488.32
               Mean episode length: 217.36
    Episode_Reward/reaching_object: 1.4249
    Episode_Reward/rotating_object: 94.9938
        Episode_Reward/action_rate: -0.0601
          Episode_Reward/joint_vel: -0.0379
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 75497472
                    Iteration time: 2.08s
                      Time elapsed: 00:29:36
                               ETA: 01:26:06

################################################################################
                     [1m Learning iteration 768/3000 [0m                      

                       Computation: 48146 steps/s (collection: 1.940s, learning 0.102s)
             Mean action noise std: 2.99
          Mean value_function loss: 112.8693
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 77.2053
                       Mean reward: 494.06
               Mean episode length: 215.96
    Episode_Reward/reaching_object: 1.4450
    Episode_Reward/rotating_object: 98.4873
        Episode_Reward/action_rate: -0.0616
          Episode_Reward/joint_vel: -0.0379
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 75595776
                    Iteration time: 2.04s
                      Time elapsed: 00:29:38
                               ETA: 01:26:03

################################################################################
                     [1m Learning iteration 769/3000 [0m                      

                       Computation: 48028 steps/s (collection: 1.923s, learning 0.124s)
             Mean action noise std: 2.99
          Mean value_function loss: 117.8739
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 77.2287
                       Mean reward: 458.84
               Mean episode length: 210.64
    Episode_Reward/reaching_object: 1.3631
    Episode_Reward/rotating_object: 91.4797
        Episode_Reward/action_rate: -0.0579
          Episode_Reward/joint_vel: -0.0360
      Episode_Termination/time_out: 13.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.0833
--------------------------------------------------------------------------------
                   Total timesteps: 75694080
                    Iteration time: 2.05s
                      Time elapsed: 00:29:41
                               ETA: 01:26:00

################################################################################
                     [1m Learning iteration 770/3000 [0m                      

                       Computation: 48256 steps/s (collection: 1.944s, learning 0.093s)
             Mean action noise std: 2.99
          Mean value_function loss: 108.7680
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 77.2584
                       Mean reward: 473.39
               Mean episode length: 216.23
    Episode_Reward/reaching_object: 1.4400
    Episode_Reward/rotating_object: 96.5488
        Episode_Reward/action_rate: -0.0605
          Episode_Reward/joint_vel: -0.0361
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.6667
--------------------------------------------------------------------------------
                   Total timesteps: 75792384
                    Iteration time: 2.04s
                      Time elapsed: 00:29:43
                               ETA: 01:25:57

################################################################################
                     [1m Learning iteration 771/3000 [0m                      

                       Computation: 47596 steps/s (collection: 1.958s, learning 0.108s)
             Mean action noise std: 3.00
          Mean value_function loss: 114.4347
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 77.2875
                       Mean reward: 495.21
               Mean episode length: 218.93
    Episode_Reward/reaching_object: 1.4207
    Episode_Reward/rotating_object: 94.8784
        Episode_Reward/action_rate: -0.0600
          Episode_Reward/joint_vel: -0.0369
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.6667
--------------------------------------------------------------------------------
                   Total timesteps: 75890688
                    Iteration time: 2.07s
                      Time elapsed: 00:29:45
                               ETA: 01:25:54

################################################################################
                     [1m Learning iteration 772/3000 [0m                      

                       Computation: 48818 steps/s (collection: 1.924s, learning 0.090s)
             Mean action noise std: 3.00
          Mean value_function loss: 112.7951
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 77.3100
                       Mean reward: 480.35
               Mean episode length: 217.63
    Episode_Reward/reaching_object: 1.4605
    Episode_Reward/rotating_object: 100.6204
        Episode_Reward/action_rate: -0.0618
          Episode_Reward/joint_vel: -0.0365
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 75988992
                    Iteration time: 2.01s
                      Time elapsed: 00:29:47
                               ETA: 01:25:51

################################################################################
                     [1m Learning iteration 773/3000 [0m                      

                       Computation: 47713 steps/s (collection: 1.963s, learning 0.098s)
             Mean action noise std: 3.00
          Mean value_function loss: 104.9658
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 77.3329
                       Mean reward: 459.70
               Mean episode length: 213.97
    Episode_Reward/reaching_object: 1.4177
    Episode_Reward/rotating_object: 93.0516
        Episode_Reward/action_rate: -0.0600
          Episode_Reward/joint_vel: -0.0377
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 76087296
                    Iteration time: 2.06s
                      Time elapsed: 00:29:49
                               ETA: 01:25:48

################################################################################
                     [1m Learning iteration 774/3000 [0m                      

                       Computation: 47741 steps/s (collection: 1.952s, learning 0.107s)
             Mean action noise std: 3.00
          Mean value_function loss: 117.8036
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 77.3530
                       Mean reward: 499.54
               Mean episode length: 212.78
    Episode_Reward/reaching_object: 1.3807
    Episode_Reward/rotating_object: 94.8384
        Episode_Reward/action_rate: -0.0587
          Episode_Reward/joint_vel: -0.0365
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.1250
--------------------------------------------------------------------------------
                   Total timesteps: 76185600
                    Iteration time: 2.06s
                      Time elapsed: 00:29:51
                               ETA: 01:25:45

################################################################################
                     [1m Learning iteration 775/3000 [0m                      

                       Computation: 47011 steps/s (collection: 1.989s, learning 0.102s)
             Mean action noise std: 3.01
          Mean value_function loss: 106.8849
               Mean surrogate loss: -0.0101
                 Mean entropy loss: 77.3664
                       Mean reward: 511.47
               Mean episode length: 216.52
    Episode_Reward/reaching_object: 1.4355
    Episode_Reward/rotating_object: 98.2338
        Episode_Reward/action_rate: -0.0611
          Episode_Reward/joint_vel: -0.0366
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 76283904
                    Iteration time: 2.09s
                      Time elapsed: 00:29:53
                               ETA: 01:25:42

################################################################################
                     [1m Learning iteration 776/3000 [0m                      

                       Computation: 47058 steps/s (collection: 1.973s, learning 0.116s)
             Mean action noise std: 3.01
          Mean value_function loss: 113.3260
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 77.3825
                       Mean reward: 467.97
               Mean episode length: 212.61
    Episode_Reward/reaching_object: 1.4245
    Episode_Reward/rotating_object: 96.5701
        Episode_Reward/action_rate: -0.0608
          Episode_Reward/joint_vel: -0.0369
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 76382208
                    Iteration time: 2.09s
                      Time elapsed: 00:29:55
                               ETA: 01:25:39

################################################################################
                     [1m Learning iteration 777/3000 [0m                      

                       Computation: 48797 steps/s (collection: 1.915s, learning 0.099s)
             Mean action noise std: 3.01
          Mean value_function loss: 105.0177
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 77.4001
                       Mean reward: 533.89
               Mean episode length: 220.41
    Episode_Reward/reaching_object: 1.4020
    Episode_Reward/rotating_object: 97.4194
        Episode_Reward/action_rate: -0.0604
          Episode_Reward/joint_vel: -0.0370
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 76480512
                    Iteration time: 2.01s
                      Time elapsed: 00:29:57
                               ETA: 01:25:35

################################################################################
                     [1m Learning iteration 778/3000 [0m                      

                       Computation: 48283 steps/s (collection: 1.940s, learning 0.096s)
             Mean action noise std: 3.01
          Mean value_function loss: 107.0518
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 77.4336
                       Mean reward: 478.44
               Mean episode length: 215.90
    Episode_Reward/reaching_object: 1.4409
    Episode_Reward/rotating_object: 99.1656
        Episode_Reward/action_rate: -0.0620
          Episode_Reward/joint_vel: -0.0377
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 76578816
                    Iteration time: 2.04s
                      Time elapsed: 00:29:59
                               ETA: 01:25:32

################################################################################
                     [1m Learning iteration 779/3000 [0m                      

                       Computation: 48924 steps/s (collection: 1.913s, learning 0.097s)
             Mean action noise std: 3.02
          Mean value_function loss: 107.2038
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 77.4658
                       Mean reward: 477.85
               Mean episode length: 209.65
    Episode_Reward/reaching_object: 1.4357
    Episode_Reward/rotating_object: 99.2405
        Episode_Reward/action_rate: -0.0615
          Episode_Reward/joint_vel: -0.0368
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 76677120
                    Iteration time: 2.01s
                      Time elapsed: 00:30:01
                               ETA: 01:25:29

################################################################################
                     [1m Learning iteration 780/3000 [0m                      

                       Computation: 47685 steps/s (collection: 1.951s, learning 0.110s)
             Mean action noise std: 3.02
          Mean value_function loss: 104.0745
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 77.4923
                       Mean reward: 535.23
               Mean episode length: 222.74
    Episode_Reward/reaching_object: 1.4340
    Episode_Reward/rotating_object: 100.3171
        Episode_Reward/action_rate: -0.0620
          Episode_Reward/joint_vel: -0.0373
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 76775424
                    Iteration time: 2.06s
                      Time elapsed: 00:30:03
                               ETA: 01:25:26

################################################################################
                     [1m Learning iteration 781/3000 [0m                      

                       Computation: 47634 steps/s (collection: 1.955s, learning 0.108s)
             Mean action noise std: 3.02
          Mean value_function loss: 100.8568
               Mean surrogate loss: -0.0097
                 Mean entropy loss: 77.5268
                       Mean reward: 515.10
               Mean episode length: 216.60
    Episode_Reward/reaching_object: 1.3815
    Episode_Reward/rotating_object: 96.0045
        Episode_Reward/action_rate: -0.0600
          Episode_Reward/joint_vel: -0.0367
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 4.2500
--------------------------------------------------------------------------------
                   Total timesteps: 76873728
                    Iteration time: 2.06s
                      Time elapsed: 00:30:05
                               ETA: 01:25:23

################################################################################
                     [1m Learning iteration 782/3000 [0m                      

                       Computation: 46662 steps/s (collection: 1.990s, learning 0.117s)
             Mean action noise std: 3.03
          Mean value_function loss: 110.7560
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 77.5656
                       Mean reward: 528.05
               Mean episode length: 218.96
    Episode_Reward/reaching_object: 1.4231
    Episode_Reward/rotating_object: 101.2523
        Episode_Reward/action_rate: -0.0618
          Episode_Reward/joint_vel: -0.0359
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 76972032
                    Iteration time: 2.11s
                      Time elapsed: 00:30:07
                               ETA: 01:25:20

################################################################################
                     [1m Learning iteration 783/3000 [0m                      

                       Computation: 47458 steps/s (collection: 1.959s, learning 0.113s)
             Mean action noise std: 3.03
          Mean value_function loss: 112.7420
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 77.5917
                       Mean reward: 509.28
               Mean episode length: 219.10
    Episode_Reward/reaching_object: 1.4613
    Episode_Reward/rotating_object: 106.5318
        Episode_Reward/action_rate: -0.0634
          Episode_Reward/joint_vel: -0.0361
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 77070336
                    Iteration time: 2.07s
                      Time elapsed: 00:30:09
                               ETA: 01:25:17

################################################################################
                     [1m Learning iteration 784/3000 [0m                      

                       Computation: 47203 steps/s (collection: 1.956s, learning 0.127s)
             Mean action noise std: 3.03
          Mean value_function loss: 106.2710
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 77.6184
                       Mean reward: 468.65
               Mean episode length: 200.96
    Episode_Reward/reaching_object: 1.3181
    Episode_Reward/rotating_object: 91.0861
        Episode_Reward/action_rate: -0.0580
          Episode_Reward/joint_vel: -0.0356
      Episode_Termination/time_out: 13.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 4.6250
--------------------------------------------------------------------------------
                   Total timesteps: 77168640
                    Iteration time: 2.08s
                      Time elapsed: 00:30:11
                               ETA: 01:25:14

################################################################################
                     [1m Learning iteration 785/3000 [0m                      

                       Computation: 45562 steps/s (collection: 2.003s, learning 0.154s)
             Mean action noise std: 3.04
          Mean value_function loss: 109.0271
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 77.6533
                       Mean reward: 524.53
               Mean episode length: 219.22
    Episode_Reward/reaching_object: 1.4324
    Episode_Reward/rotating_object: 100.9278
        Episode_Reward/action_rate: -0.0624
          Episode_Reward/joint_vel: -0.0365
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 77266944
                    Iteration time: 2.16s
                      Time elapsed: 00:30:14
                               ETA: 01:25:12

################################################################################
                     [1m Learning iteration 786/3000 [0m                      

                       Computation: 45880 steps/s (collection: 1.972s, learning 0.171s)
             Mean action noise std: 3.04
          Mean value_function loss: 110.5678
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 77.6794
                       Mean reward: 485.33
               Mean episode length: 209.50
    Episode_Reward/reaching_object: 1.3949
    Episode_Reward/rotating_object: 98.4047
        Episode_Reward/action_rate: -0.0608
          Episode_Reward/joint_vel: -0.0352
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 77365248
                    Iteration time: 2.14s
                      Time elapsed: 00:30:16
                               ETA: 01:25:09

################################################################################
                     [1m Learning iteration 787/3000 [0m                      

                       Computation: 48642 steps/s (collection: 1.921s, learning 0.100s)
             Mean action noise std: 3.04
          Mean value_function loss: 103.3285
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 77.6978
                       Mean reward: 491.76
               Mean episode length: 212.86
    Episode_Reward/reaching_object: 1.4205
    Episode_Reward/rotating_object: 100.4915
        Episode_Reward/action_rate: -0.0626
          Episode_Reward/joint_vel: -0.0366
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 77463552
                    Iteration time: 2.02s
                      Time elapsed: 00:30:18
                               ETA: 01:25:06

################################################################################
                     [1m Learning iteration 788/3000 [0m                      

                       Computation: 47438 steps/s (collection: 1.968s, learning 0.104s)
             Mean action noise std: 3.04
          Mean value_function loss: 98.0229
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 77.7134
                       Mean reward: 533.68
               Mean episode length: 223.42
    Episode_Reward/reaching_object: 1.3984
    Episode_Reward/rotating_object: 100.8542
        Episode_Reward/action_rate: -0.0619
          Episode_Reward/joint_vel: -0.0359
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.6667
--------------------------------------------------------------------------------
                   Total timesteps: 77561856
                    Iteration time: 2.07s
                      Time elapsed: 00:30:20
                               ETA: 01:25:03

################################################################################
                     [1m Learning iteration 789/3000 [0m                      

                       Computation: 48111 steps/s (collection: 1.945s, learning 0.098s)
             Mean action noise std: 3.05
          Mean value_function loss: 104.2173
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 77.7303
                       Mean reward: 495.73
               Mean episode length: 209.14
    Episode_Reward/reaching_object: 1.3713
    Episode_Reward/rotating_object: 96.2435
        Episode_Reward/action_rate: -0.0607
          Episode_Reward/joint_vel: -0.0359
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 77660160
                    Iteration time: 2.04s
                      Time elapsed: 00:30:22
                               ETA: 01:25:00

################################################################################
                     [1m Learning iteration 790/3000 [0m                      

                       Computation: 44646 steps/s (collection: 2.069s, learning 0.132s)
             Mean action noise std: 3.05
          Mean value_function loss: 101.0347
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 77.7527
                       Mean reward: 513.07
               Mean episode length: 217.37
    Episode_Reward/reaching_object: 1.4149
    Episode_Reward/rotating_object: 101.8141
        Episode_Reward/action_rate: -0.0621
          Episode_Reward/joint_vel: -0.0351
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 77758464
                    Iteration time: 2.20s
                      Time elapsed: 00:30:24
                               ETA: 01:24:57

################################################################################
                     [1m Learning iteration 791/3000 [0m                      

                       Computation: 46753 steps/s (collection: 2.011s, learning 0.092s)
             Mean action noise std: 3.05
          Mean value_function loss: 105.9664
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 77.7855
                       Mean reward: 495.02
               Mean episode length: 214.34
    Episode_Reward/reaching_object: 1.4601
    Episode_Reward/rotating_object: 102.2966
        Episode_Reward/action_rate: -0.0647
          Episode_Reward/joint_vel: -0.0389
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 77856768
                    Iteration time: 2.10s
                      Time elapsed: 00:30:26
                               ETA: 01:24:54

################################################################################
                     [1m Learning iteration 792/3000 [0m                      

                       Computation: 48417 steps/s (collection: 1.930s, learning 0.101s)
             Mean action noise std: 3.06
          Mean value_function loss: 101.9936
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 77.8080
                       Mean reward: 517.73
               Mean episode length: 227.91
    Episode_Reward/reaching_object: 1.4390
    Episode_Reward/rotating_object: 102.7650
        Episode_Reward/action_rate: -0.0638
          Episode_Reward/joint_vel: -0.0372
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 77955072
                    Iteration time: 2.03s
                      Time elapsed: 00:30:28
                               ETA: 01:24:51

################################################################################
                     [1m Learning iteration 793/3000 [0m                      

                       Computation: 48815 steps/s (collection: 1.914s, learning 0.100s)
             Mean action noise std: 3.06
          Mean value_function loss: 107.1819
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 77.8318
                       Mean reward: 518.03
               Mean episode length: 214.67
    Episode_Reward/reaching_object: 1.3646
    Episode_Reward/rotating_object: 98.3805
        Episode_Reward/action_rate: -0.0610
          Episode_Reward/joint_vel: -0.0351
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.9167
--------------------------------------------------------------------------------
                   Total timesteps: 78053376
                    Iteration time: 2.01s
                      Time elapsed: 00:30:30
                               ETA: 01:24:48

################################################################################
                     [1m Learning iteration 794/3000 [0m                      

                       Computation: 48553 steps/s (collection: 1.917s, learning 0.108s)
             Mean action noise std: 3.06
          Mean value_function loss: 105.4826
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 77.8635
                       Mean reward: 512.67
               Mean episode length: 214.05
    Episode_Reward/reaching_object: 1.4061
    Episode_Reward/rotating_object: 101.5495
        Episode_Reward/action_rate: -0.0626
          Episode_Reward/joint_vel: -0.0356
      Episode_Termination/time_out: 14.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 78151680
                    Iteration time: 2.02s
                      Time elapsed: 00:30:32
                               ETA: 01:24:45

################################################################################
                     [1m Learning iteration 795/3000 [0m                      

                       Computation: 47377 steps/s (collection: 1.973s, learning 0.102s)
             Mean action noise std: 3.07
          Mean value_function loss: 96.2740
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 77.8847
                       Mean reward: 521.16
               Mean episode length: 219.74
    Episode_Reward/reaching_object: 1.4096
    Episode_Reward/rotating_object: 102.2686
        Episode_Reward/action_rate: -0.0632
          Episode_Reward/joint_vel: -0.0374
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 78249984
                    Iteration time: 2.07s
                      Time elapsed: 00:30:34
                               ETA: 01:24:42

################################################################################
                     [1m Learning iteration 796/3000 [0m                      

                       Computation: 47778 steps/s (collection: 1.953s, learning 0.105s)
             Mean action noise std: 3.07
          Mean value_function loss: 104.4272
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 77.9139
                       Mean reward: 539.09
               Mean episode length: 227.79
    Episode_Reward/reaching_object: 1.4327
    Episode_Reward/rotating_object: 103.1696
        Episode_Reward/action_rate: -0.0642
          Episode_Reward/joint_vel: -0.0364
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 78348288
                    Iteration time: 2.06s
                      Time elapsed: 00:30:36
                               ETA: 01:24:39

################################################################################
                     [1m Learning iteration 797/3000 [0m                      

                       Computation: 46050 steps/s (collection: 2.008s, learning 0.127s)
             Mean action noise std: 3.07
          Mean value_function loss: 103.5656
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 77.9397
                       Mean reward: 478.71
               Mean episode length: 211.30
    Episode_Reward/reaching_object: 1.3875
    Episode_Reward/rotating_object: 99.6320
        Episode_Reward/action_rate: -0.0627
          Episode_Reward/joint_vel: -0.0372
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 78446592
                    Iteration time: 2.13s
                      Time elapsed: 00:30:38
                               ETA: 01:24:36

################################################################################
                     [1m Learning iteration 798/3000 [0m                      

                       Computation: 41822 steps/s (collection: 2.058s, learning 0.293s)
             Mean action noise std: 3.07
          Mean value_function loss: 103.6903
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 77.9565
                       Mean reward: 530.45
               Mean episode length: 214.02
    Episode_Reward/reaching_object: 1.3900
    Episode_Reward/rotating_object: 101.4651
        Episode_Reward/action_rate: -0.0632
          Episode_Reward/joint_vel: -0.0356
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 78544896
                    Iteration time: 2.35s
                      Time elapsed: 00:30:41
                               ETA: 01:24:34

################################################################################
                     [1m Learning iteration 799/3000 [0m                      

                       Computation: 44555 steps/s (collection: 2.108s, learning 0.098s)
             Mean action noise std: 3.08
          Mean value_function loss: 101.4184
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 77.9740
                       Mean reward: 494.41
               Mean episode length: 212.75
    Episode_Reward/reaching_object: 1.4302
    Episode_Reward/rotating_object: 99.7549
        Episode_Reward/action_rate: -0.0643
          Episode_Reward/joint_vel: -0.0379
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 78643200
                    Iteration time: 2.21s
                      Time elapsed: 00:30:43
                               ETA: 01:24:32

################################################################################
                     [1m Learning iteration 800/3000 [0m                      

                       Computation: 47203 steps/s (collection: 1.958s, learning 0.125s)
             Mean action noise std: 3.08
          Mean value_function loss: 107.9755
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 77.9914
                       Mean reward: 541.03
               Mean episode length: 222.12
    Episode_Reward/reaching_object: 1.4109
    Episode_Reward/rotating_object: 102.2930
        Episode_Reward/action_rate: -0.0638
          Episode_Reward/joint_vel: -0.0352
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 78741504
                    Iteration time: 2.08s
                      Time elapsed: 00:30:45
                               ETA: 01:24:29

################################################################################
                     [1m Learning iteration 801/3000 [0m                      

                       Computation: 47018 steps/s (collection: 1.992s, learning 0.099s)
             Mean action noise std: 3.08
          Mean value_function loss: 104.8697
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 78.0123
                       Mean reward: 532.68
               Mean episode length: 218.94
    Episode_Reward/reaching_object: 1.4343
    Episode_Reward/rotating_object: 105.7741
        Episode_Reward/action_rate: -0.0651
          Episode_Reward/joint_vel: -0.0367
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 78839808
                    Iteration time: 2.09s
                      Time elapsed: 00:30:47
                               ETA: 01:24:26

################################################################################
                     [1m Learning iteration 802/3000 [0m                      

                       Computation: 47515 steps/s (collection: 1.966s, learning 0.103s)
             Mean action noise std: 3.08
          Mean value_function loss: 99.7659
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 78.0296
                       Mean reward: 479.76
               Mean episode length: 213.40
    Episode_Reward/reaching_object: 1.4507
    Episode_Reward/rotating_object: 106.1823
        Episode_Reward/action_rate: -0.0656
          Episode_Reward/joint_vel: -0.0368
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 78938112
                    Iteration time: 2.07s
                      Time elapsed: 00:30:49
                               ETA: 01:24:23

################################################################################
                     [1m Learning iteration 803/3000 [0m                      

                       Computation: 47554 steps/s (collection: 1.972s, learning 0.095s)
             Mean action noise std: 3.08
          Mean value_function loss: 115.2408
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 78.0388
                       Mean reward: 541.10
               Mean episode length: 227.30
    Episode_Reward/reaching_object: 1.3934
    Episode_Reward/rotating_object: 102.0021
        Episode_Reward/action_rate: -0.0637
          Episode_Reward/joint_vel: -0.0366
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 79036416
                    Iteration time: 2.07s
                      Time elapsed: 00:30:51
                               ETA: 01:24:20

################################################################################
                     [1m Learning iteration 804/3000 [0m                      

                       Computation: 46590 steps/s (collection: 2.016s, learning 0.094s)
             Mean action noise std: 3.08
          Mean value_function loss: 102.9311
               Mean surrogate loss: -0.0093
                 Mean entropy loss: 78.0485
                       Mean reward: 490.94
               Mean episode length: 214.12
    Episode_Reward/reaching_object: 1.4127
    Episode_Reward/rotating_object: 99.9094
        Episode_Reward/action_rate: -0.0638
          Episode_Reward/joint_vel: -0.0358
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 79134720
                    Iteration time: 2.11s
                      Time elapsed: 00:30:53
                               ETA: 01:24:17

################################################################################
                     [1m Learning iteration 805/3000 [0m                      

                       Computation: 43531 steps/s (collection: 2.091s, learning 0.167s)
             Mean action noise std: 3.09
          Mean value_function loss: 104.7607
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 78.0636
                       Mean reward: 542.22
               Mean episode length: 217.81
    Episode_Reward/reaching_object: 1.4572
    Episode_Reward/rotating_object: 106.2635
        Episode_Reward/action_rate: -0.0656
          Episode_Reward/joint_vel: -0.0372
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 79233024
                    Iteration time: 2.26s
                      Time elapsed: 00:30:56
                               ETA: 01:24:15

################################################################################
                     [1m Learning iteration 806/3000 [0m                      

                       Computation: 48043 steps/s (collection: 1.937s, learning 0.109s)
             Mean action noise std: 3.09
          Mean value_function loss: 95.7300
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 78.0837
                       Mean reward: 527.57
               Mean episode length: 224.92
    Episode_Reward/reaching_object: 1.4724
    Episode_Reward/rotating_object: 104.6847
        Episode_Reward/action_rate: -0.0663
          Episode_Reward/joint_vel: -0.0377
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 79331328
                    Iteration time: 2.05s
                      Time elapsed: 00:30:58
                               ETA: 01:24:12

################################################################################
                     [1m Learning iteration 807/3000 [0m                      

                       Computation: 47304 steps/s (collection: 1.968s, learning 0.110s)
             Mean action noise std: 3.09
          Mean value_function loss: 104.3910
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 78.1104
                       Mean reward: 539.92
               Mean episode length: 220.13
    Episode_Reward/reaching_object: 1.4347
    Episode_Reward/rotating_object: 103.4692
        Episode_Reward/action_rate: -0.0649
          Episode_Reward/joint_vel: -0.0364
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 79429632
                    Iteration time: 2.08s
                      Time elapsed: 00:31:00
                               ETA: 01:24:09

################################################################################
                     [1m Learning iteration 808/3000 [0m                      

                       Computation: 47026 steps/s (collection: 1.971s, learning 0.120s)
             Mean action noise std: 3.10
          Mean value_function loss: 107.2360
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 78.1290
                       Mean reward: 507.63
               Mean episode length: 206.74
    Episode_Reward/reaching_object: 1.4420
    Episode_Reward/rotating_object: 104.5941
        Episode_Reward/action_rate: -0.0648
          Episode_Reward/joint_vel: -0.0355
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 79527936
                    Iteration time: 2.09s
                      Time elapsed: 00:31:02
                               ETA: 01:24:06

################################################################################
                     [1m Learning iteration 809/3000 [0m                      

                       Computation: 45560 steps/s (collection: 2.064s, learning 0.094s)
             Mean action noise std: 3.10
          Mean value_function loss: 104.0726
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 78.1479
                       Mean reward: 533.54
               Mean episode length: 221.58
    Episode_Reward/reaching_object: 1.4456
    Episode_Reward/rotating_object: 103.8822
        Episode_Reward/action_rate: -0.0654
          Episode_Reward/joint_vel: -0.0365
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 79626240
                    Iteration time: 2.16s
                      Time elapsed: 00:31:04
                               ETA: 01:24:03

################################################################################
                     [1m Learning iteration 810/3000 [0m                      

                       Computation: 47305 steps/s (collection: 1.975s, learning 0.103s)
             Mean action noise std: 3.10
          Mean value_function loss: 98.1811
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 78.1764
                       Mean reward: 527.10
               Mean episode length: 216.10
    Episode_Reward/reaching_object: 1.4052
    Episode_Reward/rotating_object: 100.6637
        Episode_Reward/action_rate: -0.0638
          Episode_Reward/joint_vel: -0.0358
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.8750
--------------------------------------------------------------------------------
                   Total timesteps: 79724544
                    Iteration time: 2.08s
                      Time elapsed: 00:31:06
                               ETA: 01:24:00

################################################################################
                     [1m Learning iteration 811/3000 [0m                      

                       Computation: 47298 steps/s (collection: 1.961s, learning 0.118s)
             Mean action noise std: 3.10
          Mean value_function loss: 104.8548
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 78.1972
                       Mean reward: 564.69
               Mean episode length: 225.05
    Episode_Reward/reaching_object: 1.4597
    Episode_Reward/rotating_object: 105.8976
        Episode_Reward/action_rate: -0.0657
          Episode_Reward/joint_vel: -0.0362
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 79822848
                    Iteration time: 2.08s
                      Time elapsed: 00:31:08
                               ETA: 01:23:57

################################################################################
                     [1m Learning iteration 812/3000 [0m                      

                       Computation: 48112 steps/s (collection: 1.932s, learning 0.111s)
             Mean action noise std: 3.11
          Mean value_function loss: 96.0648
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 78.2197
                       Mean reward: 564.32
               Mean episode length: 224.12
    Episode_Reward/reaching_object: 1.4565
    Episode_Reward/rotating_object: 109.6984
        Episode_Reward/action_rate: -0.0664
          Episode_Reward/joint_vel: -0.0358
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 79921152
                    Iteration time: 2.04s
                      Time elapsed: 00:31:10
                               ETA: 01:23:54

################################################################################
                     [1m Learning iteration 813/3000 [0m                      

                       Computation: 46160 steps/s (collection: 1.967s, learning 0.163s)
             Mean action noise std: 3.11
          Mean value_function loss: 103.2353
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 78.2426
                       Mean reward: 569.36
               Mean episode length: 225.12
    Episode_Reward/reaching_object: 1.4156
    Episode_Reward/rotating_object: 108.5710
        Episode_Reward/action_rate: -0.0650
          Episode_Reward/joint_vel: -0.0342
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 80019456
                    Iteration time: 2.13s
                      Time elapsed: 00:31:12
                               ETA: 01:23:52

################################################################################
                     [1m Learning iteration 814/3000 [0m                      

                       Computation: 46538 steps/s (collection: 1.997s, learning 0.115s)
             Mean action noise std: 3.11
          Mean value_function loss: 96.5760
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 78.2586
                       Mean reward: 537.56
               Mean episode length: 222.48
    Episode_Reward/reaching_object: 1.4585
    Episode_Reward/rotating_object: 109.4518
        Episode_Reward/action_rate: -0.0670
          Episode_Reward/joint_vel: -0.0354
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 80117760
                    Iteration time: 2.11s
                      Time elapsed: 00:31:15
                               ETA: 01:23:49

################################################################################
                     [1m Learning iteration 815/3000 [0m                      

                       Computation: 48347 steps/s (collection: 1.931s, learning 0.102s)
             Mean action noise std: 3.11
          Mean value_function loss: 99.6071
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 78.2836
                       Mean reward: 586.01
               Mean episode length: 234.53
    Episode_Reward/reaching_object: 1.4178
    Episode_Reward/rotating_object: 106.8009
        Episode_Reward/action_rate: -0.0658
          Episode_Reward/joint_vel: -0.0358
      Episode_Termination/time_out: 14.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 80216064
                    Iteration time: 2.03s
                      Time elapsed: 00:31:17
                               ETA: 01:23:46

################################################################################
                     [1m Learning iteration 816/3000 [0m                      

                       Computation: 48206 steps/s (collection: 1.935s, learning 0.104s)
             Mean action noise std: 3.12
          Mean value_function loss: 92.9015
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 78.3073
                       Mean reward: 556.86
               Mean episode length: 226.71
    Episode_Reward/reaching_object: 1.4229
    Episode_Reward/rotating_object: 106.0893
        Episode_Reward/action_rate: -0.0661
          Episode_Reward/joint_vel: -0.0360
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 80314368
                    Iteration time: 2.04s
                      Time elapsed: 00:31:19
                               ETA: 01:23:43

################################################################################
                     [1m Learning iteration 817/3000 [0m                      

                       Computation: 47685 steps/s (collection: 1.933s, learning 0.128s)
             Mean action noise std: 3.12
          Mean value_function loss: 95.7507
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 78.3313
                       Mean reward: 494.73
               Mean episode length: 204.41
    Episode_Reward/reaching_object: 1.4072
    Episode_Reward/rotating_object: 105.1096
        Episode_Reward/action_rate: -0.0658
          Episode_Reward/joint_vel: -0.0364
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 80412672
                    Iteration time: 2.06s
                      Time elapsed: 00:31:21
                               ETA: 01:23:40

################################################################################
                     [1m Learning iteration 818/3000 [0m                      

                       Computation: 44235 steps/s (collection: 2.012s, learning 0.211s)
             Mean action noise std: 3.12
          Mean value_function loss: 103.1157
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 78.3553
                       Mean reward: 584.25
               Mean episode length: 234.61
    Episode_Reward/reaching_object: 1.4576
    Episode_Reward/rotating_object: 109.5872
        Episode_Reward/action_rate: -0.0674
          Episode_Reward/joint_vel: -0.0363
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 80510976
                    Iteration time: 2.22s
                      Time elapsed: 00:31:23
                               ETA: 01:23:37

################################################################################
                     [1m Learning iteration 819/3000 [0m                      

                       Computation: 45193 steps/s (collection: 2.044s, learning 0.132s)
             Mean action noise std: 3.13
          Mean value_function loss: 104.3870
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 78.3897
                       Mean reward: 555.77
               Mean episode length: 219.79
    Episode_Reward/reaching_object: 1.4535
    Episode_Reward/rotating_object: 107.0251
        Episode_Reward/action_rate: -0.0673
          Episode_Reward/joint_vel: -0.0376
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 80609280
                    Iteration time: 2.18s
                      Time elapsed: 00:31:25
                               ETA: 01:23:35

################################################################################
                     [1m Learning iteration 820/3000 [0m                      

                       Computation: 47307 steps/s (collection: 1.980s, learning 0.098s)
             Mean action noise std: 3.13
          Mean value_function loss: 95.5423
               Mean surrogate loss: -0.0002
                 Mean entropy loss: 78.4097
                       Mean reward: 581.23
               Mean episode length: 226.84
    Episode_Reward/reaching_object: 1.4785
    Episode_Reward/rotating_object: 112.3099
        Episode_Reward/action_rate: -0.0684
          Episode_Reward/joint_vel: -0.0359
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 80707584
                    Iteration time: 2.08s
                      Time elapsed: 00:31:27
                               ETA: 01:23:32

################################################################################
                     [1m Learning iteration 821/3000 [0m                      

                       Computation: 48840 steps/s (collection: 1.908s, learning 0.105s)
             Mean action noise std: 3.13
          Mean value_function loss: 99.0126
               Mean surrogate loss: -0.0090
                 Mean entropy loss: 78.4158
                       Mean reward: 574.08
               Mean episode length: 229.89
    Episode_Reward/reaching_object: 1.5262
    Episode_Reward/rotating_object: 113.0536
        Episode_Reward/action_rate: -0.0697
          Episode_Reward/joint_vel: -0.0366
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 80805888
                    Iteration time: 2.01s
                      Time elapsed: 00:31:29
                               ETA: 01:23:29

################################################################################
                     [1m Learning iteration 822/3000 [0m                      

                       Computation: 47146 steps/s (collection: 1.990s, learning 0.095s)
             Mean action noise std: 3.13
          Mean value_function loss: 96.4130
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 78.4351
                       Mean reward: 548.92
               Mean episode length: 225.06
    Episode_Reward/reaching_object: 1.4687
    Episode_Reward/rotating_object: 111.0713
        Episode_Reward/action_rate: -0.0675
          Episode_Reward/joint_vel: -0.0356
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 80904192
                    Iteration time: 2.09s
                      Time elapsed: 00:31:31
                               ETA: 01:23:26

################################################################################
                     [1m Learning iteration 823/3000 [0m                      

                       Computation: 47573 steps/s (collection: 1.955s, learning 0.112s)
             Mean action noise std: 3.14
          Mean value_function loss: 100.4136
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 78.4651
                       Mean reward: 580.40
               Mean episode length: 232.33
    Episode_Reward/reaching_object: 1.4748
    Episode_Reward/rotating_object: 106.4469
        Episode_Reward/action_rate: -0.0673
          Episode_Reward/joint_vel: -0.0358
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 81002496
                    Iteration time: 2.07s
                      Time elapsed: 00:31:33
                               ETA: 01:23:23

################################################################################
                     [1m Learning iteration 824/3000 [0m                      

                       Computation: 47206 steps/s (collection: 1.978s, learning 0.105s)
             Mean action noise std: 3.14
          Mean value_function loss: 97.8275
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 78.4943
                       Mean reward: 588.81
               Mean episode length: 230.57
    Episode_Reward/reaching_object: 1.4896
    Episode_Reward/rotating_object: 112.3008
        Episode_Reward/action_rate: -0.0686
          Episode_Reward/joint_vel: -0.0351
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 81100800
                    Iteration time: 2.08s
                      Time elapsed: 00:31:35
                               ETA: 01:23:20

################################################################################
                     [1m Learning iteration 825/3000 [0m                      

                       Computation: 46385 steps/s (collection: 1.995s, learning 0.124s)
             Mean action noise std: 3.14
          Mean value_function loss: 90.9374
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 78.5070
                       Mean reward: 576.36
               Mean episode length: 228.91
    Episode_Reward/reaching_object: 1.5050
    Episode_Reward/rotating_object: 112.8242
        Episode_Reward/action_rate: -0.0689
          Episode_Reward/joint_vel: -0.0359
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 81199104
                    Iteration time: 2.12s
                      Time elapsed: 00:31:38
                               ETA: 01:23:17

################################################################################
                     [1m Learning iteration 826/3000 [0m                      

                       Computation: 47124 steps/s (collection: 1.983s, learning 0.103s)
             Mean action noise std: 3.14
          Mean value_function loss: 98.8172
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 78.5239
                       Mean reward: 555.76
               Mean episode length: 228.81
    Episode_Reward/reaching_object: 1.5272
    Episode_Reward/rotating_object: 111.6599
        Episode_Reward/action_rate: -0.0700
          Episode_Reward/joint_vel: -0.0366
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 81297408
                    Iteration time: 2.09s
                      Time elapsed: 00:31:40
                               ETA: 01:23:14

################################################################################
                     [1m Learning iteration 827/3000 [0m                      

                       Computation: 48232 steps/s (collection: 1.941s, learning 0.098s)
             Mean action noise std: 3.15
          Mean value_function loss: 103.1689
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 78.5409
                       Mean reward: 585.88
               Mean episode length: 221.60
    Episode_Reward/reaching_object: 1.4635
    Episode_Reward/rotating_object: 111.4261
        Episode_Reward/action_rate: -0.0676
          Episode_Reward/joint_vel: -0.0349
      Episode_Termination/time_out: 17.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 81395712
                    Iteration time: 2.04s
                      Time elapsed: 00:31:42
                               ETA: 01:23:11

################################################################################
                     [1m Learning iteration 828/3000 [0m                      

                       Computation: 47546 steps/s (collection: 1.967s, learning 0.101s)
             Mean action noise std: 3.15
          Mean value_function loss: 107.4602
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 78.5704
                       Mean reward: 578.66
               Mean episode length: 223.93
    Episode_Reward/reaching_object: 1.3995
    Episode_Reward/rotating_object: 105.9696
        Episode_Reward/action_rate: -0.0651
          Episode_Reward/joint_vel: -0.0340
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.5833
--------------------------------------------------------------------------------
                   Total timesteps: 81494016
                    Iteration time: 2.07s
                      Time elapsed: 00:31:44
                               ETA: 01:23:09

################################################################################
                     [1m Learning iteration 829/3000 [0m                      

                       Computation: 48261 steps/s (collection: 1.940s, learning 0.097s)
             Mean action noise std: 3.15
          Mean value_function loss: 106.0265
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 78.5991
                       Mean reward: 529.11
               Mean episode length: 216.25
    Episode_Reward/reaching_object: 1.4397
    Episode_Reward/rotating_object: 105.9877
        Episode_Reward/action_rate: -0.0667
          Episode_Reward/joint_vel: -0.0345
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 81592320
                    Iteration time: 2.04s
                      Time elapsed: 00:31:46
                               ETA: 01:23:06

################################################################################
                     [1m Learning iteration 830/3000 [0m                      

                       Computation: 44166 steps/s (collection: 2.004s, learning 0.222s)
             Mean action noise std: 3.15
          Mean value_function loss: 95.3928
               Mean surrogate loss: 0.0174
                 Mean entropy loss: 78.6232
                       Mean reward: 511.01
               Mean episode length: 205.24
    Episode_Reward/reaching_object: 1.4910
    Episode_Reward/rotating_object: 112.9772
        Episode_Reward/action_rate: -0.0691
          Episode_Reward/joint_vel: -0.0353
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 81690624
                    Iteration time: 2.23s
                      Time elapsed: 00:31:48
                               ETA: 01:23:03

################################################################################
                     [1m Learning iteration 831/3000 [0m                      

                       Computation: 45915 steps/s (collection: 2.016s, learning 0.125s)
             Mean action noise std: 3.15
          Mean value_function loss: 96.7174
               Mean surrogate loss: 0.0006
                 Mean entropy loss: 78.6289
                       Mean reward: 561.34
               Mean episode length: 221.05
    Episode_Reward/reaching_object: 1.4636
    Episode_Reward/rotating_object: 107.8203
        Episode_Reward/action_rate: -0.0678
          Episode_Reward/joint_vel: -0.0366
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 81788928
                    Iteration time: 2.14s
                      Time elapsed: 00:31:50
                               ETA: 01:23:00

################################################################################
                     [1m Learning iteration 832/3000 [0m                      

                       Computation: 47113 steps/s (collection: 1.991s, learning 0.095s)
             Mean action noise std: 3.16
          Mean value_function loss: 104.5894
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 78.6336
                       Mean reward: 549.96
               Mean episode length: 212.83
    Episode_Reward/reaching_object: 1.4275
    Episode_Reward/rotating_object: 105.9532
        Episode_Reward/action_rate: -0.0673
          Episode_Reward/joint_vel: -0.0372
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 81887232
                    Iteration time: 2.09s
                      Time elapsed: 00:31:52
                               ETA: 01:22:58

################################################################################
                     [1m Learning iteration 833/3000 [0m                      

                       Computation: 45164 steps/s (collection: 2.077s, learning 0.100s)
             Mean action noise std: 3.16
          Mean value_function loss: 102.2522
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 78.6456
                       Mean reward: 551.63
               Mean episode length: 217.90
    Episode_Reward/reaching_object: 1.3992
    Episode_Reward/rotating_object: 105.9419
        Episode_Reward/action_rate: -0.0663
          Episode_Reward/joint_vel: -0.0342
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 81985536
                    Iteration time: 2.18s
                      Time elapsed: 00:31:54
                               ETA: 01:22:55

################################################################################
                     [1m Learning iteration 834/3000 [0m                      

                       Computation: 46507 steps/s (collection: 2.014s, learning 0.100s)
             Mean action noise std: 3.16
          Mean value_function loss: 100.4352
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 78.6595
                       Mean reward: 483.18
               Mean episode length: 196.24
    Episode_Reward/reaching_object: 1.4083
    Episode_Reward/rotating_object: 104.1765
        Episode_Reward/action_rate: -0.0662
          Episode_Reward/joint_vel: -0.0352
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.8333
--------------------------------------------------------------------------------
                   Total timesteps: 82083840
                    Iteration time: 2.11s
                      Time elapsed: 00:31:56
                               ETA: 01:22:52

################################################################################
                     [1m Learning iteration 835/3000 [0m                      

                       Computation: 47877 steps/s (collection: 1.957s, learning 0.096s)
             Mean action noise std: 3.16
          Mean value_function loss: 102.2201
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 78.6812
                       Mean reward: 545.93
               Mean episode length: 214.64
    Episode_Reward/reaching_object: 1.4025
    Episode_Reward/rotating_object: 105.3380
        Episode_Reward/action_rate: -0.0659
          Episode_Reward/joint_vel: -0.0342
      Episode_Termination/time_out: 13.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 82182144
                    Iteration time: 2.05s
                      Time elapsed: 00:31:59
                               ETA: 01:22:49

################################################################################
                     [1m Learning iteration 836/3000 [0m                      

                       Computation: 47802 steps/s (collection: 1.957s, learning 0.100s)
             Mean action noise std: 3.17
          Mean value_function loss: 98.0849
               Mean surrogate loss: -0.0088
                 Mean entropy loss: 78.7114
                       Mean reward: 589.29
               Mean episode length: 225.50
    Episode_Reward/reaching_object: 1.4235
    Episode_Reward/rotating_object: 109.2346
        Episode_Reward/action_rate: -0.0671
          Episode_Reward/joint_vel: -0.0347
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.2917
--------------------------------------------------------------------------------
                   Total timesteps: 82280448
                    Iteration time: 2.06s
                      Time elapsed: 00:32:01
                               ETA: 01:22:46

################################################################################
                     [1m Learning iteration 837/3000 [0m                      

                       Computation: 47002 steps/s (collection: 1.996s, learning 0.095s)
             Mean action noise std: 3.17
          Mean value_function loss: 99.0578
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 78.7405
                       Mean reward: 560.49
               Mean episode length: 215.56
    Episode_Reward/reaching_object: 1.4255
    Episode_Reward/rotating_object: 108.3707
        Episode_Reward/action_rate: -0.0671
          Episode_Reward/joint_vel: -0.0344
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.7917
--------------------------------------------------------------------------------
                   Total timesteps: 82378752
                    Iteration time: 2.09s
                      Time elapsed: 00:32:03
                               ETA: 01:22:44

################################################################################
                     [1m Learning iteration 838/3000 [0m                      

                       Computation: 47786 steps/s (collection: 1.961s, learning 0.097s)
             Mean action noise std: 3.17
          Mean value_function loss: 105.1886
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 78.7586
                       Mean reward: 521.33
               Mean episode length: 213.65
    Episode_Reward/reaching_object: 1.4316
    Episode_Reward/rotating_object: 107.2395
        Episode_Reward/action_rate: -0.0671
          Episode_Reward/joint_vel: -0.0346
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.6667
--------------------------------------------------------------------------------
                   Total timesteps: 82477056
                    Iteration time: 2.06s
                      Time elapsed: 00:32:05
                               ETA: 01:22:41

################################################################################
                     [1m Learning iteration 839/3000 [0m                      

                       Computation: 49037 steps/s (collection: 1.908s, learning 0.097s)
             Mean action noise std: 3.18
          Mean value_function loss: 95.7844
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 78.7800
                       Mean reward: 543.81
               Mean episode length: 210.98
    Episode_Reward/reaching_object: 1.4189
    Episode_Reward/rotating_object: 110.7283
        Episode_Reward/action_rate: -0.0670
          Episode_Reward/joint_vel: -0.0330
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.4167
--------------------------------------------------------------------------------
                   Total timesteps: 82575360
                    Iteration time: 2.00s
                      Time elapsed: 00:32:07
                               ETA: 01:22:38

################################################################################
                     [1m Learning iteration 840/3000 [0m                      

                       Computation: 47578 steps/s (collection: 1.966s, learning 0.101s)
             Mean action noise std: 3.18
          Mean value_function loss: 108.5471
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 78.8101
                       Mean reward: 574.56
               Mean episode length: 226.42
    Episode_Reward/reaching_object: 1.4675
    Episode_Reward/rotating_object: 113.2234
        Episode_Reward/action_rate: -0.0693
          Episode_Reward/joint_vel: -0.0347
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 82673664
                    Iteration time: 2.07s
                      Time elapsed: 00:32:09
                               ETA: 01:22:35

################################################################################
                     [1m Learning iteration 841/3000 [0m                      

                       Computation: 48909 steps/s (collection: 1.917s, learning 0.093s)
             Mean action noise std: 3.18
          Mean value_function loss: 111.3542
               Mean surrogate loss: 0.0074
                 Mean entropy loss: 78.8324
                       Mean reward: 504.52
               Mean episode length: 205.59
    Episode_Reward/reaching_object: 1.4287
    Episode_Reward/rotating_object: 107.7897
        Episode_Reward/action_rate: -0.0672
          Episode_Reward/joint_vel: -0.0344
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 82771968
                    Iteration time: 2.01s
                      Time elapsed: 00:32:11
                               ETA: 01:22:32

################################################################################
                     [1m Learning iteration 842/3000 [0m                      

                       Computation: 47632 steps/s (collection: 1.969s, learning 0.095s)
             Mean action noise std: 3.18
          Mean value_function loss: 87.5232
               Mean surrogate loss: -0.0017
                 Mean entropy loss: 78.8377
                       Mean reward: 573.35
               Mean episode length: 224.25
    Episode_Reward/reaching_object: 1.4821
    Episode_Reward/rotating_object: 112.1952
        Episode_Reward/action_rate: -0.0692
          Episode_Reward/joint_vel: -0.0350
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 82870272
                    Iteration time: 2.06s
                      Time elapsed: 00:32:13
                               ETA: 01:22:29

################################################################################
                     [1m Learning iteration 843/3000 [0m                      

                       Computation: 46958 steps/s (collection: 1.964s, learning 0.129s)
             Mean action noise std: 3.18
          Mean value_function loss: 93.3025
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 78.8475
                       Mean reward: 546.60
               Mean episode length: 214.76
    Episode_Reward/reaching_object: 1.4601
    Episode_Reward/rotating_object: 109.5310
        Episode_Reward/action_rate: -0.0686
          Episode_Reward/joint_vel: -0.0349
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 82968576
                    Iteration time: 2.09s
                      Time elapsed: 00:32:15
                               ETA: 01:22:26

################################################################################
                     [1m Learning iteration 844/3000 [0m                      

                       Computation: 49229 steps/s (collection: 1.902s, learning 0.095s)
             Mean action noise std: 3.19
          Mean value_function loss: 89.3973
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 78.8640
                       Mean reward: 561.92
               Mean episode length: 221.72
    Episode_Reward/reaching_object: 1.5103
    Episode_Reward/rotating_object: 110.8861
        Episode_Reward/action_rate: -0.0704
          Episode_Reward/joint_vel: -0.0363
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 83066880
                    Iteration time: 2.00s
                      Time elapsed: 00:32:17
                               ETA: 01:22:23

################################################################################
                     [1m Learning iteration 845/3000 [0m                      

                       Computation: 47127 steps/s (collection: 1.915s, learning 0.171s)
             Mean action noise std: 3.19
          Mean value_function loss: 95.2380
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 78.8859
                       Mean reward: 541.40
               Mean episode length: 214.87
    Episode_Reward/reaching_object: 1.4730
    Episode_Reward/rotating_object: 110.2393
        Episode_Reward/action_rate: -0.0689
          Episode_Reward/joint_vel: -0.0340
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 83165184
                    Iteration time: 2.09s
                      Time elapsed: 00:32:19
                               ETA: 01:22:20

################################################################################
                     [1m Learning iteration 846/3000 [0m                      

                       Computation: 46936 steps/s (collection: 1.951s, learning 0.144s)
             Mean action noise std: 3.19
          Mean value_function loss: 87.8256
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 78.9121
                       Mean reward: 561.33
               Mean episode length: 221.11
    Episode_Reward/reaching_object: 1.4890
    Episode_Reward/rotating_object: 113.8314
        Episode_Reward/action_rate: -0.0700
          Episode_Reward/joint_vel: -0.0344
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 83263488
                    Iteration time: 2.09s
                      Time elapsed: 00:32:21
                               ETA: 01:22:17

################################################################################
                     [1m Learning iteration 847/3000 [0m                      

                       Computation: 44042 steps/s (collection: 2.080s, learning 0.152s)
             Mean action noise std: 3.20
          Mean value_function loss: 96.2696
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 78.9402
                       Mean reward: 571.72
               Mean episode length: 224.99
    Episode_Reward/reaching_object: 1.4952
    Episode_Reward/rotating_object: 112.3369
        Episode_Reward/action_rate: -0.0702
          Episode_Reward/joint_vel: -0.0346
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 83361792
                    Iteration time: 2.23s
                      Time elapsed: 00:32:23
                               ETA: 01:22:15

################################################################################
                     [1m Learning iteration 848/3000 [0m                      

                       Computation: 45506 steps/s (collection: 2.064s, learning 0.096s)
             Mean action noise std: 3.20
          Mean value_function loss: 96.7606
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 78.9767
                       Mean reward: 581.02
               Mean episode length: 223.81
    Episode_Reward/reaching_object: 1.4947
    Episode_Reward/rotating_object: 114.5959
        Episode_Reward/action_rate: -0.0702
          Episode_Reward/joint_vel: -0.0344
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 83460096
                    Iteration time: 2.16s
                      Time elapsed: 00:32:26
                               ETA: 01:22:12

################################################################################
                     [1m Learning iteration 849/3000 [0m                      

                       Computation: 47533 steps/s (collection: 1.954s, learning 0.114s)
             Mean action noise std: 3.20
          Mean value_function loss: 101.4347
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 79.0106
                       Mean reward: 556.13
               Mean episode length: 217.08
    Episode_Reward/reaching_object: 1.4733
    Episode_Reward/rotating_object: 111.1588
        Episode_Reward/action_rate: -0.0693
          Episode_Reward/joint_vel: -0.0350
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 83558400
                    Iteration time: 2.07s
                      Time elapsed: 00:32:28
                               ETA: 01:22:09

################################################################################
                     [1m Learning iteration 850/3000 [0m                      

                       Computation: 47476 steps/s (collection: 1.957s, learning 0.114s)
             Mean action noise std: 3.21
          Mean value_function loss: 95.8559
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 79.0450
                       Mean reward: 532.35
               Mean episode length: 208.00
    Episode_Reward/reaching_object: 1.4420
    Episode_Reward/rotating_object: 107.8072
        Episode_Reward/action_rate: -0.0681
          Episode_Reward/joint_vel: -0.0343
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 83656704
                    Iteration time: 2.07s
                      Time elapsed: 00:32:30
                               ETA: 01:22:07

################################################################################
                     [1m Learning iteration 851/3000 [0m                      

                       Computation: 46173 steps/s (collection: 2.009s, learning 0.120s)
             Mean action noise std: 3.21
          Mean value_function loss: 92.2039
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 79.0702
                       Mean reward: 582.25
               Mean episode length: 220.53
    Episode_Reward/reaching_object: 1.4960
    Episode_Reward/rotating_object: 115.4443
        Episode_Reward/action_rate: -0.0704
          Episode_Reward/joint_vel: -0.0342
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 83755008
                    Iteration time: 2.13s
                      Time elapsed: 00:32:32
                               ETA: 01:22:04

################################################################################
                     [1m Learning iteration 852/3000 [0m                      

                       Computation: 46273 steps/s (collection: 2.011s, learning 0.113s)
             Mean action noise std: 3.21
          Mean value_function loss: 93.9981
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 79.0972
                       Mean reward: 604.91
               Mean episode length: 232.84
    Episode_Reward/reaching_object: 1.4957
    Episode_Reward/rotating_object: 113.6269
        Episode_Reward/action_rate: -0.0705
          Episode_Reward/joint_vel: -0.0343
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 83853312
                    Iteration time: 2.12s
                      Time elapsed: 00:32:34
                               ETA: 01:22:01

################################################################################
                     [1m Learning iteration 853/3000 [0m                      

                       Computation: 46288 steps/s (collection: 2.005s, learning 0.119s)
             Mean action noise std: 3.22
          Mean value_function loss: 94.3825
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 79.1351
                       Mean reward: 557.13
               Mean episode length: 222.58
    Episode_Reward/reaching_object: 1.4883
    Episode_Reward/rotating_object: 114.9718
        Episode_Reward/action_rate: -0.0702
          Episode_Reward/joint_vel: -0.0340
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 83951616
                    Iteration time: 2.12s
                      Time elapsed: 00:32:36
                               ETA: 01:21:58

################################################################################
                     [1m Learning iteration 854/3000 [0m                      

                       Computation: 47865 steps/s (collection: 1.913s, learning 0.141s)
             Mean action noise std: 3.22
          Mean value_function loss: 92.9250
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 79.1577
                       Mean reward: 585.00
               Mean episode length: 223.45
    Episode_Reward/reaching_object: 1.4397
    Episode_Reward/rotating_object: 110.9108
        Episode_Reward/action_rate: -0.0686
          Episode_Reward/joint_vel: -0.0340
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 84049920
                    Iteration time: 2.05s
                      Time elapsed: 00:32:38
                               ETA: 01:21:56

################################################################################
                     [1m Learning iteration 855/3000 [0m                      

                       Computation: 47353 steps/s (collection: 1.976s, learning 0.100s)
             Mean action noise std: 3.22
          Mean value_function loss: 89.4397
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 79.1771
                       Mean reward: 610.30
               Mean episode length: 229.87
    Episode_Reward/reaching_object: 1.5173
    Episode_Reward/rotating_object: 117.0321
        Episode_Reward/action_rate: -0.0720
          Episode_Reward/joint_vel: -0.0343
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 84148224
                    Iteration time: 2.08s
                      Time elapsed: 00:32:40
                               ETA: 01:21:53

################################################################################
                     [1m Learning iteration 856/3000 [0m                      

                       Computation: 48105 steps/s (collection: 1.929s, learning 0.115s)
             Mean action noise std: 3.23
          Mean value_function loss: 90.9577
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 79.2059
                       Mean reward: 570.21
               Mean episode length: 224.03
    Episode_Reward/reaching_object: 1.4889
    Episode_Reward/rotating_object: 115.4215
        Episode_Reward/action_rate: -0.0712
          Episode_Reward/joint_vel: -0.0347
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 84246528
                    Iteration time: 2.04s
                      Time elapsed: 00:32:42
                               ETA: 01:21:50

################################################################################
                     [1m Learning iteration 857/3000 [0m                      

                       Computation: 46838 steps/s (collection: 1.996s, learning 0.102s)
             Mean action noise std: 3.23
          Mean value_function loss: 88.1105
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 79.2395
                       Mean reward: 608.29
               Mean episode length: 226.56
    Episode_Reward/reaching_object: 1.4676
    Episode_Reward/rotating_object: 111.8268
        Episode_Reward/action_rate: -0.0708
          Episode_Reward/joint_vel: -0.0351
      Episode_Termination/time_out: 14.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 84344832
                    Iteration time: 2.10s
                      Time elapsed: 00:32:44
                               ETA: 01:21:47

################################################################################
                     [1m Learning iteration 858/3000 [0m                      

                       Computation: 49137 steps/s (collection: 1.893s, learning 0.108s)
             Mean action noise std: 3.23
          Mean value_function loss: 88.6138
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 79.2565
                       Mean reward: 577.19
               Mean episode length: 224.50
    Episode_Reward/reaching_object: 1.4866
    Episode_Reward/rotating_object: 113.8658
        Episode_Reward/action_rate: -0.0716
          Episode_Reward/joint_vel: -0.0347
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 84443136
                    Iteration time: 2.00s
                      Time elapsed: 00:32:46
                               ETA: 01:21:44

################################################################################
                     [1m Learning iteration 859/3000 [0m                      

                       Computation: 48225 steps/s (collection: 1.945s, learning 0.093s)
             Mean action noise std: 3.23
          Mean value_function loss: 94.1999
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 79.2689
                       Mean reward: 584.57
               Mean episode length: 223.83
    Episode_Reward/reaching_object: 1.5075
    Episode_Reward/rotating_object: 115.9582
        Episode_Reward/action_rate: -0.0723
          Episode_Reward/joint_vel: -0.0343
      Episode_Termination/time_out: 17.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 84541440
                    Iteration time: 2.04s
                      Time elapsed: 00:32:48
                               ETA: 01:21:41

################################################################################
                     [1m Learning iteration 860/3000 [0m                      

                       Computation: 47166 steps/s (collection: 1.972s, learning 0.113s)
             Mean action noise std: 3.24
          Mean value_function loss: 102.5011
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 79.2982
                       Mean reward: 574.88
               Mean episode length: 216.59
    Episode_Reward/reaching_object: 1.4566
    Episode_Reward/rotating_object: 111.5376
        Episode_Reward/action_rate: -0.0703
          Episode_Reward/joint_vel: -0.0346
      Episode_Termination/time_out: 17.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 84639744
                    Iteration time: 2.08s
                      Time elapsed: 00:32:50
                               ETA: 01:21:38

################################################################################
                     [1m Learning iteration 861/3000 [0m                      

                       Computation: 44523 steps/s (collection: 2.070s, learning 0.138s)
             Mean action noise std: 3.24
          Mean value_function loss: 98.3179
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 79.3251
                       Mean reward: 596.80
               Mean episode length: 222.35
    Episode_Reward/reaching_object: 1.4551
    Episode_Reward/rotating_object: 112.5313
        Episode_Reward/action_rate: -0.0704
          Episode_Reward/joint_vel: -0.0337
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 84738048
                    Iteration time: 2.21s
                      Time elapsed: 00:32:53
                               ETA: 01:21:36

################################################################################
                     [1m Learning iteration 862/3000 [0m                      

                       Computation: 46097 steps/s (collection: 2.023s, learning 0.110s)
             Mean action noise std: 3.24
          Mean value_function loss: 98.8442
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 79.3431
                       Mean reward: 564.98
               Mean episode length: 213.08
    Episode_Reward/reaching_object: 1.4247
    Episode_Reward/rotating_object: 111.6064
        Episode_Reward/action_rate: -0.0689
          Episode_Reward/joint_vel: -0.0327
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 84836352
                    Iteration time: 2.13s
                      Time elapsed: 00:32:55
                               ETA: 01:21:33

################################################################################
                     [1m Learning iteration 863/3000 [0m                      

                       Computation: 47111 steps/s (collection: 1.968s, learning 0.119s)
             Mean action noise std: 3.25
          Mean value_function loss: 92.8537
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 79.3705
                       Mean reward: 611.73
               Mean episode length: 229.66
    Episode_Reward/reaching_object: 1.4642
    Episode_Reward/rotating_object: 115.7921
        Episode_Reward/action_rate: -0.0710
          Episode_Reward/joint_vel: -0.0332
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 84934656
                    Iteration time: 2.09s
                      Time elapsed: 00:32:57
                               ETA: 01:21:30

################################################################################
                     [1m Learning iteration 864/3000 [0m                      

                       Computation: 47086 steps/s (collection: 1.958s, learning 0.130s)
             Mean action noise std: 3.25
          Mean value_function loss: 92.9941
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 79.3943
                       Mean reward: 533.28
               Mean episode length: 204.86
    Episode_Reward/reaching_object: 1.4767
    Episode_Reward/rotating_object: 113.8881
        Episode_Reward/action_rate: -0.0720
          Episode_Reward/joint_vel: -0.0343
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 85032960
                    Iteration time: 2.09s
                      Time elapsed: 00:32:59
                               ETA: 01:21:28

################################################################################
                     [1m Learning iteration 865/3000 [0m                      

                       Computation: 47060 steps/s (collection: 1.954s, learning 0.135s)
             Mean action noise std: 3.25
          Mean value_function loss: 104.3107
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 79.4106
                       Mean reward: 587.17
               Mean episode length: 220.13
    Episode_Reward/reaching_object: 1.4377
    Episode_Reward/rotating_object: 112.9577
        Episode_Reward/action_rate: -0.0708
          Episode_Reward/joint_vel: -0.0344
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 85131264
                    Iteration time: 2.09s
                      Time elapsed: 00:33:01
                               ETA: 01:21:25

################################################################################
                     [1m Learning iteration 866/3000 [0m                      

                       Computation: 46766 steps/s (collection: 1.960s, learning 0.142s)
             Mean action noise std: 3.25
          Mean value_function loss: 89.8174
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 79.4315
                       Mean reward: 623.55
               Mean episode length: 234.98
    Episode_Reward/reaching_object: 1.4542
    Episode_Reward/rotating_object: 114.4035
        Episode_Reward/action_rate: -0.0718
          Episode_Reward/joint_vel: -0.0339
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 85229568
                    Iteration time: 2.10s
                      Time elapsed: 00:33:03
                               ETA: 01:21:22

################################################################################
                     [1m Learning iteration 867/3000 [0m                      

                       Computation: 46410 steps/s (collection: 1.931s, learning 0.188s)
             Mean action noise std: 3.26
          Mean value_function loss: 91.4435
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 79.4555
                       Mean reward: 544.73
               Mean episode length: 211.90
    Episode_Reward/reaching_object: 1.4124
    Episode_Reward/rotating_object: 109.7217
        Episode_Reward/action_rate: -0.0697
          Episode_Reward/joint_vel: -0.0334
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 85327872
                    Iteration time: 2.12s
                      Time elapsed: 00:33:05
                               ETA: 01:21:19

################################################################################
                     [1m Learning iteration 868/3000 [0m                      

                       Computation: 46755 steps/s (collection: 1.926s, learning 0.177s)
             Mean action noise std: 3.26
          Mean value_function loss: 95.5787
               Mean surrogate loss: -0.0091
                 Mean entropy loss: 79.4840
                       Mean reward: 558.54
               Mean episode length: 215.72
    Episode_Reward/reaching_object: 1.4176
    Episode_Reward/rotating_object: 110.4209
        Episode_Reward/action_rate: -0.0706
          Episode_Reward/joint_vel: -0.0338
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.2083
--------------------------------------------------------------------------------
                   Total timesteps: 85426176
                    Iteration time: 2.10s
                      Time elapsed: 00:33:07
                               ETA: 01:21:17

################################################################################
                     [1m Learning iteration 869/3000 [0m                      

                       Computation: 48182 steps/s (collection: 1.897s, learning 0.144s)
             Mean action noise std: 3.26
          Mean value_function loss: 81.5763
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 79.5165
                       Mean reward: 609.46
               Mean episode length: 224.71
    Episode_Reward/reaching_object: 1.4970
    Episode_Reward/rotating_object: 119.7327
        Episode_Reward/action_rate: -0.0742
          Episode_Reward/joint_vel: -0.0335
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 85524480
                    Iteration time: 2.04s
                      Time elapsed: 00:33:09
                               ETA: 01:21:14

################################################################################
                     [1m Learning iteration 870/3000 [0m                      

                       Computation: 46497 steps/s (collection: 1.936s, learning 0.178s)
             Mean action noise std: 3.27
          Mean value_function loss: 86.7921
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 79.5414
                       Mean reward: 599.97
               Mean episode length: 223.27
    Episode_Reward/reaching_object: 1.4900
    Episode_Reward/rotating_object: 119.6413
        Episode_Reward/action_rate: -0.0743
          Episode_Reward/joint_vel: -0.0337
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 85622784
                    Iteration time: 2.11s
                      Time elapsed: 00:33:12
                               ETA: 01:21:11

################################################################################
                     [1m Learning iteration 871/3000 [0m                      

                       Computation: 45952 steps/s (collection: 2.035s, learning 0.105s)
             Mean action noise std: 3.27
          Mean value_function loss: 96.8084
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 79.5675
                       Mean reward: 560.56
               Mean episode length: 218.16
    Episode_Reward/reaching_object: 1.4377
    Episode_Reward/rotating_object: 114.5109
        Episode_Reward/action_rate: -0.0724
          Episode_Reward/joint_vel: -0.0341
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 85721088
                    Iteration time: 2.14s
                      Time elapsed: 00:33:14
                               ETA: 01:21:08

################################################################################
                     [1m Learning iteration 872/3000 [0m                      

                       Computation: 47567 steps/s (collection: 1.955s, learning 0.112s)
             Mean action noise std: 3.27
          Mean value_function loss: 91.3609
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 79.5892
                       Mean reward: 574.88
               Mean episode length: 216.59
    Episode_Reward/reaching_object: 1.4187
    Episode_Reward/rotating_object: 113.0009
        Episode_Reward/action_rate: -0.0719
          Episode_Reward/joint_vel: -0.0334
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 85819392
                    Iteration time: 2.07s
                      Time elapsed: 00:33:16
                               ETA: 01:21:05

################################################################################
                     [1m Learning iteration 873/3000 [0m                      

                       Computation: 47962 steps/s (collection: 1.935s, learning 0.114s)
             Mean action noise std: 3.27
          Mean value_function loss: 87.9113
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 79.6037
                       Mean reward: 603.02
               Mean episode length: 223.94
    Episode_Reward/reaching_object: 1.4682
    Episode_Reward/rotating_object: 117.4570
        Episode_Reward/action_rate: -0.0738
          Episode_Reward/joint_vel: -0.0332
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 85917696
                    Iteration time: 2.05s
                      Time elapsed: 00:33:18
                               ETA: 01:21:03

################################################################################
                     [1m Learning iteration 874/3000 [0m                      

                       Computation: 47415 steps/s (collection: 1.958s, learning 0.115s)
             Mean action noise std: 3.28
          Mean value_function loss: 88.5679
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 79.6258
                       Mean reward: 574.39
               Mean episode length: 219.21
    Episode_Reward/reaching_object: 1.4253
    Episode_Reward/rotating_object: 114.5822
        Episode_Reward/action_rate: -0.0727
          Episode_Reward/joint_vel: -0.0343
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 86016000
                    Iteration time: 2.07s
                      Time elapsed: 00:33:20
                               ETA: 01:21:00

################################################################################
                     [1m Learning iteration 875/3000 [0m                      

                       Computation: 48083 steps/s (collection: 1.918s, learning 0.127s)
             Mean action noise std: 3.28
          Mean value_function loss: 98.5119
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 79.6569
                       Mean reward: 600.98
               Mean episode length: 230.46
    Episode_Reward/reaching_object: 1.4653
    Episode_Reward/rotating_object: 114.9056
        Episode_Reward/action_rate: -0.0742
          Episode_Reward/joint_vel: -0.0348
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 86114304
                    Iteration time: 2.04s
                      Time elapsed: 00:33:22
                               ETA: 01:20:57

################################################################################
                     [1m Learning iteration 876/3000 [0m                      

                       Computation: 42720 steps/s (collection: 2.176s, learning 0.126s)
             Mean action noise std: 3.28
          Mean value_function loss: 95.5896
               Mean surrogate loss: -0.0089
                 Mean entropy loss: 79.6730
                       Mean reward: 570.59
               Mean episode length: 218.34
    Episode_Reward/reaching_object: 1.4326
    Episode_Reward/rotating_object: 112.8051
        Episode_Reward/action_rate: -0.0725
          Episode_Reward/joint_vel: -0.0332
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.0000
--------------------------------------------------------------------------------
                   Total timesteps: 86212608
                    Iteration time: 2.30s
                      Time elapsed: 00:33:24
                               ETA: 01:20:55

################################################################################
                     [1m Learning iteration 877/3000 [0m                      

                       Computation: 45800 steps/s (collection: 2.002s, learning 0.145s)
             Mean action noise std: 3.28
          Mean value_function loss: 96.7538
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 79.6896
                       Mean reward: 588.85
               Mean episode length: 230.25
    Episode_Reward/reaching_object: 1.4161
    Episode_Reward/rotating_object: 111.2519
        Episode_Reward/action_rate: -0.0720
          Episode_Reward/joint_vel: -0.0336
      Episode_Termination/time_out: 13.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 86310912
                    Iteration time: 2.15s
                      Time elapsed: 00:33:26
                               ETA: 01:20:52

################################################################################
                     [1m Learning iteration 878/3000 [0m                      

                       Computation: 47321 steps/s (collection: 1.974s, learning 0.103s)
             Mean action noise std: 3.29
          Mean value_function loss: 90.5505
               Mean surrogate loss: -0.0086
                 Mean entropy loss: 79.7046
                       Mean reward: 633.52
               Mean episode length: 232.77
    Episode_Reward/reaching_object: 1.4541
    Episode_Reward/rotating_object: 118.6301
        Episode_Reward/action_rate: -0.0732
          Episode_Reward/joint_vel: -0.0325
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 86409216
                    Iteration time: 2.08s
                      Time elapsed: 00:33:28
                               ETA: 01:20:49

################################################################################
                     [1m Learning iteration 879/3000 [0m                      

                       Computation: 45169 steps/s (collection: 2.063s, learning 0.113s)
             Mean action noise std: 3.29
          Mean value_function loss: 92.8519
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 79.7243
                       Mean reward: 597.75
               Mean episode length: 225.45
    Episode_Reward/reaching_object: 1.4747
    Episode_Reward/rotating_object: 117.9932
        Episode_Reward/action_rate: -0.0741
          Episode_Reward/joint_vel: -0.0325
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 86507520
                    Iteration time: 2.18s
                      Time elapsed: 00:33:31
                               ETA: 01:20:47

################################################################################
                     [1m Learning iteration 880/3000 [0m                      

                       Computation: 45844 steps/s (collection: 2.004s, learning 0.141s)
             Mean action noise std: 3.29
          Mean value_function loss: 86.3555
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 79.7374
                       Mean reward: 624.02
               Mean episode length: 234.01
    Episode_Reward/reaching_object: 1.4690
    Episode_Reward/rotating_object: 114.7189
        Episode_Reward/action_rate: -0.0741
          Episode_Reward/joint_vel: -0.0339
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 86605824
                    Iteration time: 2.14s
                      Time elapsed: 00:33:33
                               ETA: 01:20:44

################################################################################
                     [1m Learning iteration 881/3000 [0m                      

                       Computation: 45122 steps/s (collection: 2.059s, learning 0.120s)
             Mean action noise std: 3.29
          Mean value_function loss: 92.2288
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 79.7523
                       Mean reward: 563.79
               Mean episode length: 210.74
    Episode_Reward/reaching_object: 1.4712
    Episode_Reward/rotating_object: 117.7563
        Episode_Reward/action_rate: -0.0739
          Episode_Reward/joint_vel: -0.0332
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 86704128
                    Iteration time: 2.18s
                      Time elapsed: 00:33:35
                               ETA: 01:20:42

################################################################################
                     [1m Learning iteration 882/3000 [0m                      

                       Computation: 46517 steps/s (collection: 2.010s, learning 0.103s)
             Mean action noise std: 3.30
          Mean value_function loss: 94.2302
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 79.7809
                       Mean reward: 602.96
               Mean episode length: 224.43
    Episode_Reward/reaching_object: 1.4945
    Episode_Reward/rotating_object: 119.5026
        Episode_Reward/action_rate: -0.0754
          Episode_Reward/joint_vel: -0.0338
      Episode_Termination/time_out: 17.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 86802432
                    Iteration time: 2.11s
                      Time elapsed: 00:33:37
                               ETA: 01:20:39

################################################################################
                     [1m Learning iteration 883/3000 [0m                      

                       Computation: 46724 steps/s (collection: 1.999s, learning 0.105s)
             Mean action noise std: 3.30
          Mean value_function loss: 97.3579
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 79.8026
                       Mean reward: 585.35
               Mean episode length: 219.84
    Episode_Reward/reaching_object: 1.4620
    Episode_Reward/rotating_object: 115.5659
        Episode_Reward/action_rate: -0.0734
          Episode_Reward/joint_vel: -0.0333
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 86900736
                    Iteration time: 2.10s
                      Time elapsed: 00:33:39
                               ETA: 01:20:36

################################################################################
                     [1m Learning iteration 884/3000 [0m                      

                       Computation: 46389 steps/s (collection: 1.964s, learning 0.155s)
             Mean action noise std: 3.30
          Mean value_function loss: 94.8914
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 79.8206
                       Mean reward: 564.72
               Mean episode length: 209.30
    Episode_Reward/reaching_object: 1.4771
    Episode_Reward/rotating_object: 118.7595
        Episode_Reward/action_rate: -0.0746
          Episode_Reward/joint_vel: -0.0328
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 86999040
                    Iteration time: 2.12s
                      Time elapsed: 00:33:41
                               ETA: 01:20:33

################################################################################
                     [1m Learning iteration 885/3000 [0m                      

                       Computation: 44218 steps/s (collection: 2.096s, learning 0.127s)
             Mean action noise std: 3.30
          Mean value_function loss: 95.6708
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 79.8379
                       Mean reward: 581.85
               Mean episode length: 216.62
    Episode_Reward/reaching_object: 1.4614
    Episode_Reward/rotating_object: 117.7175
        Episode_Reward/action_rate: -0.0742
          Episode_Reward/joint_vel: -0.0333
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 87097344
                    Iteration time: 2.22s
                      Time elapsed: 00:33:43
                               ETA: 01:20:31

################################################################################
                     [1m Learning iteration 886/3000 [0m                      

                       Computation: 45970 steps/s (collection: 1.997s, learning 0.141s)
             Mean action noise std: 3.31
          Mean value_function loss: 93.5124
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 79.8632
                       Mean reward: 633.42
               Mean episode length: 229.72
    Episode_Reward/reaching_object: 1.4706
    Episode_Reward/rotating_object: 119.1167
        Episode_Reward/action_rate: -0.0743
          Episode_Reward/joint_vel: -0.0322
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 87195648
                    Iteration time: 2.14s
                      Time elapsed: 00:33:46
                               ETA: 01:20:28

################################################################################
                     [1m Learning iteration 887/3000 [0m                      

                       Computation: 47139 steps/s (collection: 1.979s, learning 0.106s)
             Mean action noise std: 3.31
          Mean value_function loss: 88.1903
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 79.8859
                       Mean reward: 605.71
               Mean episode length: 227.39
    Episode_Reward/reaching_object: 1.4976
    Episode_Reward/rotating_object: 118.4229
        Episode_Reward/action_rate: -0.0755
          Episode_Reward/joint_vel: -0.0347
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 87293952
                    Iteration time: 2.09s
                      Time elapsed: 00:33:48
                               ETA: 01:20:26

################################################################################
                     [1m Learning iteration 888/3000 [0m                      

                       Computation: 46847 steps/s (collection: 1.984s, learning 0.114s)
             Mean action noise std: 3.31
          Mean value_function loss: 92.3471
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 79.9126
                       Mean reward: 592.50
               Mean episode length: 222.17
    Episode_Reward/reaching_object: 1.4648
    Episode_Reward/rotating_object: 114.9875
        Episode_Reward/action_rate: -0.0738
          Episode_Reward/joint_vel: -0.0339
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 87392256
                    Iteration time: 2.10s
                      Time elapsed: 00:33:50
                               ETA: 01:20:23

################################################################################
                     [1m Learning iteration 889/3000 [0m                      

                       Computation: 44411 steps/s (collection: 2.069s, learning 0.145s)
             Mean action noise std: 3.32
          Mean value_function loss: 89.9639
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 79.9405
                       Mean reward: 588.21
               Mean episode length: 224.30
    Episode_Reward/reaching_object: 1.5138
    Episode_Reward/rotating_object: 120.7422
        Episode_Reward/action_rate: -0.0761
          Episode_Reward/joint_vel: -0.0331
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 87490560
                    Iteration time: 2.21s
                      Time elapsed: 00:33:52
                               ETA: 01:20:20

################################################################################
                     [1m Learning iteration 890/3000 [0m                      

                       Computation: 45168 steps/s (collection: 2.059s, learning 0.117s)
             Mean action noise std: 3.32
          Mean value_function loss: 85.2864
               Mean surrogate loss: -0.0010
                 Mean entropy loss: 79.9564
                       Mean reward: 600.68
               Mean episode length: 223.54
    Episode_Reward/reaching_object: 1.4977
    Episode_Reward/rotating_object: 119.2560
        Episode_Reward/action_rate: -0.0756
          Episode_Reward/joint_vel: -0.0335
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 87588864
                    Iteration time: 2.18s
                      Time elapsed: 00:33:54
                               ETA: 01:20:18

################################################################################
                     [1m Learning iteration 891/3000 [0m                      

                       Computation: 44696 steps/s (collection: 2.045s, learning 0.154s)
             Mean action noise std: 3.32
          Mean value_function loss: 85.6826
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 79.9672
                       Mean reward: 546.23
               Mean episode length: 210.54
    Episode_Reward/reaching_object: 1.5099
    Episode_Reward/rotating_object: 122.3860
        Episode_Reward/action_rate: -0.0763
          Episode_Reward/joint_vel: -0.0330
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 87687168
                    Iteration time: 2.20s
                      Time elapsed: 00:33:56
                               ETA: 01:20:15

################################################################################
                     [1m Learning iteration 892/3000 [0m                      

                       Computation: 47443 steps/s (collection: 1.966s, learning 0.106s)
             Mean action noise std: 3.32
          Mean value_function loss: 94.1307
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 79.9867
                       Mean reward: 593.61
               Mean episode length: 219.98
    Episode_Reward/reaching_object: 1.4891
    Episode_Reward/rotating_object: 120.4246
        Episode_Reward/action_rate: -0.0763
          Episode_Reward/joint_vel: -0.0333
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 87785472
                    Iteration time: 2.07s
                      Time elapsed: 00:33:58
                               ETA: 01:20:13

################################################################################
                     [1m Learning iteration 893/3000 [0m                      

                       Computation: 46754 steps/s (collection: 1.983s, learning 0.120s)
             Mean action noise std: 3.33
          Mean value_function loss: 84.4116
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 80.0110
                       Mean reward: 626.25
               Mean episode length: 227.54
    Episode_Reward/reaching_object: 1.4806
    Episode_Reward/rotating_object: 118.7559
        Episode_Reward/action_rate: -0.0761
          Episode_Reward/joint_vel: -0.0340
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 87883776
                    Iteration time: 2.10s
                      Time elapsed: 00:34:01
                               ETA: 01:20:10

################################################################################
                     [1m Learning iteration 894/3000 [0m                      

                       Computation: 47399 steps/s (collection: 1.975s, learning 0.099s)
             Mean action noise std: 3.33
          Mean value_function loss: 82.4504
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 80.0301
                       Mean reward: 555.93
               Mean episode length: 214.54
    Episode_Reward/reaching_object: 1.4503
    Episode_Reward/rotating_object: 115.1817
        Episode_Reward/action_rate: -0.0749
          Episode_Reward/joint_vel: -0.0344
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 87982080
                    Iteration time: 2.07s
                      Time elapsed: 00:34:03
                               ETA: 01:20:07

################################################################################
                     [1m Learning iteration 895/3000 [0m                      

                       Computation: 43760 steps/s (collection: 2.151s, learning 0.095s)
             Mean action noise std: 3.33
          Mean value_function loss: 92.1361
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 80.0447
                       Mean reward: 605.57
               Mean episode length: 220.89
    Episode_Reward/reaching_object: 1.4509
    Episode_Reward/rotating_object: 119.0731
        Episode_Reward/action_rate: -0.0750
          Episode_Reward/joint_vel: -0.0323
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 88080384
                    Iteration time: 2.25s
                      Time elapsed: 00:34:05
                               ETA: 01:20:05

################################################################################
                     [1m Learning iteration 896/3000 [0m                      

                       Computation: 45041 steps/s (collection: 2.043s, learning 0.140s)
             Mean action noise std: 3.33
          Mean value_function loss: 85.6833
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 80.0642
                       Mean reward: 577.82
               Mean episode length: 212.22
    Episode_Reward/reaching_object: 1.4948
    Episode_Reward/rotating_object: 123.0097
        Episode_Reward/action_rate: -0.0780
          Episode_Reward/joint_vel: -0.0342
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 88178688
                    Iteration time: 2.18s
                      Time elapsed: 00:34:07
                               ETA: 01:20:02

################################################################################
                     [1m Learning iteration 897/3000 [0m                      

                       Computation: 40369 steps/s (collection: 2.304s, learning 0.132s)
             Mean action noise std: 3.34
          Mean value_function loss: 88.7210
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 80.0935
                       Mean reward: 606.43
               Mean episode length: 225.82
    Episode_Reward/reaching_object: 1.4766
    Episode_Reward/rotating_object: 121.8144
        Episode_Reward/action_rate: -0.0773
          Episode_Reward/joint_vel: -0.0343
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 88276992
                    Iteration time: 2.44s
                      Time elapsed: 00:34:10
                               ETA: 01:20:00

################################################################################
                     [1m Learning iteration 898/3000 [0m                      

                       Computation: 39937 steps/s (collection: 2.304s, learning 0.158s)
             Mean action noise std: 3.34
          Mean value_function loss: 92.5416
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 80.1192
                       Mean reward: 560.89
               Mean episode length: 210.16
    Episode_Reward/reaching_object: 1.3819
    Episode_Reward/rotating_object: 112.4173
        Episode_Reward/action_rate: -0.0726
          Episode_Reward/joint_vel: -0.0336
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 88375296
                    Iteration time: 2.46s
                      Time elapsed: 00:34:12
                               ETA: 01:19:59

################################################################################
                     [1m Learning iteration 899/3000 [0m                      

                       Computation: 44675 steps/s (collection: 2.074s, learning 0.127s)
             Mean action noise std: 3.34
          Mean value_function loss: 85.6253
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 80.1437
                       Mean reward: 571.17
               Mean episode length: 212.64
    Episode_Reward/reaching_object: 1.4511
    Episode_Reward/rotating_object: 117.7032
        Episode_Reward/action_rate: -0.0756
          Episode_Reward/joint_vel: -0.0341
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 88473600
                    Iteration time: 2.20s
                      Time elapsed: 00:34:14
                               ETA: 01:19:56

################################################################################
                     [1m Learning iteration 900/3000 [0m                      

                       Computation: 45969 steps/s (collection: 2.009s, learning 0.129s)
             Mean action noise std: 3.34
          Mean value_function loss: 90.0425
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 80.1718
                       Mean reward: 632.56
               Mean episode length: 228.50
    Episode_Reward/reaching_object: 1.4483
    Episode_Reward/rotating_object: 120.0178
        Episode_Reward/action_rate: -0.0758
          Episode_Reward/joint_vel: -0.0327
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 88571904
                    Iteration time: 2.14s
                      Time elapsed: 00:34:16
                               ETA: 01:19:53

################################################################################
                     [1m Learning iteration 901/3000 [0m                      

                       Computation: 46537 steps/s (collection: 1.983s, learning 0.130s)
             Mean action noise std: 3.35
          Mean value_function loss: 90.1670
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 80.1992
                       Mean reward: 594.33
               Mean episode length: 222.02
    Episode_Reward/reaching_object: 1.4299
    Episode_Reward/rotating_object: 116.7338
        Episode_Reward/action_rate: -0.0754
          Episode_Reward/joint_vel: -0.0345
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 88670208
                    Iteration time: 2.11s
                      Time elapsed: 00:34:18
                               ETA: 01:19:51

################################################################################
                     [1m Learning iteration 902/3000 [0m                      

                       Computation: 46800 steps/s (collection: 1.986s, learning 0.115s)
             Mean action noise std: 3.35
          Mean value_function loss: 86.7374
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 80.2348
                       Mean reward: 563.95
               Mean episode length: 213.08
    Episode_Reward/reaching_object: 1.4743
    Episode_Reward/rotating_object: 122.1035
        Episode_Reward/action_rate: -0.0768
          Episode_Reward/joint_vel: -0.0330
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 88768512
                    Iteration time: 2.10s
                      Time elapsed: 00:34:21
                               ETA: 01:19:48

################################################################################
                     [1m Learning iteration 903/3000 [0m                      

                       Computation: 44930 steps/s (collection: 2.075s, learning 0.113s)
             Mean action noise std: 3.35
          Mean value_function loss: 91.5171
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 80.2624
                       Mean reward: 630.18
               Mean episode length: 231.05
    Episode_Reward/reaching_object: 1.4957
    Episode_Reward/rotating_object: 122.4462
        Episode_Reward/action_rate: -0.0782
          Episode_Reward/joint_vel: -0.0343
      Episode_Termination/time_out: 17.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 88866816
                    Iteration time: 2.19s
                      Time elapsed: 00:34:23
                               ETA: 01:19:46

################################################################################
                     [1m Learning iteration 904/3000 [0m                      

                       Computation: 46100 steps/s (collection: 2.027s, learning 0.106s)
             Mean action noise std: 3.36
          Mean value_function loss: 85.3953
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 80.2775
                       Mean reward: 604.29
               Mean episode length: 222.01
    Episode_Reward/reaching_object: 1.4443
    Episode_Reward/rotating_object: 117.0396
        Episode_Reward/action_rate: -0.0756
          Episode_Reward/joint_vel: -0.0341
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.8750
--------------------------------------------------------------------------------
                   Total timesteps: 88965120
                    Iteration time: 2.13s
                      Time elapsed: 00:34:25
                               ETA: 01:19:43

################################################################################
                     [1m Learning iteration 905/3000 [0m                      

                       Computation: 46513 steps/s (collection: 1.977s, learning 0.137s)
             Mean action noise std: 3.36
          Mean value_function loss: 90.4505
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 80.2999
                       Mean reward: 614.87
               Mean episode length: 224.15
    Episode_Reward/reaching_object: 1.4505
    Episode_Reward/rotating_object: 119.6362
        Episode_Reward/action_rate: -0.0762
          Episode_Reward/joint_vel: -0.0328
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 89063424
                    Iteration time: 2.11s
                      Time elapsed: 00:34:27
                               ETA: 01:19:40

################################################################################
                     [1m Learning iteration 906/3000 [0m                      

                       Computation: 45218 steps/s (collection: 2.044s, learning 0.130s)
             Mean action noise std: 3.36
          Mean value_function loss: 93.8750
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 80.3223
                       Mean reward: 613.00
               Mean episode length: 225.38
    Episode_Reward/reaching_object: 1.5094
    Episode_Reward/rotating_object: 123.8057
        Episode_Reward/action_rate: -0.0789
          Episode_Reward/joint_vel: -0.0344
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 89161728
                    Iteration time: 2.17s
                      Time elapsed: 00:34:29
                               ETA: 01:19:38

################################################################################
                     [1m Learning iteration 907/3000 [0m                      

                       Computation: 47548 steps/s (collection: 1.959s, learning 0.108s)
             Mean action noise std: 3.37
          Mean value_function loss: 90.5129
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 80.3577
                       Mean reward: 563.04
               Mean episode length: 216.81
    Episode_Reward/reaching_object: 1.4510
    Episode_Reward/rotating_object: 116.3911
        Episode_Reward/action_rate: -0.0762
          Episode_Reward/joint_vel: -0.0341
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 89260032
                    Iteration time: 2.07s
                      Time elapsed: 00:34:31
                               ETA: 01:19:35

################################################################################
                     [1m Learning iteration 908/3000 [0m                      

                       Computation: 46424 steps/s (collection: 1.994s, learning 0.124s)
             Mean action noise std: 3.37
          Mean value_function loss: 71.7323
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 80.3928
                       Mean reward: 664.73
               Mean episode length: 237.11
    Episode_Reward/reaching_object: 1.5343
    Episode_Reward/rotating_object: 126.1287
        Episode_Reward/action_rate: -0.0804
          Episode_Reward/joint_vel: -0.0351
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 89358336
                    Iteration time: 2.12s
                      Time elapsed: 00:34:33
                               ETA: 01:19:32

################################################################################
                     [1m Learning iteration 909/3000 [0m                      

                       Computation: 45901 steps/s (collection: 1.987s, learning 0.155s)
             Mean action noise std: 3.37
          Mean value_function loss: 82.2258
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 80.4210
                       Mean reward: 637.46
               Mean episode length: 230.92
    Episode_Reward/reaching_object: 1.4744
    Episode_Reward/rotating_object: 120.1494
        Episode_Reward/action_rate: -0.0770
          Episode_Reward/joint_vel: -0.0333
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 89456640
                    Iteration time: 2.14s
                      Time elapsed: 00:34:35
                               ETA: 01:19:30

################################################################################
                     [1m Learning iteration 910/3000 [0m                      

                       Computation: 46069 steps/s (collection: 1.961s, learning 0.173s)
             Mean action noise std: 3.38
          Mean value_function loss: 84.6601
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 80.4506
                       Mean reward: 591.23
               Mean episode length: 215.53
    Episode_Reward/reaching_object: 1.4741
    Episode_Reward/rotating_object: 123.1533
        Episode_Reward/action_rate: -0.0777
          Episode_Reward/joint_vel: -0.0333
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 89554944
                    Iteration time: 2.13s
                      Time elapsed: 00:34:38
                               ETA: 01:19:27

################################################################################
                     [1m Learning iteration 911/3000 [0m                      

                       Computation: 45548 steps/s (collection: 1.962s, learning 0.196s)
             Mean action noise std: 3.38
          Mean value_function loss: 83.1671
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 80.4782
                       Mean reward: 613.44
               Mean episode length: 225.13
    Episode_Reward/reaching_object: 1.4728
    Episode_Reward/rotating_object: 121.3933
        Episode_Reward/action_rate: -0.0776
          Episode_Reward/joint_vel: -0.0339
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 89653248
                    Iteration time: 2.16s
                      Time elapsed: 00:34:40
                               ETA: 01:19:24

################################################################################
                     [1m Learning iteration 912/3000 [0m                      

                       Computation: 45610 steps/s (collection: 1.966s, learning 0.189s)
             Mean action noise std: 3.38
          Mean value_function loss: 84.6382
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 80.5087
                       Mean reward: 666.49
               Mean episode length: 234.30
    Episode_Reward/reaching_object: 1.4635
    Episode_Reward/rotating_object: 120.6490
        Episode_Reward/action_rate: -0.0776
          Episode_Reward/joint_vel: -0.0338
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 89751552
                    Iteration time: 2.16s
                      Time elapsed: 00:34:42
                               ETA: 01:19:22

################################################################################
                     [1m Learning iteration 913/3000 [0m                      

                       Computation: 45306 steps/s (collection: 2.018s, learning 0.152s)
             Mean action noise std: 3.39
          Mean value_function loss: 87.2982
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 80.5347
                       Mean reward: 632.60
               Mean episode length: 224.38
    Episode_Reward/reaching_object: 1.4623
    Episode_Reward/rotating_object: 122.7207
        Episode_Reward/action_rate: -0.0775
          Episode_Reward/joint_vel: -0.0320
      Episode_Termination/time_out: 17.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 89849856
                    Iteration time: 2.17s
                      Time elapsed: 00:34:44
                               ETA: 01:19:19

################################################################################
                     [1m Learning iteration 914/3000 [0m                      

                       Computation: 47296 steps/s (collection: 1.952s, learning 0.127s)
             Mean action noise std: 3.39
          Mean value_function loss: 96.9027
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 80.5642
                       Mean reward: 601.74
               Mean episode length: 221.14
    Episode_Reward/reaching_object: 1.4844
    Episode_Reward/rotating_object: 122.4134
        Episode_Reward/action_rate: -0.0783
          Episode_Reward/joint_vel: -0.0330
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 89948160
                    Iteration time: 2.08s
                      Time elapsed: 00:34:46
                               ETA: 01:19:17

################################################################################
                     [1m Learning iteration 915/3000 [0m                      

                       Computation: 46469 steps/s (collection: 1.984s, learning 0.132s)
             Mean action noise std: 3.39
          Mean value_function loss: 84.3547
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 80.5910
                       Mean reward: 632.37
               Mean episode length: 230.52
    Episode_Reward/reaching_object: 1.5144
    Episode_Reward/rotating_object: 123.8563
        Episode_Reward/action_rate: -0.0806
          Episode_Reward/joint_vel: -0.0352
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 90046464
                    Iteration time: 2.12s
                      Time elapsed: 00:34:48
                               ETA: 01:19:14

################################################################################
                     [1m Learning iteration 916/3000 [0m                      

                       Computation: 45898 steps/s (collection: 2.004s, learning 0.138s)
             Mean action noise std: 3.40
          Mean value_function loss: 85.4464
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 80.6132
                       Mean reward: 598.06
               Mean episode length: 223.40
    Episode_Reward/reaching_object: 1.4647
    Episode_Reward/rotating_object: 120.8784
        Episode_Reward/action_rate: -0.0784
          Episode_Reward/joint_vel: -0.0349
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 90144768
                    Iteration time: 2.14s
                      Time elapsed: 00:34:50
                               ETA: 01:19:11

################################################################################
                     [1m Learning iteration 917/3000 [0m                      

                       Computation: 43432 steps/s (collection: 2.018s, learning 0.245s)
             Mean action noise std: 3.40
          Mean value_function loss: 96.8607
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 80.6376
                       Mean reward: 565.79
               Mean episode length: 206.94
    Episode_Reward/reaching_object: 1.4264
    Episode_Reward/rotating_object: 116.4549
        Episode_Reward/action_rate: -0.0757
          Episode_Reward/joint_vel: -0.0323
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.3333
--------------------------------------------------------------------------------
                   Total timesteps: 90243072
                    Iteration time: 2.26s
                      Time elapsed: 00:34:53
                               ETA: 01:19:09

################################################################################
                     [1m Learning iteration 918/3000 [0m                      

                       Computation: 44866 steps/s (collection: 2.063s, learning 0.128s)
             Mean action noise std: 3.40
          Mean value_function loss: 97.7475
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 80.6645
                       Mean reward: 547.31
               Mean episode length: 203.01
    Episode_Reward/reaching_object: 1.3714
    Episode_Reward/rotating_object: 112.1455
        Episode_Reward/action_rate: -0.0735
          Episode_Reward/joint_vel: -0.0320
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 3.5417
--------------------------------------------------------------------------------
                   Total timesteps: 90341376
                    Iteration time: 2.19s
                      Time elapsed: 00:34:55
                               ETA: 01:19:07

################################################################################
                     [1m Learning iteration 919/3000 [0m                      

                       Computation: 44344 steps/s (collection: 2.114s, learning 0.103s)
             Mean action noise std: 3.41
          Mean value_function loss: 77.3356
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 80.6883
                       Mean reward: 622.58
               Mean episode length: 225.45
    Episode_Reward/reaching_object: 1.4268
    Episode_Reward/rotating_object: 115.5478
        Episode_Reward/action_rate: -0.0763
          Episode_Reward/joint_vel: -0.0341
      Episode_Termination/time_out: 14.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 90439680
                    Iteration time: 2.22s
                      Time elapsed: 00:34:57
                               ETA: 01:19:04

################################################################################
                     [1m Learning iteration 920/3000 [0m                      

                       Computation: 47906 steps/s (collection: 1.954s, learning 0.098s)
             Mean action noise std: 3.41
          Mean value_function loss: 82.5947
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 80.7093
                       Mean reward: 657.18
               Mean episode length: 232.79
    Episode_Reward/reaching_object: 1.4783
    Episode_Reward/rotating_object: 120.0874
        Episode_Reward/action_rate: -0.0790
          Episode_Reward/joint_vel: -0.0337
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 90537984
                    Iteration time: 2.05s
                      Time elapsed: 00:34:59
                               ETA: 01:19:01

################################################################################
                     [1m Learning iteration 921/3000 [0m                      

                       Computation: 47669 steps/s (collection: 1.963s, learning 0.099s)
             Mean action noise std: 3.41
          Mean value_function loss: 97.6102
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 80.7427
                       Mean reward: 579.20
               Mean episode length: 219.39
    Episode_Reward/reaching_object: 1.4115
    Episode_Reward/rotating_object: 115.5054
        Episode_Reward/action_rate: -0.0752
          Episode_Reward/joint_vel: -0.0319
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 90636288
                    Iteration time: 2.06s
                      Time elapsed: 00:35:01
                               ETA: 01:18:59

################################################################################
                     [1m Learning iteration 922/3000 [0m                      

                       Computation: 45519 steps/s (collection: 2.053s, learning 0.107s)
             Mean action noise std: 3.41
          Mean value_function loss: 82.0188
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 80.7639
                       Mean reward: 598.72
               Mean episode length: 215.22
    Episode_Reward/reaching_object: 1.4783
    Episode_Reward/rotating_object: 121.2114
        Episode_Reward/action_rate: -0.0787
          Episode_Reward/joint_vel: -0.0327
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 90734592
                    Iteration time: 2.16s
                      Time elapsed: 00:35:03
                               ETA: 01:18:56

################################################################################
                     [1m Learning iteration 923/3000 [0m                      

                       Computation: 44638 steps/s (collection: 2.077s, learning 0.125s)
             Mean action noise std: 3.42
          Mean value_function loss: 88.3812
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 80.7825
                       Mean reward: 671.10
               Mean episode length: 235.59
    Episode_Reward/reaching_object: 1.5062
    Episode_Reward/rotating_object: 125.1250
        Episode_Reward/action_rate: -0.0800
          Episode_Reward/joint_vel: -0.0323
      Episode_Termination/time_out: 17.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 90832896
                    Iteration time: 2.20s
                      Time elapsed: 00:35:06
                               ETA: 01:18:54

################################################################################
                     [1m Learning iteration 924/3000 [0m                      

                       Computation: 44385 steps/s (collection: 2.061s, learning 0.154s)
             Mean action noise std: 3.42
          Mean value_function loss: 96.1827
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 80.8112
                       Mean reward: 556.58
               Mean episode length: 203.23
    Episode_Reward/reaching_object: 1.4144
    Episode_Reward/rotating_object: 116.9929
        Episode_Reward/action_rate: -0.0761
          Episode_Reward/joint_vel: -0.0320
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.6250
--------------------------------------------------------------------------------
                   Total timesteps: 90931200
                    Iteration time: 2.21s
                      Time elapsed: 00:35:08
                               ETA: 01:18:51

################################################################################
                     [1m Learning iteration 925/3000 [0m                      

                       Computation: 45231 steps/s (collection: 2.016s, learning 0.158s)
             Mean action noise std: 3.42
          Mean value_function loss: 96.4546
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 80.8353
                       Mean reward: 604.62
               Mean episode length: 214.45
    Episode_Reward/reaching_object: 1.4629
    Episode_Reward/rotating_object: 120.7584
        Episode_Reward/action_rate: -0.0784
          Episode_Reward/joint_vel: -0.0318
      Episode_Termination/time_out: 14.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 91029504
                    Iteration time: 2.17s
                      Time elapsed: 00:35:10
                               ETA: 01:18:49

################################################################################
                     [1m Learning iteration 926/3000 [0m                      

                       Computation: 44042 steps/s (collection: 2.120s, learning 0.112s)
             Mean action noise std: 3.43
          Mean value_function loss: 90.2440
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 80.8676
                       Mean reward: 599.06
               Mean episode length: 223.05
    Episode_Reward/reaching_object: 1.4532
    Episode_Reward/rotating_object: 116.8403
        Episode_Reward/action_rate: -0.0780
          Episode_Reward/joint_vel: -0.0332
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.2500
--------------------------------------------------------------------------------
                   Total timesteps: 91127808
                    Iteration time: 2.23s
                      Time elapsed: 00:35:12
                               ETA: 01:18:46

################################################################################
                     [1m Learning iteration 927/3000 [0m                      

                       Computation: 44717 steps/s (collection: 2.071s, learning 0.128s)
             Mean action noise std: 3.43
          Mean value_function loss: 89.4102
               Mean surrogate loss: -0.0083
                 Mean entropy loss: 80.9001
                       Mean reward: 564.39
               Mean episode length: 211.13
    Episode_Reward/reaching_object: 1.4599
    Episode_Reward/rotating_object: 117.6778
        Episode_Reward/action_rate: -0.0781
          Episode_Reward/joint_vel: -0.0328
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.1667
--------------------------------------------------------------------------------
                   Total timesteps: 91226112
                    Iteration time: 2.20s
                      Time elapsed: 00:35:14
                               ETA: 01:18:44

################################################################################
                     [1m Learning iteration 928/3000 [0m                      

                       Computation: 45991 steps/s (collection: 2.017s, learning 0.120s)
             Mean action noise std: 3.44
          Mean value_function loss: 95.8241
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 80.9294
                       Mean reward: 569.55
               Mean episode length: 205.78
    Episode_Reward/reaching_object: 1.4348
    Episode_Reward/rotating_object: 118.6389
        Episode_Reward/action_rate: -0.0769
          Episode_Reward/joint_vel: -0.0313
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.5000
--------------------------------------------------------------------------------
                   Total timesteps: 91324416
                    Iteration time: 2.14s
                      Time elapsed: 00:35:17
                               ETA: 01:18:41

################################################################################
                     [1m Learning iteration 929/3000 [0m                      

                       Computation: 45076 steps/s (collection: 2.051s, learning 0.130s)
             Mean action noise std: 3.44
          Mean value_function loss: 93.7163
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 80.9520
                       Mean reward: 564.28
               Mean episode length: 205.87
    Episode_Reward/reaching_object: 1.4192
    Episode_Reward/rotating_object: 114.0186
        Episode_Reward/action_rate: -0.0767
          Episode_Reward/joint_vel: -0.0332
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.3750
--------------------------------------------------------------------------------
                   Total timesteps: 91422720
                    Iteration time: 2.18s
                      Time elapsed: 00:35:19
                               ETA: 01:18:39

################################################################################
                     [1m Learning iteration 930/3000 [0m                      

                       Computation: 44896 steps/s (collection: 2.040s, learning 0.150s)
             Mean action noise std: 3.44
          Mean value_function loss: 95.8157
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 80.9785
                       Mean reward: 628.01
               Mean episode length: 223.34
    Episode_Reward/reaching_object: 1.4363
    Episode_Reward/rotating_object: 116.3417
        Episode_Reward/action_rate: -0.0777
          Episode_Reward/joint_vel: -0.0326
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.0833
--------------------------------------------------------------------------------
                   Total timesteps: 91521024
                    Iteration time: 2.19s
                      Time elapsed: 00:35:21
                               ETA: 01:18:36

################################################################################
                     [1m Learning iteration 931/3000 [0m                      

                       Computation: 42770 steps/s (collection: 2.111s, learning 0.187s)
             Mean action noise std: 3.44
          Mean value_function loss: 87.1516
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 80.9999
                       Mean reward: 603.57
               Mean episode length: 220.97
    Episode_Reward/reaching_object: 1.4572
    Episode_Reward/rotating_object: 121.1352
        Episode_Reward/action_rate: -0.0784
          Episode_Reward/joint_vel: -0.0322
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.9583
--------------------------------------------------------------------------------
                   Total timesteps: 91619328
                    Iteration time: 2.30s
                      Time elapsed: 00:35:23
                               ETA: 01:18:34

################################################################################
                     [1m Learning iteration 932/3000 [0m                      

                       Computation: 45595 steps/s (collection: 2.030s, learning 0.126s)
             Mean action noise std: 3.45
          Mean value_function loss: 88.8006
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 81.0261
                       Mean reward: 592.54
               Mean episode length: 212.08
    Episode_Reward/reaching_object: 1.4735
    Episode_Reward/rotating_object: 121.4916
        Episode_Reward/action_rate: -0.0799
          Episode_Reward/joint_vel: -0.0327
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 91717632
                    Iteration time: 2.16s
                      Time elapsed: 00:35:25
                               ETA: 01:18:31

################################################################################
                     [1m Learning iteration 933/3000 [0m                      

                       Computation: 45581 steps/s (collection: 2.034s, learning 0.123s)
             Mean action noise std: 3.45
          Mean value_function loss: 85.2153
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 81.0523
                       Mean reward: 630.90
               Mean episode length: 223.43
    Episode_Reward/reaching_object: 1.4627
    Episode_Reward/rotating_object: 121.9613
        Episode_Reward/action_rate: -0.0793
          Episode_Reward/joint_vel: -0.0321
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 91815936
                    Iteration time: 2.16s
                      Time elapsed: 00:35:28
                               ETA: 01:18:29

################################################################################
                     [1m Learning iteration 934/3000 [0m                      

                       Computation: 39135 steps/s (collection: 2.303s, learning 0.209s)
             Mean action noise std: 3.45
          Mean value_function loss: 94.8182
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 81.0739
                       Mean reward: 607.23
               Mean episode length: 215.63
    Episode_Reward/reaching_object: 1.4715
    Episode_Reward/rotating_object: 122.9423
        Episode_Reward/action_rate: -0.0797
          Episode_Reward/joint_vel: -0.0319
      Episode_Termination/time_out: 17.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 91914240
                    Iteration time: 2.51s
                      Time elapsed: 00:35:30
                               ETA: 01:18:27

################################################################################
                     [1m Learning iteration 935/3000 [0m                      

                       Computation: 44146 steps/s (collection: 2.092s, learning 0.135s)
             Mean action noise std: 3.46
          Mean value_function loss: 91.4083
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 81.1030
                       Mean reward: 580.78
               Mean episode length: 213.69
    Episode_Reward/reaching_object: 1.4618
    Episode_Reward/rotating_object: 120.7107
        Episode_Reward/action_rate: -0.0802
          Episode_Reward/joint_vel: -0.0335
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 92012544
                    Iteration time: 2.23s
                      Time elapsed: 00:35:32
                               ETA: 01:18:25

################################################################################
                     [1m Learning iteration 936/3000 [0m                      

                       Computation: 45143 steps/s (collection: 2.036s, learning 0.142s)
             Mean action noise std: 3.46
          Mean value_function loss: 86.5498
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 81.1318
                       Mean reward: 603.00
               Mean episode length: 216.24
    Episode_Reward/reaching_object: 1.3842
    Episode_Reward/rotating_object: 115.1517
        Episode_Reward/action_rate: -0.0765
          Episode_Reward/joint_vel: -0.0328
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.4583
--------------------------------------------------------------------------------
                   Total timesteps: 92110848
                    Iteration time: 2.18s
                      Time elapsed: 00:35:34
                               ETA: 01:18:22

################################################################################
                     [1m Learning iteration 937/3000 [0m                      

                       Computation: 33384 steps/s (collection: 2.760s, learning 0.185s)
             Mean action noise std: 3.46
          Mean value_function loss: 89.1772
               Mean surrogate loss: -0.0077
                 Mean entropy loss: 81.1555
                       Mean reward: 625.78
               Mean episode length: 221.19
    Episode_Reward/reaching_object: 1.4434
    Episode_Reward/rotating_object: 119.5397
        Episode_Reward/action_rate: -0.0789
          Episode_Reward/joint_vel: -0.0336
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.1250
--------------------------------------------------------------------------------
                   Total timesteps: 92209152
                    Iteration time: 2.94s
                      Time elapsed: 00:35:37
                               ETA: 01:18:21

################################################################################
                     [1m Learning iteration 938/3000 [0m                      

                       Computation: 43663 steps/s (collection: 2.132s, learning 0.120s)
             Mean action noise std: 3.47
          Mean value_function loss: 92.1324
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 81.1789
                       Mean reward: 616.45
               Mean episode length: 221.05
    Episode_Reward/reaching_object: 1.4973
    Episode_Reward/rotating_object: 124.7439
        Episode_Reward/action_rate: -0.0822
          Episode_Reward/joint_vel: -0.0318
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 92307456
                    Iteration time: 2.25s
                      Time elapsed: 00:35:40
                               ETA: 01:18:19

################################################################################
                     [1m Learning iteration 939/3000 [0m                      

                       Computation: 41023 steps/s (collection: 2.225s, learning 0.172s)
             Mean action noise std: 3.47
          Mean value_function loss: 88.7923
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 81.2069
                       Mean reward: 632.00
               Mean episode length: 217.13
    Episode_Reward/reaching_object: 1.4449
    Episode_Reward/rotating_object: 122.0212
        Episode_Reward/action_rate: -0.0801
          Episode_Reward/joint_vel: -0.0327
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 92405760
                    Iteration time: 2.40s
                      Time elapsed: 00:35:42
                               ETA: 01:18:17

################################################################################
                     [1m Learning iteration 940/3000 [0m                      

                       Computation: 36027 steps/s (collection: 2.479s, learning 0.249s)
             Mean action noise std: 3.47
          Mean value_function loss: 82.2849
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 81.2320
                       Mean reward: 659.39
               Mean episode length: 232.79
    Episode_Reward/reaching_object: 1.4749
    Episode_Reward/rotating_object: 122.6192
        Episode_Reward/action_rate: -0.0816
          Episode_Reward/joint_vel: -0.0331
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 92504064
                    Iteration time: 2.73s
                      Time elapsed: 00:35:45
                               ETA: 01:18:16

################################################################################
                     [1m Learning iteration 941/3000 [0m                      

                       Computation: 42715 steps/s (collection: 2.110s, learning 0.191s)
             Mean action noise std: 3.48
          Mean value_function loss: 83.1547
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 81.2489
                       Mean reward: 670.42
               Mean episode length: 237.43
    Episode_Reward/reaching_object: 1.5458
    Episode_Reward/rotating_object: 127.9231
        Episode_Reward/action_rate: -0.0845
          Episode_Reward/joint_vel: -0.0339
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 92602368
                    Iteration time: 2.30s
                      Time elapsed: 00:35:47
                               ETA: 01:18:14

################################################################################
                     [1m Learning iteration 942/3000 [0m                      

                       Computation: 45517 steps/s (collection: 2.031s, learning 0.128s)
             Mean action noise std: 3.48
          Mean value_function loss: 90.4188
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 81.2811
                       Mean reward: 580.33
               Mean episode length: 211.77
    Episode_Reward/reaching_object: 1.4511
    Episode_Reward/rotating_object: 120.4662
        Episode_Reward/action_rate: -0.0801
          Episode_Reward/joint_vel: -0.0329
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 92700672
                    Iteration time: 2.16s
                      Time elapsed: 00:35:49
                               ETA: 01:18:11

################################################################################
                     [1m Learning iteration 943/3000 [0m                      

                       Computation: 46159 steps/s (collection: 2.010s, learning 0.120s)
             Mean action noise std: 3.48
          Mean value_function loss: 91.6807
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 81.3063
                       Mean reward: 599.81
               Mean episode length: 212.31
    Episode_Reward/reaching_object: 1.4946
    Episode_Reward/rotating_object: 123.6384
        Episode_Reward/action_rate: -0.0818
          Episode_Reward/joint_vel: -0.0333
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 92798976
                    Iteration time: 2.13s
                      Time elapsed: 00:35:51
                               ETA: 01:18:08

################################################################################
                     [1m Learning iteration 944/3000 [0m                      

                       Computation: 43665 steps/s (collection: 2.130s, learning 0.121s)
             Mean action noise std: 3.49
          Mean value_function loss: 85.8459
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 81.3230
                       Mean reward: 644.43
               Mean episode length: 227.71
    Episode_Reward/reaching_object: 1.5095
    Episode_Reward/rotating_object: 123.7841
        Episode_Reward/action_rate: -0.0828
          Episode_Reward/joint_vel: -0.0345
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 92897280
                    Iteration time: 2.25s
                      Time elapsed: 00:35:54
                               ETA: 01:18:06

################################################################################
                     [1m Learning iteration 945/3000 [0m                      

                       Computation: 45433 steps/s (collection: 2.028s, learning 0.136s)
             Mean action noise std: 3.49
          Mean value_function loss: 96.8345
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 81.3370
                       Mean reward: 556.42
               Mean episode length: 206.43
    Episode_Reward/reaching_object: 1.4783
    Episode_Reward/rotating_object: 122.1264
        Episode_Reward/action_rate: -0.0814
          Episode_Reward/joint_vel: -0.0335
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 92995584
                    Iteration time: 2.16s
                      Time elapsed: 00:35:56
                               ETA: 01:18:04

################################################################################
                     [1m Learning iteration 946/3000 [0m                      

                       Computation: 44617 steps/s (collection: 2.036s, learning 0.167s)
             Mean action noise std: 3.49
          Mean value_function loss: 87.9621
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 81.3611
                       Mean reward: 652.08
               Mean episode length: 226.16
    Episode_Reward/reaching_object: 1.4846
    Episode_Reward/rotating_object: 123.3959
        Episode_Reward/action_rate: -0.0818
          Episode_Reward/joint_vel: -0.0331
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 93093888
                    Iteration time: 2.20s
                      Time elapsed: 00:35:58
                               ETA: 01:18:01

################################################################################
                     [1m Learning iteration 947/3000 [0m                      

                       Computation: 45398 steps/s (collection: 2.060s, learning 0.106s)
             Mean action noise std: 3.49
          Mean value_function loss: 87.2214
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 81.3862
                       Mean reward: 592.92
               Mean episode length: 216.16
    Episode_Reward/reaching_object: 1.4814
    Episode_Reward/rotating_object: 122.2491
        Episode_Reward/action_rate: -0.0818
          Episode_Reward/joint_vel: -0.0328
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7917
--------------------------------------------------------------------------------
                   Total timesteps: 93192192
                    Iteration time: 2.17s
                      Time elapsed: 00:36:00
                               ETA: 01:17:59

################################################################################
                     [1m Learning iteration 948/3000 [0m                      

                       Computation: 44964 steps/s (collection: 2.075s, learning 0.112s)
             Mean action noise std: 3.50
          Mean value_function loss: 95.8118
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 81.4117
                       Mean reward: 620.08
               Mean episode length: 216.23
    Episode_Reward/reaching_object: 1.4959
    Episode_Reward/rotating_object: 124.5261
        Episode_Reward/action_rate: -0.0822
          Episode_Reward/joint_vel: -0.0322
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 93290496
                    Iteration time: 2.19s
                      Time elapsed: 00:36:02
                               ETA: 01:17:56

################################################################################
                     [1m Learning iteration 949/3000 [0m                      

                       Computation: 44913 steps/s (collection: 2.037s, learning 0.152s)
             Mean action noise std: 3.50
          Mean value_function loss: 89.1147
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 81.4410
                       Mean reward: 669.09
               Mean episode length: 228.03
    Episode_Reward/reaching_object: 1.4645
    Episode_Reward/rotating_object: 123.8300
        Episode_Reward/action_rate: -0.0814
          Episode_Reward/joint_vel: -0.0329
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 93388800
                    Iteration time: 2.19s
                      Time elapsed: 00:36:04
                               ETA: 01:17:54

################################################################################
                     [1m Learning iteration 950/3000 [0m                      

                       Computation: 46938 steps/s (collection: 1.982s, learning 0.112s)
             Mean action noise std: 3.51
          Mean value_function loss: 87.1668
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 81.4704
                       Mean reward: 643.96
               Mean episode length: 226.12
    Episode_Reward/reaching_object: 1.5102
    Episode_Reward/rotating_object: 128.3234
        Episode_Reward/action_rate: -0.0841
          Episode_Reward/joint_vel: -0.0331
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 93487104
                    Iteration time: 2.09s
                      Time elapsed: 00:36:07
                               ETA: 01:17:51

################################################################################
                     [1m Learning iteration 951/3000 [0m                      

                       Computation: 45527 steps/s (collection: 2.038s, learning 0.121s)
             Mean action noise std: 3.51
          Mean value_function loss: 87.7430
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 81.4958
                       Mean reward: 605.76
               Mean episode length: 219.71
    Episode_Reward/reaching_object: 1.4854
    Episode_Reward/rotating_object: 124.6047
        Episode_Reward/action_rate: -0.0829
          Episode_Reward/joint_vel: -0.0336
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 93585408
                    Iteration time: 2.16s
                      Time elapsed: 00:36:09
                               ETA: 01:17:48

################################################################################
                     [1m Learning iteration 952/3000 [0m                      

                       Computation: 44364 steps/s (collection: 2.031s, learning 0.185s)
             Mean action noise std: 3.51
          Mean value_function loss: 87.0644
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 81.5165
                       Mean reward: 651.76
               Mean episode length: 228.65
    Episode_Reward/reaching_object: 1.4941
    Episode_Reward/rotating_object: 127.5124
        Episode_Reward/action_rate: -0.0839
          Episode_Reward/joint_vel: -0.0333
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 93683712
                    Iteration time: 2.22s
                      Time elapsed: 00:36:11
                               ETA: 01:17:46

################################################################################
                     [1m Learning iteration 953/3000 [0m                      

                       Computation: 46035 steps/s (collection: 1.986s, learning 0.149s)
             Mean action noise std: 3.51
          Mean value_function loss: 81.1493
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 81.5403
                       Mean reward: 661.35
               Mean episode length: 230.59
    Episode_Reward/reaching_object: 1.5041
    Episode_Reward/rotating_object: 127.8643
        Episode_Reward/action_rate: -0.0845
          Episode_Reward/joint_vel: -0.0336
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 93782016
                    Iteration time: 2.14s
                      Time elapsed: 00:36:13
                               ETA: 01:17:43

################################################################################
                     [1m Learning iteration 954/3000 [0m                      

                       Computation: 45910 steps/s (collection: 2.042s, learning 0.100s)
             Mean action noise std: 3.52
          Mean value_function loss: 91.6382
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 81.5674
                       Mean reward: 581.79
               Mean episode length: 205.74
    Episode_Reward/reaching_object: 1.4731
    Episode_Reward/rotating_object: 123.1926
        Episode_Reward/action_rate: -0.0831
          Episode_Reward/joint_vel: -0.0338
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 93880320
                    Iteration time: 2.14s
                      Time elapsed: 00:36:15
                               ETA: 01:17:41

################################################################################
                     [1m Learning iteration 955/3000 [0m                      

                       Computation: 45141 steps/s (collection: 2.062s, learning 0.115s)
             Mean action noise std: 3.52
          Mean value_function loss: 87.1310
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 81.5829
                       Mean reward: 600.65
               Mean episode length: 218.23
    Episode_Reward/reaching_object: 1.4643
    Episode_Reward/rotating_object: 121.8829
        Episode_Reward/action_rate: -0.0827
          Episode_Reward/joint_vel: -0.0338
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 93978624
                    Iteration time: 2.18s
                      Time elapsed: 00:36:17
                               ETA: 01:17:38

################################################################################
                     [1m Learning iteration 956/3000 [0m                      

                       Computation: 45746 steps/s (collection: 2.036s, learning 0.113s)
             Mean action noise std: 3.52
          Mean value_function loss: 90.1837
               Mean surrogate loss: -0.0081
                 Mean entropy loss: 81.6075
                       Mean reward: 613.49
               Mean episode length: 217.39
    Episode_Reward/reaching_object: 1.4949
    Episode_Reward/rotating_object: 124.6638
        Episode_Reward/action_rate: -0.0839
          Episode_Reward/joint_vel: -0.0331
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 94076928
                    Iteration time: 2.15s
                      Time elapsed: 00:36:20
                               ETA: 01:17:36

################################################################################
                     [1m Learning iteration 957/3000 [0m                      

                       Computation: 44122 steps/s (collection: 2.031s, learning 0.197s)
             Mean action noise std: 3.53
          Mean value_function loss: 87.0462
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 81.6383
                       Mean reward: 659.73
               Mean episode length: 230.52
    Episode_Reward/reaching_object: 1.5208
    Episode_Reward/rotating_object: 127.2547
        Episode_Reward/action_rate: -0.0855
          Episode_Reward/joint_vel: -0.0340
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 94175232
                    Iteration time: 2.23s
                      Time elapsed: 00:36:22
                               ETA: 01:17:33

################################################################################
                     [1m Learning iteration 958/3000 [0m                      

                       Computation: 44154 steps/s (collection: 2.062s, learning 0.164s)
             Mean action noise std: 3.53
          Mean value_function loss: 91.1313
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 81.6600
                       Mean reward: 609.57
               Mean episode length: 217.18
    Episode_Reward/reaching_object: 1.4846
    Episode_Reward/rotating_object: 120.7083
        Episode_Reward/action_rate: -0.0835
          Episode_Reward/joint_vel: -0.0345
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 94273536
                    Iteration time: 2.23s
                      Time elapsed: 00:36:24
                               ETA: 01:17:31

################################################################################
                     [1m Learning iteration 959/3000 [0m                      

                       Computation: 45954 steps/s (collection: 1.988s, learning 0.152s)
             Mean action noise std: 3.53
          Mean value_function loss: 88.8655
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 81.6762
                       Mean reward: 637.50
               Mean episode length: 222.34
    Episode_Reward/reaching_object: 1.5193
    Episode_Reward/rotating_object: 127.9875
        Episode_Reward/action_rate: -0.0853
          Episode_Reward/joint_vel: -0.0328
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 94371840
                    Iteration time: 2.14s
                      Time elapsed: 00:36:26
                               ETA: 01:17:28

################################################################################
                     [1m Learning iteration 960/3000 [0m                      

                       Computation: 47363 steps/s (collection: 1.966s, learning 0.110s)
             Mean action noise std: 3.53
          Mean value_function loss: 91.2203
               Mean surrogate loss: -0.0087
                 Mean entropy loss: 81.6998
                       Mean reward: 650.52
               Mean episode length: 229.83
    Episode_Reward/reaching_object: 1.5210
    Episode_Reward/rotating_object: 126.9600
        Episode_Reward/action_rate: -0.0861
          Episode_Reward/joint_vel: -0.0345
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 94470144
                    Iteration time: 2.08s
                      Time elapsed: 00:36:28
                               ETA: 01:17:26

################################################################################
                     [1m Learning iteration 961/3000 [0m                      

                       Computation: 47257 steps/s (collection: 1.980s, learning 0.101s)
             Mean action noise std: 3.53
          Mean value_function loss: 86.3499
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 81.7242
                       Mean reward: 606.77
               Mean episode length: 218.41
    Episode_Reward/reaching_object: 1.4750
    Episode_Reward/rotating_object: 122.7341
        Episode_Reward/action_rate: -0.0834
          Episode_Reward/joint_vel: -0.0336
      Episode_Termination/time_out: 14.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 94568448
                    Iteration time: 2.08s
                      Time elapsed: 00:36:30
                               ETA: 01:17:23

################################################################################
                     [1m Learning iteration 962/3000 [0m                      

                       Computation: 45591 steps/s (collection: 2.021s, learning 0.135s)
             Mean action noise std: 3.54
          Mean value_function loss: 82.4270
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 81.7426
                       Mean reward: 611.53
               Mean episode length: 216.50
    Episode_Reward/reaching_object: 1.5032
    Episode_Reward/rotating_object: 124.9639
        Episode_Reward/action_rate: -0.0849
          Episode_Reward/joint_vel: -0.0340
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 94666752
                    Iteration time: 2.16s
                      Time elapsed: 00:36:32
                               ETA: 01:17:20

################################################################################
                     [1m Learning iteration 963/3000 [0m                      

                       Computation: 45807 steps/s (collection: 2.006s, learning 0.140s)
             Mean action noise std: 3.54
          Mean value_function loss: 78.7563
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 81.7626
                       Mean reward: 626.02
               Mean episode length: 220.49
    Episode_Reward/reaching_object: 1.4773
    Episode_Reward/rotating_object: 124.0601
        Episode_Reward/action_rate: -0.0841
          Episode_Reward/joint_vel: -0.0341
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 94765056
                    Iteration time: 2.15s
                      Time elapsed: 00:36:35
                               ETA: 01:17:18

################################################################################
                     [1m Learning iteration 964/3000 [0m                      

                       Computation: 45771 steps/s (collection: 2.020s, learning 0.128s)
             Mean action noise std: 3.54
          Mean value_function loss: 81.5974
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 81.7745
                       Mean reward: 623.76
               Mean episode length: 217.98
    Episode_Reward/reaching_object: 1.5204
    Episode_Reward/rotating_object: 129.4080
        Episode_Reward/action_rate: -0.0861
          Episode_Reward/joint_vel: -0.0322
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 94863360
                    Iteration time: 2.15s
                      Time elapsed: 00:36:37
                               ETA: 01:17:15

################################################################################
                     [1m Learning iteration 965/3000 [0m                      

                       Computation: 39691 steps/s (collection: 2.270s, learning 0.207s)
             Mean action noise std: 3.55
          Mean value_function loss: 77.1932
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 81.7981
                       Mean reward: 630.43
               Mean episode length: 220.40
    Episode_Reward/reaching_object: 1.5278
    Episode_Reward/rotating_object: 128.4548
        Episode_Reward/action_rate: -0.0864
          Episode_Reward/joint_vel: -0.0335
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 94961664
                    Iteration time: 2.48s
                      Time elapsed: 00:36:39
                               ETA: 01:17:14

################################################################################
                     [1m Learning iteration 966/3000 [0m                      

                       Computation: 41039 steps/s (collection: 2.212s, learning 0.184s)
             Mean action noise std: 3.55
          Mean value_function loss: 82.5596
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 81.8317
                       Mean reward: 617.12
               Mean episode length: 218.49
    Episode_Reward/reaching_object: 1.4750
    Episode_Reward/rotating_object: 125.7375
        Episode_Reward/action_rate: -0.0845
          Episode_Reward/joint_vel: -0.0328
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 95059968
                    Iteration time: 2.40s
                      Time elapsed: 00:36:42
                               ETA: 01:17:11

################################################################################
                     [1m Learning iteration 967/3000 [0m                      

                       Computation: 40359 steps/s (collection: 2.312s, learning 0.124s)
             Mean action noise std: 3.55
          Mean value_function loss: 87.4761
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 81.8653
                       Mean reward: 611.11
               Mean episode length: 220.46
    Episode_Reward/reaching_object: 1.5033
    Episode_Reward/rotating_object: 123.7175
        Episode_Reward/action_rate: -0.0859
          Episode_Reward/joint_vel: -0.0355
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 95158272
                    Iteration time: 2.44s
                      Time elapsed: 00:36:44
                               ETA: 01:17:10

################################################################################
                     [1m Learning iteration 968/3000 [0m                      

                       Computation: 40231 steps/s (collection: 2.260s, learning 0.184s)
             Mean action noise std: 3.56
          Mean value_function loss: 76.0921
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 81.8958
                       Mean reward: 631.48
               Mean episode length: 223.69
    Episode_Reward/reaching_object: 1.5341
    Episode_Reward/rotating_object: 129.5328
        Episode_Reward/action_rate: -0.0876
          Episode_Reward/joint_vel: -0.0340
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 95256576
                    Iteration time: 2.44s
                      Time elapsed: 00:36:47
                               ETA: 01:17:08

################################################################################
                     [1m Learning iteration 969/3000 [0m                      

                       Computation: 39948 steps/s (collection: 2.226s, learning 0.235s)
             Mean action noise std: 3.56
          Mean value_function loss: 92.0715
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 81.9300
                       Mean reward: 622.78
               Mean episode length: 218.89
    Episode_Reward/reaching_object: 1.5280
    Episode_Reward/rotating_object: 129.6228
        Episode_Reward/action_rate: -0.0870
          Episode_Reward/joint_vel: -0.0326
      Episode_Termination/time_out: 17.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 95354880
                    Iteration time: 2.46s
                      Time elapsed: 00:36:49
                               ETA: 01:17:06

################################################################################
                     [1m Learning iteration 970/3000 [0m                      

                       Computation: 39479 steps/s (collection: 2.324s, learning 0.166s)
             Mean action noise std: 3.56
          Mean value_function loss: 89.7433
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 81.9539
                       Mean reward: 675.21
               Mean episode length: 233.11
    Episode_Reward/reaching_object: 1.5206
    Episode_Reward/rotating_object: 130.0750
        Episode_Reward/action_rate: -0.0869
          Episode_Reward/joint_vel: -0.0327
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 95453184
                    Iteration time: 2.49s
                      Time elapsed: 00:36:51
                               ETA: 01:17:04

################################################################################
                     [1m Learning iteration 971/3000 [0m                      

                       Computation: 40595 steps/s (collection: 2.234s, learning 0.188s)
             Mean action noise std: 3.57
          Mean value_function loss: 77.7237
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 81.9806
                       Mean reward: 654.99
               Mean episode length: 226.99
    Episode_Reward/reaching_object: 1.4672
    Episode_Reward/rotating_object: 123.3668
        Episode_Reward/action_rate: -0.0843
          Episode_Reward/joint_vel: -0.0333
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 95551488
                    Iteration time: 2.42s
                      Time elapsed: 00:36:54
                               ETA: 01:17:02

################################################################################
                     [1m Learning iteration 972/3000 [0m                      

                       Computation: 44842 steps/s (collection: 2.031s, learning 0.161s)
             Mean action noise std: 3.57
          Mean value_function loss: 82.6036
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 82.0149
                       Mean reward: 635.02
               Mean episode length: 222.21
    Episode_Reward/reaching_object: 1.5022
    Episode_Reward/rotating_object: 126.9490
        Episode_Reward/action_rate: -0.0859
          Episode_Reward/joint_vel: -0.0323
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 95649792
                    Iteration time: 2.19s
                      Time elapsed: 00:36:56
                               ETA: 01:16:59

################################################################################
                     [1m Learning iteration 973/3000 [0m                      

                       Computation: 47038 steps/s (collection: 1.971s, learning 0.119s)
             Mean action noise std: 3.57
          Mean value_function loss: 68.9109
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 82.0385
                       Mean reward: 686.89
               Mean episode length: 236.29
    Episode_Reward/reaching_object: 1.5276
    Episode_Reward/rotating_object: 130.5296
        Episode_Reward/action_rate: -0.0880
          Episode_Reward/joint_vel: -0.0333
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 95748096
                    Iteration time: 2.09s
                      Time elapsed: 00:36:58
                               ETA: 01:16:57

################################################################################
                     [1m Learning iteration 974/3000 [0m                      

                       Computation: 47117 steps/s (collection: 1.981s, learning 0.106s)
             Mean action noise std: 3.58
          Mean value_function loss: 73.3565
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 82.0541
                       Mean reward: 664.20
               Mean episode length: 226.87
    Episode_Reward/reaching_object: 1.4966
    Episode_Reward/rotating_object: 125.7832
        Episode_Reward/action_rate: -0.0860
          Episode_Reward/joint_vel: -0.0333
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 95846400
                    Iteration time: 2.09s
                      Time elapsed: 00:37:00
                               ETA: 01:16:54

################################################################################
                     [1m Learning iteration 975/3000 [0m                      

                       Computation: 46187 steps/s (collection: 2.020s, learning 0.108s)
             Mean action noise std: 3.58
          Mean value_function loss: 74.5108
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 82.0791
                       Mean reward: 627.43
               Mean episode length: 220.87
    Episode_Reward/reaching_object: 1.5219
    Episode_Reward/rotating_object: 128.4788
        Episode_Reward/action_rate: -0.0877
          Episode_Reward/joint_vel: -0.0338
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 95944704
                    Iteration time: 2.13s
                      Time elapsed: 00:37:02
                               ETA: 01:16:52

################################################################################
                     [1m Learning iteration 976/3000 [0m                      

                       Computation: 44788 steps/s (collection: 2.067s, learning 0.128s)
             Mean action noise std: 3.58
          Mean value_function loss: 82.5929
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 82.0974
                       Mean reward: 648.09
               Mean episode length: 232.62
    Episode_Reward/reaching_object: 1.5331
    Episode_Reward/rotating_object: 127.3974
        Episode_Reward/action_rate: -0.0877
          Episode_Reward/joint_vel: -0.0336
      Episode_Termination/time_out: 17.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 96043008
                    Iteration time: 2.19s
                      Time elapsed: 00:37:05
                               ETA: 01:16:49

################################################################################
                     [1m Learning iteration 977/3000 [0m                      

                       Computation: 45716 steps/s (collection: 2.036s, learning 0.115s)
             Mean action noise std: 3.58
          Mean value_function loss: 86.0335
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 82.1171
                       Mean reward: 644.53
               Mean episode length: 227.12
    Episode_Reward/reaching_object: 1.5159
    Episode_Reward/rotating_object: 126.7853
        Episode_Reward/action_rate: -0.0878
          Episode_Reward/joint_vel: -0.0344
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 96141312
                    Iteration time: 2.15s
                      Time elapsed: 00:37:07
                               ETA: 01:16:47

################################################################################
                     [1m Learning iteration 978/3000 [0m                      

                       Computation: 44253 steps/s (collection: 2.054s, learning 0.168s)
             Mean action noise std: 3.59
          Mean value_function loss: 75.1180
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 82.1479
                       Mean reward: 621.21
               Mean episode length: 220.59
    Episode_Reward/reaching_object: 1.5097
    Episode_Reward/rotating_object: 127.4861
        Episode_Reward/action_rate: -0.0865
          Episode_Reward/joint_vel: -0.0324
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 96239616
                    Iteration time: 2.22s
                      Time elapsed: 00:37:09
                               ETA: 01:16:44

################################################################################
                     [1m Learning iteration 979/3000 [0m                      

                       Computation: 43103 steps/s (collection: 2.075s, learning 0.206s)
             Mean action noise std: 3.59
          Mean value_function loss: 86.5924
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 82.1759
                       Mean reward: 634.84
               Mean episode length: 222.98
    Episode_Reward/reaching_object: 1.5116
    Episode_Reward/rotating_object: 127.2248
        Episode_Reward/action_rate: -0.0873
          Episode_Reward/joint_vel: -0.0326
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 96337920
                    Iteration time: 2.28s
                      Time elapsed: 00:37:11
                               ETA: 01:16:42

################################################################################
                     [1m Learning iteration 980/3000 [0m                      

                       Computation: 44896 steps/s (collection: 2.071s, learning 0.119s)
             Mean action noise std: 3.59
          Mean value_function loss: 80.2945
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 82.1957
                       Mean reward: 674.17
               Mean episode length: 232.11
    Episode_Reward/reaching_object: 1.5172
    Episode_Reward/rotating_object: 128.4604
        Episode_Reward/action_rate: -0.0873
          Episode_Reward/joint_vel: -0.0323
      Episode_Termination/time_out: 17.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 96436224
                    Iteration time: 2.19s
                      Time elapsed: 00:37:13
                               ETA: 01:16:39

################################################################################
                     [1m Learning iteration 981/3000 [0m                      

                       Computation: 46468 steps/s (collection: 1.989s, learning 0.127s)
             Mean action noise std: 3.60
          Mean value_function loss: 93.5664
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 82.2214
                       Mean reward: 627.01
               Mean episode length: 223.15
    Episode_Reward/reaching_object: 1.5038
    Episode_Reward/rotating_object: 127.1229
        Episode_Reward/action_rate: -0.0876
          Episode_Reward/joint_vel: -0.0332
      Episode_Termination/time_out: 14.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 96534528
                    Iteration time: 2.12s
                      Time elapsed: 00:37:16
                               ETA: 01:16:37

################################################################################
                     [1m Learning iteration 982/3000 [0m                      

                       Computation: 45304 steps/s (collection: 2.035s, learning 0.135s)
             Mean action noise std: 3.60
          Mean value_function loss: 88.9366
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 82.2548
                       Mean reward: 613.67
               Mean episode length: 219.06
    Episode_Reward/reaching_object: 1.4681
    Episode_Reward/rotating_object: 123.5668
        Episode_Reward/action_rate: -0.0852
          Episode_Reward/joint_vel: -0.0326
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7083
--------------------------------------------------------------------------------
                   Total timesteps: 96632832
                    Iteration time: 2.17s
                      Time elapsed: 00:37:18
                               ETA: 01:16:34

################################################################################
                     [1m Learning iteration 983/3000 [0m                      

                       Computation: 45043 steps/s (collection: 2.071s, learning 0.112s)
             Mean action noise std: 3.60
          Mean value_function loss: 75.3465
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 82.2842
                       Mean reward: 651.40
               Mean episode length: 229.01
    Episode_Reward/reaching_object: 1.5248
    Episode_Reward/rotating_object: 128.4946
        Episode_Reward/action_rate: -0.0884
          Episode_Reward/joint_vel: -0.0332
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 96731136
                    Iteration time: 2.18s
                      Time elapsed: 00:37:20
                               ETA: 01:16:32

################################################################################
                     [1m Learning iteration 984/3000 [0m                      

                       Computation: 42085 steps/s (collection: 2.133s, learning 0.202s)
             Mean action noise std: 3.61
          Mean value_function loss: 86.2848
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 82.3051
                       Mean reward: 610.32
               Mean episode length: 213.71
    Episode_Reward/reaching_object: 1.5318
    Episode_Reward/rotating_object: 129.0317
        Episode_Reward/action_rate: -0.0888
          Episode_Reward/joint_vel: -0.0334
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 96829440
                    Iteration time: 2.34s
                      Time elapsed: 00:37:22
                               ETA: 01:16:30

################################################################################
                     [1m Learning iteration 985/3000 [0m                      

                       Computation: 45459 steps/s (collection: 2.047s, learning 0.116s)
             Mean action noise std: 3.61
          Mean value_function loss: 86.2673
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 82.3294
                       Mean reward: 647.42
               Mean episode length: 223.47
    Episode_Reward/reaching_object: 1.4486
    Episode_Reward/rotating_object: 123.8575
        Episode_Reward/action_rate: -0.0851
          Episode_Reward/joint_vel: -0.0321
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.9167
--------------------------------------------------------------------------------
                   Total timesteps: 96927744
                    Iteration time: 2.16s
                      Time elapsed: 00:37:24
                               ETA: 01:16:27

################################################################################
                     [1m Learning iteration 986/3000 [0m                      

                       Computation: 46172 steps/s (collection: 2.022s, learning 0.107s)
             Mean action noise std: 3.61
          Mean value_function loss: 86.5544
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 82.3598
                       Mean reward: 645.29
               Mean episode length: 223.47
    Episode_Reward/reaching_object: 1.5134
    Episode_Reward/rotating_object: 128.1378
        Episode_Reward/action_rate: -0.0887
          Episode_Reward/joint_vel: -0.0335
      Episode_Termination/time_out: 17.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 97026048
                    Iteration time: 2.13s
                      Time elapsed: 00:37:27
                               ETA: 01:16:25

################################################################################
                     [1m Learning iteration 987/3000 [0m                      

                       Computation: 46159 steps/s (collection: 2.011s, learning 0.118s)
             Mean action noise std: 3.62
          Mean value_function loss: 91.0726
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 82.3994
                       Mean reward: 619.40
               Mean episode length: 217.48
    Episode_Reward/reaching_object: 1.5154
    Episode_Reward/rotating_object: 129.0836
        Episode_Reward/action_rate: -0.0888
          Episode_Reward/joint_vel: -0.0326
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 97124352
                    Iteration time: 2.13s
                      Time elapsed: 00:37:29
                               ETA: 01:16:22

################################################################################
                     [1m Learning iteration 988/3000 [0m                      

                       Computation: 45895 steps/s (collection: 2.023s, learning 0.119s)
             Mean action noise std: 3.62
          Mean value_function loss: 89.7546
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 82.4363
                       Mean reward: 588.60
               Mean episode length: 213.14
    Episode_Reward/reaching_object: 1.4383
    Episode_Reward/rotating_object: 120.1708
        Episode_Reward/action_rate: -0.0850
          Episode_Reward/joint_vel: -0.0331
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 3.0417
--------------------------------------------------------------------------------
                   Total timesteps: 97222656
                    Iteration time: 2.14s
                      Time elapsed: 00:37:31
                               ETA: 01:16:19

################################################################################
                     [1m Learning iteration 989/3000 [0m                      

                       Computation: 43702 steps/s (collection: 2.113s, learning 0.137s)
             Mean action noise std: 3.63
          Mean value_function loss: 79.2672
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 82.4700
                       Mean reward: 652.90
               Mean episode length: 226.24
    Episode_Reward/reaching_object: 1.5275
    Episode_Reward/rotating_object: 129.8993
        Episode_Reward/action_rate: -0.0899
          Episode_Reward/joint_vel: -0.0339
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 97320960
                    Iteration time: 2.25s
                      Time elapsed: 00:37:33
                               ETA: 01:16:17

################################################################################
                     [1m Learning iteration 990/3000 [0m                      

                       Computation: 45288 steps/s (collection: 2.053s, learning 0.118s)
             Mean action noise std: 3.63
          Mean value_function loss: 85.5824
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 82.4983
                       Mean reward: 618.58
               Mean episode length: 216.82
    Episode_Reward/reaching_object: 1.4991
    Episode_Reward/rotating_object: 126.1822
        Episode_Reward/action_rate: -0.0890
          Episode_Reward/joint_vel: -0.0343
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 97419264
                    Iteration time: 2.17s
                      Time elapsed: 00:37:35
                               ETA: 01:16:15

################################################################################
                     [1m Learning iteration 991/3000 [0m                      

                       Computation: 45315 steps/s (collection: 1.974s, learning 0.196s)
             Mean action noise std: 3.63
          Mean value_function loss: 78.9811
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 82.5217
                       Mean reward: 645.96
               Mean episode length: 223.75
    Episode_Reward/reaching_object: 1.4742
    Episode_Reward/rotating_object: 124.9603
        Episode_Reward/action_rate: -0.0876
          Episode_Reward/joint_vel: -0.0328
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 97517568
                    Iteration time: 2.17s
                      Time elapsed: 00:37:37
                               ETA: 01:16:12

################################################################################
                     [1m Learning iteration 992/3000 [0m                      

                       Computation: 47279 steps/s (collection: 1.948s, learning 0.132s)
             Mean action noise std: 3.64
          Mean value_function loss: 85.9235
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 82.5554
                       Mean reward: 622.90
               Mean episode length: 218.94
    Episode_Reward/reaching_object: 1.4599
    Episode_Reward/rotating_object: 125.4940
        Episode_Reward/action_rate: -0.0874
          Episode_Reward/joint_vel: -0.0323
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 97615872
                    Iteration time: 2.08s
                      Time elapsed: 00:37:39
                               ETA: 01:16:09

################################################################################
                     [1m Learning iteration 993/3000 [0m                      

                       Computation: 44819 steps/s (collection: 2.054s, learning 0.140s)
             Mean action noise std: 3.64
          Mean value_function loss: 83.0956
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 82.5811
                       Mean reward: 608.87
               Mean episode length: 216.68
    Episode_Reward/reaching_object: 1.4695
    Episode_Reward/rotating_object: 123.3752
        Episode_Reward/action_rate: -0.0880
          Episode_Reward/joint_vel: -0.0337
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 97714176
                    Iteration time: 2.19s
                      Time elapsed: 00:37:42
                               ETA: 01:16:07

################################################################################
                     [1m Learning iteration 994/3000 [0m                      

                       Computation: 43690 steps/s (collection: 2.107s, learning 0.143s)
             Mean action noise std: 3.64
          Mean value_function loss: 87.9312
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 82.6050
                       Mean reward: 638.02
               Mean episode length: 224.54
    Episode_Reward/reaching_object: 1.4701
    Episode_Reward/rotating_object: 124.4710
        Episode_Reward/action_rate: -0.0882
          Episode_Reward/joint_vel: -0.0327
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 97812480
                    Iteration time: 2.25s
                      Time elapsed: 00:37:44
                               ETA: 01:16:05

################################################################################
                     [1m Learning iteration 995/3000 [0m                      

                       Computation: 44469 steps/s (collection: 2.032s, learning 0.178s)
             Mean action noise std: 3.65
          Mean value_function loss: 79.3454
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 82.6413
                       Mean reward: 646.33
               Mean episode length: 224.33
    Episode_Reward/reaching_object: 1.5248
    Episode_Reward/rotating_object: 130.7163
        Episode_Reward/action_rate: -0.0917
          Episode_Reward/joint_vel: -0.0335
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 97910784
                    Iteration time: 2.21s
                      Time elapsed: 00:37:46
                               ETA: 01:16:02

################################################################################
                     [1m Learning iteration 996/3000 [0m                      

                       Computation: 46284 steps/s (collection: 1.965s, learning 0.159s)
             Mean action noise std: 3.65
          Mean value_function loss: 85.1858
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 82.6754
                       Mean reward: 645.20
               Mean episode length: 220.96
    Episode_Reward/reaching_object: 1.4632
    Episode_Reward/rotating_object: 124.9759
        Episode_Reward/action_rate: -0.0880
          Episode_Reward/joint_vel: -0.0326
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.8333
--------------------------------------------------------------------------------
                   Total timesteps: 98009088
                    Iteration time: 2.12s
                      Time elapsed: 00:37:48
                               ETA: 01:16:00

################################################################################
                     [1m Learning iteration 997/3000 [0m                      

                       Computation: 46339 steps/s (collection: 1.962s, learning 0.160s)
             Mean action noise std: 3.65
          Mean value_function loss: 74.9634
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 82.7017
                       Mean reward: 684.17
               Mean episode length: 235.95
    Episode_Reward/reaching_object: 1.5573
    Episode_Reward/rotating_object: 134.1907
        Episode_Reward/action_rate: -0.0930
          Episode_Reward/joint_vel: -0.0329
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 98107392
                    Iteration time: 2.12s
                      Time elapsed: 00:37:50
                               ETA: 01:15:57

################################################################################
                     [1m Learning iteration 998/3000 [0m                      

                       Computation: 45189 steps/s (collection: 2.022s, learning 0.153s)
             Mean action noise std: 3.66
          Mean value_function loss: 77.9761
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 82.7315
                       Mean reward: 691.33
               Mean episode length: 233.46
    Episode_Reward/reaching_object: 1.5386
    Episode_Reward/rotating_object: 130.3296
        Episode_Reward/action_rate: -0.0924
          Episode_Reward/joint_vel: -0.0335
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 98205696
                    Iteration time: 2.18s
                      Time elapsed: 00:37:53
                               ETA: 01:15:55

################################################################################
                     [1m Learning iteration 999/3000 [0m                      

                       Computation: 45999 steps/s (collection: 1.993s, learning 0.144s)
             Mean action noise std: 3.66
          Mean value_function loss: 79.2321
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 82.7529
                       Mean reward: 675.90
               Mean episode length: 235.16
    Episode_Reward/reaching_object: 1.5073
    Episode_Reward/rotating_object: 128.2190
        Episode_Reward/action_rate: -0.0905
          Episode_Reward/joint_vel: -0.0331
      Episode_Termination/time_out: 14.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 98304000
                    Iteration time: 2.14s
                      Time elapsed: 00:37:55
                               ETA: 01:15:52

################################################################################
                     [1m Learning iteration 1000/3000 [0m                     

                       Computation: 14553 steps/s (collection: 6.586s, learning 0.168s)
             Mean action noise std: 3.66
          Mean value_function loss: 79.5879
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 82.7750
                       Mean reward: 669.04
               Mean episode length: 232.72
    Episode_Reward/reaching_object: 1.5682
    Episode_Reward/rotating_object: 133.6589
        Episode_Reward/action_rate: -0.0936
          Episode_Reward/joint_vel: -0.0325
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 98402304
                    Iteration time: 6.75s
                      Time elapsed: 00:38:01
                               ETA: 01:15:59

################################################################################
                     [1m Learning iteration 1001/3000 [0m                     

                       Computation: 14043 steps/s (collection: 6.855s, learning 0.145s)
             Mean action noise std: 3.67
          Mean value_function loss: 79.4626
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 82.8004
                       Mean reward: 680.46
               Mean episode length: 232.27
    Episode_Reward/reaching_object: 1.5374
    Episode_Reward/rotating_object: 130.9225
        Episode_Reward/action_rate: -0.0923
          Episode_Reward/joint_vel: -0.0332
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 98500608
                    Iteration time: 7.00s
                      Time elapsed: 00:38:08
                               ETA: 01:16:06

################################################################################
                     [1m Learning iteration 1002/3000 [0m                     

                       Computation: 14411 steps/s (collection: 6.693s, learning 0.129s)
             Mean action noise std: 3.67
          Mean value_function loss: 80.8329
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 82.8155
                       Mean reward: 637.49
               Mean episode length: 218.85
    Episode_Reward/reaching_object: 1.4701
    Episode_Reward/rotating_object: 123.7827
        Episode_Reward/action_rate: -0.0891
          Episode_Reward/joint_vel: -0.0331
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 98598912
                    Iteration time: 6.82s
                      Time elapsed: 00:38:15
                               ETA: 01:16:13

################################################################################
                     [1m Learning iteration 1003/3000 [0m                     

                       Computation: 14451 steps/s (collection: 6.678s, learning 0.125s)
             Mean action noise std: 3.67
          Mean value_function loss: 82.2792
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 82.8435
                       Mean reward: 694.37
               Mean episode length: 235.41
    Episode_Reward/reaching_object: 1.5323
    Episode_Reward/rotating_object: 130.4191
        Episode_Reward/action_rate: -0.0922
          Episode_Reward/joint_vel: -0.0323
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 98697216
                    Iteration time: 6.80s
                      Time elapsed: 00:38:22
                               ETA: 01:16:19

################################################################################
                     [1m Learning iteration 1004/3000 [0m                     

                       Computation: 14613 steps/s (collection: 6.586s, learning 0.141s)
             Mean action noise std: 3.67
          Mean value_function loss: 86.1136
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 82.8736
                       Mean reward: 603.41
               Mean episode length: 210.63
    Episode_Reward/reaching_object: 1.4844
    Episode_Reward/rotating_object: 127.3888
        Episode_Reward/action_rate: -0.0904
          Episode_Reward/joint_vel: -0.0325
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 98795520
                    Iteration time: 6.73s
                      Time elapsed: 00:38:29
                               ETA: 01:16:26

################################################################################
                     [1m Learning iteration 1005/3000 [0m                     

                       Computation: 14344 steps/s (collection: 6.709s, learning 0.144s)
             Mean action noise std: 3.68
          Mean value_function loss: 82.2547
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 82.9015
                       Mean reward: 634.46
               Mean episode length: 218.80
    Episode_Reward/reaching_object: 1.5233
    Episode_Reward/rotating_object: 131.4055
        Episode_Reward/action_rate: -0.0925
          Episode_Reward/joint_vel: -0.0322
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 98893824
                    Iteration time: 6.85s
                      Time elapsed: 00:38:36
                               ETA: 01:16:33

################################################################################
                     [1m Learning iteration 1006/3000 [0m                     

                       Computation: 14195 steps/s (collection: 6.743s, learning 0.182s)
             Mean action noise std: 3.68
          Mean value_function loss: 76.2342
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 82.9297
                       Mean reward: 708.70
               Mean episode length: 239.31
    Episode_Reward/reaching_object: 1.5317
    Episode_Reward/rotating_object: 131.6590
        Episode_Reward/action_rate: -0.0929
          Episode_Reward/joint_vel: -0.0325
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 98992128
                    Iteration time: 6.93s
                      Time elapsed: 00:38:43
                               ETA: 01:16:39

################################################################################
                     [1m Learning iteration 1007/3000 [0m                     

                       Computation: 14345 steps/s (collection: 6.691s, learning 0.161s)
             Mean action noise std: 3.68
          Mean value_function loss: 73.6830
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 82.9502
                       Mean reward: 651.58
               Mean episode length: 226.88
    Episode_Reward/reaching_object: 1.5265
    Episode_Reward/rotating_object: 130.2462
        Episode_Reward/action_rate: -0.0933
          Episode_Reward/joint_vel: -0.0334
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 99090432
                    Iteration time: 6.85s
                      Time elapsed: 00:38:49
                               ETA: 01:16:46

################################################################################
                     [1m Learning iteration 1008/3000 [0m                     

                       Computation: 15354 steps/s (collection: 6.271s, learning 0.131s)
             Mean action noise std: 3.69
          Mean value_function loss: 82.8375
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 82.9694
                       Mean reward: 668.70
               Mean episode length: 233.79
    Episode_Reward/reaching_object: 1.5297
    Episode_Reward/rotating_object: 130.2577
        Episode_Reward/action_rate: -0.0931
          Episode_Reward/joint_vel: -0.0331
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 99188736
                    Iteration time: 6.40s
                      Time elapsed: 00:38:56
                               ETA: 01:16:52

################################################################################
                     [1m Learning iteration 1009/3000 [0m                     

                       Computation: 49487 steps/s (collection: 1.879s, learning 0.107s)
             Mean action noise std: 3.69
          Mean value_function loss: 84.2069
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 82.9816
                       Mean reward: 661.25
               Mean episode length: 227.58
    Episode_Reward/reaching_object: 1.5390
    Episode_Reward/rotating_object: 129.6495
        Episode_Reward/action_rate: -0.0939
          Episode_Reward/joint_vel: -0.0342
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 99287040
                    Iteration time: 1.99s
                      Time elapsed: 00:38:58
                               ETA: 01:16:49

################################################################################
                     [1m Learning iteration 1010/3000 [0m                     

                       Computation: 46205 steps/s (collection: 1.936s, learning 0.192s)
             Mean action noise std: 3.69
          Mean value_function loss: 83.1578
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 83.0077
                       Mean reward: 610.04
               Mean episode length: 216.64
    Episode_Reward/reaching_object: 1.4612
    Episode_Reward/rotating_object: 124.4308
        Episode_Reward/action_rate: -0.0906
          Episode_Reward/joint_vel: -0.0336
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 99385344
                    Iteration time: 2.13s
                      Time elapsed: 00:39:00
                               ETA: 01:16:46

################################################################################
                     [1m Learning iteration 1011/3000 [0m                     

                       Computation: 48331 steps/s (collection: 1.901s, learning 0.133s)
             Mean action noise std: 3.70
          Mean value_function loss: 75.6347
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 83.0491
                       Mean reward: 657.42
               Mean episode length: 225.64
    Episode_Reward/reaching_object: 1.5181
    Episode_Reward/rotating_object: 130.9298
        Episode_Reward/action_rate: -0.0932
          Episode_Reward/joint_vel: -0.0323
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 99483648
                    Iteration time: 2.03s
                      Time elapsed: 00:39:02
                               ETA: 01:16:43

################################################################################
                     [1m Learning iteration 1012/3000 [0m                     

                       Computation: 49238 steps/s (collection: 1.900s, learning 0.096s)
             Mean action noise std: 3.70
          Mean value_function loss: 78.9160
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 83.0697
                       Mean reward: 647.61
               Mean episode length: 227.28
    Episode_Reward/reaching_object: 1.4809
    Episode_Reward/rotating_object: 127.4910
        Episode_Reward/action_rate: -0.0922
          Episode_Reward/joint_vel: -0.0330
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 99581952
                    Iteration time: 2.00s
                      Time elapsed: 00:39:04
                               ETA: 01:16:40

################################################################################
                     [1m Learning iteration 1013/3000 [0m                     

                       Computation: 50332 steps/s (collection: 1.852s, learning 0.102s)
             Mean action noise std: 3.70
          Mean value_function loss: 68.8822
               Mean surrogate loss: -0.0078
                 Mean entropy loss: 83.0774
                       Mean reward: 653.27
               Mean episode length: 225.84
    Episode_Reward/reaching_object: 1.5154
    Episode_Reward/rotating_object: 130.2633
        Episode_Reward/action_rate: -0.0938
          Episode_Reward/joint_vel: -0.0332
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 99680256
                    Iteration time: 1.95s
                      Time elapsed: 00:39:06
                               ETA: 01:16:37

################################################################################
                     [1m Learning iteration 1014/3000 [0m                     

                       Computation: 48941 steps/s (collection: 1.897s, learning 0.112s)
             Mean action noise std: 3.71
          Mean value_function loss: 78.3390
               Mean surrogate loss: -0.0085
                 Mean entropy loss: 83.0992
                       Mean reward: 653.82
               Mean episode length: 232.22
    Episode_Reward/reaching_object: 1.5359
    Episode_Reward/rotating_object: 131.7443
        Episode_Reward/action_rate: -0.0954
          Episode_Reward/joint_vel: -0.0336
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 99778560
                    Iteration time: 2.01s
                      Time elapsed: 00:39:08
                               ETA: 01:16:35

################################################################################
                     [1m Learning iteration 1015/3000 [0m                     

                       Computation: 43584 steps/s (collection: 2.049s, learning 0.207s)
             Mean action noise std: 3.71
          Mean value_function loss: 92.4800
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 83.1318
                       Mean reward: 590.48
               Mean episode length: 207.55
    Episode_Reward/reaching_object: 1.4758
    Episode_Reward/rotating_object: 125.6826
        Episode_Reward/action_rate: -0.0920
          Episode_Reward/joint_vel: -0.0328
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 99876864
                    Iteration time: 2.26s
                      Time elapsed: 00:39:10
                               ETA: 01:16:32

################################################################################
                     [1m Learning iteration 1016/3000 [0m                     

                       Computation: 48034 steps/s (collection: 1.947s, learning 0.099s)
             Mean action noise std: 3.71
          Mean value_function loss: 74.4410
               Mean surrogate loss: -0.0084
                 Mean entropy loss: 83.1542
                       Mean reward: 667.20
               Mean episode length: 227.69
    Episode_Reward/reaching_object: 1.4949
    Episode_Reward/rotating_object: 128.6488
        Episode_Reward/action_rate: -0.0934
          Episode_Reward/joint_vel: -0.0329
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 99975168
                    Iteration time: 2.05s
                      Time elapsed: 00:39:12
                               ETA: 01:16:29

################################################################################
                     [1m Learning iteration 1017/3000 [0m                     

                       Computation: 48296 steps/s (collection: 1.925s, learning 0.110s)
             Mean action noise std: 3.71
          Mean value_function loss: 77.4438
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 83.1740
                       Mean reward: 706.32
               Mean episode length: 240.77
    Episode_Reward/reaching_object: 1.5288
    Episode_Reward/rotating_object: 133.0145
        Episode_Reward/action_rate: -0.0958
          Episode_Reward/joint_vel: -0.0325
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 100073472
                    Iteration time: 2.04s
                      Time elapsed: 00:39:14
                               ETA: 01:16:26

################################################################################
                     [1m Learning iteration 1018/3000 [0m                     

                       Computation: 47347 steps/s (collection: 1.880s, learning 0.196s)
             Mean action noise std: 3.72
          Mean value_function loss: 86.0107
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 83.1916
                       Mean reward: 642.53
               Mean episode length: 225.56
    Episode_Reward/reaching_object: 1.5048
    Episode_Reward/rotating_object: 128.9425
        Episode_Reward/action_rate: -0.0943
          Episode_Reward/joint_vel: -0.0334
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 100171776
                    Iteration time: 2.08s
                      Time elapsed: 00:39:16
                               ETA: 01:16:24

################################################################################
                     [1m Learning iteration 1019/3000 [0m                     

                       Computation: 49195 steps/s (collection: 1.908s, learning 0.090s)
             Mean action noise std: 3.72
          Mean value_function loss: 83.9438
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 83.2137
                       Mean reward: 639.52
               Mean episode length: 221.32
    Episode_Reward/reaching_object: 1.4553
    Episode_Reward/rotating_object: 126.4279
        Episode_Reward/action_rate: -0.0917
          Episode_Reward/joint_vel: -0.0330
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 100270080
                    Iteration time: 2.00s
                      Time elapsed: 00:39:18
                               ETA: 01:16:21

################################################################################
                     [1m Learning iteration 1020/3000 [0m                     

                       Computation: 49333 steps/s (collection: 1.889s, learning 0.104s)
             Mean action noise std: 3.72
          Mean value_function loss: 82.3149
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 83.2368
                       Mean reward: 649.57
               Mean episode length: 223.89
    Episode_Reward/reaching_object: 1.4920
    Episode_Reward/rotating_object: 128.4049
        Episode_Reward/action_rate: -0.0926
          Episode_Reward/joint_vel: -0.0314
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 100368384
                    Iteration time: 1.99s
                      Time elapsed: 00:39:20
                               ETA: 01:16:18

################################################################################
                     [1m Learning iteration 1021/3000 [0m                     

                       Computation: 50038 steps/s (collection: 1.867s, learning 0.098s)
             Mean action noise std: 3.73
          Mean value_function loss: 84.2055
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 83.2631
                       Mean reward: 675.21
               Mean episode length: 228.30
    Episode_Reward/reaching_object: 1.5502
    Episode_Reward/rotating_object: 134.5253
        Episode_Reward/action_rate: -0.0960
          Episode_Reward/joint_vel: -0.0320
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 100466688
                    Iteration time: 1.96s
                      Time elapsed: 00:39:22
                               ETA: 01:16:15

################################################################################
                     [1m Learning iteration 1022/3000 [0m                     

                       Computation: 49873 steps/s (collection: 1.872s, learning 0.099s)
             Mean action noise std: 3.73
          Mean value_function loss: 79.5248
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 83.2839
                       Mean reward: 676.85
               Mean episode length: 232.89
    Episode_Reward/reaching_object: 1.5185
    Episode_Reward/rotating_object: 130.5356
        Episode_Reward/action_rate: -0.0949
          Episode_Reward/joint_vel: -0.0323
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 100564992
                    Iteration time: 1.97s
                      Time elapsed: 00:39:24
                               ETA: 01:16:12

################################################################################
                     [1m Learning iteration 1023/3000 [0m                     

                       Computation: 49178 steps/s (collection: 1.890s, learning 0.109s)
             Mean action noise std: 3.73
          Mean value_function loss: 84.8675
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 83.3119
                       Mean reward: 627.20
               Mean episode length: 224.82
    Episode_Reward/reaching_object: 1.5054
    Episode_Reward/rotating_object: 126.1463
        Episode_Reward/action_rate: -0.0940
          Episode_Reward/joint_vel: -0.0338
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 100663296
                    Iteration time: 2.00s
                      Time elapsed: 00:39:26
                               ETA: 01:16:09

################################################################################
                     [1m Learning iteration 1024/3000 [0m                     

                       Computation: 50496 steps/s (collection: 1.856s, learning 0.091s)
             Mean action noise std: 3.74
          Mean value_function loss: 77.4256
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 83.3380
                       Mean reward: 681.68
               Mean episode length: 231.75
    Episode_Reward/reaching_object: 1.5145
    Episode_Reward/rotating_object: 129.5182
        Episode_Reward/action_rate: -0.0944
          Episode_Reward/joint_vel: -0.0322
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 100761600
                    Iteration time: 1.95s
                      Time elapsed: 00:39:28
                               ETA: 01:16:06

################################################################################
                     [1m Learning iteration 1025/3000 [0m                     

                       Computation: 50887 steps/s (collection: 1.834s, learning 0.097s)
             Mean action noise std: 3.74
          Mean value_function loss: 71.4280
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 83.3623
                       Mean reward: 684.03
               Mean episode length: 237.32
    Episode_Reward/reaching_object: 1.5444
    Episode_Reward/rotating_object: 133.3984
        Episode_Reward/action_rate: -0.0961
          Episode_Reward/joint_vel: -0.0321
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 100859904
                    Iteration time: 1.93s
                      Time elapsed: 00:39:30
                               ETA: 01:16:03

################################################################################
                     [1m Learning iteration 1026/3000 [0m                     

                       Computation: 46899 steps/s (collection: 1.971s, learning 0.125s)
             Mean action noise std: 3.74
          Mean value_function loss: 69.0920
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 83.3869
                       Mean reward: 684.97
               Mean episode length: 232.07
    Episode_Reward/reaching_object: 1.5857
    Episode_Reward/rotating_object: 137.8536
        Episode_Reward/action_rate: -0.0988
          Episode_Reward/joint_vel: -0.0325
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 100958208
                    Iteration time: 2.10s
                      Time elapsed: 00:39:32
                               ETA: 01:16:00

################################################################################
                     [1m Learning iteration 1027/3000 [0m                     

                       Computation: 48122 steps/s (collection: 1.929s, learning 0.114s)
             Mean action noise std: 3.74
          Mean value_function loss: 74.8252
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 83.4026
                       Mean reward: 692.42
               Mean episode length: 232.61
    Episode_Reward/reaching_object: 1.5476
    Episode_Reward/rotating_object: 134.1888
        Episode_Reward/action_rate: -0.0964
          Episode_Reward/joint_vel: -0.0318
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 101056512
                    Iteration time: 2.04s
                      Time elapsed: 00:39:34
                               ETA: 01:15:57

################################################################################
                     [1m Learning iteration 1028/3000 [0m                     

                       Computation: 45812 steps/s (collection: 1.980s, learning 0.166s)
             Mean action noise std: 3.75
          Mean value_function loss: 75.4350
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 83.4131
                       Mean reward: 671.43
               Mean episode length: 233.74
    Episode_Reward/reaching_object: 1.5277
    Episode_Reward/rotating_object: 129.7188
        Episode_Reward/action_rate: -0.0953
          Episode_Reward/joint_vel: -0.0329
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 101154816
                    Iteration time: 2.15s
                      Time elapsed: 00:39:36
                               ETA: 01:15:55

################################################################################
                     [1m Learning iteration 1029/3000 [0m                     

                       Computation: 47769 steps/s (collection: 1.964s, learning 0.094s)
             Mean action noise std: 3.75
          Mean value_function loss: 84.7135
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 83.4394
                       Mean reward: 621.24
               Mean episode length: 216.59
    Episode_Reward/reaching_object: 1.5272
    Episode_Reward/rotating_object: 130.7171
        Episode_Reward/action_rate: -0.0952
          Episode_Reward/joint_vel: -0.0324
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 101253120
                    Iteration time: 2.06s
                      Time elapsed: 00:39:38
                               ETA: 01:15:52

################################################################################
                     [1m Learning iteration 1030/3000 [0m                     

                       Computation: 48957 steps/s (collection: 1.903s, learning 0.105s)
             Mean action noise std: 3.75
          Mean value_function loss: 71.0628
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 83.4669
                       Mean reward: 670.03
               Mean episode length: 227.18
    Episode_Reward/reaching_object: 1.5506
    Episode_Reward/rotating_object: 133.3303
        Episode_Reward/action_rate: -0.0968
          Episode_Reward/joint_vel: -0.0326
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 101351424
                    Iteration time: 2.01s
                      Time elapsed: 00:39:40
                               ETA: 01:15:49

################################################################################
                     [1m Learning iteration 1031/3000 [0m                     

                       Computation: 47088 steps/s (collection: 1.978s, learning 0.109s)
             Mean action noise std: 3.75
          Mean value_function loss: 70.8073
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 83.4840
                       Mean reward: 665.54
               Mean episode length: 229.85
    Episode_Reward/reaching_object: 1.5599
    Episode_Reward/rotating_object: 136.0527
        Episode_Reward/action_rate: -0.0976
          Episode_Reward/joint_vel: -0.0316
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 101449728
                    Iteration time: 2.09s
                      Time elapsed: 00:39:43
                               ETA: 01:15:46

################################################################################
                     [1m Learning iteration 1032/3000 [0m                     

                       Computation: 48641 steps/s (collection: 1.918s, learning 0.103s)
             Mean action noise std: 3.76
          Mean value_function loss: 74.5236
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 83.5090
                       Mean reward: 687.24
               Mean episode length: 230.68
    Episode_Reward/reaching_object: 1.5339
    Episode_Reward/rotating_object: 132.2362
        Episode_Reward/action_rate: -0.0960
          Episode_Reward/joint_vel: -0.0312
      Episode_Termination/time_out: 17.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 101548032
                    Iteration time: 2.02s
                      Time elapsed: 00:39:45
                               ETA: 01:15:43

################################################################################
                     [1m Learning iteration 1033/3000 [0m                     

                       Computation: 49756 steps/s (collection: 1.874s, learning 0.102s)
             Mean action noise std: 3.76
          Mean value_function loss: 81.9141
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 83.5322
                       Mean reward: 650.14
               Mean episode length: 221.27
    Episode_Reward/reaching_object: 1.5106
    Episode_Reward/rotating_object: 130.7928
        Episode_Reward/action_rate: -0.0950
          Episode_Reward/joint_vel: -0.0318
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 101646336
                    Iteration time: 1.98s
                      Time elapsed: 00:39:47
                               ETA: 01:15:40

################################################################################
                     [1m Learning iteration 1034/3000 [0m                     

                       Computation: 48512 steps/s (collection: 1.931s, learning 0.095s)
             Mean action noise std: 3.76
          Mean value_function loss: 91.3209
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 83.5497
                       Mean reward: 646.47
               Mean episode length: 221.34
    Episode_Reward/reaching_object: 1.5012
    Episode_Reward/rotating_object: 129.9338
        Episode_Reward/action_rate: -0.0948
          Episode_Reward/joint_vel: -0.0315
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6250
--------------------------------------------------------------------------------
                   Total timesteps: 101744640
                    Iteration time: 2.03s
                      Time elapsed: 00:39:49
                               ETA: 01:15:38

################################################################################
                     [1m Learning iteration 1035/3000 [0m                     

                       Computation: 45110 steps/s (collection: 2.012s, learning 0.168s)
             Mean action noise std: 3.76
          Mean value_function loss: 81.3952
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 83.5645
                       Mean reward: 655.04
               Mean episode length: 223.56
    Episode_Reward/reaching_object: 1.5232
    Episode_Reward/rotating_object: 131.5704
        Episode_Reward/action_rate: -0.0957
          Episode_Reward/joint_vel: -0.0320
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 101842944
                    Iteration time: 2.18s
                      Time elapsed: 00:39:51
                               ETA: 01:15:35

################################################################################
                     [1m Learning iteration 1036/3000 [0m                     

                       Computation: 49069 steps/s (collection: 1.875s, learning 0.129s)
             Mean action noise std: 3.77
          Mean value_function loss: 86.9215
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 83.5824
                       Mean reward: 647.93
               Mean episode length: 221.48
    Episode_Reward/reaching_object: 1.4861
    Episode_Reward/rotating_object: 126.6911
        Episode_Reward/action_rate: -0.0940
          Episode_Reward/joint_vel: -0.0321
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5000
--------------------------------------------------------------------------------
                   Total timesteps: 101941248
                    Iteration time: 2.00s
                      Time elapsed: 00:39:53
                               ETA: 01:15:32

################################################################################
                     [1m Learning iteration 1037/3000 [0m                     

                       Computation: 47675 steps/s (collection: 1.909s, learning 0.153s)
             Mean action noise std: 3.77
          Mean value_function loss: 84.7880
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 83.6049
                       Mean reward: 668.96
               Mean episode length: 228.60
    Episode_Reward/reaching_object: 1.5059
    Episode_Reward/rotating_object: 129.1298
        Episode_Reward/action_rate: -0.0952
          Episode_Reward/joint_vel: -0.0318
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 102039552
                    Iteration time: 2.06s
                      Time elapsed: 00:39:55
                               ETA: 01:15:29

################################################################################
                     [1m Learning iteration 1038/3000 [0m                     

                       Computation: 46251 steps/s (collection: 1.992s, learning 0.133s)
             Mean action noise std: 3.77
          Mean value_function loss: 79.9182
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 83.6322
                       Mean reward: 657.23
               Mean episode length: 232.74
    Episode_Reward/reaching_object: 1.5493
    Episode_Reward/rotating_object: 132.8918
        Episode_Reward/action_rate: -0.0985
          Episode_Reward/joint_vel: -0.0328
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 102137856
                    Iteration time: 2.13s
                      Time elapsed: 00:39:57
                               ETA: 01:15:27

################################################################################
                     [1m Learning iteration 1039/3000 [0m                     

                       Computation: 49964 steps/s (collection: 1.870s, learning 0.098s)
             Mean action noise std: 3.78
          Mean value_function loss: 79.1102
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 83.6634
                       Mean reward: 629.32
               Mean episode length: 220.70
    Episode_Reward/reaching_object: 1.5430
    Episode_Reward/rotating_object: 130.6091
        Episode_Reward/action_rate: -0.0976
          Episode_Reward/joint_vel: -0.0334
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 102236160
                    Iteration time: 1.97s
                      Time elapsed: 00:39:59
                               ETA: 01:15:24

################################################################################
                     [1m Learning iteration 1040/3000 [0m                     

                       Computation: 45285 steps/s (collection: 2.055s, learning 0.116s)
             Mean action noise std: 3.78
          Mean value_function loss: 97.2188
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 83.6869
                       Mean reward: 632.58
               Mean episode length: 218.08
    Episode_Reward/reaching_object: 1.4949
    Episode_Reward/rotating_object: 127.8019
        Episode_Reward/action_rate: -0.0954
          Episode_Reward/joint_vel: -0.0322
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3750
--------------------------------------------------------------------------------
                   Total timesteps: 102334464
                    Iteration time: 2.17s
                      Time elapsed: 00:40:01
                               ETA: 01:15:21

################################################################################
                     [1m Learning iteration 1041/3000 [0m                     

                       Computation: 47642 steps/s (collection: 1.950s, learning 0.114s)
             Mean action noise std: 3.78
          Mean value_function loss: 84.3355
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 83.7074
                       Mean reward: 636.10
               Mean episode length: 220.80
    Episode_Reward/reaching_object: 1.5005
    Episode_Reward/rotating_object: 127.3564
        Episode_Reward/action_rate: -0.0956
          Episode_Reward/joint_vel: -0.0322
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 102432768
                    Iteration time: 2.06s
                      Time elapsed: 00:40:03
                               ETA: 01:15:18

################################################################################
                     [1m Learning iteration 1042/3000 [0m                     

                       Computation: 50006 steps/s (collection: 1.876s, learning 0.090s)
             Mean action noise std: 3.79
          Mean value_function loss: 77.9905
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 83.7345
                       Mean reward: 675.35
               Mean episode length: 229.86
    Episode_Reward/reaching_object: 1.5022
    Episode_Reward/rotating_object: 128.1397
        Episode_Reward/action_rate: -0.0957
          Episode_Reward/joint_vel: -0.0321
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4583
--------------------------------------------------------------------------------
                   Total timesteps: 102531072
                    Iteration time: 1.97s
                      Time elapsed: 00:40:05
                               ETA: 01:15:16

################################################################################
                     [1m Learning iteration 1043/3000 [0m                     

                       Computation: 46792 steps/s (collection: 1.992s, learning 0.109s)
             Mean action noise std: 3.79
          Mean value_function loss: 82.8805
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 83.7582
                       Mean reward: 643.94
               Mean episode length: 222.02
    Episode_Reward/reaching_object: 1.5322
    Episode_Reward/rotating_object: 130.4343
        Episode_Reward/action_rate: -0.0977
          Episode_Reward/joint_vel: -0.0331
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 102629376
                    Iteration time: 2.10s
                      Time elapsed: 00:40:07
                               ETA: 01:15:13

################################################################################
                     [1m Learning iteration 1044/3000 [0m                     

                       Computation: 49704 steps/s (collection: 1.854s, learning 0.124s)
             Mean action noise std: 3.79
          Mean value_function loss: 85.9966
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 83.7831
                       Mean reward: 645.89
               Mean episode length: 216.45
    Episode_Reward/reaching_object: 1.4971
    Episode_Reward/rotating_object: 129.6145
        Episode_Reward/action_rate: -0.0961
          Episode_Reward/joint_vel: -0.0313
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.4167
--------------------------------------------------------------------------------
                   Total timesteps: 102727680
                    Iteration time: 1.98s
                      Time elapsed: 00:40:09
                               ETA: 01:15:10

################################################################################
                     [1m Learning iteration 1045/3000 [0m                     

                       Computation: 47574 steps/s (collection: 1.954s, learning 0.112s)
             Mean action noise std: 3.80
          Mean value_function loss: 78.2638
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 83.8056
                       Mean reward: 652.68
               Mean episode length: 225.37
    Episode_Reward/reaching_object: 1.4854
    Episode_Reward/rotating_object: 128.1792
        Episode_Reward/action_rate: -0.0954
          Episode_Reward/joint_vel: -0.0322
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5417
--------------------------------------------------------------------------------
                   Total timesteps: 102825984
                    Iteration time: 2.07s
                      Time elapsed: 00:40:11
                               ETA: 01:15:07

################################################################################
                     [1m Learning iteration 1046/3000 [0m                     

                       Computation: 48841 steps/s (collection: 1.904s, learning 0.109s)
             Mean action noise std: 3.80
          Mean value_function loss: 69.4567
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 83.8314
                       Mean reward: 665.49
               Mean episode length: 229.59
    Episode_Reward/reaching_object: 1.5142
    Episode_Reward/rotating_object: 130.4513
        Episode_Reward/action_rate: -0.0977
          Episode_Reward/joint_vel: -0.0331
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 102924288
                    Iteration time: 2.01s
                      Time elapsed: 00:40:13
                               ETA: 01:15:04

################################################################################
                     [1m Learning iteration 1047/3000 [0m                     

                       Computation: 49343 steps/s (collection: 1.887s, learning 0.105s)
             Mean action noise std: 3.80
          Mean value_function loss: 71.0088
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 83.8578
                       Mean reward: 697.56
               Mean episode length: 240.10
    Episode_Reward/reaching_object: 1.5491
    Episode_Reward/rotating_object: 132.6047
        Episode_Reward/action_rate: -0.0996
          Episode_Reward/joint_vel: -0.0337
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 103022592
                    Iteration time: 1.99s
                      Time elapsed: 00:40:15
                               ETA: 01:15:01

################################################################################
                     [1m Learning iteration 1048/3000 [0m                     

                       Computation: 49588 steps/s (collection: 1.867s, learning 0.116s)
             Mean action noise std: 3.81
          Mean value_function loss: 74.9447
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 83.8823
                       Mean reward: 638.13
               Mean episode length: 216.61
    Episode_Reward/reaching_object: 1.5656
    Episode_Reward/rotating_object: 135.2174
        Episode_Reward/action_rate: -0.1008
          Episode_Reward/joint_vel: -0.0333
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 103120896
                    Iteration time: 1.98s
                      Time elapsed: 00:40:17
                               ETA: 01:14:59

################################################################################
                     [1m Learning iteration 1049/3000 [0m                     

                       Computation: 49862 steps/s (collection: 1.864s, learning 0.107s)
             Mean action noise std: 3.81
          Mean value_function loss: 68.7693
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 83.9142
                       Mean reward: 683.30
               Mean episode length: 226.76
    Episode_Reward/reaching_object: 1.5571
    Episode_Reward/rotating_object: 136.9999
        Episode_Reward/action_rate: -0.0995
          Episode_Reward/joint_vel: -0.0311
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 103219200
                    Iteration time: 1.97s
                      Time elapsed: 00:40:19
                               ETA: 01:14:56

################################################################################
                     [1m Learning iteration 1050/3000 [0m                     

                       Computation: 49798 steps/s (collection: 1.881s, learning 0.093s)
             Mean action noise std: 3.81
          Mean value_function loss: 73.4649
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 83.9407
                       Mean reward: 623.26
               Mean episode length: 226.61
    Episode_Reward/reaching_object: 1.5164
    Episode_Reward/rotating_object: 130.6056
        Episode_Reward/action_rate: -0.0988
          Episode_Reward/joint_vel: -0.0326
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 103317504
                    Iteration time: 1.97s
                      Time elapsed: 00:40:21
                               ETA: 01:14:53

################################################################################
                     [1m Learning iteration 1051/3000 [0m                     

                       Computation: 47729 steps/s (collection: 1.960s, learning 0.100s)
             Mean action noise std: 3.82
          Mean value_function loss: 70.4489
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 83.9666
                       Mean reward: 705.37
               Mean episode length: 234.51
    Episode_Reward/reaching_object: 1.5161
    Episode_Reward/rotating_object: 131.6785
        Episode_Reward/action_rate: -0.0990
          Episode_Reward/joint_vel: -0.0336
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 103415808
                    Iteration time: 2.06s
                      Time elapsed: 00:40:23
                               ETA: 01:14:50

################################################################################
                     [1m Learning iteration 1052/3000 [0m                     

                       Computation: 49748 steps/s (collection: 1.857s, learning 0.119s)
             Mean action noise std: 3.82
          Mean value_function loss: 79.9962
               Mean surrogate loss: -0.0080
                 Mean entropy loss: 83.9921
                       Mean reward: 668.76
               Mean episode length: 225.82
    Episode_Reward/reaching_object: 1.5535
    Episode_Reward/rotating_object: 134.4922
        Episode_Reward/action_rate: -0.1002
          Episode_Reward/joint_vel: -0.0328
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 103514112
                    Iteration time: 1.98s
                      Time elapsed: 00:40:25
                               ETA: 01:14:47

################################################################################
                     [1m Learning iteration 1053/3000 [0m                     

                       Computation: 48838 steps/s (collection: 1.888s, learning 0.125s)
             Mean action noise std: 3.82
          Mean value_function loss: 78.9335
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 84.0131
                       Mean reward: 676.80
               Mean episode length: 226.54
    Episode_Reward/reaching_object: 1.5122
    Episode_Reward/rotating_object: 131.4702
        Episode_Reward/action_rate: -0.0981
          Episode_Reward/joint_vel: -0.0320
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 103612416
                    Iteration time: 2.01s
                      Time elapsed: 00:40:27
                               ETA: 01:14:44

################################################################################
                     [1m Learning iteration 1054/3000 [0m                     

                       Computation: 49410 steps/s (collection: 1.870s, learning 0.120s)
             Mean action noise std: 3.83
          Mean value_function loss: 69.4793
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 84.0319
                       Mean reward: 710.57
               Mean episode length: 234.86
    Episode_Reward/reaching_object: 1.5756
    Episode_Reward/rotating_object: 136.3576
        Episode_Reward/action_rate: -0.1018
          Episode_Reward/joint_vel: -0.0324
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 103710720
                    Iteration time: 1.99s
                      Time elapsed: 00:40:29
                               ETA: 01:14:41

################################################################################
                     [1m Learning iteration 1055/3000 [0m                     

                       Computation: 46957 steps/s (collection: 1.980s, learning 0.113s)
             Mean action noise std: 3.83
          Mean value_function loss: 79.7800
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 84.0517
                       Mean reward: 682.24
               Mean episode length: 228.65
    Episode_Reward/reaching_object: 1.5600
    Episode_Reward/rotating_object: 136.0635
        Episode_Reward/action_rate: -0.1003
          Episode_Reward/joint_vel: -0.0316
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 103809024
                    Iteration time: 2.09s
                      Time elapsed: 00:40:31
                               ETA: 01:14:39

################################################################################
                     [1m Learning iteration 1056/3000 [0m                     

                       Computation: 48969 steps/s (collection: 1.897s, learning 0.111s)
             Mean action noise std: 3.83
          Mean value_function loss: 72.3994
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 84.0683
                       Mean reward: 681.81
               Mean episode length: 231.32
    Episode_Reward/reaching_object: 1.5834
    Episode_Reward/rotating_object: 136.4042
        Episode_Reward/action_rate: -0.1026
          Episode_Reward/joint_vel: -0.0331
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 103907328
                    Iteration time: 2.01s
                      Time elapsed: 00:40:33
                               ETA: 01:14:36

################################################################################
                     [1m Learning iteration 1057/3000 [0m                     

                       Computation: 48401 steps/s (collection: 1.901s, learning 0.130s)
             Mean action noise std: 3.84
          Mean value_function loss: 91.4437
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 84.0909
                       Mean reward: 643.88
               Mean episode length: 221.75
    Episode_Reward/reaching_object: 1.5344
    Episode_Reward/rotating_object: 131.2555
        Episode_Reward/action_rate: -0.0998
          Episode_Reward/joint_vel: -0.0332
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 104005632
                    Iteration time: 2.03s
                      Time elapsed: 00:40:35
                               ETA: 01:14:33

################################################################################
                     [1m Learning iteration 1058/3000 [0m                     

                       Computation: 49159 steps/s (collection: 1.881s, learning 0.119s)
             Mean action noise std: 3.84
          Mean value_function loss: 92.1245
               Mean surrogate loss: -0.0074
                 Mean entropy loss: 84.1234
                       Mean reward: 671.00
               Mean episode length: 226.26
    Episode_Reward/reaching_object: 1.5524
    Episode_Reward/rotating_object: 133.6727
        Episode_Reward/action_rate: -0.1011
          Episode_Reward/joint_vel: -0.0329
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 104103936
                    Iteration time: 2.00s
                      Time elapsed: 00:40:37
                               ETA: 01:14:30

################################################################################
                     [1m Learning iteration 1059/3000 [0m                     

                       Computation: 48768 steps/s (collection: 1.923s, learning 0.093s)
             Mean action noise std: 3.84
          Mean value_function loss: 77.4354
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 84.1533
                       Mean reward: 698.29
               Mean episode length: 234.02
    Episode_Reward/reaching_object: 1.5276
    Episode_Reward/rotating_object: 131.2332
        Episode_Reward/action_rate: -0.1000
          Episode_Reward/joint_vel: -0.0327
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 104202240
                    Iteration time: 2.02s
                      Time elapsed: 00:40:39
                               ETA: 01:14:27

################################################################################
                     [1m Learning iteration 1060/3000 [0m                     

                       Computation: 45419 steps/s (collection: 2.048s, learning 0.117s)
             Mean action noise std: 3.85
          Mean value_function loss: 77.9776
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 84.1775
                       Mean reward: 663.84
               Mean episode length: 222.73
    Episode_Reward/reaching_object: 1.5439
    Episode_Reward/rotating_object: 135.5035
        Episode_Reward/action_rate: -0.1007
          Episode_Reward/joint_vel: -0.0315
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 104300544
                    Iteration time: 2.16s
                      Time elapsed: 00:40:42
                               ETA: 01:14:25

################################################################################
                     [1m Learning iteration 1061/3000 [0m                     

                       Computation: 49610 steps/s (collection: 1.876s, learning 0.106s)
             Mean action noise std: 3.85
          Mean value_function loss: 80.3993
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 84.1981
                       Mean reward: 670.68
               Mean episode length: 226.63
    Episode_Reward/reaching_object: 1.5309
    Episode_Reward/rotating_object: 132.9091
        Episode_Reward/action_rate: -0.1007
          Episode_Reward/joint_vel: -0.0325
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 104398848
                    Iteration time: 1.98s
                      Time elapsed: 00:40:44
                               ETA: 01:14:22

################################################################################
                     [1m Learning iteration 1062/3000 [0m                     

                       Computation: 49388 steps/s (collection: 1.898s, learning 0.092s)
             Mean action noise std: 3.85
          Mean value_function loss: 80.5277
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 84.2173
                       Mean reward: 694.93
               Mean episode length: 230.09
    Episode_Reward/reaching_object: 1.5447
    Episode_Reward/rotating_object: 134.2793
        Episode_Reward/action_rate: -0.1021
          Episode_Reward/joint_vel: -0.0333
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 104497152
                    Iteration time: 1.99s
                      Time elapsed: 00:40:46
                               ETA: 01:14:19

################################################################################
                     [1m Learning iteration 1063/3000 [0m                     

                       Computation: 48695 steps/s (collection: 1.920s, learning 0.099s)
             Mean action noise std: 3.85
          Mean value_function loss: 73.0190
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 84.2319
                       Mean reward: 695.65
               Mean episode length: 238.07
    Episode_Reward/reaching_object: 1.5885
    Episode_Reward/rotating_object: 135.7265
        Episode_Reward/action_rate: -0.1039
          Episode_Reward/joint_vel: -0.0338
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 104595456
                    Iteration time: 2.02s
                      Time elapsed: 00:40:48
                               ETA: 01:14:16

################################################################################
                     [1m Learning iteration 1064/3000 [0m                     

                       Computation: 48488 steps/s (collection: 1.916s, learning 0.111s)
             Mean action noise std: 3.86
          Mean value_function loss: 69.2823
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 84.2519
                       Mean reward: 693.19
               Mean episode length: 231.31
    Episode_Reward/reaching_object: 1.5836
    Episode_Reward/rotating_object: 139.0959
        Episode_Reward/action_rate: -0.1047
          Episode_Reward/joint_vel: -0.0338
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 104693760
                    Iteration time: 2.03s
                      Time elapsed: 00:40:50
                               ETA: 01:14:13

################################################################################
                     [1m Learning iteration 1065/3000 [0m                     

                       Computation: 47983 steps/s (collection: 1.953s, learning 0.096s)
             Mean action noise std: 3.86
          Mean value_function loss: 70.9303
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 84.2838
                       Mean reward: 687.43
               Mean episode length: 233.19
    Episode_Reward/reaching_object: 1.5674
    Episode_Reward/rotating_object: 135.5319
        Episode_Reward/action_rate: -0.1034
          Episode_Reward/joint_vel: -0.0332
      Episode_Termination/time_out: 17.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 104792064
                    Iteration time: 2.05s
                      Time elapsed: 00:40:52
                               ETA: 01:14:11

################################################################################
                     [1m Learning iteration 1066/3000 [0m                     

                       Computation: 49185 steps/s (collection: 1.906s, learning 0.093s)
             Mean action noise std: 3.86
          Mean value_function loss: 73.6819
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 84.3125
                       Mean reward: 644.82
               Mean episode length: 222.59
    Episode_Reward/reaching_object: 1.5571
    Episode_Reward/rotating_object: 134.7012
        Episode_Reward/action_rate: -0.1029
          Episode_Reward/joint_vel: -0.0339
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 104890368
                    Iteration time: 2.00s
                      Time elapsed: 00:40:54
                               ETA: 01:14:08

################################################################################
                     [1m Learning iteration 1067/3000 [0m                     

                       Computation: 48502 steps/s (collection: 1.918s, learning 0.109s)
             Mean action noise std: 3.87
          Mean value_function loss: 77.0738
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 84.3318
                       Mean reward: 691.55
               Mean episode length: 234.85
    Episode_Reward/reaching_object: 1.5390
    Episode_Reward/rotating_object: 131.3018
        Episode_Reward/action_rate: -0.1018
          Episode_Reward/joint_vel: -0.0343
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 104988672
                    Iteration time: 2.03s
                      Time elapsed: 00:40:56
                               ETA: 01:14:05

################################################################################
                     [1m Learning iteration 1068/3000 [0m                     

                       Computation: 48860 steps/s (collection: 1.896s, learning 0.116s)
             Mean action noise std: 3.87
          Mean value_function loss: 73.7515
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 84.3568
                       Mean reward: 703.44
               Mean episode length: 235.68
    Episode_Reward/reaching_object: 1.5828
    Episode_Reward/rotating_object: 136.9777
        Episode_Reward/action_rate: -0.1049
          Episode_Reward/joint_vel: -0.0337
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 105086976
                    Iteration time: 2.01s
                      Time elapsed: 00:40:58
                               ETA: 01:14:02

################################################################################
                     [1m Learning iteration 1069/3000 [0m                     

                       Computation: 48972 steps/s (collection: 1.909s, learning 0.099s)
             Mean action noise std: 3.87
          Mean value_function loss: 80.4594
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 84.3731
                       Mean reward: 648.99
               Mean episode length: 229.52
    Episode_Reward/reaching_object: 1.5380
    Episode_Reward/rotating_object: 133.0649
        Episode_Reward/action_rate: -0.1025
          Episode_Reward/joint_vel: -0.0331
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 105185280
                    Iteration time: 2.01s
                      Time elapsed: 00:41:00
                               ETA: 01:13:59

################################################################################
                     [1m Learning iteration 1070/3000 [0m                     

                       Computation: 44330 steps/s (collection: 2.094s, learning 0.123s)
             Mean action noise std: 3.88
          Mean value_function loss: 80.0856
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 84.3977
                       Mean reward: 699.24
               Mean episode length: 232.69
    Episode_Reward/reaching_object: 1.5580
    Episode_Reward/rotating_object: 135.4434
        Episode_Reward/action_rate: -0.1028
          Episode_Reward/joint_vel: -0.0328
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 105283584
                    Iteration time: 2.22s
                      Time elapsed: 00:41:02
                               ETA: 01:13:57

################################################################################
                     [1m Learning iteration 1071/3000 [0m                     

                       Computation: 48180 steps/s (collection: 1.914s, learning 0.127s)
             Mean action noise std: 3.88
          Mean value_function loss: 77.3891
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 84.4301
                       Mean reward: 664.83
               Mean episode length: 222.80
    Episode_Reward/reaching_object: 1.5257
    Episode_Reward/rotating_object: 131.3044
        Episode_Reward/action_rate: -0.1018
          Episode_Reward/joint_vel: -0.0335
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 105381888
                    Iteration time: 2.04s
                      Time elapsed: 00:41:04
                               ETA: 01:13:54

################################################################################
                     [1m Learning iteration 1072/3000 [0m                     

                       Computation: 49353 steps/s (collection: 1.876s, learning 0.116s)
             Mean action noise std: 3.88
          Mean value_function loss: 78.9644
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 84.4539
                       Mean reward: 680.40
               Mean episode length: 230.93
    Episode_Reward/reaching_object: 1.5364
    Episode_Reward/rotating_object: 132.2799
        Episode_Reward/action_rate: -0.1024
          Episode_Reward/joint_vel: -0.0336
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 105480192
                    Iteration time: 1.99s
                      Time elapsed: 00:41:06
                               ETA: 01:13:51

################################################################################
                     [1m Learning iteration 1073/3000 [0m                     

                       Computation: 47734 steps/s (collection: 1.936s, learning 0.124s)
             Mean action noise std: 3.89
          Mean value_function loss: 78.0087
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 84.4675
                       Mean reward: 686.46
               Mean episode length: 230.70
    Episode_Reward/reaching_object: 1.5419
    Episode_Reward/rotating_object: 131.9658
        Episode_Reward/action_rate: -0.1025
          Episode_Reward/joint_vel: -0.0342
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 105578496
                    Iteration time: 2.06s
                      Time elapsed: 00:41:08
                               ETA: 01:13:49

################################################################################
                     [1m Learning iteration 1074/3000 [0m                     

                       Computation: 46370 steps/s (collection: 1.929s, learning 0.191s)
             Mean action noise std: 3.89
          Mean value_function loss: 67.5411
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 84.4840
                       Mean reward: 673.09
               Mean episode length: 226.61
    Episode_Reward/reaching_object: 1.5298
    Episode_Reward/rotating_object: 131.7731
        Episode_Reward/action_rate: -0.1023
          Episode_Reward/joint_vel: -0.0332
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 105676800
                    Iteration time: 2.12s
                      Time elapsed: 00:41:10
                               ETA: 01:13:46

################################################################################
                     [1m Learning iteration 1075/3000 [0m                     

                       Computation: 47239 steps/s (collection: 1.966s, learning 0.115s)
             Mean action noise std: 3.89
          Mean value_function loss: 74.1588
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 84.5103
                       Mean reward: 657.90
               Mean episode length: 227.77
    Episode_Reward/reaching_object: 1.5520
    Episode_Reward/rotating_object: 135.3762
        Episode_Reward/action_rate: -0.1039
          Episode_Reward/joint_vel: -0.0329
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 105775104
                    Iteration time: 2.08s
                      Time elapsed: 00:41:12
                               ETA: 01:13:43

################################################################################
                     [1m Learning iteration 1076/3000 [0m                     

                       Computation: 47590 steps/s (collection: 1.917s, learning 0.149s)
             Mean action noise std: 3.90
          Mean value_function loss: 77.7080
               Mean surrogate loss: -0.0082
                 Mean entropy loss: 84.5313
                       Mean reward: 715.89
               Mean episode length: 237.17
    Episode_Reward/reaching_object: 1.5750
    Episode_Reward/rotating_object: 135.7053
        Episode_Reward/action_rate: -0.1060
          Episode_Reward/joint_vel: -0.0357
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 105873408
                    Iteration time: 2.07s
                      Time elapsed: 00:41:14
                               ETA: 01:13:40

################################################################################
                     [1m Learning iteration 1077/3000 [0m                     

                       Computation: 48967 steps/s (collection: 1.903s, learning 0.104s)
             Mean action noise std: 3.90
          Mean value_function loss: 71.8666
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 84.5537
                       Mean reward: 687.83
               Mean episode length: 233.34
    Episode_Reward/reaching_object: 1.5500
    Episode_Reward/rotating_object: 133.9489
        Episode_Reward/action_rate: -0.1050
          Episode_Reward/joint_vel: -0.0345
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 105971712
                    Iteration time: 2.01s
                      Time elapsed: 00:41:16
                               ETA: 01:13:38

################################################################################
                     [1m Learning iteration 1078/3000 [0m                     

                       Computation: 47871 steps/s (collection: 1.960s, learning 0.093s)
             Mean action noise std: 3.90
          Mean value_function loss: 73.0172
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 84.5755
                       Mean reward: 646.72
               Mean episode length: 222.25
    Episode_Reward/reaching_object: 1.5663
    Episode_Reward/rotating_object: 135.6471
        Episode_Reward/action_rate: -0.1055
          Episode_Reward/joint_vel: -0.0338
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 106070016
                    Iteration time: 2.05s
                      Time elapsed: 00:41:18
                               ETA: 01:13:35

################################################################################
                     [1m Learning iteration 1079/3000 [0m                     

                       Computation: 48244 steps/s (collection: 1.931s, learning 0.107s)
             Mean action noise std: 3.90
          Mean value_function loss: 72.2680
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 84.5955
                       Mean reward: 672.78
               Mean episode length: 228.83
    Episode_Reward/reaching_object: 1.5464
    Episode_Reward/rotating_object: 135.4666
        Episode_Reward/action_rate: -0.1059
          Episode_Reward/joint_vel: -0.0347
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 106168320
                    Iteration time: 2.04s
                      Time elapsed: 00:41:20
                               ETA: 01:13:32

################################################################################
                     [1m Learning iteration 1080/3000 [0m                     

                       Computation: 46510 steps/s (collection: 2.007s, learning 0.107s)
             Mean action noise std: 3.91
          Mean value_function loss: 71.3212
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 84.6153
                       Mean reward: 690.88
               Mean episode length: 234.41
    Episode_Reward/reaching_object: 1.5709
    Episode_Reward/rotating_object: 134.3027
        Episode_Reward/action_rate: -0.1065
          Episode_Reward/joint_vel: -0.0357
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 106266624
                    Iteration time: 2.11s
                      Time elapsed: 00:41:22
                               ETA: 01:13:30

################################################################################
                     [1m Learning iteration 1081/3000 [0m                     

                       Computation: 48203 steps/s (collection: 1.908s, learning 0.131s)
             Mean action noise std: 3.91
          Mean value_function loss: 70.5358
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 84.6377
                       Mean reward: 692.07
               Mean episode length: 231.04
    Episode_Reward/reaching_object: 1.5170
    Episode_Reward/rotating_object: 133.9022
        Episode_Reward/action_rate: -0.1036
          Episode_Reward/joint_vel: -0.0336
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 106364928
                    Iteration time: 2.04s
                      Time elapsed: 00:41:24
                               ETA: 01:13:27

################################################################################
                     [1m Learning iteration 1082/3000 [0m                     

                       Computation: 46811 steps/s (collection: 1.992s, learning 0.108s)
             Mean action noise std: 3.91
          Mean value_function loss: 83.8009
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 84.6626
                       Mean reward: 610.43
               Mean episode length: 213.15
    Episode_Reward/reaching_object: 1.5251
    Episode_Reward/rotating_object: 131.2584
        Episode_Reward/action_rate: -0.1039
          Episode_Reward/joint_vel: -0.0343
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 106463232
                    Iteration time: 2.10s
                      Time elapsed: 00:41:27
                               ETA: 01:13:24

################################################################################
                     [1m Learning iteration 1083/3000 [0m                     

                       Computation: 48816 steps/s (collection: 1.888s, learning 0.126s)
             Mean action noise std: 3.92
          Mean value_function loss: 68.8436
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 84.6988
                       Mean reward: 635.63
               Mean episode length: 214.68
    Episode_Reward/reaching_object: 1.5245
    Episode_Reward/rotating_object: 135.8544
        Episode_Reward/action_rate: -0.1035
          Episode_Reward/joint_vel: -0.0327
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 106561536
                    Iteration time: 2.01s
                      Time elapsed: 00:41:29
                               ETA: 01:13:21

################################################################################
                     [1m Learning iteration 1084/3000 [0m                     

                       Computation: 46525 steps/s (collection: 1.933s, learning 0.180s)
             Mean action noise std: 3.92
          Mean value_function loss: 72.7218
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 84.7296
                       Mean reward: 660.05
               Mean episode length: 223.39
    Episode_Reward/reaching_object: 1.5455
    Episode_Reward/rotating_object: 133.4264
        Episode_Reward/action_rate: -0.1056
          Episode_Reward/joint_vel: -0.0351
      Episode_Termination/time_out: 17.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 106659840
                    Iteration time: 2.11s
                      Time elapsed: 00:41:31
                               ETA: 01:13:19

################################################################################
                     [1m Learning iteration 1085/3000 [0m                     

                       Computation: 46536 steps/s (collection: 2.016s, learning 0.096s)
             Mean action noise std: 3.93
          Mean value_function loss: 71.5280
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 84.7595
                       Mean reward: 698.57
               Mean episode length: 234.32
    Episode_Reward/reaching_object: 1.5132
    Episode_Reward/rotating_object: 132.6352
        Episode_Reward/action_rate: -0.1047
          Episode_Reward/joint_vel: -0.0347
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 106758144
                    Iteration time: 2.11s
                      Time elapsed: 00:41:33
                               ETA: 01:13:16

################################################################################
                     [1m Learning iteration 1086/3000 [0m                     

                       Computation: 49779 steps/s (collection: 1.869s, learning 0.106s)
             Mean action noise std: 3.93
          Mean value_function loss: 70.2074
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 84.7819
                       Mean reward: 697.71
               Mean episode length: 232.78
    Episode_Reward/reaching_object: 1.5541
    Episode_Reward/rotating_object: 139.3389
        Episode_Reward/action_rate: -0.1077
          Episode_Reward/joint_vel: -0.0340
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 106856448
                    Iteration time: 1.97s
                      Time elapsed: 00:41:35
                               ETA: 01:13:13

################################################################################
                     [1m Learning iteration 1087/3000 [0m                     

                       Computation: 47645 steps/s (collection: 1.935s, learning 0.129s)
             Mean action noise std: 3.93
          Mean value_function loss: 75.0105
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 84.7988
                       Mean reward: 704.38
               Mean episode length: 233.34
    Episode_Reward/reaching_object: 1.5352
    Episode_Reward/rotating_object: 137.1754
        Episode_Reward/action_rate: -0.1073
          Episode_Reward/joint_vel: -0.0345
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 106954752
                    Iteration time: 2.06s
                      Time elapsed: 00:41:37
                               ETA: 01:13:11

################################################################################
                     [1m Learning iteration 1088/3000 [0m                     

                       Computation: 44518 steps/s (collection: 2.028s, learning 0.180s)
             Mean action noise std: 3.93
          Mean value_function loss: 80.1493
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 84.8179
                       Mean reward: 675.74
               Mean episode length: 226.77
    Episode_Reward/reaching_object: 1.5015
    Episode_Reward/rotating_object: 131.5078
        Episode_Reward/action_rate: -0.1045
          Episode_Reward/joint_vel: -0.0342
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 107053056
                    Iteration time: 2.21s
                      Time elapsed: 00:41:39
                               ETA: 01:13:08

################################################################################
                     [1m Learning iteration 1089/3000 [0m                     

                       Computation: 41944 steps/s (collection: 2.186s, learning 0.158s)
             Mean action noise std: 3.94
          Mean value_function loss: 77.8550
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 84.8414
                       Mean reward: 675.65
               Mean episode length: 233.39
    Episode_Reward/reaching_object: 1.4945
    Episode_Reward/rotating_object: 131.3435
        Episode_Reward/action_rate: -0.1049
          Episode_Reward/joint_vel: -0.0348
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.2917
--------------------------------------------------------------------------------
                   Total timesteps: 107151360
                    Iteration time: 2.34s
                      Time elapsed: 00:41:41
                               ETA: 01:13:06

################################################################################
                     [1m Learning iteration 1090/3000 [0m                     

                       Computation: 48606 steps/s (collection: 1.912s, learning 0.111s)
             Mean action noise std: 3.94
          Mean value_function loss: 73.4102
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 84.8678
                       Mean reward: 690.84
               Mean episode length: 231.89
    Episode_Reward/reaching_object: 1.5003
    Episode_Reward/rotating_object: 133.1824
        Episode_Reward/action_rate: -0.1056
          Episode_Reward/joint_vel: -0.0334
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 107249664
                    Iteration time: 2.02s
                      Time elapsed: 00:41:43
                               ETA: 01:13:03

################################################################################
                     [1m Learning iteration 1091/3000 [0m                     

                       Computation: 49097 steps/s (collection: 1.880s, learning 0.123s)
             Mean action noise std: 3.94
          Mean value_function loss: 79.1725
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 84.8967
                       Mean reward: 658.23
               Mean episode length: 222.66
    Episode_Reward/reaching_object: 1.5052
    Episode_Reward/rotating_object: 135.9748
        Episode_Reward/action_rate: -0.1058
          Episode_Reward/joint_vel: -0.0329
      Episode_Termination/time_out: 14.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 107347968
                    Iteration time: 2.00s
                      Time elapsed: 00:41:45
                               ETA: 01:13:00

################################################################################
                     [1m Learning iteration 1092/3000 [0m                     

                       Computation: 49507 steps/s (collection: 1.881s, learning 0.105s)
             Mean action noise std: 3.95
          Mean value_function loss: 71.9824
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 84.9211
                       Mean reward: 681.64
               Mean episode length: 232.18
    Episode_Reward/reaching_object: 1.4945
    Episode_Reward/rotating_object: 133.4924
        Episode_Reward/action_rate: -0.1061
          Episode_Reward/joint_vel: -0.0336
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 107446272
                    Iteration time: 1.99s
                      Time elapsed: 00:41:47
                               ETA: 01:12:57

################################################################################
                     [1m Learning iteration 1093/3000 [0m                     

                       Computation: 48524 steps/s (collection: 1.912s, learning 0.114s)
             Mean action noise std: 3.95
          Mean value_function loss: 78.0465
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 84.9415
                       Mean reward: 667.37
               Mean episode length: 223.55
    Episode_Reward/reaching_object: 1.4725
    Episode_Reward/rotating_object: 129.6872
        Episode_Reward/action_rate: -0.1042
          Episode_Reward/joint_vel: -0.0339
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 107544576
                    Iteration time: 2.03s
                      Time elapsed: 00:41:49
                               ETA: 01:12:55

################################################################################
                     [1m Learning iteration 1094/3000 [0m                     

                       Computation: 47408 steps/s (collection: 1.948s, learning 0.125s)
             Mean action noise std: 3.95
          Mean value_function loss: 68.1869
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 84.9720
                       Mean reward: 699.15
               Mean episode length: 235.48
    Episode_Reward/reaching_object: 1.5267
    Episode_Reward/rotating_object: 136.5074
        Episode_Reward/action_rate: -0.1071
          Episode_Reward/joint_vel: -0.0336
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 107642880
                    Iteration time: 2.07s
                      Time elapsed: 00:41:52
                               ETA: 01:12:52

################################################################################
                     [1m Learning iteration 1095/3000 [0m                     

                       Computation: 46522 steps/s (collection: 2.013s, learning 0.100s)
             Mean action noise std: 3.96
          Mean value_function loss: 72.2036
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 84.9904
                       Mean reward: 698.54
               Mean episode length: 239.43
    Episode_Reward/reaching_object: 1.5278
    Episode_Reward/rotating_object: 135.4968
        Episode_Reward/action_rate: -0.1080
          Episode_Reward/joint_vel: -0.0344
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 107741184
                    Iteration time: 2.11s
                      Time elapsed: 00:41:54
                               ETA: 01:12:49

################################################################################
                     [1m Learning iteration 1096/3000 [0m                     

                       Computation: 46784 steps/s (collection: 1.942s, learning 0.160s)
             Mean action noise std: 3.96
          Mean value_function loss: 78.1127
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 85.0071
                       Mean reward: 705.64
               Mean episode length: 235.97
    Episode_Reward/reaching_object: 1.5223
    Episode_Reward/rotating_object: 134.3062
        Episode_Reward/action_rate: -0.1071
          Episode_Reward/joint_vel: -0.0331
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 107839488
                    Iteration time: 2.10s
                      Time elapsed: 00:41:56
                               ETA: 01:12:47

################################################################################
                     [1m Learning iteration 1097/3000 [0m                     

                       Computation: 48663 steps/s (collection: 1.923s, learning 0.097s)
             Mean action noise std: 3.96
          Mean value_function loss: 77.4859
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 85.0334
                       Mean reward: 664.50
               Mean episode length: 222.83
    Episode_Reward/reaching_object: 1.4445
    Episode_Reward/rotating_object: 129.4963
        Episode_Reward/action_rate: -0.1026
          Episode_Reward/joint_vel: -0.0327
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.6667
--------------------------------------------------------------------------------
                   Total timesteps: 107937792
                    Iteration time: 2.02s
                      Time elapsed: 00:41:58
                               ETA: 01:12:44

################################################################################
                     [1m Learning iteration 1098/3000 [0m                     

                       Computation: 48398 steps/s (collection: 1.925s, learning 0.107s)
             Mean action noise std: 3.96
          Mean value_function loss: 79.2442
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 85.0576
                       Mean reward: 668.19
               Mean episode length: 223.54
    Episode_Reward/reaching_object: 1.4928
    Episode_Reward/rotating_object: 131.3559
        Episode_Reward/action_rate: -0.1049
          Episode_Reward/joint_vel: -0.0323
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 108036096
                    Iteration time: 2.03s
                      Time elapsed: 00:42:00
                               ETA: 01:12:41

################################################################################
                     [1m Learning iteration 1099/3000 [0m                     

                       Computation: 43390 steps/s (collection: 2.154s, learning 0.111s)
             Mean action noise std: 3.97
          Mean value_function loss: 76.6550
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 85.0750
                       Mean reward: 677.55
               Mean episode length: 224.13
    Episode_Reward/reaching_object: 1.5442
    Episode_Reward/rotating_object: 137.1937
        Episode_Reward/action_rate: -0.1084
          Episode_Reward/joint_vel: -0.0335
      Episode_Termination/time_out: 17.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 108134400
                    Iteration time: 2.27s
                      Time elapsed: 00:42:02
                               ETA: 01:12:39

################################################################################
                     [1m Learning iteration 1100/3000 [0m                     

                       Computation: 48932 steps/s (collection: 1.907s, learning 0.102s)
             Mean action noise std: 3.97
          Mean value_function loss: 76.3474
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 85.0924
                       Mean reward: 722.01
               Mean episode length: 242.28
    Episode_Reward/reaching_object: 1.5530
    Episode_Reward/rotating_object: 135.9962
        Episode_Reward/action_rate: -0.1091
          Episode_Reward/joint_vel: -0.0337
      Episode_Termination/time_out: 17.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 108232704
                    Iteration time: 2.01s
                      Time elapsed: 00:42:04
                               ETA: 01:12:36

################################################################################
                     [1m Learning iteration 1101/3000 [0m                     

                       Computation: 48252 steps/s (collection: 1.928s, learning 0.109s)
             Mean action noise std: 3.97
          Mean value_function loss: 91.3320
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 85.1154
                       Mean reward: 619.68
               Mean episode length: 212.53
    Episode_Reward/reaching_object: 1.4394
    Episode_Reward/rotating_object: 126.2190
        Episode_Reward/action_rate: -0.1025
          Episode_Reward/joint_vel: -0.0339
      Episode_Termination/time_out: 14.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.7500
--------------------------------------------------------------------------------
                   Total timesteps: 108331008
                    Iteration time: 2.04s
                      Time elapsed: 00:42:06
                               ETA: 01:12:33

################################################################################
                     [1m Learning iteration 1102/3000 [0m                     

                       Computation: 48286 steps/s (collection: 1.900s, learning 0.136s)
             Mean action noise std: 3.98
          Mean value_function loss: 74.0986
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 85.1460
                       Mean reward: 666.88
               Mean episode length: 226.51
    Episode_Reward/reaching_object: 1.5063
    Episode_Reward/rotating_object: 132.8717
        Episode_Reward/action_rate: -0.1064
          Episode_Reward/joint_vel: -0.0341
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 108429312
                    Iteration time: 2.04s
                      Time elapsed: 00:42:08
                               ETA: 01:12:31

################################################################################
                     [1m Learning iteration 1103/3000 [0m                     

                       Computation: 47770 steps/s (collection: 1.955s, learning 0.102s)
             Mean action noise std: 3.98
          Mean value_function loss: 74.7255
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 85.1722
                       Mean reward: 694.58
               Mean episode length: 230.72
    Episode_Reward/reaching_object: 1.5073
    Episode_Reward/rotating_object: 133.3560
        Episode_Reward/action_rate: -0.1064
          Episode_Reward/joint_vel: -0.0328
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1667
--------------------------------------------------------------------------------
                   Total timesteps: 108527616
                    Iteration time: 2.06s
                      Time elapsed: 00:42:10
                               ETA: 01:12:28

################################################################################
                     [1m Learning iteration 1104/3000 [0m                     

                       Computation: 45698 steps/s (collection: 2.008s, learning 0.143s)
             Mean action noise std: 3.98
          Mean value_function loss: 71.5354
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 85.2003
                       Mean reward: 675.95
               Mean episode length: 226.94
    Episode_Reward/reaching_object: 1.5200
    Episode_Reward/rotating_object: 132.7512
        Episode_Reward/action_rate: -0.1071
          Episode_Reward/joint_vel: -0.0338
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 108625920
                    Iteration time: 2.15s
                      Time elapsed: 00:42:12
                               ETA: 01:12:25

################################################################################
                     [1m Learning iteration 1105/3000 [0m                     

                       Computation: 47662 steps/s (collection: 1.932s, learning 0.131s)
             Mean action noise std: 3.99
          Mean value_function loss: 68.1853
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 85.2253
                       Mean reward: 671.75
               Mean episode length: 226.64
    Episode_Reward/reaching_object: 1.5408
    Episode_Reward/rotating_object: 136.8626
        Episode_Reward/action_rate: -0.1090
          Episode_Reward/joint_vel: -0.0330
      Episode_Termination/time_out: 17.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 108724224
                    Iteration time: 2.06s
                      Time elapsed: 00:42:14
                               ETA: 01:12:23

################################################################################
                     [1m Learning iteration 1106/3000 [0m                     

                       Computation: 45970 steps/s (collection: 2.022s, learning 0.117s)
             Mean action noise std: 3.99
          Mean value_function loss: 72.8419
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 85.2498
                       Mean reward: 675.27
               Mean episode length: 230.04
    Episode_Reward/reaching_object: 1.5133
    Episode_Reward/rotating_object: 134.6418
        Episode_Reward/action_rate: -0.1069
          Episode_Reward/joint_vel: -0.0321
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 108822528
                    Iteration time: 2.14s
                      Time elapsed: 00:42:17
                               ETA: 01:12:20

################################################################################
                     [1m Learning iteration 1107/3000 [0m                     

                       Computation: 46395 steps/s (collection: 1.994s, learning 0.125s)
             Mean action noise std: 3.99
          Mean value_function loss: 73.1948
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 85.2714
                       Mean reward: 699.85
               Mean episode length: 234.97
    Episode_Reward/reaching_object: 1.5618
    Episode_Reward/rotating_object: 138.1257
        Episode_Reward/action_rate: -0.1101
          Episode_Reward/joint_vel: -0.0337
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 108920832
                    Iteration time: 2.12s
                      Time elapsed: 00:42:19
                               ETA: 01:12:18

################################################################################
                     [1m Learning iteration 1108/3000 [0m                     

                       Computation: 48555 steps/s (collection: 1.889s, learning 0.136s)
             Mean action noise std: 3.99
          Mean value_function loss: 79.3939
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 85.2894
                       Mean reward: 684.37
               Mean episode length: 231.92
    Episode_Reward/reaching_object: 1.5215
    Episode_Reward/rotating_object: 133.2230
        Episode_Reward/action_rate: -0.1073
          Episode_Reward/joint_vel: -0.0331
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.1250
--------------------------------------------------------------------------------
                   Total timesteps: 109019136
                    Iteration time: 2.02s
                      Time elapsed: 00:42:21
                               ETA: 01:12:15

################################################################################
                     [1m Learning iteration 1109/3000 [0m                     

                       Computation: 48272 steps/s (collection: 1.930s, learning 0.107s)
             Mean action noise std: 4.00
          Mean value_function loss: 81.4769
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 85.3062
                       Mean reward: 670.79
               Mean episode length: 224.51
    Episode_Reward/reaching_object: 1.4932
    Episode_Reward/rotating_object: 129.6588
        Episode_Reward/action_rate: -0.1059
          Episode_Reward/joint_vel: -0.0336
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.3333
--------------------------------------------------------------------------------
                   Total timesteps: 109117440
                    Iteration time: 2.04s
                      Time elapsed: 00:42:23
                               ETA: 01:12:12

################################################################################
                     [1m Learning iteration 1110/3000 [0m                     

                       Computation: 49127 steps/s (collection: 1.877s, learning 0.124s)
             Mean action noise std: 4.00
          Mean value_function loss: 70.4379
               Mean surrogate loss: -0.0079
                 Mean entropy loss: 85.3288
                       Mean reward: 708.95
               Mean episode length: 236.13
    Episode_Reward/reaching_object: 1.5292
    Episode_Reward/rotating_object: 133.2874
        Episode_Reward/action_rate: -0.1083
          Episode_Reward/joint_vel: -0.0341
      Episode_Termination/time_out: 18.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 109215744
                    Iteration time: 2.00s
                      Time elapsed: 00:42:25
                               ETA: 01:12:09

################################################################################
                     [1m Learning iteration 1111/3000 [0m                     

                       Computation: 48698 steps/s (collection: 1.918s, learning 0.101s)
             Mean action noise std: 4.00
          Mean value_function loss: 81.0229
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 85.3570
                       Mean reward: 683.25
               Mean episode length: 231.84
    Episode_Reward/reaching_object: 1.5434
    Episode_Reward/rotating_object: 132.6584
        Episode_Reward/action_rate: -0.1100
          Episode_Reward/joint_vel: -0.0343
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 109314048
                    Iteration time: 2.02s
                      Time elapsed: 00:42:27
                               ETA: 01:12:07

################################################################################
                     [1m Learning iteration 1112/3000 [0m                     

                       Computation: 48739 steps/s (collection: 1.905s, learning 0.111s)
             Mean action noise std: 4.01
          Mean value_function loss: 78.3671
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 85.3713
                       Mean reward: 654.99
               Mean episode length: 228.02
    Episode_Reward/reaching_object: 1.5097
    Episode_Reward/rotating_object: 132.0644
        Episode_Reward/action_rate: -0.1079
          Episode_Reward/joint_vel: -0.0335
      Episode_Termination/time_out: 14.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 109412352
                    Iteration time: 2.02s
                      Time elapsed: 00:42:29
                               ETA: 01:12:04

################################################################################
                     [1m Learning iteration 1113/3000 [0m                     

                       Computation: 49013 steps/s (collection: 1.915s, learning 0.091s)
             Mean action noise std: 4.01
          Mean value_function loss: 62.1054
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 85.3910
                       Mean reward: 704.10
               Mean episode length: 238.25
    Episode_Reward/reaching_object: 1.5743
    Episode_Reward/rotating_object: 137.3791
        Episode_Reward/action_rate: -0.1119
          Episode_Reward/joint_vel: -0.0349
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 109510656
                    Iteration time: 2.01s
                      Time elapsed: 00:42:31
                               ETA: 01:12:01

################################################################################
                     [1m Learning iteration 1114/3000 [0m                     

                       Computation: 47821 steps/s (collection: 1.957s, learning 0.099s)
             Mean action noise std: 4.01
          Mean value_function loss: 76.3026
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 85.4098
                       Mean reward: 697.71
               Mean episode length: 233.69
    Episode_Reward/reaching_object: 1.5784
    Episode_Reward/rotating_object: 141.3917
        Episode_Reward/action_rate: -0.1119
          Episode_Reward/joint_vel: -0.0328
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 109608960
                    Iteration time: 2.06s
                      Time elapsed: 00:42:33
                               ETA: 01:11:58

################################################################################
                     [1m Learning iteration 1115/3000 [0m                     

                       Computation: 48464 steps/s (collection: 1.920s, learning 0.108s)
             Mean action noise std: 4.01
          Mean value_function loss: 73.8913
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 85.4274
                       Mean reward: 667.00
               Mean episode length: 224.76
    Episode_Reward/reaching_object: 1.5238
    Episode_Reward/rotating_object: 133.8249
        Episode_Reward/action_rate: -0.1091
          Episode_Reward/joint_vel: -0.0333
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 109707264
                    Iteration time: 2.03s
                      Time elapsed: 00:42:35
                               ETA: 01:11:56

################################################################################
                     [1m Learning iteration 1116/3000 [0m                     

                       Computation: 47394 steps/s (collection: 1.944s, learning 0.130s)
             Mean action noise std: 4.02
          Mean value_function loss: 71.8308
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 85.4492
                       Mean reward: 656.82
               Mean episode length: 223.80
    Episode_Reward/reaching_object: 1.5525
    Episode_Reward/rotating_object: 136.0472
        Episode_Reward/action_rate: -0.1106
          Episode_Reward/joint_vel: -0.0333
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 109805568
                    Iteration time: 2.07s
                      Time elapsed: 00:42:37
                               ETA: 01:11:53

################################################################################
                     [1m Learning iteration 1117/3000 [0m                     

                       Computation: 48586 steps/s (collection: 1.912s, learning 0.112s)
             Mean action noise std: 4.02
          Mean value_function loss: 83.3778
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 85.4722
                       Mean reward: 640.67
               Mean episode length: 220.31
    Episode_Reward/reaching_object: 1.5128
    Episode_Reward/rotating_object: 130.2326
        Episode_Reward/action_rate: -0.1081
          Episode_Reward/joint_vel: -0.0339
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.2500
--------------------------------------------------------------------------------
                   Total timesteps: 109903872
                    Iteration time: 2.02s
                      Time elapsed: 00:42:39
                               ETA: 01:11:50

################################################################################
                     [1m Learning iteration 1118/3000 [0m                     

                       Computation: 45349 steps/s (collection: 2.042s, learning 0.125s)
             Mean action noise std: 4.02
          Mean value_function loss: 72.7935
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 85.4962
                       Mean reward: 713.02
               Mean episode length: 237.66
    Episode_Reward/reaching_object: 1.5111
    Episode_Reward/rotating_object: 133.8371
        Episode_Reward/action_rate: -0.1091
          Episode_Reward/joint_vel: -0.0340
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 2.2083
--------------------------------------------------------------------------------
                   Total timesteps: 110002176
                    Iteration time: 2.17s
                      Time elapsed: 00:42:41
                               ETA: 01:11:48

################################################################################
                     [1m Learning iteration 1119/3000 [0m                     

                       Computation: 50061 steps/s (collection: 1.866s, learning 0.098s)
             Mean action noise std: 4.03
          Mean value_function loss: 66.1619
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 85.5168
                       Mean reward: 685.29
               Mean episode length: 227.13
    Episode_Reward/reaching_object: 1.5217
    Episode_Reward/rotating_object: 134.7758
        Episode_Reward/action_rate: -0.1094
          Episode_Reward/joint_vel: -0.0332
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 110100480
                    Iteration time: 1.96s
                      Time elapsed: 00:42:43
                               ETA: 01:11:45

################################################################################
                     [1m Learning iteration 1120/3000 [0m                     

                       Computation: 49429 steps/s (collection: 1.897s, learning 0.092s)
             Mean action noise std: 4.03
          Mean value_function loss: 70.1357
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 85.5434
                       Mean reward: 668.54
               Mean episode length: 224.49
    Episode_Reward/reaching_object: 1.5326
    Episode_Reward/rotating_object: 136.6265
        Episode_Reward/action_rate: -0.1098
          Episode_Reward/joint_vel: -0.0331
      Episode_Termination/time_out: 17.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 110198784
                    Iteration time: 1.99s
                      Time elapsed: 00:42:45
                               ETA: 01:11:42

################################################################################
                     [1m Learning iteration 1121/3000 [0m                     

                       Computation: 49374 steps/s (collection: 1.879s, learning 0.112s)
             Mean action noise std: 4.03
          Mean value_function loss: 69.2981
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 85.5640
                       Mean reward: 714.84
               Mean episode length: 232.45
    Episode_Reward/reaching_object: 1.5621
    Episode_Reward/rotating_object: 139.8867
        Episode_Reward/action_rate: -0.1122
          Episode_Reward/joint_vel: -0.0338
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 110297088
                    Iteration time: 1.99s
                      Time elapsed: 00:42:47
                               ETA: 01:11:39

################################################################################
                     [1m Learning iteration 1122/3000 [0m                     

                       Computation: 46318 steps/s (collection: 1.953s, learning 0.169s)
             Mean action noise std: 4.04
          Mean value_function loss: 87.7192
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 85.5844
                       Mean reward: 673.42
               Mean episode length: 228.36
    Episode_Reward/reaching_object: 1.5317
    Episode_Reward/rotating_object: 136.1608
        Episode_Reward/action_rate: -0.1106
          Episode_Reward/joint_vel: -0.0334
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 110395392
                    Iteration time: 2.12s
                      Time elapsed: 00:42:49
                               ETA: 01:11:37

################################################################################
                     [1m Learning iteration 1123/3000 [0m                     

                       Computation: 45318 steps/s (collection: 1.990s, learning 0.179s)
             Mean action noise std: 4.04
          Mean value_function loss: 71.2476
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 85.6067
                       Mean reward: 681.73
               Mean episode length: 226.55
    Episode_Reward/reaching_object: 1.5292
    Episode_Reward/rotating_object: 133.4953
        Episode_Reward/action_rate: -0.1112
          Episode_Reward/joint_vel: -0.0346
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 110493696
                    Iteration time: 2.17s
                      Time elapsed: 00:42:51
                               ETA: 01:11:34

################################################################################
                     [1m Learning iteration 1124/3000 [0m                     

                       Computation: 46905 steps/s (collection: 1.933s, learning 0.163s)
             Mean action noise std: 4.04
          Mean value_function loss: 74.4556
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 85.6341
                       Mean reward: 677.59
               Mean episode length: 231.31
    Episode_Reward/reaching_object: 1.5308
    Episode_Reward/rotating_object: 133.6956
        Episode_Reward/action_rate: -0.1106
          Episode_Reward/joint_vel: -0.0345
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 110592000
                    Iteration time: 2.10s
                      Time elapsed: 00:42:53
                               ETA: 01:11:32

################################################################################
                     [1m Learning iteration 1125/3000 [0m                     

                       Computation: 47019 steps/s (collection: 1.926s, learning 0.165s)
             Mean action noise std: 4.05
          Mean value_function loss: 64.6543
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 85.6562
                       Mean reward: 709.18
               Mean episode length: 233.79
    Episode_Reward/reaching_object: 1.5801
    Episode_Reward/rotating_object: 140.1454
        Episode_Reward/action_rate: -0.1138
          Episode_Reward/joint_vel: -0.0342
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 110690304
                    Iteration time: 2.09s
                      Time elapsed: 00:42:56
                               ETA: 01:11:29

################################################################################
                     [1m Learning iteration 1126/3000 [0m                     

                       Computation: 47299 steps/s (collection: 1.974s, learning 0.104s)
             Mean action noise std: 4.05
          Mean value_function loss: 64.3872
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 85.6699
                       Mean reward: 674.52
               Mean episode length: 225.02
    Episode_Reward/reaching_object: 1.5747
    Episode_Reward/rotating_object: 138.0213
        Episode_Reward/action_rate: -0.1136
          Episode_Reward/joint_vel: -0.0350
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 110788608
                    Iteration time: 2.08s
                      Time elapsed: 00:42:58
                               ETA: 01:11:26

################################################################################
                     [1m Learning iteration 1127/3000 [0m                     

                       Computation: 45100 steps/s (collection: 2.068s, learning 0.111s)
             Mean action noise std: 4.05
          Mean value_function loss: 75.8890
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 85.6785
                       Mean reward: 656.03
               Mean episode length: 220.12
    Episode_Reward/reaching_object: 1.5584
    Episode_Reward/rotating_object: 135.5168
        Episode_Reward/action_rate: -0.1122
          Episode_Reward/joint_vel: -0.0341
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 110886912
                    Iteration time: 2.18s
                      Time elapsed: 00:43:00
                               ETA: 01:11:24

################################################################################
                     [1m Learning iteration 1128/3000 [0m                     

                       Computation: 47725 steps/s (collection: 1.928s, learning 0.132s)
             Mean action noise std: 4.05
          Mean value_function loss: 71.0991
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 85.6962
                       Mean reward: 663.99
               Mean episode length: 220.10
    Episode_Reward/reaching_object: 1.5578
    Episode_Reward/rotating_object: 136.2322
        Episode_Reward/action_rate: -0.1126
          Episode_Reward/joint_vel: -0.0346
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 110985216
                    Iteration time: 2.06s
                      Time elapsed: 00:43:02
                               ETA: 01:11:21

################################################################################
                     [1m Learning iteration 1129/3000 [0m                     

                       Computation: 48227 steps/s (collection: 1.913s, learning 0.125s)
             Mean action noise std: 4.06
          Mean value_function loss: 64.5270
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 85.7206
                       Mean reward: 687.28
               Mean episode length: 226.62
    Episode_Reward/reaching_object: 1.5876
    Episode_Reward/rotating_object: 142.6193
        Episode_Reward/action_rate: -0.1151
          Episode_Reward/joint_vel: -0.0333
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 111083520
                    Iteration time: 2.04s
                      Time elapsed: 00:43:04
                               ETA: 01:11:19

################################################################################
                     [1m Learning iteration 1130/3000 [0m                     

                       Computation: 48516 steps/s (collection: 1.933s, learning 0.093s)
             Mean action noise std: 4.06
          Mean value_function loss: 65.6265
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 85.7544
                       Mean reward: 693.37
               Mean episode length: 232.53
    Episode_Reward/reaching_object: 1.5801
    Episode_Reward/rotating_object: 140.1335
        Episode_Reward/action_rate: -0.1149
          Episode_Reward/joint_vel: -0.0330
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 111181824
                    Iteration time: 2.03s
                      Time elapsed: 00:43:06
                               ETA: 01:11:16

################################################################################
                     [1m Learning iteration 1131/3000 [0m                     

                       Computation: 49068 steps/s (collection: 1.901s, learning 0.102s)
             Mean action noise std: 4.06
          Mean value_function loss: 68.4443
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 85.7708
                       Mean reward: 691.13
               Mean episode length: 230.21
    Episode_Reward/reaching_object: 1.5409
    Episode_Reward/rotating_object: 134.9313
        Episode_Reward/action_rate: -0.1126
          Episode_Reward/joint_vel: -0.0340
      Episode_Termination/time_out: 17.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 111280128
                    Iteration time: 2.00s
                      Time elapsed: 00:43:08
                               ETA: 01:11:13

################################################################################
                     [1m Learning iteration 1132/3000 [0m                     

                       Computation: 46144 steps/s (collection: 2.019s, learning 0.111s)
             Mean action noise std: 4.06
          Mean value_function loss: 72.8296
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 85.7818
                       Mean reward: 671.72
               Mean episode length: 230.05
    Episode_Reward/reaching_object: 1.5418
    Episode_Reward/rotating_object: 134.9304
        Episode_Reward/action_rate: -0.1132
          Episode_Reward/joint_vel: -0.0338
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 111378432
                    Iteration time: 2.13s
                      Time elapsed: 00:43:10
                               ETA: 01:11:11

################################################################################
                     [1m Learning iteration 1133/3000 [0m                     

                       Computation: 48993 steps/s (collection: 1.896s, learning 0.111s)
             Mean action noise std: 4.07
          Mean value_function loss: 73.7117
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 85.7900
                       Mean reward: 658.31
               Mean episode length: 224.15
    Episode_Reward/reaching_object: 1.5428
    Episode_Reward/rotating_object: 135.7126
        Episode_Reward/action_rate: -0.1128
          Episode_Reward/joint_vel: -0.0338
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 111476736
                    Iteration time: 2.01s
                      Time elapsed: 00:43:12
                               ETA: 01:11:08

################################################################################
                     [1m Learning iteration 1134/3000 [0m                     

                       Computation: 48328 steps/s (collection: 1.909s, learning 0.125s)
             Mean action noise std: 4.07
          Mean value_function loss: 69.7740
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 85.8063
                       Mean reward: 665.55
               Mean episode length: 224.48
    Episode_Reward/reaching_object: 1.5195
    Episode_Reward/rotating_object: 135.0185
        Episode_Reward/action_rate: -0.1118
          Episode_Reward/joint_vel: -0.0337
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 111575040
                    Iteration time: 2.03s
                      Time elapsed: 00:43:14
                               ETA: 01:11:05

################################################################################
                     [1m Learning iteration 1135/3000 [0m                     

                       Computation: 47160 steps/s (collection: 1.981s, learning 0.103s)
             Mean action noise std: 4.07
          Mean value_function loss: 77.9871
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 85.8269
                       Mean reward: 668.15
               Mean episode length: 222.97
    Episode_Reward/reaching_object: 1.5690
    Episode_Reward/rotating_object: 139.3929
        Episode_Reward/action_rate: -0.1145
          Episode_Reward/joint_vel: -0.0330
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 111673344
                    Iteration time: 2.08s
                      Time elapsed: 00:43:16
                               ETA: 01:11:03

################################################################################
                     [1m Learning iteration 1136/3000 [0m                     

                       Computation: 50376 steps/s (collection: 1.852s, learning 0.100s)
             Mean action noise std: 4.07
          Mean value_function loss: 65.3825
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 85.8496
                       Mean reward: 674.84
               Mean episode length: 232.33
    Episode_Reward/reaching_object: 1.5605
    Episode_Reward/rotating_object: 138.6236
        Episode_Reward/action_rate: -0.1151
          Episode_Reward/joint_vel: -0.0336
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 111771648
                    Iteration time: 1.95s
                      Time elapsed: 00:43:18
                               ETA: 01:11:00

################################################################################
                     [1m Learning iteration 1137/3000 [0m                     

                       Computation: 46888 steps/s (collection: 1.973s, learning 0.124s)
             Mean action noise std: 4.08
          Mean value_function loss: 78.7069
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 85.8730
                       Mean reward: 690.03
               Mean episode length: 228.09
    Episode_Reward/reaching_object: 1.5231
    Episode_Reward/rotating_object: 135.4950
        Episode_Reward/action_rate: -0.1118
          Episode_Reward/joint_vel: -0.0326
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 111869952
                    Iteration time: 2.10s
                      Time elapsed: 00:43:20
                               ETA: 01:10:57

################################################################################
                     [1m Learning iteration 1138/3000 [0m                     

                       Computation: 44536 steps/s (collection: 2.032s, learning 0.176s)
             Mean action noise std: 4.08
          Mean value_function loss: 74.4970
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 85.8938
                       Mean reward: 704.92
               Mean episode length: 233.32
    Episode_Reward/reaching_object: 1.5526
    Episode_Reward/rotating_object: 137.5178
        Episode_Reward/action_rate: -0.1139
          Episode_Reward/joint_vel: -0.0336
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 111968256
                    Iteration time: 2.21s
                      Time elapsed: 00:43:22
                               ETA: 01:10:55

################################################################################
                     [1m Learning iteration 1139/3000 [0m                     

                       Computation: 48946 steps/s (collection: 1.872s, learning 0.136s)
             Mean action noise std: 4.08
          Mean value_function loss: 71.1456
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 85.9137
                       Mean reward: 694.75
               Mean episode length: 228.37
    Episode_Reward/reaching_object: 1.5506
    Episode_Reward/rotating_object: 137.6686
        Episode_Reward/action_rate: -0.1143
          Episode_Reward/joint_vel: -0.0334
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 112066560
                    Iteration time: 2.01s
                      Time elapsed: 00:43:24
                               ETA: 01:10:52

################################################################################
                     [1m Learning iteration 1140/3000 [0m                     

                       Computation: 48968 steps/s (collection: 1.896s, learning 0.112s)
             Mean action noise std: 4.09
          Mean value_function loss: 78.2749
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 85.9341
                       Mean reward: 691.49
               Mean episode length: 232.38
    Episode_Reward/reaching_object: 1.5442
    Episode_Reward/rotating_object: 135.1778
        Episode_Reward/action_rate: -0.1139
          Episode_Reward/joint_vel: -0.0344
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 112164864
                    Iteration time: 2.01s
                      Time elapsed: 00:43:26
                               ETA: 01:10:49

################################################################################
                     [1m Learning iteration 1141/3000 [0m                     

                       Computation: 50012 steps/s (collection: 1.860s, learning 0.106s)
             Mean action noise std: 4.09
          Mean value_function loss: 72.8517
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 85.9523
                       Mean reward: 677.08
               Mean episode length: 225.81
    Episode_Reward/reaching_object: 1.5390
    Episode_Reward/rotating_object: 136.7590
        Episode_Reward/action_rate: -0.1131
          Episode_Reward/joint_vel: -0.0326
      Episode_Termination/time_out: 17.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 112263168
                    Iteration time: 1.97s
                      Time elapsed: 00:43:28
                               ETA: 01:10:46

################################################################################
                     [1m Learning iteration 1142/3000 [0m                     

                       Computation: 48743 steps/s (collection: 1.902s, learning 0.115s)
             Mean action noise std: 4.09
          Mean value_function loss: 84.0834
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 85.9753
                       Mean reward: 667.76
               Mean episode length: 229.01
    Episode_Reward/reaching_object: 1.5514
    Episode_Reward/rotating_object: 136.4503
        Episode_Reward/action_rate: -0.1147
          Episode_Reward/joint_vel: -0.0344
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 112361472
                    Iteration time: 2.02s
                      Time elapsed: 00:43:30
                               ETA: 01:10:44

################################################################################
                     [1m Learning iteration 1143/3000 [0m                     

                       Computation: 47380 steps/s (collection: 1.925s, learning 0.150s)
             Mean action noise std: 4.10
          Mean value_function loss: 82.9745
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 86.0036
                       Mean reward: 687.33
               Mean episode length: 226.29
    Episode_Reward/reaching_object: 1.4971
    Episode_Reward/rotating_object: 131.7889
        Episode_Reward/action_rate: -0.1114
          Episode_Reward/joint_vel: -0.0339
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.5833
--------------------------------------------------------------------------------
                   Total timesteps: 112459776
                    Iteration time: 2.07s
                      Time elapsed: 00:43:33
                               ETA: 01:10:41

################################################################################
                     [1m Learning iteration 1144/3000 [0m                     

                       Computation: 44611 steps/s (collection: 2.067s, learning 0.137s)
             Mean action noise std: 4.10
          Mean value_function loss: 76.0935
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 86.0290
                       Mean reward: 698.41
               Mean episode length: 228.36
    Episode_Reward/reaching_object: 1.5419
    Episode_Reward/rotating_object: 136.2915
        Episode_Reward/action_rate: -0.1144
          Episode_Reward/joint_vel: -0.0341
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 112558080
                    Iteration time: 2.20s
                      Time elapsed: 00:43:35
                               ETA: 01:10:39

################################################################################
                     [1m Learning iteration 1145/3000 [0m                     

                       Computation: 47648 steps/s (collection: 1.935s, learning 0.129s)
             Mean action noise std: 4.10
          Mean value_function loss: 66.4124
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 86.0549
                       Mean reward: 708.93
               Mean episode length: 233.30
    Episode_Reward/reaching_object: 1.5734
    Episode_Reward/rotating_object: 138.9517
        Episode_Reward/action_rate: -0.1174
          Episode_Reward/joint_vel: -0.0354
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 112656384
                    Iteration time: 2.06s
                      Time elapsed: 00:43:37
                               ETA: 01:10:36

################################################################################
                     [1m Learning iteration 1146/3000 [0m                     

                       Computation: 43469 steps/s (collection: 2.116s, learning 0.146s)
             Mean action noise std: 4.11
          Mean value_function loss: 62.1743
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 86.0823
                       Mean reward: 709.30
               Mean episode length: 233.87
    Episode_Reward/reaching_object: 1.5301
    Episode_Reward/rotating_object: 136.6192
        Episode_Reward/action_rate: -0.1142
          Episode_Reward/joint_vel: -0.0340
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 112754688
                    Iteration time: 2.26s
                      Time elapsed: 00:43:39
                               ETA: 01:10:34

################################################################################
                     [1m Learning iteration 1147/3000 [0m                     

                       Computation: 46954 steps/s (collection: 1.978s, learning 0.116s)
             Mean action noise std: 4.11
          Mean value_function loss: 58.7198
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 86.1043
                       Mean reward: 697.51
               Mean episode length: 233.63
    Episode_Reward/reaching_object: 1.5766
    Episode_Reward/rotating_object: 140.1128
        Episode_Reward/action_rate: -0.1175
          Episode_Reward/joint_vel: -0.0349
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 112852992
                    Iteration time: 2.09s
                      Time elapsed: 00:43:41
                               ETA: 01:10:31

################################################################################
                     [1m Learning iteration 1148/3000 [0m                     

                       Computation: 49929 steps/s (collection: 1.880s, learning 0.089s)
             Mean action noise std: 4.11
          Mean value_function loss: 72.0807
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 86.1214
                       Mean reward: 693.78
               Mean episode length: 229.82
    Episode_Reward/reaching_object: 1.5364
    Episode_Reward/rotating_object: 136.2027
        Episode_Reward/action_rate: -0.1149
          Episode_Reward/joint_vel: -0.0336
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 112951296
                    Iteration time: 1.97s
                      Time elapsed: 00:43:43
                               ETA: 01:10:28

################################################################################
                     [1m Learning iteration 1149/3000 [0m                     

                       Computation: 49965 steps/s (collection: 1.866s, learning 0.101s)
             Mean action noise std: 4.12
          Mean value_function loss: 70.1563
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 86.1479
                       Mean reward: 720.46
               Mean episode length: 237.33
    Episode_Reward/reaching_object: 1.5560
    Episode_Reward/rotating_object: 139.4455
        Episode_Reward/action_rate: -0.1164
          Episode_Reward/joint_vel: -0.0330
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 113049600
                    Iteration time: 1.97s
                      Time elapsed: 00:43:45
                               ETA: 01:10:26

################################################################################
                     [1m Learning iteration 1150/3000 [0m                     

                       Computation: 49744 steps/s (collection: 1.871s, learning 0.106s)
             Mean action noise std: 4.12
          Mean value_function loss: 68.7990
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 86.1705
                       Mean reward: 696.28
               Mean episode length: 232.26
    Episode_Reward/reaching_object: 1.5528
    Episode_Reward/rotating_object: 140.4969
        Episode_Reward/action_rate: -0.1164
          Episode_Reward/joint_vel: -0.0325
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 113147904
                    Iteration time: 1.98s
                      Time elapsed: 00:43:47
                               ETA: 01:10:23

################################################################################
                     [1m Learning iteration 1151/3000 [0m                     

                       Computation: 44068 steps/s (collection: 2.082s, learning 0.149s)
             Mean action noise std: 4.12
          Mean value_function loss: 64.3988
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 86.1970
                       Mean reward: 743.77
               Mean episode length: 244.13
    Episode_Reward/reaching_object: 1.5669
    Episode_Reward/rotating_object: 139.5013
        Episode_Reward/action_rate: -0.1174
          Episode_Reward/joint_vel: -0.0341
      Episode_Termination/time_out: 17.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 113246208
                    Iteration time: 2.23s
                      Time elapsed: 00:43:49
                               ETA: 01:10:20

################################################################################
                     [1m Learning iteration 1152/3000 [0m                     

                       Computation: 43563 steps/s (collection: 2.112s, learning 0.145s)
             Mean action noise std: 4.12
          Mean value_function loss: 65.2133
               Mean surrogate loss: -0.0001
                 Mean entropy loss: 86.2183
                       Mean reward: 732.08
               Mean episode length: 239.64
    Episode_Reward/reaching_object: 1.5605
    Episode_Reward/rotating_object: 138.8316
        Episode_Reward/action_rate: -0.1170
          Episode_Reward/joint_vel: -0.0342
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 113344512
                    Iteration time: 2.26s
                      Time elapsed: 00:43:52
                               ETA: 01:10:18

################################################################################
                     [1m Learning iteration 1153/3000 [0m                     

                       Computation: 48219 steps/s (collection: 1.913s, learning 0.126s)
             Mean action noise std: 4.13
          Mean value_function loss: 64.4014
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 86.2290
                       Mean reward: 659.86
               Mean episode length: 218.51
    Episode_Reward/reaching_object: 1.5372
    Episode_Reward/rotating_object: 136.4325
        Episode_Reward/action_rate: -0.1160
          Episode_Reward/joint_vel: -0.0349
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 113442816
                    Iteration time: 2.04s
                      Time elapsed: 00:43:54
                               ETA: 01:10:15

################################################################################
                     [1m Learning iteration 1154/3000 [0m                     

                       Computation: 48682 steps/s (collection: 1.874s, learning 0.145s)
             Mean action noise std: 4.13
          Mean value_function loss: 56.7265
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 86.2470
                       Mean reward: 728.46
               Mean episode length: 239.95
    Episode_Reward/reaching_object: 1.5729
    Episode_Reward/rotating_object: 140.2215
        Episode_Reward/action_rate: -0.1188
          Episode_Reward/joint_vel: -0.0342
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 113541120
                    Iteration time: 2.02s
                      Time elapsed: 00:43:56
                               ETA: 01:10:13

################################################################################
                     [1m Learning iteration 1155/3000 [0m                     

                       Computation: 48789 steps/s (collection: 1.884s, learning 0.131s)
             Mean action noise std: 4.13
          Mean value_function loss: 80.3387
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 86.2747
                       Mean reward: 702.17
               Mean episode length: 228.20
    Episode_Reward/reaching_object: 1.5089
    Episode_Reward/rotating_object: 135.8600
        Episode_Reward/action_rate: -0.1138
          Episode_Reward/joint_vel: -0.0322
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 113639424
                    Iteration time: 2.01s
                      Time elapsed: 00:43:58
                               ETA: 01:10:10

################################################################################
                     [1m Learning iteration 1156/3000 [0m                     

                       Computation: 42761 steps/s (collection: 2.062s, learning 0.236s)
             Mean action noise std: 4.14
          Mean value_function loss: 67.4068
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 86.3064
                       Mean reward: 747.35
               Mean episode length: 241.58
    Episode_Reward/reaching_object: 1.5529
    Episode_Reward/rotating_object: 138.8945
        Episode_Reward/action_rate: -0.1181
          Episode_Reward/joint_vel: -0.0342
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 113737728
                    Iteration time: 2.30s
                      Time elapsed: 00:44:00
                               ETA: 01:10:08

################################################################################
                     [1m Learning iteration 1157/3000 [0m                     

                       Computation: 42859 steps/s (collection: 2.180s, learning 0.114s)
             Mean action noise std: 4.14
          Mean value_function loss: 66.7757
               Mean surrogate loss: -0.0072
                 Mean entropy loss: 86.3297
                       Mean reward: 713.64
               Mean episode length: 237.63
    Episode_Reward/reaching_object: 1.5716
    Episode_Reward/rotating_object: 142.8779
        Episode_Reward/action_rate: -0.1196
          Episode_Reward/joint_vel: -0.0333
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 113836032
                    Iteration time: 2.29s
                      Time elapsed: 00:44:02
                               ETA: 01:10:05

################################################################################
                     [1m Learning iteration 1158/3000 [0m                     

                       Computation: 48327 steps/s (collection: 1.933s, learning 0.101s)
             Mean action noise std: 4.14
          Mean value_function loss: 69.1174
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 86.3479
                       Mean reward: 631.83
               Mean episode length: 218.89
    Episode_Reward/reaching_object: 1.5170
    Episode_Reward/rotating_object: 136.2539
        Episode_Reward/action_rate: -0.1166
          Episode_Reward/joint_vel: -0.0350
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 113934336
                    Iteration time: 2.03s
                      Time elapsed: 00:44:04
                               ETA: 01:10:03

################################################################################
                     [1m Learning iteration 1159/3000 [0m                     

                       Computation: 49014 steps/s (collection: 1.885s, learning 0.121s)
             Mean action noise std: 4.15
          Mean value_function loss: 69.8444
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 86.3669
                       Mean reward: 712.66
               Mean episode length: 235.22
    Episode_Reward/reaching_object: 1.5597
    Episode_Reward/rotating_object: 140.3752
        Episode_Reward/action_rate: -0.1199
          Episode_Reward/joint_vel: -0.0344
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 114032640
                    Iteration time: 2.01s
                      Time elapsed: 00:44:06
                               ETA: 01:10:00

################################################################################
                     [1m Learning iteration 1160/3000 [0m                     

                       Computation: 48079 steps/s (collection: 1.896s, learning 0.149s)
             Mean action noise std: 4.15
          Mean value_function loss: 74.2778
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 86.3844
                       Mean reward: 678.82
               Mean episode length: 225.14
    Episode_Reward/reaching_object: 1.5000
    Episode_Reward/rotating_object: 134.5403
        Episode_Reward/action_rate: -0.1154
          Episode_Reward/joint_vel: -0.0337
      Episode_Termination/time_out: 14.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 114130944
                    Iteration time: 2.04s
                      Time elapsed: 00:44:08
                               ETA: 01:09:57

################################################################################
                     [1m Learning iteration 1161/3000 [0m                     

                       Computation: 44560 steps/s (collection: 2.089s, learning 0.118s)
             Mean action noise std: 4.15
          Mean value_function loss: 68.6357
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 86.4065
                       Mean reward: 645.58
               Mean episode length: 225.19
    Episode_Reward/reaching_object: 1.5202
    Episode_Reward/rotating_object: 137.3201
        Episode_Reward/action_rate: -0.1177
          Episode_Reward/joint_vel: -0.0342
      Episode_Termination/time_out: 16.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 114229248
                    Iteration time: 2.21s
                      Time elapsed: 00:44:10
                               ETA: 01:09:55

################################################################################
                     [1m Learning iteration 1162/3000 [0m                     

                       Computation: 49414 steps/s (collection: 1.893s, learning 0.097s)
             Mean action noise std: 4.16
          Mean value_function loss: 68.0518
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 86.4265
                       Mean reward: 688.04
               Mean episode length: 229.60
    Episode_Reward/reaching_object: 1.5346
    Episode_Reward/rotating_object: 138.4548
        Episode_Reward/action_rate: -0.1191
          Episode_Reward/joint_vel: -0.0352
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 114327552
                    Iteration time: 1.99s
                      Time elapsed: 00:44:12
                               ETA: 01:09:52

################################################################################
                     [1m Learning iteration 1163/3000 [0m                     

                       Computation: 49236 steps/s (collection: 1.891s, learning 0.105s)
             Mean action noise std: 4.16
          Mean value_function loss: 72.4073
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 86.4480
                       Mean reward: 729.99
               Mean episode length: 237.60
    Episode_Reward/reaching_object: 1.5162
    Episode_Reward/rotating_object: 137.2528
        Episode_Reward/action_rate: -0.1178
          Episode_Reward/joint_vel: -0.0338
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 114425856
                    Iteration time: 2.00s
                      Time elapsed: 00:44:14
                               ETA: 01:09:50

################################################################################
                     [1m Learning iteration 1164/3000 [0m                     

                       Computation: 45460 steps/s (collection: 2.024s, learning 0.138s)
             Mean action noise std: 4.16
          Mean value_function loss: 63.9848
               Mean surrogate loss: 0.0149
                 Mean entropy loss: 86.4671
                       Mean reward: 729.49
               Mean episode length: 239.45
    Episode_Reward/reaching_object: 1.5615
    Episode_Reward/rotating_object: 141.7433
        Episode_Reward/action_rate: -0.1214
          Episode_Reward/joint_vel: -0.0340
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 114524160
                    Iteration time: 2.16s
                      Time elapsed: 00:44:17
                               ETA: 01:09:47

################################################################################
                     [1m Learning iteration 1165/3000 [0m                     

                       Computation: 47747 steps/s (collection: 1.903s, learning 0.156s)
             Mean action noise std: 4.16
          Mean value_function loss: 68.5789
               Mean surrogate loss: 0.0004
                 Mean entropy loss: 86.4693
                       Mean reward: 714.45
               Mean episode length: 236.94
    Episode_Reward/reaching_object: 1.5501
    Episode_Reward/rotating_object: 140.5149
        Episode_Reward/action_rate: -0.1199
          Episode_Reward/joint_vel: -0.0331
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 114622464
                    Iteration time: 2.06s
                      Time elapsed: 00:44:19
                               ETA: 01:09:44

################################################################################
                     [1m Learning iteration 1166/3000 [0m                     

                       Computation: 45702 steps/s (collection: 2.031s, learning 0.120s)
             Mean action noise std: 4.16
          Mean value_function loss: 62.2705
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 86.4730
                       Mean reward: 693.22
               Mean episode length: 230.39
    Episode_Reward/reaching_object: 1.5210
    Episode_Reward/rotating_object: 138.6480
        Episode_Reward/action_rate: -0.1190
          Episode_Reward/joint_vel: -0.0330
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 114720768
                    Iteration time: 2.15s
                      Time elapsed: 00:44:21
                               ETA: 01:09:42

################################################################################
                     [1m Learning iteration 1167/3000 [0m                     

                       Computation: 48312 steps/s (collection: 1.867s, learning 0.168s)
             Mean action noise std: 4.16
          Mean value_function loss: 63.8057
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 86.4860
                       Mean reward: 707.35
               Mean episode length: 237.08
    Episode_Reward/reaching_object: 1.5379
    Episode_Reward/rotating_object: 140.2775
        Episode_Reward/action_rate: -0.1203
          Episode_Reward/joint_vel: -0.0335
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 114819072
                    Iteration time: 2.03s
                      Time elapsed: 00:44:23
                               ETA: 01:09:39

################################################################################
                     [1m Learning iteration 1168/3000 [0m                     

                       Computation: 47349 steps/s (collection: 1.903s, learning 0.173s)
             Mean action noise std: 4.17
          Mean value_function loss: 66.4730
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 86.5096
                       Mean reward: 675.20
               Mean episode length: 220.95
    Episode_Reward/reaching_object: 1.5226
    Episode_Reward/rotating_object: 136.2434
        Episode_Reward/action_rate: -0.1192
          Episode_Reward/joint_vel: -0.0337
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 114917376
                    Iteration time: 2.08s
                      Time elapsed: 00:44:25
                               ETA: 01:09:37

################################################################################
                     [1m Learning iteration 1169/3000 [0m                     

                       Computation: 48207 steps/s (collection: 1.948s, learning 0.092s)
             Mean action noise std: 4.17
          Mean value_function loss: 73.8474
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 86.5414
                       Mean reward: 700.86
               Mean episode length: 232.52
    Episode_Reward/reaching_object: 1.5105
    Episode_Reward/rotating_object: 136.9067
        Episode_Reward/action_rate: -0.1185
          Episode_Reward/joint_vel: -0.0331
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 115015680
                    Iteration time: 2.04s
                      Time elapsed: 00:44:27
                               ETA: 01:09:34

################################################################################
                     [1m Learning iteration 1170/3000 [0m                     

                       Computation: 46442 steps/s (collection: 1.956s, learning 0.161s)
             Mean action noise std: 4.17
          Mean value_function loss: 64.0467
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 86.5693
                       Mean reward: 711.29
               Mean episode length: 233.47
    Episode_Reward/reaching_object: 1.5338
    Episode_Reward/rotating_object: 139.8367
        Episode_Reward/action_rate: -0.1204
          Episode_Reward/joint_vel: -0.0331
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 115113984
                    Iteration time: 2.12s
                      Time elapsed: 00:44:29
                               ETA: 01:09:31

################################################################################
                     [1m Learning iteration 1171/3000 [0m                     

                       Computation: 43943 steps/s (collection: 2.120s, learning 0.117s)
             Mean action noise std: 4.18
          Mean value_function loss: 67.0485
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 86.5891
                       Mean reward: 716.01
               Mean episode length: 239.90
    Episode_Reward/reaching_object: 1.5373
    Episode_Reward/rotating_object: 138.8096
        Episode_Reward/action_rate: -0.1211
          Episode_Reward/joint_vel: -0.0335
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 115212288
                    Iteration time: 2.24s
                      Time elapsed: 00:44:31
                               ETA: 01:09:29

################################################################################
                     [1m Learning iteration 1172/3000 [0m                     

                       Computation: 50006 steps/s (collection: 1.865s, learning 0.101s)
             Mean action noise std: 4.18
          Mean value_function loss: 73.2401
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 86.6128
                       Mean reward: 710.62
               Mean episode length: 232.57
    Episode_Reward/reaching_object: 1.5394
    Episode_Reward/rotating_object: 141.6728
        Episode_Reward/action_rate: -0.1214
          Episode_Reward/joint_vel: -0.0323
      Episode_Termination/time_out: 17.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 115310592
                    Iteration time: 1.97s
                      Time elapsed: 00:44:33
                               ETA: 01:09:26

################################################################################
                     [1m Learning iteration 1173/3000 [0m                     

                       Computation: 48784 steps/s (collection: 1.892s, learning 0.123s)
             Mean action noise std: 4.18
          Mean value_function loss: 61.0810
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 86.6365
                       Mean reward: 714.61
               Mean episode length: 233.91
    Episode_Reward/reaching_object: 1.5654
    Episode_Reward/rotating_object: 141.7403
        Episode_Reward/action_rate: -0.1232
          Episode_Reward/joint_vel: -0.0337
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 115408896
                    Iteration time: 2.02s
                      Time elapsed: 00:44:35
                               ETA: 01:09:24

################################################################################
                     [1m Learning iteration 1174/3000 [0m                     

                       Computation: 48857 steps/s (collection: 1.890s, learning 0.122s)
             Mean action noise std: 4.19
          Mean value_function loss: 63.5778
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 86.6507
                       Mean reward: 720.11
               Mean episode length: 239.47
    Episode_Reward/reaching_object: 1.5325
    Episode_Reward/rotating_object: 136.9822
        Episode_Reward/action_rate: -0.1210
          Episode_Reward/joint_vel: -0.0341
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 115507200
                    Iteration time: 2.01s
                      Time elapsed: 00:44:37
                               ETA: 01:09:21

################################################################################
                     [1m Learning iteration 1175/3000 [0m                     

                       Computation: 49380 steps/s (collection: 1.876s, learning 0.115s)
             Mean action noise std: 4.19
          Mean value_function loss: 57.1636
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 86.6626
                       Mean reward: 693.23
               Mean episode length: 232.54
    Episode_Reward/reaching_object: 1.4871
    Episode_Reward/rotating_object: 135.6612
        Episode_Reward/action_rate: -0.1182
          Episode_Reward/joint_vel: -0.0329
      Episode_Termination/time_out: 14.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 115605504
                    Iteration time: 1.99s
                      Time elapsed: 00:44:39
                               ETA: 01:09:18

################################################################################
                     [1m Learning iteration 1176/3000 [0m                     

                       Computation: 48327 steps/s (collection: 1.921s, learning 0.114s)
             Mean action noise std: 4.19
          Mean value_function loss: 61.4041
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 86.6749
                       Mean reward: 677.09
               Mean episode length: 227.80
    Episode_Reward/reaching_object: 1.5533
    Episode_Reward/rotating_object: 142.3077
        Episode_Reward/action_rate: -0.1230
          Episode_Reward/joint_vel: -0.0325
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 115703808
                    Iteration time: 2.03s
                      Time elapsed: 00:44:41
                               ETA: 01:09:16

################################################################################
                     [1m Learning iteration 1177/3000 [0m                     

                       Computation: 50100 steps/s (collection: 1.843s, learning 0.120s)
             Mean action noise std: 4.19
          Mean value_function loss: 72.2025
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 86.6862
                       Mean reward: 707.40
               Mean episode length: 234.54
    Episode_Reward/reaching_object: 1.5354
    Episode_Reward/rotating_object: 138.4596
        Episode_Reward/action_rate: -0.1204
          Episode_Reward/joint_vel: -0.0328
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 115802112
                    Iteration time: 1.96s
                      Time elapsed: 00:44:43
                               ETA: 01:09:13

################################################################################
                     [1m Learning iteration 1178/3000 [0m                     

                       Computation: 48010 steps/s (collection: 1.933s, learning 0.115s)
             Mean action noise std: 4.20
          Mean value_function loss: 60.6174
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 86.7082
                       Mean reward: 698.50
               Mean episode length: 226.53
    Episode_Reward/reaching_object: 1.5448
    Episode_Reward/rotating_object: 141.4974
        Episode_Reward/action_rate: -0.1211
          Episode_Reward/joint_vel: -0.0319
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 115900416
                    Iteration time: 2.05s
                      Time elapsed: 00:44:45
                               ETA: 01:09:10

################################################################################
                     [1m Learning iteration 1179/3000 [0m                     

                       Computation: 49624 steps/s (collection: 1.868s, learning 0.113s)
             Mean action noise std: 4.20
          Mean value_function loss: 77.6866
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 86.7278
                       Mean reward: 659.36
               Mean episode length: 223.80
    Episode_Reward/reaching_object: 1.5371
    Episode_Reward/rotating_object: 137.8642
        Episode_Reward/action_rate: -0.1210
          Episode_Reward/joint_vel: -0.0330
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 115998720
                    Iteration time: 1.98s
                      Time elapsed: 00:44:47
                               ETA: 01:09:07

################################################################################
                     [1m Learning iteration 1180/3000 [0m                     

                       Computation: 48706 steps/s (collection: 1.890s, learning 0.128s)
             Mean action noise std: 4.20
          Mean value_function loss: 64.7902
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 86.7462
                       Mean reward: 697.72
               Mean episode length: 233.18
    Episode_Reward/reaching_object: 1.5401
    Episode_Reward/rotating_object: 137.9989
        Episode_Reward/action_rate: -0.1209
          Episode_Reward/joint_vel: -0.0333
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 116097024
                    Iteration time: 2.02s
                      Time elapsed: 00:44:49
                               ETA: 01:09:05

################################################################################
                     [1m Learning iteration 1181/3000 [0m                     

                       Computation: 48081 steps/s (collection: 1.934s, learning 0.111s)
             Mean action noise std: 4.20
          Mean value_function loss: 67.0525
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 86.7705
                       Mean reward: 693.81
               Mean episode length: 233.95
    Episode_Reward/reaching_object: 1.5580
    Episode_Reward/rotating_object: 138.7912
        Episode_Reward/action_rate: -0.1210
          Episode_Reward/joint_vel: -0.0328
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 116195328
                    Iteration time: 2.04s
                      Time elapsed: 00:44:51
                               ETA: 01:09:02

################################################################################
                     [1m Learning iteration 1182/3000 [0m                     

                       Computation: 48679 steps/s (collection: 1.905s, learning 0.115s)
             Mean action noise std: 4.21
          Mean value_function loss: 67.4653
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 86.7818
                       Mean reward: 720.27
               Mean episode length: 233.57
    Episode_Reward/reaching_object: 1.5929
    Episode_Reward/rotating_object: 141.8054
        Episode_Reward/action_rate: -0.1234
          Episode_Reward/joint_vel: -0.0337
      Episode_Termination/time_out: 17.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 116293632
                    Iteration time: 2.02s
                      Time elapsed: 00:44:53
                               ETA: 01:08:59

################################################################################
                     [1m Learning iteration 1183/3000 [0m                     

                       Computation: 48396 steps/s (collection: 1.915s, learning 0.116s)
             Mean action noise std: 4.21
          Mean value_function loss: 71.9893
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 86.7928
                       Mean reward: 664.38
               Mean episode length: 225.01
    Episode_Reward/reaching_object: 1.5809
    Episode_Reward/rotating_object: 141.5511
        Episode_Reward/action_rate: -0.1225
          Episode_Reward/joint_vel: -0.0325
      Episode_Termination/time_out: 17.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 116391936
                    Iteration time: 2.03s
                      Time elapsed: 00:44:55
                               ETA: 01:08:57

################################################################################
                     [1m Learning iteration 1184/3000 [0m                     

                       Computation: 49666 steps/s (collection: 1.867s, learning 0.112s)
             Mean action noise std: 4.21
          Mean value_function loss: 67.8635
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 86.8113
                       Mean reward: 725.94
               Mean episode length: 233.98
    Episode_Reward/reaching_object: 1.5625
    Episode_Reward/rotating_object: 138.4605
        Episode_Reward/action_rate: -0.1214
          Episode_Reward/joint_vel: -0.0325
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 116490240
                    Iteration time: 1.98s
                      Time elapsed: 00:44:57
                               ETA: 01:08:54

################################################################################
                     [1m Learning iteration 1185/3000 [0m                     

                       Computation: 49512 steps/s (collection: 1.862s, learning 0.123s)
             Mean action noise std: 4.22
          Mean value_function loss: 60.5759
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 86.8358
                       Mean reward: 703.12
               Mean episode length: 228.38
    Episode_Reward/reaching_object: 1.5156
    Episode_Reward/rotating_object: 135.2734
        Episode_Reward/action_rate: -0.1189
          Episode_Reward/joint_vel: -0.0326
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0833
--------------------------------------------------------------------------------
                   Total timesteps: 116588544
                    Iteration time: 1.99s
                      Time elapsed: 00:44:59
                               ETA: 01:08:51

################################################################################
                     [1m Learning iteration 1186/3000 [0m                     

                       Computation: 48434 steps/s (collection: 1.917s, learning 0.113s)
             Mean action noise std: 4.22
          Mean value_function loss: 59.2055
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 86.8597
                       Mean reward: 714.10
               Mean episode length: 237.87
    Episode_Reward/reaching_object: 1.5604
    Episode_Reward/rotating_object: 138.6326
        Episode_Reward/action_rate: -0.1218
          Episode_Reward/joint_vel: -0.0333
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 116686848
                    Iteration time: 2.03s
                      Time elapsed: 00:45:01
                               ETA: 01:08:49

################################################################################
                     [1m Learning iteration 1187/3000 [0m                     

                       Computation: 50693 steps/s (collection: 1.835s, learning 0.105s)
             Mean action noise std: 4.22
          Mean value_function loss: 62.3351
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 86.8805
                       Mean reward: 719.38
               Mean episode length: 234.82
    Episode_Reward/reaching_object: 1.5822
    Episode_Reward/rotating_object: 143.9415
        Episode_Reward/action_rate: -0.1238
          Episode_Reward/joint_vel: -0.0325
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 116785152
                    Iteration time: 1.94s
                      Time elapsed: 00:45:03
                               ETA: 01:08:46

################################################################################
                     [1m Learning iteration 1188/3000 [0m                     

                       Computation: 50142 steps/s (collection: 1.850s, learning 0.111s)
             Mean action noise std: 4.22
          Mean value_function loss: 71.0294
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 86.9008
                       Mean reward: 673.21
               Mean episode length: 224.55
    Episode_Reward/reaching_object: 1.5224
    Episode_Reward/rotating_object: 138.3651
        Episode_Reward/action_rate: -0.1208
          Episode_Reward/joint_vel: -0.0320
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 116883456
                    Iteration time: 1.96s
                      Time elapsed: 00:45:05
                               ETA: 01:08:43

################################################################################
                     [1m Learning iteration 1189/3000 [0m                     

                       Computation: 50471 steps/s (collection: 1.837s, learning 0.111s)
             Mean action noise std: 4.23
          Mean value_function loss: 64.0059
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 86.9107
                       Mean reward: 695.73
               Mean episode length: 230.98
    Episode_Reward/reaching_object: 1.5408
    Episode_Reward/rotating_object: 139.7186
        Episode_Reward/action_rate: -0.1216
          Episode_Reward/joint_vel: -0.0321
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 116981760
                    Iteration time: 1.95s
                      Time elapsed: 00:45:07
                               ETA: 01:08:40

################################################################################
                     [1m Learning iteration 1190/3000 [0m                     

                       Computation: 49323 steps/s (collection: 1.867s, learning 0.126s)
             Mean action noise std: 4.23
          Mean value_function loss: 68.6167
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 86.9277
                       Mean reward: 718.92
               Mean episode length: 234.12
    Episode_Reward/reaching_object: 1.5419
    Episode_Reward/rotating_object: 139.4107
        Episode_Reward/action_rate: -0.1217
          Episode_Reward/joint_vel: -0.0323
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 117080064
                    Iteration time: 1.99s
                      Time elapsed: 00:45:09
                               ETA: 01:08:38

################################################################################
                     [1m Learning iteration 1191/3000 [0m                     

                       Computation: 50237 steps/s (collection: 1.836s, learning 0.121s)
             Mean action noise std: 4.23
          Mean value_function loss: 61.5811
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 86.9439
                       Mean reward: 695.99
               Mean episode length: 229.20
    Episode_Reward/reaching_object: 1.5105
    Episode_Reward/rotating_object: 137.3791
        Episode_Reward/action_rate: -0.1205
          Episode_Reward/joint_vel: -0.0326
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 117178368
                    Iteration time: 1.96s
                      Time elapsed: 00:45:11
                               ETA: 01:08:35

################################################################################
                     [1m Learning iteration 1192/3000 [0m                     

                       Computation: 50551 steps/s (collection: 1.827s, learning 0.117s)
             Mean action noise std: 4.23
          Mean value_function loss: 62.8787
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 86.9517
                       Mean reward: 703.89
               Mean episode length: 228.77
    Episode_Reward/reaching_object: 1.5585
    Episode_Reward/rotating_object: 142.6456
        Episode_Reward/action_rate: -0.1231
          Episode_Reward/joint_vel: -0.0314
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 117276672
                    Iteration time: 1.94s
                      Time elapsed: 00:45:13
                               ETA: 01:08:32

################################################################################
                     [1m Learning iteration 1193/3000 [0m                     

                       Computation: 50103 steps/s (collection: 1.845s, learning 0.117s)
             Mean action noise std: 4.23
          Mean value_function loss: 71.3567
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 86.9654
                       Mean reward: 725.09
               Mean episode length: 234.58
    Episode_Reward/reaching_object: 1.5739
    Episode_Reward/rotating_object: 144.0136
        Episode_Reward/action_rate: -0.1248
          Episode_Reward/joint_vel: -0.0318
      Episode_Termination/time_out: 17.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 117374976
                    Iteration time: 1.96s
                      Time elapsed: 00:45:15
                               ETA: 01:08:29

################################################################################
                     [1m Learning iteration 1194/3000 [0m                     

                       Computation: 49022 steps/s (collection: 1.893s, learning 0.113s)
             Mean action noise std: 4.24
          Mean value_function loss: 62.8296
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 86.9879
                       Mean reward: 753.33
               Mean episode length: 241.21
    Episode_Reward/reaching_object: 1.5889
    Episode_Reward/rotating_object: 145.5961
        Episode_Reward/action_rate: -0.1255
          Episode_Reward/joint_vel: -0.0317
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 117473280
                    Iteration time: 2.01s
                      Time elapsed: 00:45:17
                               ETA: 01:08:27

################################################################################
                     [1m Learning iteration 1195/3000 [0m                     

                       Computation: 49637 steps/s (collection: 1.863s, learning 0.117s)
             Mean action noise std: 4.24
          Mean value_function loss: 59.4608
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 87.0018
                       Mean reward: 712.13
               Mean episode length: 234.27
    Episode_Reward/reaching_object: 1.5567
    Episode_Reward/rotating_object: 140.4548
        Episode_Reward/action_rate: -0.1238
          Episode_Reward/joint_vel: -0.0330
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 117571584
                    Iteration time: 1.98s
                      Time elapsed: 00:45:19
                               ETA: 01:08:24

################################################################################
                     [1m Learning iteration 1196/3000 [0m                     

                       Computation: 49041 steps/s (collection: 1.884s, learning 0.120s)
             Mean action noise std: 4.24
          Mean value_function loss: 60.2288
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 87.0163
                       Mean reward: 712.85
               Mean episode length: 235.44
    Episode_Reward/reaching_object: 1.5638
    Episode_Reward/rotating_object: 141.4700
        Episode_Reward/action_rate: -0.1245
          Episode_Reward/joint_vel: -0.0329
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 117669888
                    Iteration time: 2.00s
                      Time elapsed: 00:45:21
                               ETA: 01:08:21

################################################################################
                     [1m Learning iteration 1197/3000 [0m                     

                       Computation: 50093 steps/s (collection: 1.851s, learning 0.112s)
             Mean action noise std: 4.24
          Mean value_function loss: 61.4688
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 87.0344
                       Mean reward: 696.10
               Mean episode length: 231.37
    Episode_Reward/reaching_object: 1.5511
    Episode_Reward/rotating_object: 141.1479
        Episode_Reward/action_rate: -0.1238
          Episode_Reward/joint_vel: -0.0323
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 117768192
                    Iteration time: 1.96s
                      Time elapsed: 00:45:23
                               ETA: 01:08:19

################################################################################
                     [1m Learning iteration 1198/3000 [0m                     

                       Computation: 50854 steps/s (collection: 1.821s, learning 0.113s)
             Mean action noise std: 4.25
          Mean value_function loss: 62.5093
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 87.0541
                       Mean reward: 718.22
               Mean episode length: 231.58
    Episode_Reward/reaching_object: 1.5449
    Episode_Reward/rotating_object: 141.3463
        Episode_Reward/action_rate: -0.1236
          Episode_Reward/joint_vel: -0.0324
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 117866496
                    Iteration time: 1.93s
                      Time elapsed: 00:45:25
                               ETA: 01:08:16

################################################################################
                     [1m Learning iteration 1199/3000 [0m                     

                       Computation: 50702 steps/s (collection: 1.833s, learning 0.106s)
             Mean action noise std: 4.25
          Mean value_function loss: 72.5623
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 87.0756
                       Mean reward: 694.39
               Mean episode length: 226.49
    Episode_Reward/reaching_object: 1.5368
    Episode_Reward/rotating_object: 139.5381
        Episode_Reward/action_rate: -0.1227
          Episode_Reward/joint_vel: -0.0323
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 117964800
                    Iteration time: 1.94s
                      Time elapsed: 00:45:27
                               ETA: 01:08:13

################################################################################
                     [1m Learning iteration 1200/3000 [0m                     

                       Computation: 50951 steps/s (collection: 1.828s, learning 0.101s)
             Mean action noise std: 4.25
          Mean value_function loss: 58.6293
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 87.0924
                       Mean reward: 693.58
               Mean episode length: 231.61
    Episode_Reward/reaching_object: 1.5517
    Episode_Reward/rotating_object: 141.8403
        Episode_Reward/action_rate: -0.1249
          Episode_Reward/joint_vel: -0.0336
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 118063104
                    Iteration time: 1.93s
                      Time elapsed: 00:45:29
                               ETA: 01:08:10

################################################################################
                     [1m Learning iteration 1201/3000 [0m                     

                       Computation: 49893 steps/s (collection: 1.870s, learning 0.100s)
             Mean action noise std: 4.26
          Mean value_function loss: 66.4113
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 87.1133
                       Mean reward: 723.88
               Mean episode length: 235.31
    Episode_Reward/reaching_object: 1.5781
    Episode_Reward/rotating_object: 145.0933
        Episode_Reward/action_rate: -0.1264
          Episode_Reward/joint_vel: -0.0329
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 118161408
                    Iteration time: 1.97s
                      Time elapsed: 00:45:31
                               ETA: 01:08:08

################################################################################
                     [1m Learning iteration 1202/3000 [0m                     

                       Computation: 49984 steps/s (collection: 1.855s, learning 0.112s)
             Mean action noise std: 4.26
          Mean value_function loss: 65.3699
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 87.1356
                       Mean reward: 684.32
               Mean episode length: 224.24
    Episode_Reward/reaching_object: 1.5376
    Episode_Reward/rotating_object: 139.6567
        Episode_Reward/action_rate: -0.1244
          Episode_Reward/joint_vel: -0.0338
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 118259712
                    Iteration time: 1.97s
                      Time elapsed: 00:45:33
                               ETA: 01:08:05

################################################################################
                     [1m Learning iteration 1203/3000 [0m                     

                       Computation: 49533 steps/s (collection: 1.852s, learning 0.133s)
             Mean action noise std: 4.26
          Mean value_function loss: 61.9995
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 87.1610
                       Mean reward: 685.41
               Mean episode length: 226.72
    Episode_Reward/reaching_object: 1.5566
    Episode_Reward/rotating_object: 141.3258
        Episode_Reward/action_rate: -0.1257
          Episode_Reward/joint_vel: -0.0330
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 118358016
                    Iteration time: 1.98s
                      Time elapsed: 00:45:35
                               ETA: 01:08:02

################################################################################
                     [1m Learning iteration 1204/3000 [0m                     

                       Computation: 49941 steps/s (collection: 1.843s, learning 0.125s)
             Mean action noise std: 4.27
          Mean value_function loss: 57.8937
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 87.1885
                       Mean reward: 672.55
               Mean episode length: 224.34
    Episode_Reward/reaching_object: 1.5525
    Episode_Reward/rotating_object: 140.7510
        Episode_Reward/action_rate: -0.1249
          Episode_Reward/joint_vel: -0.0335
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 118456320
                    Iteration time: 1.97s
                      Time elapsed: 00:45:37
                               ETA: 01:07:59

################################################################################
                     [1m Learning iteration 1205/3000 [0m                     

                       Computation: 49842 steps/s (collection: 1.849s, learning 0.123s)
             Mean action noise std: 4.27
          Mean value_function loss: 67.8018
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 87.2148
                       Mean reward: 731.59
               Mean episode length: 236.80
    Episode_Reward/reaching_object: 1.5839
    Episode_Reward/rotating_object: 144.8194
        Episode_Reward/action_rate: -0.1272
          Episode_Reward/joint_vel: -0.0322
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 118554624
                    Iteration time: 1.97s
                      Time elapsed: 00:45:39
                               ETA: 01:07:57

################################################################################
                     [1m Learning iteration 1206/3000 [0m                     

                       Computation: 50074 steps/s (collection: 1.849s, learning 0.114s)
             Mean action noise std: 4.27
          Mean value_function loss: 62.7149
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 87.2427
                       Mean reward: 704.73
               Mean episode length: 230.63
    Episode_Reward/reaching_object: 1.5306
    Episode_Reward/rotating_object: 139.8190
        Episode_Reward/action_rate: -0.1244
          Episode_Reward/joint_vel: -0.0334
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 118652928
                    Iteration time: 1.96s
                      Time elapsed: 00:45:41
                               ETA: 01:07:54

################################################################################
                     [1m Learning iteration 1207/3000 [0m                     

                       Computation: 50046 steps/s (collection: 1.851s, learning 0.114s)
             Mean action noise std: 4.28
          Mean value_function loss: 55.6461
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 87.2629
                       Mean reward: 710.33
               Mean episode length: 228.03
    Episode_Reward/reaching_object: 1.5524
    Episode_Reward/rotating_object: 143.0598
        Episode_Reward/action_rate: -0.1270
          Episode_Reward/joint_vel: -0.0338
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 118751232
                    Iteration time: 1.96s
                      Time elapsed: 00:45:43
                               ETA: 01:07:51

################################################################################
                     [1m Learning iteration 1208/3000 [0m                     

                       Computation: 49560 steps/s (collection: 1.869s, learning 0.115s)
             Mean action noise std: 4.28
          Mean value_function loss: 61.3030
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 87.2754
                       Mean reward: 692.60
               Mean episode length: 225.35
    Episode_Reward/reaching_object: 1.5250
    Episode_Reward/rotating_object: 138.3969
        Episode_Reward/action_rate: -0.1245
          Episode_Reward/joint_vel: -0.0344
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 118849536
                    Iteration time: 1.98s
                      Time elapsed: 00:45:45
                               ETA: 01:07:48

################################################################################
                     [1m Learning iteration 1209/3000 [0m                     

                       Computation: 50715 steps/s (collection: 1.825s, learning 0.113s)
             Mean action noise std: 4.28
          Mean value_function loss: 64.5855
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 87.2943
                       Mean reward: 721.15
               Mean episode length: 234.84
    Episode_Reward/reaching_object: 1.5452
    Episode_Reward/rotating_object: 142.3349
        Episode_Reward/action_rate: -0.1266
          Episode_Reward/joint_vel: -0.0335
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 118947840
                    Iteration time: 1.94s
                      Time elapsed: 00:45:47
                               ETA: 01:07:46

################################################################################
                     [1m Learning iteration 1210/3000 [0m                     

                       Computation: 50453 steps/s (collection: 1.838s, learning 0.111s)
             Mean action noise std: 4.29
          Mean value_function loss: 57.2817
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 87.3149
                       Mean reward: 744.49
               Mean episode length: 238.19
    Episode_Reward/reaching_object: 1.5222
    Episode_Reward/rotating_object: 142.3424
        Episode_Reward/action_rate: -0.1261
          Episode_Reward/joint_vel: -0.0321
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 119046144
                    Iteration time: 1.95s
                      Time elapsed: 00:45:49
                               ETA: 01:07:43

################################################################################
                     [1m Learning iteration 1211/3000 [0m                     

                       Computation: 49515 steps/s (collection: 1.879s, learning 0.106s)
             Mean action noise std: 4.29
          Mean value_function loss: 67.0239
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 87.3311
                       Mean reward: 698.21
               Mean episode length: 227.96
    Episode_Reward/reaching_object: 1.5345
    Episode_Reward/rotating_object: 142.5896
        Episode_Reward/action_rate: -0.1263
          Episode_Reward/joint_vel: -0.0323
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 119144448
                    Iteration time: 1.99s
                      Time elapsed: 00:45:51
                               ETA: 01:07:40

################################################################################
                     [1m Learning iteration 1212/3000 [0m                     

                       Computation: 50027 steps/s (collection: 1.860s, learning 0.105s)
             Mean action noise std: 4.29
          Mean value_function loss: 66.8228
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 87.3512
                       Mean reward: 681.30
               Mean episode length: 229.18
    Episode_Reward/reaching_object: 1.5504
    Episode_Reward/rotating_object: 140.2907
        Episode_Reward/action_rate: -0.1280
          Episode_Reward/joint_vel: -0.0345
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 119242752
                    Iteration time: 1.96s
                      Time elapsed: 00:45:53
                               ETA: 01:07:38

################################################################################
                     [1m Learning iteration 1213/3000 [0m                     

                       Computation: 50372 steps/s (collection: 1.843s, learning 0.109s)
             Mean action noise std: 4.29
          Mean value_function loss: 61.1511
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 87.3729
                       Mean reward: 731.23
               Mean episode length: 238.69
    Episode_Reward/reaching_object: 1.5273
    Episode_Reward/rotating_object: 139.9769
        Episode_Reward/action_rate: -0.1265
          Episode_Reward/joint_vel: -0.0345
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 119341056
                    Iteration time: 1.95s
                      Time elapsed: 00:45:54
                               ETA: 01:07:35

################################################################################
                     [1m Learning iteration 1214/3000 [0m                     

                       Computation: 49975 steps/s (collection: 1.844s, learning 0.123s)
             Mean action noise std: 4.30
          Mean value_function loss: 68.9973
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 87.3803
                       Mean reward: 716.28
               Mean episode length: 235.59
    Episode_Reward/reaching_object: 1.5760
    Episode_Reward/rotating_object: 143.8219
        Episode_Reward/action_rate: -0.1295
          Episode_Reward/joint_vel: -0.0338
      Episode_Termination/time_out: 17.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 119439360
                    Iteration time: 1.97s
                      Time elapsed: 00:45:56
                               ETA: 01:07:32

################################################################################
                     [1m Learning iteration 1215/3000 [0m                     

                       Computation: 49733 steps/s (collection: 1.854s, learning 0.123s)
             Mean action noise std: 4.30
          Mean value_function loss: 67.0119
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 87.3899
                       Mean reward: 689.66
               Mean episode length: 228.22
    Episode_Reward/reaching_object: 1.5370
    Episode_Reward/rotating_object: 139.5339
        Episode_Reward/action_rate: -0.1261
          Episode_Reward/joint_vel: -0.0333
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8333
--------------------------------------------------------------------------------
                   Total timesteps: 119537664
                    Iteration time: 1.98s
                      Time elapsed: 00:45:58
                               ETA: 01:07:29

################################################################################
                     [1m Learning iteration 1216/3000 [0m                     

                       Computation: 48099 steps/s (collection: 1.921s, learning 0.123s)
             Mean action noise std: 4.30
          Mean value_function loss: 65.4670
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 87.4120
                       Mean reward: 724.35
               Mean episode length: 235.64
    Episode_Reward/reaching_object: 1.5460
    Episode_Reward/rotating_object: 141.1783
        Episode_Reward/action_rate: -0.1272
          Episode_Reward/joint_vel: -0.0333
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 119635968
                    Iteration time: 2.04s
                      Time elapsed: 00:46:00
                               ETA: 01:07:27

################################################################################
                     [1m Learning iteration 1217/3000 [0m                     

                       Computation: 48851 steps/s (collection: 1.891s, learning 0.121s)
             Mean action noise std: 4.31
          Mean value_function loss: 58.5992
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 87.4385
                       Mean reward: 684.92
               Mean episode length: 227.86
    Episode_Reward/reaching_object: 1.5586
    Episode_Reward/rotating_object: 142.0744
        Episode_Reward/action_rate: -0.1276
          Episode_Reward/joint_vel: -0.0328
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 119734272
                    Iteration time: 2.01s
                      Time elapsed: 00:46:02
                               ETA: 01:07:24

################################################################################
                     [1m Learning iteration 1218/3000 [0m                     

                       Computation: 49178 steps/s (collection: 1.873s, learning 0.126s)
             Mean action noise std: 4.31
          Mean value_function loss: 60.0215
               Mean surrogate loss: 0.0337
                 Mean entropy loss: 87.4595
                       Mean reward: 713.58
               Mean episode length: 233.89
    Episode_Reward/reaching_object: 1.5806
    Episode_Reward/rotating_object: 143.7080
        Episode_Reward/action_rate: -0.1297
          Episode_Reward/joint_vel: -0.0335
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 119832576
                    Iteration time: 2.00s
                      Time elapsed: 00:46:04
                               ETA: 01:07:22

################################################################################
                     [1m Learning iteration 1219/3000 [0m                     

                       Computation: 48884 steps/s (collection: 1.888s, learning 0.123s)
             Mean action noise std: 4.31
          Mean value_function loss: 59.9886
               Mean surrogate loss: 0.0006
                 Mean entropy loss: 87.4618
                       Mean reward: 708.03
               Mean episode length: 232.96
    Episode_Reward/reaching_object: 1.5433
    Episode_Reward/rotating_object: 140.4285
        Episode_Reward/action_rate: -0.1272
          Episode_Reward/joint_vel: -0.0336
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 119930880
                    Iteration time: 2.01s
                      Time elapsed: 00:46:06
                               ETA: 01:07:19

################################################################################
                     [1m Learning iteration 1220/3000 [0m                     

                       Computation: 49205 steps/s (collection: 1.880s, learning 0.118s)
             Mean action noise std: 4.31
          Mean value_function loss: 68.0725
               Mean surrogate loss: 0.0001
                 Mean entropy loss: 87.4626
                       Mean reward: 717.84
               Mean episode length: 231.37
    Episode_Reward/reaching_object: 1.5622
    Episode_Reward/rotating_object: 142.5460
        Episode_Reward/action_rate: -0.1294
          Episode_Reward/joint_vel: -0.0340
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 120029184
                    Iteration time: 2.00s
                      Time elapsed: 00:46:08
                               ETA: 01:07:16

################################################################################
                     [1m Learning iteration 1221/3000 [0m                     

                       Computation: 47887 steps/s (collection: 1.913s, learning 0.140s)
             Mean action noise std: 4.31
          Mean value_function loss: 69.6351
               Mean surrogate loss: -0.0000
                 Mean entropy loss: 87.4640
                       Mean reward: 721.73
               Mean episode length: 233.29
    Episode_Reward/reaching_object: 1.5591
    Episode_Reward/rotating_object: 141.5499
        Episode_Reward/action_rate: -0.1288
          Episode_Reward/joint_vel: -0.0334
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 120127488
                    Iteration time: 2.05s
                      Time elapsed: 00:46:11
                               ETA: 01:07:14

################################################################################
                     [1m Learning iteration 1222/3000 [0m                     

                       Computation: 48729 steps/s (collection: 1.896s, learning 0.122s)
             Mean action noise std: 4.31
          Mean value_function loss: 65.2068
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 87.4672
                       Mean reward: 674.42
               Mean episode length: 225.74
    Episode_Reward/reaching_object: 1.5560
    Episode_Reward/rotating_object: 141.8990
        Episode_Reward/action_rate: -0.1288
          Episode_Reward/joint_vel: -0.0335
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 120225792
                    Iteration time: 2.02s
                      Time elapsed: 00:46:13
                               ETA: 01:07:11

################################################################################
                     [1m Learning iteration 1223/3000 [0m                     

                       Computation: 48935 steps/s (collection: 1.879s, learning 0.130s)
             Mean action noise std: 4.31
          Mean value_function loss: 67.7472
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 87.4744
                       Mean reward: 728.81
               Mean episode length: 232.90
    Episode_Reward/reaching_object: 1.5409
    Episode_Reward/rotating_object: 141.3790
        Episode_Reward/action_rate: -0.1268
          Episode_Reward/joint_vel: -0.0324
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 120324096
                    Iteration time: 2.01s
                      Time elapsed: 00:46:15
                               ETA: 01:07:08

################################################################################
                     [1m Learning iteration 1224/3000 [0m                     

                       Computation: 48848 steps/s (collection: 1.894s, learning 0.118s)
             Mean action noise std: 4.31
          Mean value_function loss: 67.5158
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 87.4886
                       Mean reward: 728.84
               Mean episode length: 233.66
    Episode_Reward/reaching_object: 1.5614
    Episode_Reward/rotating_object: 142.7867
        Episode_Reward/action_rate: -0.1291
          Episode_Reward/joint_vel: -0.0337
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 120422400
                    Iteration time: 2.01s
                      Time elapsed: 00:46:17
                               ETA: 01:07:06

################################################################################
                     [1m Learning iteration 1225/3000 [0m                     

                       Computation: 47061 steps/s (collection: 1.951s, learning 0.138s)
             Mean action noise std: 4.31
          Mean value_function loss: 72.4751
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 87.5071
                       Mean reward: 709.10
               Mean episode length: 231.67
    Episode_Reward/reaching_object: 1.5715
    Episode_Reward/rotating_object: 142.2573
        Episode_Reward/action_rate: -0.1292
          Episode_Reward/joint_vel: -0.0336
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 120520704
                    Iteration time: 2.09s
                      Time elapsed: 00:46:19
                               ETA: 01:07:03

################################################################################
                     [1m Learning iteration 1226/3000 [0m                     

                       Computation: 45900 steps/s (collection: 2.009s, learning 0.133s)
             Mean action noise std: 4.32
          Mean value_function loss: 77.5113
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 87.5275
                       Mean reward: 672.67
               Mean episode length: 222.92
    Episode_Reward/reaching_object: 1.5296
    Episode_Reward/rotating_object: 140.8117
        Episode_Reward/action_rate: -0.1272
          Episode_Reward/joint_vel: -0.0332
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 120619008
                    Iteration time: 2.14s
                      Time elapsed: 00:46:21
                               ETA: 01:07:01

################################################################################
                     [1m Learning iteration 1227/3000 [0m                     

                       Computation: 48346 steps/s (collection: 1.916s, learning 0.117s)
             Mean action noise std: 4.32
          Mean value_function loss: 68.0114
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 87.5547
                       Mean reward: 715.45
               Mean episode length: 235.15
    Episode_Reward/reaching_object: 1.5472
    Episode_Reward/rotating_object: 141.5779
        Episode_Reward/action_rate: -0.1283
          Episode_Reward/joint_vel: -0.0332
      Episode_Termination/time_out: 14.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 120717312
                    Iteration time: 2.03s
                      Time elapsed: 00:46:23
                               ETA: 01:06:58

################################################################################
                     [1m Learning iteration 1228/3000 [0m                     

                       Computation: 46218 steps/s (collection: 1.971s, learning 0.156s)
             Mean action noise std: 4.32
          Mean value_function loss: 60.9082
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 87.5757
                       Mean reward: 719.19
               Mean episode length: 235.45
    Episode_Reward/reaching_object: 1.5923
    Episode_Reward/rotating_object: 145.6623
        Episode_Reward/action_rate: -0.1313
          Episode_Reward/joint_vel: -0.0330
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 120815616
                    Iteration time: 2.13s
                      Time elapsed: 00:46:25
                               ETA: 01:06:56

################################################################################
                     [1m Learning iteration 1229/3000 [0m                     

                       Computation: 41232 steps/s (collection: 2.270s, learning 0.115s)
             Mean action noise std: 4.33
          Mean value_function loss: 56.8354
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 87.5863
                       Mean reward: 739.94
               Mean episode length: 236.81
    Episode_Reward/reaching_object: 1.5820
    Episode_Reward/rotating_object: 142.3900
        Episode_Reward/action_rate: -0.1312
          Episode_Reward/joint_vel: -0.0346
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 120913920
                    Iteration time: 2.38s
                      Time elapsed: 00:46:27
                               ETA: 01:06:54

################################################################################
                     [1m Learning iteration 1230/3000 [0m                     

                       Computation: 45078 steps/s (collection: 2.074s, learning 0.107s)
             Mean action noise std: 4.33
          Mean value_function loss: 65.0398
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 87.5974
                       Mean reward: 729.76
               Mean episode length: 239.42
    Episode_Reward/reaching_object: 1.5662
    Episode_Reward/rotating_object: 142.4409
        Episode_Reward/action_rate: -0.1310
          Episode_Reward/joint_vel: -0.0351
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 121012224
                    Iteration time: 2.18s
                      Time elapsed: 00:46:30
                               ETA: 01:06:51

################################################################################
                     [1m Learning iteration 1231/3000 [0m                     

                       Computation: 47109 steps/s (collection: 1.971s, learning 0.116s)
             Mean action noise std: 4.33
          Mean value_function loss: 71.2147
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 87.6084
                       Mean reward: 710.33
               Mean episode length: 232.00
    Episode_Reward/reaching_object: 1.5252
    Episode_Reward/rotating_object: 138.0273
        Episode_Reward/action_rate: -0.1266
          Episode_Reward/joint_vel: -0.0340
      Episode_Termination/time_out: 15.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 121110528
                    Iteration time: 2.09s
                      Time elapsed: 00:46:32
                               ETA: 01:06:49

################################################################################
                     [1m Learning iteration 1232/3000 [0m                     

                       Computation: 47237 steps/s (collection: 1.977s, learning 0.104s)
             Mean action noise std: 4.33
          Mean value_function loss: 65.5778
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 87.6276
                       Mean reward: 690.94
               Mean episode length: 229.86
    Episode_Reward/reaching_object: 1.5644
    Episode_Reward/rotating_object: 140.5530
        Episode_Reward/action_rate: -0.1305
          Episode_Reward/joint_vel: -0.0348
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 121208832
                    Iteration time: 2.08s
                      Time elapsed: 00:46:34
                               ETA: 01:06:46

################################################################################
                     [1m Learning iteration 1233/3000 [0m                     

                       Computation: 46150 steps/s (collection: 2.006s, learning 0.125s)
             Mean action noise std: 4.34
          Mean value_function loss: 67.2560
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 87.6442
                       Mean reward: 688.17
               Mean episode length: 229.87
    Episode_Reward/reaching_object: 1.5715
    Episode_Reward/rotating_object: 141.3852
        Episode_Reward/action_rate: -0.1298
          Episode_Reward/joint_vel: -0.0330
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 121307136
                    Iteration time: 2.13s
                      Time elapsed: 00:46:36
                               ETA: 01:06:44

################################################################################
                     [1m Learning iteration 1234/3000 [0m                     

                       Computation: 44227 steps/s (collection: 2.093s, learning 0.130s)
             Mean action noise std: 4.34
          Mean value_function loss: 65.6373
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 87.6594
                       Mean reward: 690.58
               Mean episode length: 226.60
    Episode_Reward/reaching_object: 1.5491
    Episode_Reward/rotating_object: 139.8145
        Episode_Reward/action_rate: -0.1292
          Episode_Reward/joint_vel: -0.0335
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 121405440
                    Iteration time: 2.22s
                      Time elapsed: 00:46:38
                               ETA: 01:06:41

################################################################################
                     [1m Learning iteration 1235/3000 [0m                     

                       Computation: 43175 steps/s (collection: 2.093s, learning 0.184s)
             Mean action noise std: 4.34
          Mean value_function loss: 69.6978
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 87.6794
                       Mean reward: 713.62
               Mean episode length: 233.34
    Episode_Reward/reaching_object: 1.5863
    Episode_Reward/rotating_object: 141.7644
        Episode_Reward/action_rate: -0.1308
          Episode_Reward/joint_vel: -0.0342
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 121503744
                    Iteration time: 2.28s
                      Time elapsed: 00:46:40
                               ETA: 01:06:39

################################################################################
                     [1m Learning iteration 1236/3000 [0m                     

                       Computation: 47028 steps/s (collection: 1.990s, learning 0.100s)
             Mean action noise std: 4.34
          Mean value_function loss: 78.4179
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 87.7047
                       Mean reward: 706.79
               Mean episode length: 231.97
    Episode_Reward/reaching_object: 1.5565
    Episode_Reward/rotating_object: 140.8186
        Episode_Reward/action_rate: -0.1297
          Episode_Reward/joint_vel: -0.0330
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 121602048
                    Iteration time: 2.09s
                      Time elapsed: 00:46:42
                               ETA: 01:06:37

################################################################################
                     [1m Learning iteration 1237/3000 [0m                     

                       Computation: 35785 steps/s (collection: 2.580s, learning 0.167s)
             Mean action noise std: 4.35
          Mean value_function loss: 62.4036
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 87.7241
                       Mean reward: 753.78
               Mean episode length: 242.14
    Episode_Reward/reaching_object: 1.5988
    Episode_Reward/rotating_object: 145.4721
        Episode_Reward/action_rate: -0.1328
          Episode_Reward/joint_vel: -0.0333
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 121700352
                    Iteration time: 2.75s
                      Time elapsed: 00:46:45
                               ETA: 01:06:35

################################################################################
                     [1m Learning iteration 1238/3000 [0m                     

                       Computation: 41324 steps/s (collection: 2.149s, learning 0.230s)
             Mean action noise std: 4.35
          Mean value_function loss: 64.6008
               Mean surrogate loss: -0.0075
                 Mean entropy loss: 87.7438
                       Mean reward: 690.75
               Mean episode length: 229.16
    Episode_Reward/reaching_object: 1.5616
    Episode_Reward/rotating_object: 139.1999
        Episode_Reward/action_rate: -0.1303
          Episode_Reward/joint_vel: -0.0346
      Episode_Termination/time_out: 14.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 121798656
                    Iteration time: 2.38s
                      Time elapsed: 00:46:48
                               ETA: 01:06:33

################################################################################
                     [1m Learning iteration 1239/3000 [0m                     

                       Computation: 42649 steps/s (collection: 2.186s, learning 0.119s)
             Mean action noise std: 4.35
          Mean value_function loss: 50.9831
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 87.7641
                       Mean reward: 710.38
               Mean episode length: 233.50
    Episode_Reward/reaching_object: 1.5870
    Episode_Reward/rotating_object: 143.1034
        Episode_Reward/action_rate: -0.1326
          Episode_Reward/joint_vel: -0.0336
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 121896960
                    Iteration time: 2.30s
                      Time elapsed: 00:46:50
                               ETA: 01:06:31

################################################################################
                     [1m Learning iteration 1240/3000 [0m                     

                       Computation: 47131 steps/s (collection: 1.973s, learning 0.113s)
             Mean action noise std: 4.36
          Mean value_function loss: 60.1125
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 87.7803
                       Mean reward: 718.74
               Mean episode length: 230.50
    Episode_Reward/reaching_object: 1.5666
    Episode_Reward/rotating_object: 143.3356
        Episode_Reward/action_rate: -0.1315
          Episode_Reward/joint_vel: -0.0329
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 121995264
                    Iteration time: 2.09s
                      Time elapsed: 00:46:52
                               ETA: 01:06:28

################################################################################
                     [1m Learning iteration 1241/3000 [0m                     

                       Computation: 45797 steps/s (collection: 2.040s, learning 0.106s)
             Mean action noise std: 4.36
          Mean value_function loss: 62.3191
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 87.7951
                       Mean reward: 731.72
               Mean episode length: 236.92
    Episode_Reward/reaching_object: 1.5939
    Episode_Reward/rotating_object: 145.3265
        Episode_Reward/action_rate: -0.1336
          Episode_Reward/joint_vel: -0.0331
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 122093568
                    Iteration time: 2.15s
                      Time elapsed: 00:46:54
                               ETA: 01:06:26

################################################################################
                     [1m Learning iteration 1242/3000 [0m                     

                       Computation: 46022 steps/s (collection: 1.964s, learning 0.172s)
             Mean action noise std: 4.36
          Mean value_function loss: 63.4851
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 87.8100
                       Mean reward: 676.06
               Mean episode length: 222.64
    Episode_Reward/reaching_object: 1.5605
    Episode_Reward/rotating_object: 140.2585
        Episode_Reward/action_rate: -0.1312
          Episode_Reward/joint_vel: -0.0338
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 122191872
                    Iteration time: 2.14s
                      Time elapsed: 00:46:56
                               ETA: 01:06:23

################################################################################
                     [1m Learning iteration 1243/3000 [0m                     

                       Computation: 43230 steps/s (collection: 2.041s, learning 0.233s)
             Mean action noise std: 4.37
          Mean value_function loss: 67.4281
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 87.8400
                       Mean reward: 701.56
               Mean episode length: 230.19
    Episode_Reward/reaching_object: 1.5505
    Episode_Reward/rotating_object: 140.1767
        Episode_Reward/action_rate: -0.1308
          Episode_Reward/joint_vel: -0.0330
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 122290176
                    Iteration time: 2.27s
                      Time elapsed: 00:46:59
                               ETA: 01:06:21

################################################################################
                     [1m Learning iteration 1244/3000 [0m                     

                       Computation: 45164 steps/s (collection: 2.057s, learning 0.120s)
             Mean action noise std: 4.37
          Mean value_function loss: 61.1059
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 87.8641
                       Mean reward: 715.35
               Mean episode length: 233.76
    Episode_Reward/reaching_object: 1.5467
    Episode_Reward/rotating_object: 140.7072
        Episode_Reward/action_rate: -0.1313
          Episode_Reward/joint_vel: -0.0329
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 122388480
                    Iteration time: 2.18s
                      Time elapsed: 00:47:01
                               ETA: 01:06:19

################################################################################
                     [1m Learning iteration 1245/3000 [0m                     

                       Computation: 48111 steps/s (collection: 1.947s, learning 0.096s)
             Mean action noise std: 4.37
          Mean value_function loss: 52.1374
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 87.8919
                       Mean reward: 750.00
               Mean episode length: 240.68
    Episode_Reward/reaching_object: 1.5911
    Episode_Reward/rotating_object: 146.4719
        Episode_Reward/action_rate: -0.1346
          Episode_Reward/joint_vel: -0.0326
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 122486784
                    Iteration time: 2.04s
                      Time elapsed: 00:47:03
                               ETA: 01:06:16

################################################################################
                     [1m Learning iteration 1246/3000 [0m                     

                       Computation: 47017 steps/s (collection: 1.988s, learning 0.103s)
             Mean action noise std: 4.38
          Mean value_function loss: 72.1763
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 87.9227
                       Mean reward: 698.04
               Mean episode length: 228.22
    Episode_Reward/reaching_object: 1.5504
    Episode_Reward/rotating_object: 141.9499
        Episode_Reward/action_rate: -0.1321
          Episode_Reward/joint_vel: -0.0327
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 122585088
                    Iteration time: 2.09s
                      Time elapsed: 00:47:05
                               ETA: 01:06:14

################################################################################
                     [1m Learning iteration 1247/3000 [0m                     

                       Computation: 46217 steps/s (collection: 1.982s, learning 0.145s)
             Mean action noise std: 4.38
          Mean value_function loss: 68.8412
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 87.9464
                       Mean reward: 716.48
               Mean episode length: 230.84
    Episode_Reward/reaching_object: 1.5110
    Episode_Reward/rotating_object: 140.4200
        Episode_Reward/action_rate: -0.1293
          Episode_Reward/joint_vel: -0.0313
      Episode_Termination/time_out: 17.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9583
--------------------------------------------------------------------------------
                   Total timesteps: 122683392
                    Iteration time: 2.13s
                      Time elapsed: 00:47:07
                               ETA: 01:06:11

################################################################################
                     [1m Learning iteration 1248/3000 [0m                     

                       Computation: 41123 steps/s (collection: 2.152s, learning 0.238s)
             Mean action noise std: 4.38
          Mean value_function loss: 72.3014
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 87.9663
                       Mean reward: 711.97
               Mean episode length: 230.04
    Episode_Reward/reaching_object: 1.4985
    Episode_Reward/rotating_object: 140.2279
        Episode_Reward/action_rate: -0.1295
          Episode_Reward/joint_vel: -0.0310
      Episode_Termination/time_out: 14.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 122781696
                    Iteration time: 2.39s
                      Time elapsed: 00:47:09
                               ETA: 01:06:09

################################################################################
                     [1m Learning iteration 1249/3000 [0m                     

                       Computation: 45227 steps/s (collection: 2.025s, learning 0.148s)
             Mean action noise std: 4.39
          Mean value_function loss: 55.0816
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 87.9895
                       Mean reward: 661.50
               Mean episode length: 218.89
    Episode_Reward/reaching_object: 1.4988
    Episode_Reward/rotating_object: 137.8532
        Episode_Reward/action_rate: -0.1301
          Episode_Reward/joint_vel: -0.0325
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 122880000
                    Iteration time: 2.17s
                      Time elapsed: 00:47:12
                               ETA: 01:06:07

################################################################################
                     [1m Learning iteration 1250/3000 [0m                     

                       Computation: 43603 steps/s (collection: 2.034s, learning 0.220s)
             Mean action noise std: 4.39
          Mean value_function loss: 60.9202
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 87.9998
                       Mean reward: 742.52
               Mean episode length: 239.00
    Episode_Reward/reaching_object: 1.5357
    Episode_Reward/rotating_object: 142.6943
        Episode_Reward/action_rate: -0.1327
          Episode_Reward/joint_vel: -0.0319
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 122978304
                    Iteration time: 2.25s
                      Time elapsed: 00:47:14
                               ETA: 01:06:04

################################################################################
                     [1m Learning iteration 1251/3000 [0m                     

                       Computation: 43493 steps/s (collection: 2.125s, learning 0.135s)
             Mean action noise std: 4.39
          Mean value_function loss: 61.4105
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 88.0114
                       Mean reward: 735.59
               Mean episode length: 241.04
    Episode_Reward/reaching_object: 1.5312
    Episode_Reward/rotating_object: 142.1970
        Episode_Reward/action_rate: -0.1332
          Episode_Reward/joint_vel: -0.0318
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 123076608
                    Iteration time: 2.26s
                      Time elapsed: 00:47:16
                               ETA: 01:06:02

################################################################################
                     [1m Learning iteration 1252/3000 [0m                     

                       Computation: 43553 steps/s (collection: 2.072s, learning 0.185s)
             Mean action noise std: 4.39
          Mean value_function loss: 80.1830
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 88.0336
                       Mean reward: 644.80
               Mean episode length: 214.51
    Episode_Reward/reaching_object: 1.4878
    Episode_Reward/rotating_object: 138.3613
        Episode_Reward/action_rate: -0.1293
          Episode_Reward/joint_vel: -0.0312
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0417
--------------------------------------------------------------------------------
                   Total timesteps: 123174912
                    Iteration time: 2.26s
                      Time elapsed: 00:47:18
                               ETA: 01:06:00

################################################################################
                     [1m Learning iteration 1253/3000 [0m                     

                       Computation: 44508 steps/s (collection: 2.079s, learning 0.130s)
             Mean action noise std: 4.40
          Mean value_function loss: 54.3509
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 88.0657
                       Mean reward: 765.32
               Mean episode length: 242.81
    Episode_Reward/reaching_object: 1.5495
    Episode_Reward/rotating_object: 144.7441
        Episode_Reward/action_rate: -0.1341
          Episode_Reward/joint_vel: -0.0314
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 123273216
                    Iteration time: 2.21s
                      Time elapsed: 00:47:20
                               ETA: 01:05:57

################################################################################
                     [1m Learning iteration 1254/3000 [0m                     

                       Computation: 46293 steps/s (collection: 2.000s, learning 0.123s)
             Mean action noise std: 4.40
          Mean value_function loss: 62.6369
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 88.0914
                       Mean reward: 766.35
               Mean episode length: 243.74
    Episode_Reward/reaching_object: 1.5328
    Episode_Reward/rotating_object: 143.4078
        Episode_Reward/action_rate: -0.1324
          Episode_Reward/joint_vel: -0.0315
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 123371520
                    Iteration time: 2.12s
                      Time elapsed: 00:47:23
                               ETA: 01:05:55

################################################################################
                     [1m Learning iteration 1255/3000 [0m                     

                       Computation: 45916 steps/s (collection: 2.048s, learning 0.093s)
             Mean action noise std: 4.41
          Mean value_function loss: 64.7631
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 88.1160
                       Mean reward: 719.49
               Mean episode length: 234.84
    Episode_Reward/reaching_object: 1.5189
    Episode_Reward/rotating_object: 140.0623
        Episode_Reward/action_rate: -0.1317
          Episode_Reward/joint_vel: -0.0328
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 123469824
                    Iteration time: 2.14s
                      Time elapsed: 00:47:25
                               ETA: 01:05:52

################################################################################
                     [1m Learning iteration 1256/3000 [0m                     

                       Computation: 46922 steps/s (collection: 1.975s, learning 0.120s)
             Mean action noise std: 4.41
          Mean value_function loss: 70.2437
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 88.1453
                       Mean reward: 712.77
               Mean episode length: 233.63
    Episode_Reward/reaching_object: 1.5208
    Episode_Reward/rotating_object: 140.9634
        Episode_Reward/action_rate: -0.1326
          Episode_Reward/joint_vel: -0.0335
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 123568128
                    Iteration time: 2.10s
                      Time elapsed: 00:47:27
                               ETA: 01:05:50

################################################################################
                     [1m Learning iteration 1257/3000 [0m                     

                       Computation: 43320 steps/s (collection: 2.063s, learning 0.206s)
             Mean action noise std: 4.41
          Mean value_function loss: 67.0117
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 88.1693
                       Mean reward: 724.68
               Mean episode length: 235.58
    Episode_Reward/reaching_object: 1.5062
    Episode_Reward/rotating_object: 137.9024
        Episode_Reward/action_rate: -0.1312
          Episode_Reward/joint_vel: -0.0330
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 123666432
                    Iteration time: 2.27s
                      Time elapsed: 00:47:29
                               ETA: 01:05:48

################################################################################
                     [1m Learning iteration 1258/3000 [0m                     

                       Computation: 42161 steps/s (collection: 2.165s, learning 0.166s)
             Mean action noise std: 4.42
          Mean value_function loss: 70.2376
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 88.1876
                       Mean reward: 703.78
               Mean episode length: 229.42
    Episode_Reward/reaching_object: 1.5377
    Episode_Reward/rotating_object: 143.0177
        Episode_Reward/action_rate: -0.1339
          Episode_Reward/joint_vel: -0.0324
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 123764736
                    Iteration time: 2.33s
                      Time elapsed: 00:47:31
                               ETA: 01:05:46

################################################################################
                     [1m Learning iteration 1259/3000 [0m                     

                       Computation: 43589 steps/s (collection: 2.076s, learning 0.180s)
             Mean action noise std: 4.42
          Mean value_function loss: 58.8768
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 88.2052
                       Mean reward: 719.13
               Mean episode length: 235.67
    Episode_Reward/reaching_object: 1.5530
    Episode_Reward/rotating_object: 143.1495
        Episode_Reward/action_rate: -0.1352
          Episode_Reward/joint_vel: -0.0326
      Episode_Termination/time_out: 14.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 123863040
                    Iteration time: 2.26s
                      Time elapsed: 00:47:34
                               ETA: 01:05:43

################################################################################
                     [1m Learning iteration 1260/3000 [0m                     

                       Computation: 46118 steps/s (collection: 2.002s, learning 0.129s)
             Mean action noise std: 4.42
          Mean value_function loss: 47.5237
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 88.2202
                       Mean reward: 750.66
               Mean episode length: 239.29
    Episode_Reward/reaching_object: 1.5862
    Episode_Reward/rotating_object: 147.2767
        Episode_Reward/action_rate: -0.1381
          Episode_Reward/joint_vel: -0.0326
      Episode_Termination/time_out: 17.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 123961344
                    Iteration time: 2.13s
                      Time elapsed: 00:47:36
                               ETA: 01:05:41

################################################################################
                     [1m Learning iteration 1261/3000 [0m                     

                       Computation: 45973 steps/s (collection: 1.998s, learning 0.141s)
             Mean action noise std: 4.42
          Mean value_function loss: 59.9890
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 88.2334
                       Mean reward: 715.70
               Mean episode length: 234.70
    Episode_Reward/reaching_object: 1.5410
    Episode_Reward/rotating_object: 142.4232
        Episode_Reward/action_rate: -0.1354
          Episode_Reward/joint_vel: -0.0331
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 124059648
                    Iteration time: 2.14s
                      Time elapsed: 00:47:38
                               ETA: 01:05:38

################################################################################
                     [1m Learning iteration 1262/3000 [0m                     

                       Computation: 42147 steps/s (collection: 2.169s, learning 0.163s)
             Mean action noise std: 4.42
          Mean value_function loss: 57.1712
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 88.2529
                       Mean reward: 722.85
               Mean episode length: 235.39
    Episode_Reward/reaching_object: 1.5298
    Episode_Reward/rotating_object: 141.9811
        Episode_Reward/action_rate: -0.1355
          Episode_Reward/joint_vel: -0.0328
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 124157952
                    Iteration time: 2.33s
                      Time elapsed: 00:47:40
                               ETA: 01:05:36

################################################################################
                     [1m Learning iteration 1263/3000 [0m                     

                       Computation: 45408 steps/s (collection: 2.016s, learning 0.149s)
             Mean action noise std: 4.43
          Mean value_function loss: 65.2776
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 88.2629
                       Mean reward: 707.89
               Mean episode length: 227.18
    Episode_Reward/reaching_object: 1.5226
    Episode_Reward/rotating_object: 141.1668
        Episode_Reward/action_rate: -0.1336
          Episode_Reward/joint_vel: -0.0320
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 124256256
                    Iteration time: 2.16s
                      Time elapsed: 00:47:42
                               ETA: 01:05:34

################################################################################
                     [1m Learning iteration 1264/3000 [0m                     

                       Computation: 45801 steps/s (collection: 1.986s, learning 0.161s)
             Mean action noise std: 4.43
          Mean value_function loss: 59.7734
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 88.2828
                       Mean reward: 685.40
               Mean episode length: 226.76
    Episode_Reward/reaching_object: 1.5285
    Episode_Reward/rotating_object: 141.0231
        Episode_Reward/action_rate: -0.1357
          Episode_Reward/joint_vel: -0.0335
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 124354560
                    Iteration time: 2.15s
                      Time elapsed: 00:47:45
                               ETA: 01:05:31

################################################################################
                     [1m Learning iteration 1265/3000 [0m                     

                       Computation: 42685 steps/s (collection: 2.121s, learning 0.182s)
             Mean action noise std: 4.43
          Mean value_function loss: 64.6704
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 88.3010
                       Mean reward: 723.06
               Mean episode length: 231.16
    Episode_Reward/reaching_object: 1.5159
    Episode_Reward/rotating_object: 140.4944
        Episode_Reward/action_rate: -0.1330
          Episode_Reward/joint_vel: -0.0319
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 124452864
                    Iteration time: 2.30s
                      Time elapsed: 00:47:47
                               ETA: 01:05:29

################################################################################
                     [1m Learning iteration 1266/3000 [0m                     

                       Computation: 43840 steps/s (collection: 2.123s, learning 0.119s)
             Mean action noise std: 4.44
          Mean value_function loss: 58.8171
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 88.3217
                       Mean reward: 738.54
               Mean episode length: 236.24
    Episode_Reward/reaching_object: 1.5238
    Episode_Reward/rotating_object: 143.2887
        Episode_Reward/action_rate: -0.1349
          Episode_Reward/joint_vel: -0.0313
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 124551168
                    Iteration time: 2.24s
                      Time elapsed: 00:47:49
                               ETA: 01:05:27

################################################################################
                     [1m Learning iteration 1267/3000 [0m                     

                       Computation: 43991 steps/s (collection: 2.031s, learning 0.203s)
             Mean action noise std: 4.44
          Mean value_function loss: 65.8510
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 88.3373
                       Mean reward: 744.90
               Mean episode length: 241.93
    Episode_Reward/reaching_object: 1.5585
    Episode_Reward/rotating_object: 145.1747
        Episode_Reward/action_rate: -0.1370
          Episode_Reward/joint_vel: -0.0331
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 124649472
                    Iteration time: 2.23s
                      Time elapsed: 00:47:51
                               ETA: 01:05:25

################################################################################
                     [1m Learning iteration 1268/3000 [0m                     

                       Computation: 41591 steps/s (collection: 2.232s, learning 0.132s)
             Mean action noise std: 4.44
          Mean value_function loss: 74.2434
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 88.3551
                       Mean reward: 674.31
               Mean episode length: 219.78
    Episode_Reward/reaching_object: 1.5059
    Episode_Reward/rotating_object: 138.9978
        Episode_Reward/action_rate: -0.1339
          Episode_Reward/joint_vel: -0.0318
      Episode_Termination/time_out: 17.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 2.0000
--------------------------------------------------------------------------------
                   Total timesteps: 124747776
                    Iteration time: 2.36s
                      Time elapsed: 00:47:54
                               ETA: 01:05:22

################################################################################
                     [1m Learning iteration 1269/3000 [0m                     

                       Computation: 46734 steps/s (collection: 1.999s, learning 0.105s)
             Mean action noise std: 4.44
          Mean value_function loss: 62.8761
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 88.3793
                       Mean reward: 748.40
               Mean episode length: 237.55
    Episode_Reward/reaching_object: 1.5566
    Episode_Reward/rotating_object: 146.1853
        Episode_Reward/action_rate: -0.1367
          Episode_Reward/joint_vel: -0.0308
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 124846080
                    Iteration time: 2.10s
                      Time elapsed: 00:47:56
                               ETA: 01:05:20

################################################################################
                     [1m Learning iteration 1270/3000 [0m                     

                       Computation: 47666 steps/s (collection: 1.962s, learning 0.101s)
             Mean action noise std: 4.45
          Mean value_function loss: 62.8126
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 88.3942
                       Mean reward: 756.99
               Mean episode length: 245.97
    Episode_Reward/reaching_object: 1.5471
    Episode_Reward/rotating_object: 142.4386
        Episode_Reward/action_rate: -0.1354
          Episode_Reward/joint_vel: -0.0318
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 124944384
                    Iteration time: 2.06s
                      Time elapsed: 00:47:58
                               ETA: 01:05:17

################################################################################
                     [1m Learning iteration 1271/3000 [0m                     

                       Computation: 44233 steps/s (collection: 2.043s, learning 0.179s)
             Mean action noise std: 4.45
          Mean value_function loss: 59.7108
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 88.4074
                       Mean reward: 694.44
               Mean episode length: 229.08
    Episode_Reward/reaching_object: 1.5242
    Episode_Reward/rotating_object: 140.9877
        Episode_Reward/action_rate: -0.1352
          Episode_Reward/joint_vel: -0.0326
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 125042688
                    Iteration time: 2.22s
                      Time elapsed: 00:48:00
                               ETA: 01:05:15

################################################################################
                     [1m Learning iteration 1272/3000 [0m                     

                       Computation: 44455 steps/s (collection: 1.985s, learning 0.227s)
             Mean action noise std: 4.45
          Mean value_function loss: 72.7433
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 88.4232
                       Mean reward: 660.18
               Mean episode length: 220.30
    Episode_Reward/reaching_object: 1.4963
    Episode_Reward/rotating_object: 138.5743
        Episode_Reward/action_rate: -0.1335
          Episode_Reward/joint_vel: -0.0317
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.8750
--------------------------------------------------------------------------------
                   Total timesteps: 125140992
                    Iteration time: 2.21s
                      Time elapsed: 00:48:02
                               ETA: 01:05:13

################################################################################
                     [1m Learning iteration 1273/3000 [0m                     

                       Computation: 40341 steps/s (collection: 2.184s, learning 0.253s)
             Mean action noise std: 4.45
          Mean value_function loss: 57.0995
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 88.4452
                       Mean reward: 764.31
               Mean episode length: 242.10
    Episode_Reward/reaching_object: 1.5656
    Episode_Reward/rotating_object: 146.5431
        Episode_Reward/action_rate: -0.1388
          Episode_Reward/joint_vel: -0.0319
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 125239296
                    Iteration time: 2.44s
                      Time elapsed: 00:48:05
                               ETA: 01:05:11

################################################################################
                     [1m Learning iteration 1274/3000 [0m                     

                       Computation: 43446 steps/s (collection: 2.082s, learning 0.181s)
             Mean action noise std: 4.46
          Mean value_function loss: 65.0642
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 88.4634
                       Mean reward: 738.85
               Mean episode length: 235.96
    Episode_Reward/reaching_object: 1.5362
    Episode_Reward/rotating_object: 143.4535
        Episode_Reward/action_rate: -0.1364
          Episode_Reward/joint_vel: -0.0322
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 125337600
                    Iteration time: 2.26s
                      Time elapsed: 00:48:07
                               ETA: 01:05:08

################################################################################
                     [1m Learning iteration 1275/3000 [0m                     

                       Computation: 45865 steps/s (collection: 2.034s, learning 0.109s)
             Mean action noise std: 4.46
          Mean value_function loss: 72.6940
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 88.4913
                       Mean reward: 706.84
               Mean episode length: 226.09
    Episode_Reward/reaching_object: 1.5090
    Episode_Reward/rotating_object: 139.9587
        Episode_Reward/action_rate: -0.1346
          Episode_Reward/joint_vel: -0.0314
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 125435904
                    Iteration time: 2.14s
                      Time elapsed: 00:48:09
                               ETA: 01:05:06

################################################################################
                     [1m Learning iteration 1276/3000 [0m                     

                       Computation: 46335 steps/s (collection: 1.960s, learning 0.161s)
             Mean action noise std: 4.46
          Mean value_function loss: 59.1544
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 88.5209
                       Mean reward: 721.04
               Mean episode length: 235.81
    Episode_Reward/reaching_object: 1.5510
    Episode_Reward/rotating_object: 143.3715
        Episode_Reward/action_rate: -0.1383
          Episode_Reward/joint_vel: -0.0329
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 125534208
                    Iteration time: 2.12s
                      Time elapsed: 00:48:11
                               ETA: 01:05:04

################################################################################
                     [1m Learning iteration 1277/3000 [0m                     

                       Computation: 45460 steps/s (collection: 1.942s, learning 0.221s)
             Mean action noise std: 4.47
          Mean value_function loss: 64.7920
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 88.5363
                       Mean reward: 682.12
               Mean episode length: 222.56
    Episode_Reward/reaching_object: 1.5177
    Episode_Reward/rotating_object: 139.3123
        Episode_Reward/action_rate: -0.1348
          Episode_Reward/joint_vel: -0.0313
      Episode_Termination/time_out: 15.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6667
--------------------------------------------------------------------------------
                   Total timesteps: 125632512
                    Iteration time: 2.16s
                      Time elapsed: 00:48:13
                               ETA: 01:05:01

################################################################################
                     [1m Learning iteration 1278/3000 [0m                     

                       Computation: 45946 steps/s (collection: 2.007s, learning 0.133s)
             Mean action noise std: 4.47
          Mean value_function loss: 53.6470
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 88.5546
                       Mean reward: 728.41
               Mean episode length: 237.98
    Episode_Reward/reaching_object: 1.5402
    Episode_Reward/rotating_object: 141.0342
        Episode_Reward/action_rate: -0.1376
          Episode_Reward/joint_vel: -0.0325
      Episode_Termination/time_out: 17.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 125730816
                    Iteration time: 2.14s
                      Time elapsed: 00:48:16
                               ETA: 01:04:59

################################################################################
                     [1m Learning iteration 1279/3000 [0m                     

                       Computation: 43241 steps/s (collection: 2.065s, learning 0.208s)
             Mean action noise std: 4.47
          Mean value_function loss: 61.7122
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 88.5679
                       Mean reward: 702.72
               Mean episode length: 228.20
    Episode_Reward/reaching_object: 1.5475
    Episode_Reward/rotating_object: 143.3940
        Episode_Reward/action_rate: -0.1387
          Episode_Reward/joint_vel: -0.0329
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 125829120
                    Iteration time: 2.27s
                      Time elapsed: 00:48:18
                               ETA: 01:04:56

################################################################################
                     [1m Learning iteration 1280/3000 [0m                     

                       Computation: 43029 steps/s (collection: 2.166s, learning 0.119s)
             Mean action noise std: 4.47
          Mean value_function loss: 56.8889
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 88.5837
                       Mean reward: 742.83
               Mean episode length: 236.67
    Episode_Reward/reaching_object: 1.5326
    Episode_Reward/rotating_object: 143.7475
        Episode_Reward/action_rate: -0.1379
          Episode_Reward/joint_vel: -0.0316
      Episode_Termination/time_out: 14.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 125927424
                    Iteration time: 2.28s
                      Time elapsed: 00:48:20
                               ETA: 01:04:54

################################################################################
                     [1m Learning iteration 1281/3000 [0m                     

                       Computation: 47523 steps/s (collection: 1.962s, learning 0.107s)
             Mean action noise std: 4.48
          Mean value_function loss: 50.2760
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 88.5951
                       Mean reward: 747.79
               Mean episode length: 242.15
    Episode_Reward/reaching_object: 1.5444
    Episode_Reward/rotating_object: 144.3568
        Episode_Reward/action_rate: -0.1388
          Episode_Reward/joint_vel: -0.0323
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 126025728
                    Iteration time: 2.07s
                      Time elapsed: 00:48:22
                               ETA: 01:04:52

################################################################################
                     [1m Learning iteration 1282/3000 [0m                     

                       Computation: 44633 steps/s (collection: 2.041s, learning 0.162s)
             Mean action noise std: 4.48
          Mean value_function loss: 59.9038
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 88.6070
                       Mean reward: 748.35
               Mean episode length: 237.28
    Episode_Reward/reaching_object: 1.5081
    Episode_Reward/rotating_object: 141.1890
        Episode_Reward/action_rate: -0.1366
          Episode_Reward/joint_vel: -0.0327
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 126124032
                    Iteration time: 2.20s
                      Time elapsed: 00:48:24
                               ETA: 01:04:49

################################################################################
                     [1m Learning iteration 1283/3000 [0m                     

                       Computation: 45571 steps/s (collection: 2.008s, learning 0.150s)
             Mean action noise std: 4.48
          Mean value_function loss: 64.5972
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 88.6244
                       Mean reward: 707.98
               Mean episode length: 227.19
    Episode_Reward/reaching_object: 1.5225
    Episode_Reward/rotating_object: 142.7965
        Episode_Reward/action_rate: -0.1373
          Episode_Reward/joint_vel: -0.0315
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 126222336
                    Iteration time: 2.16s
                      Time elapsed: 00:48:27
                               ETA: 01:04:47

################################################################################
                     [1m Learning iteration 1284/3000 [0m                     

                       Computation: 45626 steps/s (collection: 2.049s, learning 0.106s)
             Mean action noise std: 4.48
          Mean value_function loss: 56.8398
               Mean surrogate loss: -0.0015
                 Mean entropy loss: 88.6445
                       Mean reward: 713.22
               Mean episode length: 233.42
    Episode_Reward/reaching_object: 1.5211
    Episode_Reward/rotating_object: 142.4198
        Episode_Reward/action_rate: -0.1382
          Episode_Reward/joint_vel: -0.0319
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 126320640
                    Iteration time: 2.15s
                      Time elapsed: 00:48:29
                               ETA: 01:04:45

################################################################################
                     [1m Learning iteration 1285/3000 [0m                     

                       Computation: 45753 steps/s (collection: 2.048s, learning 0.101s)
             Mean action noise std: 4.49
          Mean value_function loss: 63.0907
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 88.6538
                       Mean reward: 733.03
               Mean episode length: 234.66
    Episode_Reward/reaching_object: 1.5161
    Episode_Reward/rotating_object: 142.3389
        Episode_Reward/action_rate: -0.1369
          Episode_Reward/joint_vel: -0.0313
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 126418944
                    Iteration time: 2.15s
                      Time elapsed: 00:48:31
                               ETA: 01:04:42

################################################################################
                     [1m Learning iteration 1286/3000 [0m                     

                       Computation: 47270 steps/s (collection: 1.959s, learning 0.120s)
             Mean action noise std: 4.49
          Mean value_function loss: 63.7762
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 88.6715
                       Mean reward: 712.66
               Mean episode length: 232.52
    Episode_Reward/reaching_object: 1.5351
    Episode_Reward/rotating_object: 141.2273
        Episode_Reward/action_rate: -0.1388
          Episode_Reward/joint_vel: -0.0320
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 126517248
                    Iteration time: 2.08s
                      Time elapsed: 00:48:33
                               ETA: 01:04:40

################################################################################
                     [1m Learning iteration 1287/3000 [0m                     

                       Computation: 47503 steps/s (collection: 1.942s, learning 0.127s)
             Mean action noise std: 4.49
          Mean value_function loss: 58.9170
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 88.6941
                       Mean reward: 739.52
               Mean episode length: 239.08
    Episode_Reward/reaching_object: 1.5488
    Episode_Reward/rotating_object: 144.7836
        Episode_Reward/action_rate: -0.1394
          Episode_Reward/joint_vel: -0.0327
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 126615552
                    Iteration time: 2.07s
                      Time elapsed: 00:48:35
                               ETA: 01:04:37

################################################################################
                     [1m Learning iteration 1288/3000 [0m                     

                       Computation: 46846 steps/s (collection: 1.964s, learning 0.134s)
             Mean action noise std: 4.49
          Mean value_function loss: 65.1579
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 88.7048
                       Mean reward: 760.35
               Mean episode length: 241.38
    Episode_Reward/reaching_object: 1.5374
    Episode_Reward/rotating_object: 143.4342
        Episode_Reward/action_rate: -0.1387
          Episode_Reward/joint_vel: -0.0322
      Episode_Termination/time_out: 17.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 126713856
                    Iteration time: 2.10s
                      Time elapsed: 00:48:37
                               ETA: 01:04:35

################################################################################
                     [1m Learning iteration 1289/3000 [0m                     

                       Computation: 40673 steps/s (collection: 2.258s, learning 0.159s)
             Mean action noise std: 4.50
          Mean value_function loss: 57.7881
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 88.7279
                       Mean reward: 742.28
               Mean episode length: 239.67
    Episode_Reward/reaching_object: 1.5852
    Episode_Reward/rotating_object: 146.3655
        Episode_Reward/action_rate: -0.1407
          Episode_Reward/joint_vel: -0.0314
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 126812160
                    Iteration time: 2.42s
                      Time elapsed: 00:48:40
                               ETA: 01:04:33

################################################################################
                     [1m Learning iteration 1290/3000 [0m                     

                       Computation: 46193 steps/s (collection: 1.995s, learning 0.133s)
             Mean action noise std: 4.50
          Mean value_function loss: 79.6046
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 88.7498
                       Mean reward: 711.51
               Mean episode length: 228.68
    Episode_Reward/reaching_object: 1.5096
    Episode_Reward/rotating_object: 139.4854
        Episode_Reward/action_rate: -0.1353
          Episode_Reward/joint_vel: -0.0316
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.9167
--------------------------------------------------------------------------------
                   Total timesteps: 126910464
                    Iteration time: 2.13s
                      Time elapsed: 00:48:42
                               ETA: 01:04:30

################################################################################
                     [1m Learning iteration 1291/3000 [0m                     

                       Computation: 41480 steps/s (collection: 2.175s, learning 0.195s)
             Mean action noise std: 4.50
          Mean value_function loss: 63.9872
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 88.7630
                       Mean reward: 692.85
               Mean episode length: 224.38
    Episode_Reward/reaching_object: 1.5342
    Episode_Reward/rotating_object: 139.6512
        Episode_Reward/action_rate: -0.1358
          Episode_Reward/joint_vel: -0.0315
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7917
--------------------------------------------------------------------------------
                   Total timesteps: 127008768
                    Iteration time: 2.37s
                      Time elapsed: 00:48:44
                               ETA: 01:04:28

################################################################################
                     [1m Learning iteration 1292/3000 [0m                     

                       Computation: 43498 steps/s (collection: 2.146s, learning 0.114s)
             Mean action noise std: 4.51
          Mean value_function loss: 46.9511
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 88.7810
                       Mean reward: 723.30
               Mean episode length: 236.20
    Episode_Reward/reaching_object: 1.5933
    Episode_Reward/rotating_object: 146.0681
        Episode_Reward/action_rate: -0.1415
          Episode_Reward/joint_vel: -0.0325
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 127107072
                    Iteration time: 2.26s
                      Time elapsed: 00:48:46
                               ETA: 01:04:26

################################################################################
                     [1m Learning iteration 1293/3000 [0m                     

                       Computation: 42682 steps/s (collection: 2.132s, learning 0.171s)
             Mean action noise std: 4.51
          Mean value_function loss: 53.1398
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 88.7978
                       Mean reward: 732.28
               Mean episode length: 233.16
    Episode_Reward/reaching_object: 1.5903
    Episode_Reward/rotating_object: 147.8241
        Episode_Reward/action_rate: -0.1419
          Episode_Reward/joint_vel: -0.0320
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 127205376
                    Iteration time: 2.30s
                      Time elapsed: 00:48:49
                               ETA: 01:04:24

################################################################################
                     [1m Learning iteration 1294/3000 [0m                     

                       Computation: 45760 steps/s (collection: 1.984s, learning 0.164s)
             Mean action noise std: 4.51
          Mean value_function loss: 52.4496
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 88.8181
                       Mean reward: 743.90
               Mean episode length: 237.46
    Episode_Reward/reaching_object: 1.5631
    Episode_Reward/rotating_object: 143.6934
        Episode_Reward/action_rate: -0.1400
          Episode_Reward/joint_vel: -0.0325
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 127303680
                    Iteration time: 2.15s
                      Time elapsed: 00:48:51
                               ETA: 01:04:21

################################################################################
                     [1m Learning iteration 1295/3000 [0m                     

                       Computation: 45270 steps/s (collection: 2.033s, learning 0.138s)
             Mean action noise std: 4.52
          Mean value_function loss: 57.5500
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 88.8381
                       Mean reward: 756.96
               Mean episode length: 244.14
    Episode_Reward/reaching_object: 1.6062
    Episode_Reward/rotating_object: 146.7796
        Episode_Reward/action_rate: -0.1425
          Episode_Reward/joint_vel: -0.0317
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 127401984
                    Iteration time: 2.17s
                      Time elapsed: 00:48:53
                               ETA: 01:04:19

################################################################################
                     [1m Learning iteration 1296/3000 [0m                     

                       Computation: 46858 steps/s (collection: 1.982s, learning 0.116s)
             Mean action noise std: 4.52
          Mean value_function loss: 72.8893
               Mean surrogate loss: 0.0020
                 Mean entropy loss: 88.8535
                       Mean reward: 707.92
               Mean episode length: 228.76
    Episode_Reward/reaching_object: 1.5513
    Episode_Reward/rotating_object: 142.1501
        Episode_Reward/action_rate: -0.1389
          Episode_Reward/joint_vel: -0.0330
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 127500288
                    Iteration time: 2.10s
                      Time elapsed: 00:48:55
                               ETA: 01:04:16

################################################################################
                     [1m Learning iteration 1297/3000 [0m                     

                       Computation: 46542 steps/s (collection: 2.007s, learning 0.105s)
             Mean action noise std: 4.52
          Mean value_function loss: 63.8835
               Mean surrogate loss: -0.0070
                 Mean entropy loss: 88.8585
                       Mean reward: 711.06
               Mean episode length: 230.64
    Episode_Reward/reaching_object: 1.5644
    Episode_Reward/rotating_object: 141.8407
        Episode_Reward/action_rate: -0.1391
          Episode_Reward/joint_vel: -0.0328
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 127598592
                    Iteration time: 2.11s
                      Time elapsed: 00:48:57
                               ETA: 01:04:14

################################################################################
                     [1m Learning iteration 1298/3000 [0m                     

                       Computation: 42388 steps/s (collection: 2.135s, learning 0.184s)
             Mean action noise std: 4.52
          Mean value_function loss: 68.3780
               Mean surrogate loss: -0.0076
                 Mean entropy loss: 88.8773
                       Mean reward: 679.97
               Mean episode length: 220.06
    Episode_Reward/reaching_object: 1.5553
    Episode_Reward/rotating_object: 141.5265
        Episode_Reward/action_rate: -0.1392
          Episode_Reward/joint_vel: -0.0329
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 127696896
                    Iteration time: 2.32s
                      Time elapsed: 00:48:59
                               ETA: 01:04:12

################################################################################
                     [1m Learning iteration 1299/3000 [0m                     

                       Computation: 41477 steps/s (collection: 2.189s, learning 0.181s)
             Mean action noise std: 4.53
          Mean value_function loss: 52.1000
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 88.9067
                       Mean reward: 733.56
               Mean episode length: 236.75
    Episode_Reward/reaching_object: 1.5963
    Episode_Reward/rotating_object: 145.6506
        Episode_Reward/action_rate: -0.1428
          Episode_Reward/joint_vel: -0.0333
      Episode_Termination/time_out: 17.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 127795200
                    Iteration time: 2.37s
                      Time elapsed: 00:49:02
                               ETA: 01:04:09

################################################################################
                     [1m Learning iteration 1300/3000 [0m                     

                       Computation: 40731 steps/s (collection: 2.238s, learning 0.175s)
             Mean action noise std: 4.53
          Mean value_function loss: 63.2561
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 88.9259
                       Mean reward: 703.17
               Mean episode length: 227.03
    Episode_Reward/reaching_object: 1.5568
    Episode_Reward/rotating_object: 143.7403
        Episode_Reward/action_rate: -0.1398
          Episode_Reward/joint_vel: -0.0319
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 127893504
                    Iteration time: 2.41s
                      Time elapsed: 00:49:04
                               ETA: 01:04:07

################################################################################
                     [1m Learning iteration 1301/3000 [0m                     

                       Computation: 42257 steps/s (collection: 2.158s, learning 0.169s)
             Mean action noise std: 4.53
          Mean value_function loss: 53.0673
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 88.9383
                       Mean reward: 738.20
               Mean episode length: 235.35
    Episode_Reward/reaching_object: 1.5974
    Episode_Reward/rotating_object: 146.9316
        Episode_Reward/action_rate: -0.1428
          Episode_Reward/joint_vel: -0.0326
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 127991808
                    Iteration time: 2.33s
                      Time elapsed: 00:49:07
                               ETA: 01:04:05

################################################################################
                     [1m Learning iteration 1302/3000 [0m                     

                       Computation: 44143 steps/s (collection: 2.046s, learning 0.181s)
             Mean action noise std: 4.53
          Mean value_function loss: 49.6353
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 88.9548
                       Mean reward: 743.82
               Mean episode length: 239.08
    Episode_Reward/reaching_object: 1.6264
    Episode_Reward/rotating_object: 149.2119
        Episode_Reward/action_rate: -0.1460
          Episode_Reward/joint_vel: -0.0323
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 128090112
                    Iteration time: 2.23s
                      Time elapsed: 00:49:09
                               ETA: 01:04:03

################################################################################
                     [1m Learning iteration 1303/3000 [0m                     

                       Computation: 43769 steps/s (collection: 2.143s, learning 0.103s)
             Mean action noise std: 4.54
          Mean value_function loss: 57.1646
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 88.9659
                       Mean reward: 724.07
               Mean episode length: 234.78
    Episode_Reward/reaching_object: 1.5617
    Episode_Reward/rotating_object: 143.7857
        Episode_Reward/action_rate: -0.1411
          Episode_Reward/joint_vel: -0.0325
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 128188416
                    Iteration time: 2.25s
                      Time elapsed: 00:49:11
                               ETA: 01:04:01

################################################################################
                     [1m Learning iteration 1304/3000 [0m                     

                       Computation: 47629 steps/s (collection: 1.956s, learning 0.108s)
             Mean action noise std: 4.54
          Mean value_function loss: 52.6982
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 88.9813
                       Mean reward: 729.66
               Mean episode length: 236.58
    Episode_Reward/reaching_object: 1.6061
    Episode_Reward/rotating_object: 146.9494
        Episode_Reward/action_rate: -0.1447
          Episode_Reward/joint_vel: -0.0328
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 128286720
                    Iteration time: 2.06s
                      Time elapsed: 00:49:13
                               ETA: 01:03:58

################################################################################
                     [1m Learning iteration 1305/3000 [0m                     

                       Computation: 46262 steps/s (collection: 1.989s, learning 0.136s)
             Mean action noise std: 4.54
          Mean value_function loss: 61.8424
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 88.9974
                       Mean reward: 744.14
               Mean episode length: 236.74
    Episode_Reward/reaching_object: 1.5680
    Episode_Reward/rotating_object: 145.7363
        Episode_Reward/action_rate: -0.1417
          Episode_Reward/joint_vel: -0.0319
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 128385024
                    Iteration time: 2.12s
                      Time elapsed: 00:49:15
                               ETA: 01:03:56

################################################################################
                     [1m Learning iteration 1306/3000 [0m                     

                       Computation: 46554 steps/s (collection: 1.970s, learning 0.142s)
             Mean action noise std: 4.54
          Mean value_function loss: 54.9653
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 89.0098
                       Mean reward: 706.69
               Mean episode length: 232.18
    Episode_Reward/reaching_object: 1.5757
    Episode_Reward/rotating_object: 142.8065
        Episode_Reward/action_rate: -0.1418
          Episode_Reward/joint_vel: -0.0333
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 128483328
                    Iteration time: 2.11s
                      Time elapsed: 00:49:17
                               ETA: 01:03:53

################################################################################
                     [1m Learning iteration 1307/3000 [0m                     

                       Computation: 43922 steps/s (collection: 2.037s, learning 0.201s)
             Mean action noise std: 4.55
          Mean value_function loss: 63.3980
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 89.0294
                       Mean reward: 701.98
               Mean episode length: 229.71
    Episode_Reward/reaching_object: 1.5874
    Episode_Reward/rotating_object: 144.2249
        Episode_Reward/action_rate: -0.1440
          Episode_Reward/joint_vel: -0.0340
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 128581632
                    Iteration time: 2.24s
                      Time elapsed: 00:49:20
                               ETA: 01:03:51

################################################################################
                     [1m Learning iteration 1308/3000 [0m                     

                       Computation: 47306 steps/s (collection: 1.977s, learning 0.101s)
             Mean action noise std: 4.55
          Mean value_function loss: 53.3132
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 89.0436
                       Mean reward: 695.83
               Mean episode length: 225.72
    Episode_Reward/reaching_object: 1.6097
    Episode_Reward/rotating_object: 148.0472
        Episode_Reward/action_rate: -0.1452
          Episode_Reward/joint_vel: -0.0325
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 128679936
                    Iteration time: 2.08s
                      Time elapsed: 00:49:22
                               ETA: 01:03:48

################################################################################
                     [1m Learning iteration 1309/3000 [0m                     

                       Computation: 43272 steps/s (collection: 2.061s, learning 0.211s)
             Mean action noise std: 4.55
          Mean value_function loss: 61.5603
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 89.0563
                       Mean reward: 737.42
               Mean episode length: 235.08
    Episode_Reward/reaching_object: 1.5919
    Episode_Reward/rotating_object: 147.6542
        Episode_Reward/action_rate: -0.1440
          Episode_Reward/joint_vel: -0.0317
      Episode_Termination/time_out: 17.7083
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 128778240
                    Iteration time: 2.27s
                      Time elapsed: 00:49:24
                               ETA: 01:03:46

################################################################################
                     [1m Learning iteration 1310/3000 [0m                     

                       Computation: 45801 steps/s (collection: 2.044s, learning 0.102s)
             Mean action noise std: 4.55
          Mean value_function loss: 61.9725
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 89.0693
                       Mean reward: 720.97
               Mean episode length: 229.95
    Episode_Reward/reaching_object: 1.5587
    Episode_Reward/rotating_object: 144.8323
        Episode_Reward/action_rate: -0.1424
          Episode_Reward/joint_vel: -0.0322
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 128876544
                    Iteration time: 2.15s
                      Time elapsed: 00:49:26
                               ETA: 01:03:44

################################################################################
                     [1m Learning iteration 1311/3000 [0m                     

                       Computation: 47012 steps/s (collection: 1.970s, learning 0.121s)
             Mean action noise std: 4.55
          Mean value_function loss: 54.3496
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 89.0778
                       Mean reward: 765.76
               Mean episode length: 242.12
    Episode_Reward/reaching_object: 1.6123
    Episode_Reward/rotating_object: 150.9382
        Episode_Reward/action_rate: -0.1478
          Episode_Reward/joint_vel: -0.0333
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 128974848
                    Iteration time: 2.09s
                      Time elapsed: 00:49:28
                               ETA: 01:03:41

################################################################################
                     [1m Learning iteration 1312/3000 [0m                     

                       Computation: 41095 steps/s (collection: 2.254s, learning 0.138s)
             Mean action noise std: 4.56
          Mean value_function loss: 65.3162
               Mean surrogate loss: -0.0068
                 Mean entropy loss: 89.0869
                       Mean reward: 706.70
               Mean episode length: 227.34
    Episode_Reward/reaching_object: 1.5480
    Episode_Reward/rotating_object: 143.5379
        Episode_Reward/action_rate: -0.1417
          Episode_Reward/joint_vel: -0.0327
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 129073152
                    Iteration time: 2.39s
                      Time elapsed: 00:49:31
                               ETA: 01:03:39

################################################################################
                     [1m Learning iteration 1313/3000 [0m                     

                       Computation: 46798 steps/s (collection: 1.961s, learning 0.140s)
             Mean action noise std: 4.56
          Mean value_function loss: 53.6082
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 89.1125
                       Mean reward: 737.72
               Mean episode length: 236.86
    Episode_Reward/reaching_object: 1.5942
    Episode_Reward/rotating_object: 147.7869
        Episode_Reward/action_rate: -0.1453
          Episode_Reward/joint_vel: -0.0326
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 129171456
                    Iteration time: 2.10s
                      Time elapsed: 00:49:33
                               ETA: 01:03:37

################################################################################
                     [1m Learning iteration 1314/3000 [0m                     

                       Computation: 48054 steps/s (collection: 1.897s, learning 0.149s)
             Mean action noise std: 4.56
          Mean value_function loss: 52.7919
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 89.1301
                       Mean reward: 703.72
               Mean episode length: 234.07
    Episode_Reward/reaching_object: 1.5798
    Episode_Reward/rotating_object: 144.1654
        Episode_Reward/action_rate: -0.1442
          Episode_Reward/joint_vel: -0.0324
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 129269760
                    Iteration time: 2.05s
                      Time elapsed: 00:49:35
                               ETA: 01:03:34

################################################################################
                     [1m Learning iteration 1315/3000 [0m                     

                       Computation: 46694 steps/s (collection: 1.951s, learning 0.154s)
             Mean action noise std: 4.56
          Mean value_function loss: 62.5225
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 89.1404
                       Mean reward: 750.12
               Mean episode length: 239.51
    Episode_Reward/reaching_object: 1.5767
    Episode_Reward/rotating_object: 147.2420
        Episode_Reward/action_rate: -0.1446
          Episode_Reward/joint_vel: -0.0319
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 129368064
                    Iteration time: 2.11s
                      Time elapsed: 00:49:37
                               ETA: 01:03:32

################################################################################
                     [1m Learning iteration 1316/3000 [0m                     

                       Computation: 44631 steps/s (collection: 2.009s, learning 0.194s)
             Mean action noise std: 4.57
          Mean value_function loss: 44.3537
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 89.1537
                       Mean reward: 768.12
               Mean episode length: 244.57
    Episode_Reward/reaching_object: 1.6246
    Episode_Reward/rotating_object: 151.2899
        Episode_Reward/action_rate: -0.1490
          Episode_Reward/joint_vel: -0.0322
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.6250
--------------------------------------------------------------------------------
                   Total timesteps: 129466368
                    Iteration time: 2.20s
                      Time elapsed: 00:49:39
                               ETA: 01:03:29

################################################################################
                     [1m Learning iteration 1317/3000 [0m                     

                       Computation: 47688 steps/s (collection: 1.963s, learning 0.099s)
             Mean action noise std: 4.57
          Mean value_function loss: 51.7118
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 89.1691
                       Mean reward: 727.29
               Mean episode length: 234.76
    Episode_Reward/reaching_object: 1.5698
    Episode_Reward/rotating_object: 144.5007
        Episode_Reward/action_rate: -0.1447
          Episode_Reward/joint_vel: -0.0337
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 129564672
                    Iteration time: 2.06s
                      Time elapsed: 00:49:41
                               ETA: 01:03:27

################################################################################
                     [1m Learning iteration 1318/3000 [0m                     

                       Computation: 48380 steps/s (collection: 1.916s, learning 0.116s)
             Mean action noise std: 4.57
          Mean value_function loss: 56.0480
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 89.1925
                       Mean reward: 743.51
               Mean episode length: 235.68
    Episode_Reward/reaching_object: 1.5862
    Episode_Reward/rotating_object: 146.4653
        Episode_Reward/action_rate: -0.1451
          Episode_Reward/joint_vel: -0.0324
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 129662976
                    Iteration time: 2.03s
                      Time elapsed: 00:49:43
                               ETA: 01:03:24

################################################################################
                     [1m Learning iteration 1319/3000 [0m                     

                       Computation: 48659 steps/s (collection: 1.907s, learning 0.113s)
             Mean action noise std: 4.57
          Mean value_function loss: 58.5972
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 89.2099
                       Mean reward: 760.98
               Mean episode length: 242.41
    Episode_Reward/reaching_object: 1.5844
    Episode_Reward/rotating_object: 146.1438
        Episode_Reward/action_rate: -0.1454
          Episode_Reward/joint_vel: -0.0328
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 129761280
                    Iteration time: 2.02s
                      Time elapsed: 00:49:45
                               ETA: 01:03:22

################################################################################
                     [1m Learning iteration 1320/3000 [0m                     

                       Computation: 47350 steps/s (collection: 1.964s, learning 0.112s)
             Mean action noise std: 4.58
          Mean value_function loss: 64.4789
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 89.2211
                       Mean reward: 716.31
               Mean episode length: 234.80
    Episode_Reward/reaching_object: 1.5694
    Episode_Reward/rotating_object: 144.2218
        Episode_Reward/action_rate: -0.1447
          Episode_Reward/joint_vel: -0.0329
      Episode_Termination/time_out: 17.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 129859584
                    Iteration time: 2.08s
                      Time elapsed: 00:49:47
                               ETA: 01:03:19

################################################################################
                     [1m Learning iteration 1321/3000 [0m                     

                       Computation: 48130 steps/s (collection: 1.936s, learning 0.106s)
             Mean action noise std: 4.58
          Mean value_function loss: 65.5128
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 89.2395
                       Mean reward: 703.22
               Mean episode length: 231.57
    Episode_Reward/reaching_object: 1.5432
    Episode_Reward/rotating_object: 140.5664
        Episode_Reward/action_rate: -0.1422
          Episode_Reward/joint_vel: -0.0330
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0833
     Episode_Termination/robot_out: 1.6250
--------------------------------------------------------------------------------
                   Total timesteps: 129957888
                    Iteration time: 2.04s
                      Time elapsed: 00:49:49
                               ETA: 01:03:17

################################################################################
                     [1m Learning iteration 1322/3000 [0m                     

                       Computation: 47171 steps/s (collection: 1.965s, learning 0.119s)
             Mean action noise std: 4.58
          Mean value_function loss: 64.4981
               Mean surrogate loss: -0.0067
                 Mean entropy loss: 89.2526
                       Mean reward: 724.61
               Mean episode length: 233.91
    Episode_Reward/reaching_object: 1.5489
    Episode_Reward/rotating_object: 141.0201
        Episode_Reward/action_rate: -0.1425
          Episode_Reward/joint_vel: -0.0333
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7083
--------------------------------------------------------------------------------
                   Total timesteps: 130056192
                    Iteration time: 2.08s
                      Time elapsed: 00:49:51
                               ETA: 01:03:14

################################################################################
                     [1m Learning iteration 1323/3000 [0m                     

                       Computation: 47395 steps/s (collection: 1.950s, learning 0.125s)
             Mean action noise std: 4.58
          Mean value_function loss: 55.1789
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 89.2698
                       Mean reward: 728.37
               Mean episode length: 233.51
    Episode_Reward/reaching_object: 1.5739
    Episode_Reward/rotating_object: 144.9890
        Episode_Reward/action_rate: -0.1446
          Episode_Reward/joint_vel: -0.0321
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 130154496
                    Iteration time: 2.07s
                      Time elapsed: 00:49:53
                               ETA: 01:03:12

################################################################################
                     [1m Learning iteration 1324/3000 [0m                     

                       Computation: 48287 steps/s (collection: 1.929s, learning 0.107s)
             Mean action noise std: 4.59
          Mean value_function loss: 57.4212
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 89.2857
                       Mean reward: 745.96
               Mean episode length: 234.53
    Episode_Reward/reaching_object: 1.5939
    Episode_Reward/rotating_object: 146.9903
        Episode_Reward/action_rate: -0.1460
          Episode_Reward/joint_vel: -0.0330
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 130252800
                    Iteration time: 2.04s
                      Time elapsed: 00:49:55
                               ETA: 01:03:09

################################################################################
                     [1m Learning iteration 1325/3000 [0m                     

                       Computation: 46272 steps/s (collection: 1.953s, learning 0.172s)
             Mean action noise std: 4.59
          Mean value_function loss: 50.3625
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 89.3021
                       Mean reward: 735.48
               Mean episode length: 233.51
    Episode_Reward/reaching_object: 1.5765
    Episode_Reward/rotating_object: 144.8087
        Episode_Reward/action_rate: -0.1439
          Episode_Reward/joint_vel: -0.0321
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 130351104
                    Iteration time: 2.12s
                      Time elapsed: 00:49:58
                               ETA: 01:03:07

################################################################################
                     [1m Learning iteration 1326/3000 [0m                     

                       Computation: 46701 steps/s (collection: 1.955s, learning 0.150s)
             Mean action noise std: 4.59
          Mean value_function loss: 50.0059
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 89.3229
                       Mean reward: 730.73
               Mean episode length: 236.15
    Episode_Reward/reaching_object: 1.5980
    Episode_Reward/rotating_object: 145.4560
        Episode_Reward/action_rate: -0.1459
          Episode_Reward/joint_vel: -0.0337
      Episode_Termination/time_out: 14.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 130449408
                    Iteration time: 2.10s
                      Time elapsed: 00:50:00
                               ETA: 01:03:04

################################################################################
                     [1m Learning iteration 1327/3000 [0m                     

                       Computation: 48258 steps/s (collection: 1.918s, learning 0.119s)
             Mean action noise std: 4.60
          Mean value_function loss: 57.0238
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 89.3476
                       Mean reward: 763.66
               Mean episode length: 236.77
    Episode_Reward/reaching_object: 1.5863
    Episode_Reward/rotating_object: 146.6515
        Episode_Reward/action_rate: -0.1456
          Episode_Reward/joint_vel: -0.0326
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 130547712
                    Iteration time: 2.04s
                      Time elapsed: 00:50:02
                               ETA: 01:03:02

################################################################################
                     [1m Learning iteration 1328/3000 [0m                     

                       Computation: 47281 steps/s (collection: 1.958s, learning 0.122s)
             Mean action noise std: 4.60
          Mean value_function loss: 53.6076
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 89.3694
                       Mean reward: 760.80
               Mean episode length: 238.93
    Episode_Reward/reaching_object: 1.6127
    Episode_Reward/rotating_object: 149.7220
        Episode_Reward/action_rate: -0.1475
          Episode_Reward/joint_vel: -0.0312
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 130646016
                    Iteration time: 2.08s
                      Time elapsed: 00:50:04
                               ETA: 01:02:59

################################################################################
                     [1m Learning iteration 1329/3000 [0m                     

                       Computation: 47380 steps/s (collection: 1.930s, learning 0.145s)
             Mean action noise std: 4.61
          Mean value_function loss: 61.6287
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 89.3944
                       Mean reward: 712.50
               Mean episode length: 228.57
    Episode_Reward/reaching_object: 1.5473
    Episode_Reward/rotating_object: 141.3174
        Episode_Reward/action_rate: -0.1423
          Episode_Reward/joint_vel: -0.0317
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 130744320
                    Iteration time: 2.07s
                      Time elapsed: 00:50:06
                               ETA: 01:02:57

################################################################################
                     [1m Learning iteration 1330/3000 [0m                     

                       Computation: 47287 steps/s (collection: 1.973s, learning 0.106s)
             Mean action noise std: 4.61
          Mean value_function loss: 52.2501
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 89.4203
                       Mean reward: 744.34
               Mean episode length: 234.79
    Episode_Reward/reaching_object: 1.5747
    Episode_Reward/rotating_object: 145.4534
        Episode_Reward/action_rate: -0.1461
          Episode_Reward/joint_vel: -0.0329
      Episode_Termination/time_out: 17.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 130842624
                    Iteration time: 2.08s
                      Time elapsed: 00:50:08
                               ETA: 01:02:54

################################################################################
                     [1m Learning iteration 1331/3000 [0m                     

                       Computation: 47907 steps/s (collection: 1.932s, learning 0.120s)
             Mean action noise std: 4.61
          Mean value_function loss: 60.1174
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 89.4387
                       Mean reward: 720.35
               Mean episode length: 228.97
    Episode_Reward/reaching_object: 1.5882
    Episode_Reward/rotating_object: 146.1034
        Episode_Reward/action_rate: -0.1462
          Episode_Reward/joint_vel: -0.0321
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 130940928
                    Iteration time: 2.05s
                      Time elapsed: 00:50:10
                               ETA: 01:02:52

################################################################################
                     [1m Learning iteration 1332/3000 [0m                     

                       Computation: 47586 steps/s (collection: 1.945s, learning 0.121s)
             Mean action noise std: 4.62
          Mean value_function loss: 46.0534
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 89.4582
                       Mean reward: 770.22
               Mean episode length: 243.54
    Episode_Reward/reaching_object: 1.6001
    Episode_Reward/rotating_object: 148.6864
        Episode_Reward/action_rate: -0.1480
          Episode_Reward/joint_vel: -0.0312
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 131039232
                    Iteration time: 2.07s
                      Time elapsed: 00:50:12
                               ETA: 01:02:49

################################################################################
                     [1m Learning iteration 1333/3000 [0m                     

                       Computation: 19506 steps/s (collection: 4.916s, learning 0.123s)
             Mean action noise std: 4.62
          Mean value_function loss: 62.5574
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 89.4816
                       Mean reward: 724.00
               Mean episode length: 233.43
    Episode_Reward/reaching_object: 1.5616
    Episode_Reward/rotating_object: 143.8391
        Episode_Reward/action_rate: -0.1454
          Episode_Reward/joint_vel: -0.0322
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.7500
--------------------------------------------------------------------------------
                   Total timesteps: 131137536
                    Iteration time: 5.04s
                      Time elapsed: 00:50:17
                               ETA: 01:02:50

################################################################################
                     [1m Learning iteration 1334/3000 [0m                     

                       Computation: 14152 steps/s (collection: 6.796s, learning 0.150s)
             Mean action noise std: 4.62
          Mean value_function loss: 47.2715
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 89.5090
                       Mean reward: 768.17
               Mean episode length: 241.66
    Episode_Reward/reaching_object: 1.5825
    Episode_Reward/rotating_object: 148.9510
        Episode_Reward/action_rate: -0.1481
          Episode_Reward/joint_vel: -0.0313
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 131235840
                    Iteration time: 6.95s
                      Time elapsed: 00:50:24
                               ETA: 01:02:54

################################################################################
                     [1m Learning iteration 1335/3000 [0m                     

                       Computation: 14351 steps/s (collection: 6.732s, learning 0.118s)
             Mean action noise std: 4.62
          Mean value_function loss: 60.6466
               Mean surrogate loss: 0.0294
                 Mean entropy loss: 89.5300
                       Mean reward: 746.71
               Mean episode length: 241.78
    Episode_Reward/reaching_object: 1.5818
    Episode_Reward/rotating_object: 147.2141
        Episode_Reward/action_rate: -0.1489
          Episode_Reward/joint_vel: -0.0328
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 131334144
                    Iteration time: 6.85s
                      Time elapsed: 00:50:31
                               ETA: 01:02:57

################################################################################
                     [1m Learning iteration 1336/3000 [0m                     

                       Computation: 14922 steps/s (collection: 6.450s, learning 0.138s)
             Mean action noise std: 4.62
          Mean value_function loss: 47.4308
               Mean surrogate loss: 0.0015
                 Mean entropy loss: 89.5318
                       Mean reward: 729.90
               Mean episode length: 236.72
    Episode_Reward/reaching_object: 1.5793
    Episode_Reward/rotating_object: 148.1212
        Episode_Reward/action_rate: -0.1495
          Episode_Reward/joint_vel: -0.0330
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 131432448
                    Iteration time: 6.59s
                      Time elapsed: 00:50:38
                               ETA: 01:03:01

################################################################################
                     [1m Learning iteration 1337/3000 [0m                     

                       Computation: 14189 steps/s (collection: 6.776s, learning 0.152s)
             Mean action noise std: 4.62
          Mean value_function loss: 54.8107
               Mean surrogate loss: -0.0005
                 Mean entropy loss: 89.5323
                       Mean reward: 731.34
               Mean episode length: 232.80
    Episode_Reward/reaching_object: 1.5216
    Episode_Reward/rotating_object: 144.7250
        Episode_Reward/action_rate: -0.1454
          Episode_Reward/joint_vel: -0.0333
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 131530752
                    Iteration time: 6.93s
                      Time elapsed: 00:50:44
                               ETA: 01:03:04

################################################################################
                     [1m Learning iteration 1338/3000 [0m                     

                       Computation: 14442 steps/s (collection: 6.649s, learning 0.158s)
             Mean action noise std: 4.63
          Mean value_function loss: 46.0902
               Mean surrogate loss: -0.0029
                 Mean entropy loss: 89.5349
                       Mean reward: 762.26
               Mean episode length: 243.80
    Episode_Reward/reaching_object: 1.5637
    Episode_Reward/rotating_object: 148.2109
        Episode_Reward/action_rate: -0.1488
          Episode_Reward/joint_vel: -0.0323
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 131629056
                    Iteration time: 6.81s
                      Time elapsed: 00:50:51
                               ETA: 01:03:07

################################################################################
                     [1m Learning iteration 1339/3000 [0m                     

                       Computation: 14341 steps/s (collection: 6.680s, learning 0.174s)
             Mean action noise std: 4.63
          Mean value_function loss: 47.9006
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 89.5418
                       Mean reward: 754.40
               Mean episode length: 242.20
    Episode_Reward/reaching_object: 1.5801
    Episode_Reward/rotating_object: 149.0136
        Episode_Reward/action_rate: -0.1502
          Episode_Reward/joint_vel: -0.0326
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 131727360
                    Iteration time: 6.85s
                      Time elapsed: 00:50:58
                               ETA: 01:03:11

################################################################################
                     [1m Learning iteration 1340/3000 [0m                     

                       Computation: 14376 steps/s (collection: 6.698s, learning 0.140s)
             Mean action noise std: 4.63
          Mean value_function loss: 49.8568
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 89.5491
                       Mean reward: 745.65
               Mean episode length: 238.70
    Episode_Reward/reaching_object: 1.5559
    Episode_Reward/rotating_object: 147.3194
        Episode_Reward/action_rate: -0.1485
          Episode_Reward/joint_vel: -0.0315
      Episode_Termination/time_out: 17.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 131825664
                    Iteration time: 6.84s
                      Time elapsed: 00:51:05
                               ETA: 01:03:14

################################################################################
                     [1m Learning iteration 1341/3000 [0m                     

                       Computation: 13624 steps/s (collection: 7.091s, learning 0.124s)
             Mean action noise std: 4.63
          Mean value_function loss: 61.0239
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 89.5628
                       Mean reward: 740.68
               Mean episode length: 233.47
    Episode_Reward/reaching_object: 1.5563
    Episode_Reward/rotating_object: 148.3865
        Episode_Reward/action_rate: -0.1483
          Episode_Reward/joint_vel: -0.0316
      Episode_Termination/time_out: 16.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 131923968
                    Iteration time: 7.22s
                      Time elapsed: 00:51:12
                               ETA: 01:03:18

################################################################################
                     [1m Learning iteration 1342/3000 [0m                     

                       Computation: 48352 steps/s (collection: 1.901s, learning 0.132s)
             Mean action noise std: 4.63
          Mean value_function loss: 61.6735
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 89.5817
                       Mean reward: 729.84
               Mean episode length: 234.11
    Episode_Reward/reaching_object: 1.5411
    Episode_Reward/rotating_object: 144.5337
        Episode_Reward/action_rate: -0.1475
          Episode_Reward/joint_vel: -0.0324
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 132022272
                    Iteration time: 2.03s
                      Time elapsed: 00:51:14
                               ETA: 01:03:15

################################################################################
                     [1m Learning iteration 1343/3000 [0m                     

                       Computation: 50389 steps/s (collection: 1.820s, learning 0.131s)
             Mean action noise std: 4.64
          Mean value_function loss: 57.1612
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 89.5944
                       Mean reward: 753.20
               Mean episode length: 239.43
    Episode_Reward/reaching_object: 1.5840
    Episode_Reward/rotating_object: 147.8746
        Episode_Reward/action_rate: -0.1511
          Episode_Reward/joint_vel: -0.0330
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 132120576
                    Iteration time: 1.95s
                      Time elapsed: 00:51:16
                               ETA: 01:03:13

################################################################################
                     [1m Learning iteration 1344/3000 [0m                     

                       Computation: 47531 steps/s (collection: 1.895s, learning 0.174s)
             Mean action noise std: 4.64
          Mean value_function loss: 56.9401
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 89.6119
                       Mean reward: 757.21
               Mean episode length: 239.84
    Episode_Reward/reaching_object: 1.5290
    Episode_Reward/rotating_object: 143.9392
        Episode_Reward/action_rate: -0.1467
          Episode_Reward/joint_vel: -0.0329
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 132218880
                    Iteration time: 2.07s
                      Time elapsed: 00:51:18
                               ETA: 01:03:10

################################################################################
                     [1m Learning iteration 1345/3000 [0m                     

                       Computation: 49927 steps/s (collection: 1.814s, learning 0.155s)
             Mean action noise std: 4.64
          Mean value_function loss: 54.8627
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 89.6331
                       Mean reward: 745.58
               Mean episode length: 236.13
    Episode_Reward/reaching_object: 1.5658
    Episode_Reward/rotating_object: 147.7330
        Episode_Reward/action_rate: -0.1497
          Episode_Reward/joint_vel: -0.0325
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 132317184
                    Iteration time: 1.97s
                      Time elapsed: 00:51:20
                               ETA: 01:03:07

################################################################################
                     [1m Learning iteration 1346/3000 [0m                     

                       Computation: 48016 steps/s (collection: 1.932s, learning 0.115s)
             Mean action noise std: 4.64
          Mean value_function loss: 63.3954
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 89.6464
                       Mean reward: 752.96
               Mean episode length: 235.79
    Episode_Reward/reaching_object: 1.5509
    Episode_Reward/rotating_object: 147.7270
        Episode_Reward/action_rate: -0.1490
          Episode_Reward/joint_vel: -0.0324
      Episode_Termination/time_out: 17.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 132415488
                    Iteration time: 2.05s
                      Time elapsed: 00:51:22
                               ETA: 01:03:05

################################################################################
                     [1m Learning iteration 1347/3000 [0m                     

                       Computation: 47545 steps/s (collection: 1.926s, learning 0.142s)
             Mean action noise std: 4.65
          Mean value_function loss: 56.8123
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 89.6654
                       Mean reward: 759.34
               Mean episode length: 241.71
    Episode_Reward/reaching_object: 1.5382
    Episode_Reward/rotating_object: 147.4580
        Episode_Reward/action_rate: -0.1487
          Episode_Reward/joint_vel: -0.0322
      Episode_Termination/time_out: 14.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 132513792
                    Iteration time: 2.07s
                      Time elapsed: 00:51:24
                               ETA: 01:03:02

################################################################################
                     [1m Learning iteration 1348/3000 [0m                     

                       Computation: 49699 steps/s (collection: 1.850s, learning 0.128s)
             Mean action noise std: 4.65
          Mean value_function loss: 42.4494
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 89.6793
                       Mean reward: 741.65
               Mean episode length: 236.38
    Episode_Reward/reaching_object: 1.5669
    Episode_Reward/rotating_object: 148.7065
        Episode_Reward/action_rate: -0.1514
          Episode_Reward/joint_vel: -0.0332
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 132612096
                    Iteration time: 1.98s
                      Time elapsed: 00:51:26
                               ETA: 01:03:00

################################################################################
                     [1m Learning iteration 1349/3000 [0m                     

                       Computation: 51791 steps/s (collection: 1.791s, learning 0.107s)
             Mean action noise std: 4.65
          Mean value_function loss: 46.2699
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 89.6956
                       Mean reward: 766.28
               Mean episode length: 240.50
    Episode_Reward/reaching_object: 1.5622
    Episode_Reward/rotating_object: 148.5146
        Episode_Reward/action_rate: -0.1502
          Episode_Reward/joint_vel: -0.0323
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 132710400
                    Iteration time: 1.90s
                      Time elapsed: 00:51:28
                               ETA: 01:02:57

################################################################################
                     [1m Learning iteration 1350/3000 [0m                     

                       Computation: 49440 steps/s (collection: 1.851s, learning 0.137s)
             Mean action noise std: 4.66
          Mean value_function loss: 54.1625
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 89.7159
                       Mean reward: 754.03
               Mean episode length: 241.26
    Episode_Reward/reaching_object: 1.5694
    Episode_Reward/rotating_object: 148.6093
        Episode_Reward/action_rate: -0.1512
          Episode_Reward/joint_vel: -0.0329
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 132808704
                    Iteration time: 1.99s
                      Time elapsed: 00:51:30
                               ETA: 01:02:54

################################################################################
                     [1m Learning iteration 1351/3000 [0m                     

                       Computation: 50928 steps/s (collection: 1.830s, learning 0.100s)
             Mean action noise std: 4.66
          Mean value_function loss: 61.6659
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 89.7418
                       Mean reward: 755.63
               Mean episode length: 237.29
    Episode_Reward/reaching_object: 1.5773
    Episode_Reward/rotating_object: 150.9632
        Episode_Reward/action_rate: -0.1514
          Episode_Reward/joint_vel: -0.0314
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 132907008
                    Iteration time: 1.93s
                      Time elapsed: 00:51:32
                               ETA: 01:02:51

################################################################################
                     [1m Learning iteration 1352/3000 [0m                     

                       Computation: 52285 steps/s (collection: 1.786s, learning 0.094s)
             Mean action noise std: 4.66
          Mean value_function loss: 62.4247
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 89.7663
                       Mean reward: 703.24
               Mean episode length: 228.99
    Episode_Reward/reaching_object: 1.5680
    Episode_Reward/rotating_object: 145.6854
        Episode_Reward/action_rate: -0.1508
          Episode_Reward/joint_vel: -0.0341
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 133005312
                    Iteration time: 1.88s
                      Time elapsed: 00:51:34
                               ETA: 01:02:49

################################################################################
                     [1m Learning iteration 1353/3000 [0m                     

                       Computation: 50160 steps/s (collection: 1.833s, learning 0.127s)
             Mean action noise std: 4.67
          Mean value_function loss: 51.7960
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 89.7883
                       Mean reward: 737.01
               Mean episode length: 236.39
    Episode_Reward/reaching_object: 1.5924
    Episode_Reward/rotating_object: 146.8419
        Episode_Reward/action_rate: -0.1514
          Episode_Reward/joint_vel: -0.0337
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 133103616
                    Iteration time: 1.96s
                      Time elapsed: 00:51:36
                               ETA: 01:02:46

################################################################################
                     [1m Learning iteration 1354/3000 [0m                     

                       Computation: 48003 steps/s (collection: 1.868s, learning 0.180s)
             Mean action noise std: 4.67
          Mean value_function loss: 58.5396
               Mean surrogate loss: -0.0037
                 Mean entropy loss: 89.8041
                       Mean reward: 734.19
               Mean episode length: 237.89
    Episode_Reward/reaching_object: 1.5661
    Episode_Reward/rotating_object: 145.5326
        Episode_Reward/action_rate: -0.1503
          Episode_Reward/joint_vel: -0.0336
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 133201920
                    Iteration time: 2.05s
                      Time elapsed: 00:51:38
                               ETA: 01:02:43

################################################################################
                     [1m Learning iteration 1355/3000 [0m                     

                       Computation: 50193 steps/s (collection: 1.843s, learning 0.115s)
             Mean action noise std: 4.67
          Mean value_function loss: 55.5718
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 89.8254
                       Mean reward: 758.53
               Mean episode length: 239.47
    Episode_Reward/reaching_object: 1.5665
    Episode_Reward/rotating_object: 145.3241
        Episode_Reward/action_rate: -0.1504
          Episode_Reward/joint_vel: -0.0334
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 133300224
                    Iteration time: 1.96s
                      Time elapsed: 00:51:40
                               ETA: 01:02:41

################################################################################
                     [1m Learning iteration 1356/3000 [0m                     

                       Computation: 51243 steps/s (collection: 1.800s, learning 0.118s)
             Mean action noise std: 4.67
          Mean value_function loss: 47.6817
               Mean surrogate loss: -0.0014
                 Mean entropy loss: 89.8427
                       Mean reward: 727.04
               Mean episode length: 232.00
    Episode_Reward/reaching_object: 1.5883
    Episode_Reward/rotating_object: 146.4314
        Episode_Reward/action_rate: -0.1521
          Episode_Reward/joint_vel: -0.0337
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 133398528
                    Iteration time: 1.92s
                      Time elapsed: 00:51:42
                               ETA: 01:02:38

################################################################################
                     [1m Learning iteration 1357/3000 [0m                     

                       Computation: 49763 steps/s (collection: 1.882s, learning 0.094s)
             Mean action noise std: 4.68
          Mean value_function loss: 56.7852
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 89.8512
                       Mean reward: 716.24
               Mean episode length: 228.87
    Episode_Reward/reaching_object: 1.5473
    Episode_Reward/rotating_object: 144.3286
        Episode_Reward/action_rate: -0.1477
          Episode_Reward/joint_vel: -0.0319
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 133496832
                    Iteration time: 1.98s
                      Time elapsed: 00:51:44
                               ETA: 01:02:35

################################################################################
                     [1m Learning iteration 1358/3000 [0m                     

                       Computation: 48679 steps/s (collection: 1.899s, learning 0.120s)
             Mean action noise std: 4.68
          Mean value_function loss: 53.8542
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 89.8657
                       Mean reward: 695.09
               Mean episode length: 230.92
    Episode_Reward/reaching_object: 1.5785
    Episode_Reward/rotating_object: 144.9663
        Episode_Reward/action_rate: -0.1515
          Episode_Reward/joint_vel: -0.0337
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 133595136
                    Iteration time: 2.02s
                      Time elapsed: 00:51:46
                               ETA: 01:02:33

################################################################################
                     [1m Learning iteration 1359/3000 [0m                     

                       Computation: 52203 steps/s (collection: 1.785s, learning 0.098s)
             Mean action noise std: 4.68
          Mean value_function loss: 56.9864
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 89.8803
                       Mean reward: 722.21
               Mean episode length: 234.53
    Episode_Reward/reaching_object: 1.5793
    Episode_Reward/rotating_object: 146.9856
        Episode_Reward/action_rate: -0.1523
          Episode_Reward/joint_vel: -0.0322
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 133693440
                    Iteration time: 1.88s
                      Time elapsed: 00:51:48
                               ETA: 01:02:30

################################################################################
                     [1m Learning iteration 1360/3000 [0m                     

                       Computation: 50582 steps/s (collection: 1.840s, learning 0.103s)
             Mean action noise std: 4.68
          Mean value_function loss: 46.4721
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 89.8962
                       Mean reward: 758.21
               Mean episode length: 241.49
    Episode_Reward/reaching_object: 1.5796
    Episode_Reward/rotating_object: 147.3651
        Episode_Reward/action_rate: -0.1522
          Episode_Reward/joint_vel: -0.0327
      Episode_Termination/time_out: 14.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 133791744
                    Iteration time: 1.94s
                      Time elapsed: 00:51:50
                               ETA: 01:02:27

################################################################################
                     [1m Learning iteration 1361/3000 [0m                     

                       Computation: 51535 steps/s (collection: 1.797s, learning 0.110s)
             Mean action noise std: 4.69
          Mean value_function loss: 51.0870
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 89.9121
                       Mean reward: 769.14
               Mean episode length: 241.19
    Episode_Reward/reaching_object: 1.5668
    Episode_Reward/rotating_object: 147.7939
        Episode_Reward/action_rate: -0.1513
          Episode_Reward/joint_vel: -0.0319
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 133890048
                    Iteration time: 1.91s
                      Time elapsed: 00:51:52
                               ETA: 01:02:25

################################################################################
                     [1m Learning iteration 1362/3000 [0m                     

                       Computation: 51713 steps/s (collection: 1.794s, learning 0.107s)
             Mean action noise std: 4.69
          Mean value_function loss: 58.9782
               Mean surrogate loss: -0.0038
                 Mean entropy loss: 89.9341
                       Mean reward: 747.29
               Mean episode length: 236.55
    Episode_Reward/reaching_object: 1.5700
    Episode_Reward/rotating_object: 148.5929
        Episode_Reward/action_rate: -0.1525
          Episode_Reward/joint_vel: -0.0316
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 133988352
                    Iteration time: 1.90s
                      Time elapsed: 00:51:53
                               ETA: 01:02:22

################################################################################
                     [1m Learning iteration 1363/3000 [0m                     

                       Computation: 51180 steps/s (collection: 1.776s, learning 0.145s)
             Mean action noise std: 4.69
          Mean value_function loss: 56.1107
               Mean surrogate loss: -0.0006
                 Mean entropy loss: 89.9516
                       Mean reward: 731.58
               Mean episode length: 238.32
    Episode_Reward/reaching_object: 1.5711
    Episode_Reward/rotating_object: 143.8509
        Episode_Reward/action_rate: -0.1521
          Episode_Reward/joint_vel: -0.0351
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 134086656
                    Iteration time: 1.92s
                      Time elapsed: 00:51:55
                               ETA: 01:02:19

################################################################################
                     [1m Learning iteration 1364/3000 [0m                     

                       Computation: 51492 steps/s (collection: 1.776s, learning 0.134s)
             Mean action noise std: 4.69
          Mean value_function loss: 57.2089
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 89.9596
                       Mean reward: 741.67
               Mean episode length: 234.97
    Episode_Reward/reaching_object: 1.5846
    Episode_Reward/rotating_object: 147.8088
        Episode_Reward/action_rate: -0.1529
          Episode_Reward/joint_vel: -0.0322
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 134184960
                    Iteration time: 1.91s
                      Time elapsed: 00:51:57
                               ETA: 01:02:16

################################################################################
                     [1m Learning iteration 1365/3000 [0m                     

                       Computation: 50269 steps/s (collection: 1.810s, learning 0.146s)
             Mean action noise std: 4.69
          Mean value_function loss: 53.0738
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 89.9741
                       Mean reward: 776.58
               Mean episode length: 243.23
    Episode_Reward/reaching_object: 1.6244
    Episode_Reward/rotating_object: 150.8511
        Episode_Reward/action_rate: -0.1552
          Episode_Reward/joint_vel: -0.0317
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 134283264
                    Iteration time: 1.96s
                      Time elapsed: 00:51:59
                               ETA: 01:02:14

################################################################################
                     [1m Learning iteration 1366/3000 [0m                     

                       Computation: 49719 steps/s (collection: 1.799s, learning 0.178s)
             Mean action noise std: 4.70
          Mean value_function loss: 47.1273
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 89.9908
                       Mean reward: 740.80
               Mean episode length: 239.08
    Episode_Reward/reaching_object: 1.5881
    Episode_Reward/rotating_object: 147.1877
        Episode_Reward/action_rate: -0.1530
          Episode_Reward/joint_vel: -0.0332
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 134381568
                    Iteration time: 1.98s
                      Time elapsed: 00:52:01
                               ETA: 01:02:11

################################################################################
                     [1m Learning iteration 1367/3000 [0m                     

                       Computation: 49653 steps/s (collection: 1.842s, learning 0.138s)
             Mean action noise std: 4.70
          Mean value_function loss: 58.9495
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 90.0080
                       Mean reward: 730.86
               Mean episode length: 234.40
    Episode_Reward/reaching_object: 1.5852
    Episode_Reward/rotating_object: 146.9837
        Episode_Reward/action_rate: -0.1533
          Episode_Reward/joint_vel: -0.0341
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 134479872
                    Iteration time: 1.98s
                      Time elapsed: 00:52:03
                               ETA: 01:02:08

################################################################################
                     [1m Learning iteration 1368/3000 [0m                     

                       Computation: 50016 steps/s (collection: 1.858s, learning 0.107s)
             Mean action noise std: 4.70
          Mean value_function loss: 55.7323
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 90.0283
                       Mean reward: 703.82
               Mean episode length: 224.02
    Episode_Reward/reaching_object: 1.5844
    Episode_Reward/rotating_object: 144.7288
        Episode_Reward/action_rate: -0.1520
          Episode_Reward/joint_vel: -0.0333
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 134578176
                    Iteration time: 1.97s
                      Time elapsed: 00:52:05
                               ETA: 01:02:06

################################################################################
                     [1m Learning iteration 1369/3000 [0m                     

                       Computation: 49814 steps/s (collection: 1.856s, learning 0.117s)
             Mean action noise std: 4.71
          Mean value_function loss: 61.2044
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 90.0498
                       Mean reward: 761.86
               Mean episode length: 241.13
    Episode_Reward/reaching_object: 1.6295
    Episode_Reward/rotating_object: 148.9250
        Episode_Reward/action_rate: -0.1558
          Episode_Reward/joint_vel: -0.0327
      Episode_Termination/time_out: 16.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 134676480
                    Iteration time: 1.97s
                      Time elapsed: 00:52:07
                               ETA: 01:02:03

################################################################################
                     [1m Learning iteration 1370/3000 [0m                     

                       Computation: 51389 steps/s (collection: 1.807s, learning 0.106s)
             Mean action noise std: 4.71
          Mean value_function loss: 57.6149
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 90.0701
                       Mean reward: 708.71
               Mean episode length: 228.03
    Episode_Reward/reaching_object: 1.5636
    Episode_Reward/rotating_object: 143.6536
        Episode_Reward/action_rate: -0.1509
          Episode_Reward/joint_vel: -0.0327
      Episode_Termination/time_out: 15.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 134774784
                    Iteration time: 1.91s
                      Time elapsed: 00:52:09
                               ETA: 01:02:00

################################################################################
                     [1m Learning iteration 1371/3000 [0m                     

                       Computation: 52169 steps/s (collection: 1.782s, learning 0.103s)
             Mean action noise std: 4.71
          Mean value_function loss: 50.1232
               Mean surrogate loss: -0.0023
                 Mean entropy loss: 90.0840
                       Mean reward: 742.06
               Mean episode length: 239.20
    Episode_Reward/reaching_object: 1.6207
    Episode_Reward/rotating_object: 148.6618
        Episode_Reward/action_rate: -0.1563
          Episode_Reward/joint_vel: -0.0331
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 134873088
                    Iteration time: 1.88s
                      Time elapsed: 00:52:11
                               ETA: 01:01:58

################################################################################
                     [1m Learning iteration 1372/3000 [0m                     

                       Computation: 50938 steps/s (collection: 1.835s, learning 0.095s)
             Mean action noise std: 4.71
          Mean value_function loss: 51.6820
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 90.0923
                       Mean reward: 759.25
               Mean episode length: 242.42
    Episode_Reward/reaching_object: 1.6188
    Episode_Reward/rotating_object: 148.0481
        Episode_Reward/action_rate: -0.1554
          Episode_Reward/joint_vel: -0.0336
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 134971392
                    Iteration time: 1.93s
                      Time elapsed: 00:52:13
                               ETA: 01:01:55

################################################################################
                     [1m Learning iteration 1373/3000 [0m                     

                       Computation: 47108 steps/s (collection: 1.980s, learning 0.107s)
             Mean action noise std: 4.72
          Mean value_function loss: 51.6995
               Mean surrogate loss: -0.0071
                 Mean entropy loss: 90.1068
                       Mean reward: 745.06
               Mean episode length: 238.32
    Episode_Reward/reaching_object: 1.5913
    Episode_Reward/rotating_object: 146.7599
        Episode_Reward/action_rate: -0.1537
          Episode_Reward/joint_vel: -0.0328
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 135069696
                    Iteration time: 2.09s
                      Time elapsed: 00:52:15
                               ETA: 01:01:52

################################################################################
                     [1m Learning iteration 1374/3000 [0m                     

                       Computation: 49437 steps/s (collection: 1.875s, learning 0.114s)
             Mean action noise std: 4.72
          Mean value_function loss: 55.5289
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 90.1235
                       Mean reward: 754.55
               Mean episode length: 239.60
    Episode_Reward/reaching_object: 1.6107
    Episode_Reward/rotating_object: 148.1097
        Episode_Reward/action_rate: -0.1554
          Episode_Reward/joint_vel: -0.0331
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 135168000
                    Iteration time: 1.99s
                      Time elapsed: 00:52:17
                               ETA: 01:01:50

################################################################################
                     [1m Learning iteration 1375/3000 [0m                     

                       Computation: 50013 steps/s (collection: 1.872s, learning 0.094s)
             Mean action noise std: 4.72
          Mean value_function loss: 49.2306
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 90.1383
                       Mean reward: 735.50
               Mean episode length: 235.48
    Episode_Reward/reaching_object: 1.6098
    Episode_Reward/rotating_object: 148.5484
        Episode_Reward/action_rate: -0.1551
          Episode_Reward/joint_vel: -0.0324
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 135266304
                    Iteration time: 1.97s
                      Time elapsed: 00:52:19
                               ETA: 01:01:47

################################################################################
                     [1m Learning iteration 1376/3000 [0m                     

                       Computation: 50887 steps/s (collection: 1.830s, learning 0.102s)
             Mean action noise std: 4.72
          Mean value_function loss: 59.0589
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 90.1515
                       Mean reward: 710.89
               Mean episode length: 227.86
    Episode_Reward/reaching_object: 1.5729
    Episode_Reward/rotating_object: 145.2519
        Episode_Reward/action_rate: -0.1527
          Episode_Reward/joint_vel: -0.0330
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 135364608
                    Iteration time: 1.93s
                      Time elapsed: 00:52:21
                               ETA: 01:01:44

################################################################################
                     [1m Learning iteration 1377/3000 [0m                     

                       Computation: 51305 steps/s (collection: 1.823s, learning 0.094s)
             Mean action noise std: 4.73
          Mean value_function loss: 44.3077
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 90.1659
                       Mean reward: 765.22
               Mean episode length: 242.09
    Episode_Reward/reaching_object: 1.6257
    Episode_Reward/rotating_object: 149.2943
        Episode_Reward/action_rate: -0.1573
          Episode_Reward/joint_vel: -0.0330
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 135462912
                    Iteration time: 1.92s
                      Time elapsed: 00:52:23
                               ETA: 01:01:42

################################################################################
                     [1m Learning iteration 1378/3000 [0m                     

                       Computation: 51034 steps/s (collection: 1.836s, learning 0.090s)
             Mean action noise std: 4.73
          Mean value_function loss: 57.5787
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 90.1827
                       Mean reward: 751.68
               Mean episode length: 238.15
    Episode_Reward/reaching_object: 1.5828
    Episode_Reward/rotating_object: 147.6710
        Episode_Reward/action_rate: -0.1558
          Episode_Reward/joint_vel: -0.0341
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 135561216
                    Iteration time: 1.93s
                      Time elapsed: 00:52:25
                               ETA: 01:01:39

################################################################################
                     [1m Learning iteration 1379/3000 [0m                     

                       Computation: 51663 steps/s (collection: 1.809s, learning 0.094s)
             Mean action noise std: 4.73
          Mean value_function loss: 56.4013
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 90.1909
                       Mean reward: 738.73
               Mean episode length: 231.32
    Episode_Reward/reaching_object: 1.5751
    Episode_Reward/rotating_object: 144.0480
        Episode_Reward/action_rate: -0.1546
          Episode_Reward/joint_vel: -0.0349
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 135659520
                    Iteration time: 1.90s
                      Time elapsed: 00:52:27
                               ETA: 01:01:36

################################################################################
                     [1m Learning iteration 1380/3000 [0m                     

                       Computation: 51085 steps/s (collection: 1.824s, learning 0.101s)
             Mean action noise std: 4.73
          Mean value_function loss: 57.6925
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 90.1994
                       Mean reward: 756.11
               Mean episode length: 238.91
    Episode_Reward/reaching_object: 1.5957
    Episode_Reward/rotating_object: 148.5677
        Episode_Reward/action_rate: -0.1561
          Episode_Reward/joint_vel: -0.0329
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 135757824
                    Iteration time: 1.92s
                      Time elapsed: 00:52:29
                               ETA: 01:01:34

################################################################################
                     [1m Learning iteration 1381/3000 [0m                     

                       Computation: 51289 steps/s (collection: 1.808s, learning 0.109s)
             Mean action noise std: 4.74
          Mean value_function loss: 54.1087
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 90.2176
                       Mean reward: 769.25
               Mean episode length: 242.66
    Episode_Reward/reaching_object: 1.5981
    Episode_Reward/rotating_object: 146.5093
        Episode_Reward/action_rate: -0.1553
          Episode_Reward/joint_vel: -0.0336
      Episode_Termination/time_out: 15.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 135856128
                    Iteration time: 1.92s
                      Time elapsed: 00:52:30
                               ETA: 01:01:31

################################################################################
                     [1m Learning iteration 1382/3000 [0m                     

                       Computation: 48129 steps/s (collection: 1.854s, learning 0.188s)
             Mean action noise std: 4.74
          Mean value_function loss: 55.0756
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 90.2382
                       Mean reward: 764.06
               Mean episode length: 240.40
    Episode_Reward/reaching_object: 1.5824
    Episode_Reward/rotating_object: 144.8655
        Episode_Reward/action_rate: -0.1547
          Episode_Reward/joint_vel: -0.0338
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 135954432
                    Iteration time: 2.04s
                      Time elapsed: 00:52:32
                               ETA: 01:01:28

################################################################################
                     [1m Learning iteration 1383/3000 [0m                     

                       Computation: 51986 steps/s (collection: 1.793s, learning 0.098s)
             Mean action noise std: 4.74
          Mean value_function loss: 56.0219
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 90.2577
                       Mean reward: 720.95
               Mean episode length: 229.80
    Episode_Reward/reaching_object: 1.5955
    Episode_Reward/rotating_object: 146.6604
        Episode_Reward/action_rate: -0.1554
          Episode_Reward/joint_vel: -0.0333
      Episode_Termination/time_out: 16.4167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 136052736
                    Iteration time: 1.89s
                      Time elapsed: 00:52:34
                               ETA: 01:01:26

################################################################################
                     [1m Learning iteration 1384/3000 [0m                     

                       Computation: 50206 steps/s (collection: 1.824s, learning 0.134s)
             Mean action noise std: 4.75
          Mean value_function loss: 66.4991
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 90.2876
                       Mean reward: 715.95
               Mean episode length: 230.68
    Episode_Reward/reaching_object: 1.5947
    Episode_Reward/rotating_object: 146.0482
        Episode_Reward/action_rate: -0.1555
          Episode_Reward/joint_vel: -0.0334
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 136151040
                    Iteration time: 1.96s
                      Time elapsed: 00:52:36
                               ETA: 01:01:23

################################################################################
                     [1m Learning iteration 1385/3000 [0m                     

                       Computation: 50675 steps/s (collection: 1.821s, learning 0.119s)
             Mean action noise std: 4.75
          Mean value_function loss: 46.5229
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 90.3140
                       Mean reward: 790.17
               Mean episode length: 245.74
    Episode_Reward/reaching_object: 1.6009
    Episode_Reward/rotating_object: 148.3960
        Episode_Reward/action_rate: -0.1562
          Episode_Reward/joint_vel: -0.0325
      Episode_Termination/time_out: 18.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 136249344
                    Iteration time: 1.94s
                      Time elapsed: 00:52:38
                               ETA: 01:01:20

################################################################################
                     [1m Learning iteration 1386/3000 [0m                     

                       Computation: 50984 steps/s (collection: 1.810s, learning 0.118s)
             Mean action noise std: 4.75
          Mean value_function loss: 46.4517
               Mean surrogate loss: -0.0063
                 Mean entropy loss: 90.3231
                       Mean reward: 765.29
               Mean episode length: 241.54
    Episode_Reward/reaching_object: 1.5931
    Episode_Reward/rotating_object: 149.1070
        Episode_Reward/action_rate: -0.1572
          Episode_Reward/joint_vel: -0.0322
      Episode_Termination/time_out: 14.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 136347648
                    Iteration time: 1.93s
                      Time elapsed: 00:52:40
                               ETA: 01:01:17

################################################################################
                     [1m Learning iteration 1387/3000 [0m                     

                       Computation: 51112 steps/s (collection: 1.832s, learning 0.092s)
             Mean action noise std: 4.75
          Mean value_function loss: 44.5480
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 90.3377
                       Mean reward: 743.72
               Mean episode length: 235.27
    Episode_Reward/reaching_object: 1.5808
    Episode_Reward/rotating_object: 148.0644
        Episode_Reward/action_rate: -0.1560
          Episode_Reward/joint_vel: -0.0333
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 136445952
                    Iteration time: 1.92s
                      Time elapsed: 00:52:42
                               ETA: 01:01:15

################################################################################
                     [1m Learning iteration 1388/3000 [0m                     

                       Computation: 51054 steps/s (collection: 1.816s, learning 0.109s)
             Mean action noise std: 4.76
          Mean value_function loss: 49.5709
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 90.3563
                       Mean reward: 748.08
               Mean episode length: 237.14
    Episode_Reward/reaching_object: 1.5680
    Episode_Reward/rotating_object: 146.2054
        Episode_Reward/action_rate: -0.1549
          Episode_Reward/joint_vel: -0.0328
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 136544256
                    Iteration time: 1.93s
                      Time elapsed: 00:52:44
                               ETA: 01:01:12

################################################################################
                     [1m Learning iteration 1389/3000 [0m                     

                       Computation: 48199 steps/s (collection: 1.864s, learning 0.176s)
             Mean action noise std: 4.76
          Mean value_function loss: 60.7219
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 90.3762
                       Mean reward: 755.58
               Mean episode length: 242.21
    Episode_Reward/reaching_object: 1.5868
    Episode_Reward/rotating_object: 148.1815
        Episode_Reward/action_rate: -0.1573
          Episode_Reward/joint_vel: -0.0330
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 136642560
                    Iteration time: 2.04s
                      Time elapsed: 00:52:46
                               ETA: 01:01:10

################################################################################
                     [1m Learning iteration 1390/3000 [0m                     

                       Computation: 50790 steps/s (collection: 1.824s, learning 0.112s)
             Mean action noise std: 4.76
          Mean value_function loss: 54.7761
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 90.3883
                       Mean reward: 747.18
               Mean episode length: 240.64
    Episode_Reward/reaching_object: 1.6003
    Episode_Reward/rotating_object: 150.0018
        Episode_Reward/action_rate: -0.1586
          Episode_Reward/joint_vel: -0.0326
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 136740864
                    Iteration time: 1.94s
                      Time elapsed: 00:52:48
                               ETA: 01:01:07

################################################################################
                     [1m Learning iteration 1391/3000 [0m                     

                       Computation: 50598 steps/s (collection: 1.824s, learning 0.119s)
             Mean action noise std: 4.76
          Mean value_function loss: 51.2397
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 90.4068
                       Mean reward: 754.40
               Mean episode length: 239.13
    Episode_Reward/reaching_object: 1.5590
    Episode_Reward/rotating_object: 145.5214
        Episode_Reward/action_rate: -0.1565
          Episode_Reward/joint_vel: -0.0339
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 136839168
                    Iteration time: 1.94s
                      Time elapsed: 00:52:50
                               ETA: 01:01:04

################################################################################
                     [1m Learning iteration 1392/3000 [0m                     

                       Computation: 50588 steps/s (collection: 1.832s, learning 0.112s)
             Mean action noise std: 4.77
          Mean value_function loss: 55.9332
               Mean surrogate loss: -0.0039
                 Mean entropy loss: 90.4274
                       Mean reward: 719.82
               Mean episode length: 230.50
    Episode_Reward/reaching_object: 1.5725
    Episode_Reward/rotating_object: 147.8805
        Episode_Reward/action_rate: -0.1574
          Episode_Reward/joint_vel: -0.0328
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 136937472
                    Iteration time: 1.94s
                      Time elapsed: 00:52:52
                               ETA: 01:01:02

################################################################################
                     [1m Learning iteration 1393/3000 [0m                     

                       Computation: 52021 steps/s (collection: 1.783s, learning 0.107s)
             Mean action noise std: 4.77
          Mean value_function loss: 54.0718
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 90.4459
                       Mean reward: 734.07
               Mean episode length: 230.49
    Episode_Reward/reaching_object: 1.5855
    Episode_Reward/rotating_object: 148.1891
        Episode_Reward/action_rate: -0.1591
          Episode_Reward/joint_vel: -0.0337
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 137035776
                    Iteration time: 1.89s
                      Time elapsed: 00:52:54
                               ETA: 01:00:59

################################################################################
                     [1m Learning iteration 1394/3000 [0m                     

                       Computation: 51136 steps/s (collection: 1.805s, learning 0.117s)
             Mean action noise std: 4.77
          Mean value_function loss: 54.0777
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 90.4678
                       Mean reward: 758.16
               Mean episode length: 239.23
    Episode_Reward/reaching_object: 1.5750
    Episode_Reward/rotating_object: 149.7896
        Episode_Reward/action_rate: -0.1591
          Episode_Reward/joint_vel: -0.0332
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 137134080
                    Iteration time: 1.92s
                      Time elapsed: 00:52:56
                               ETA: 01:00:56

################################################################################
                     [1m Learning iteration 1395/3000 [0m                     

                       Computation: 50235 steps/s (collection: 1.856s, learning 0.101s)
             Mean action noise std: 4.78
          Mean value_function loss: 55.2799
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 90.4816
                       Mean reward: 766.49
               Mean episode length: 242.31
    Episode_Reward/reaching_object: 1.5762
    Episode_Reward/rotating_object: 148.1857
        Episode_Reward/action_rate: -0.1576
          Episode_Reward/joint_vel: -0.0326
      Episode_Termination/time_out: 16.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 137232384
                    Iteration time: 1.96s
                      Time elapsed: 00:52:58
                               ETA: 01:00:53

################################################################################
                     [1m Learning iteration 1396/3000 [0m                     

                       Computation: 51150 steps/s (collection: 1.825s, learning 0.097s)
             Mean action noise std: 4.78
          Mean value_function loss: 52.2055
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 90.4971
                       Mean reward: 731.93
               Mean episode length: 234.11
    Episode_Reward/reaching_object: 1.6022
    Episode_Reward/rotating_object: 149.9889
        Episode_Reward/action_rate: -0.1598
          Episode_Reward/joint_vel: -0.0323
      Episode_Termination/time_out: 15.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 137330688
                    Iteration time: 1.92s
                      Time elapsed: 00:53:00
                               ETA: 01:00:51

################################################################################
                     [1m Learning iteration 1397/3000 [0m                     

                       Computation: 49885 steps/s (collection: 1.821s, learning 0.150s)
             Mean action noise std: 4.78
          Mean value_function loss: 49.4960
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 90.5166
                       Mean reward: 753.08
               Mean episode length: 240.12
    Episode_Reward/reaching_object: 1.5741
    Episode_Reward/rotating_object: 146.0049
        Episode_Reward/action_rate: -0.1567
          Episode_Reward/joint_vel: -0.0329
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 137428992
                    Iteration time: 1.97s
                      Time elapsed: 00:53:02
                               ETA: 01:00:48

################################################################################
                     [1m Learning iteration 1398/3000 [0m                     

                       Computation: 48619 steps/s (collection: 1.852s, learning 0.170s)
             Mean action noise std: 4.79
          Mean value_function loss: 53.0611
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 90.5429
                       Mean reward: 723.62
               Mean episode length: 232.77
    Episode_Reward/reaching_object: 1.5941
    Episode_Reward/rotating_object: 146.2551
        Episode_Reward/action_rate: -0.1582
          Episode_Reward/joint_vel: -0.0337
      Episode_Termination/time_out: 15.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 137527296
                    Iteration time: 2.02s
                      Time elapsed: 00:53:04
                               ETA: 01:00:46

################################################################################
                     [1m Learning iteration 1399/3000 [0m                     

                       Computation: 50842 steps/s (collection: 1.806s, learning 0.128s)
             Mean action noise std: 4.79
          Mean value_function loss: 48.6868
               Mean surrogate loss: -0.0018
                 Mean entropy loss: 90.5598
                       Mean reward: 767.43
               Mean episode length: 241.21
    Episode_Reward/reaching_object: 1.5933
    Episode_Reward/rotating_object: 148.6567
        Episode_Reward/action_rate: -0.1580
          Episode_Reward/joint_vel: -0.0321
      Episode_Termination/time_out: 15.7500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 137625600
                    Iteration time: 1.93s
                      Time elapsed: 00:53:06
                               ETA: 01:00:43

################################################################################
                     [1m Learning iteration 1400/3000 [0m                     

                       Computation: 48160 steps/s (collection: 1.827s, learning 0.214s)
             Mean action noise std: 4.79
          Mean value_function loss: 53.5565
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 90.5699
                       Mean reward: 769.89
               Mean episode length: 241.22
    Episode_Reward/reaching_object: 1.5825
    Episode_Reward/rotating_object: 146.3996
        Episode_Reward/action_rate: -0.1583
          Episode_Reward/joint_vel: -0.0333
      Episode_Termination/time_out: 17.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 137723904
                    Iteration time: 2.04s
                      Time elapsed: 00:53:08
                               ETA: 01:00:40

################################################################################
                     [1m Learning iteration 1401/3000 [0m                     

                       Computation: 50587 steps/s (collection: 1.799s, learning 0.145s)
             Mean action noise std: 4.79
          Mean value_function loss: 50.7692
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 90.5860
                       Mean reward: 761.85
               Mean episode length: 240.98
    Episode_Reward/reaching_object: 1.6203
    Episode_Reward/rotating_object: 150.3047
        Episode_Reward/action_rate: -0.1609
          Episode_Reward/joint_vel: -0.0327
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 137822208
                    Iteration time: 1.94s
                      Time elapsed: 00:53:10
                               ETA: 01:00:38

################################################################################
                     [1m Learning iteration 1402/3000 [0m                     

                       Computation: 49770 steps/s (collection: 1.849s, learning 0.127s)
             Mean action noise std: 4.80
          Mean value_function loss: 42.0123
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 90.6002
                       Mean reward: 761.16
               Mean episode length: 241.33
    Episode_Reward/reaching_object: 1.5938
    Episode_Reward/rotating_object: 148.8468
        Episode_Reward/action_rate: -0.1587
          Episode_Reward/joint_vel: -0.0328
      Episode_Termination/time_out: 15.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 137920512
                    Iteration time: 1.98s
                      Time elapsed: 00:53:11
                               ETA: 01:00:35

################################################################################
                     [1m Learning iteration 1403/3000 [0m                     

                       Computation: 49202 steps/s (collection: 1.845s, learning 0.153s)
             Mean action noise std: 4.80
          Mean value_function loss: 54.4770
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 90.6124
                       Mean reward: 748.35
               Mean episode length: 235.47
    Episode_Reward/reaching_object: 1.5990
    Episode_Reward/rotating_object: 150.0025
        Episode_Reward/action_rate: -0.1605
          Episode_Reward/joint_vel: -0.0321
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 138018816
                    Iteration time: 2.00s
                      Time elapsed: 00:53:13
                               ETA: 01:00:33

################################################################################
                     [1m Learning iteration 1404/3000 [0m                     

                       Computation: 50421 steps/s (collection: 1.827s, learning 0.123s)
             Mean action noise std: 4.80
          Mean value_function loss: 49.5812
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 90.6309
                       Mean reward: 729.69
               Mean episode length: 233.28
    Episode_Reward/reaching_object: 1.5939
    Episode_Reward/rotating_object: 149.5991
        Episode_Reward/action_rate: -0.1599
          Episode_Reward/joint_vel: -0.0336
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 138117120
                    Iteration time: 1.95s
                      Time elapsed: 00:53:15
                               ETA: 01:00:30

################################################################################
                     [1m Learning iteration 1405/3000 [0m                     

                       Computation: 50268 steps/s (collection: 1.819s, learning 0.137s)
             Mean action noise std: 4.80
          Mean value_function loss: 50.0487
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 90.6472
                       Mean reward: 745.82
               Mean episode length: 235.94
    Episode_Reward/reaching_object: 1.5813
    Episode_Reward/rotating_object: 146.7579
        Episode_Reward/action_rate: -0.1578
          Episode_Reward/joint_vel: -0.0329
      Episode_Termination/time_out: 16.5833
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 138215424
                    Iteration time: 1.96s
                      Time elapsed: 00:53:17
                               ETA: 01:00:27

################################################################################
                     [1m Learning iteration 1406/3000 [0m                     

                       Computation: 49405 steps/s (collection: 1.873s, learning 0.117s)
             Mean action noise std: 4.81
          Mean value_function loss: 67.0980
               Mean surrogate loss: -0.0041
                 Mean entropy loss: 90.6579
                       Mean reward: 764.01
               Mean episode length: 240.00
    Episode_Reward/reaching_object: 1.5851
    Episode_Reward/rotating_object: 146.8653
        Episode_Reward/action_rate: -0.1583
          Episode_Reward/joint_vel: -0.0331
      Episode_Termination/time_out: 16.5000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 138313728
                    Iteration time: 1.99s
                      Time elapsed: 00:53:19
                               ETA: 01:00:25

################################################################################
                     [1m Learning iteration 1407/3000 [0m                     

                       Computation: 49126 steps/s (collection: 1.903s, learning 0.098s)
             Mean action noise std: 4.81
          Mean value_function loss: 52.7985
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 90.6652
                       Mean reward: 773.42
               Mean episode length: 246.59
    Episode_Reward/reaching_object: 1.5904
    Episode_Reward/rotating_object: 146.4986
        Episode_Reward/action_rate: -0.1599
          Episode_Reward/joint_vel: -0.0339
      Episode_Termination/time_out: 15.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 138412032
                    Iteration time: 2.00s
                      Time elapsed: 00:53:21
                               ETA: 01:00:22

################################################################################
                     [1m Learning iteration 1408/3000 [0m                     

                       Computation: 49624 steps/s (collection: 1.889s, learning 0.092s)
             Mean action noise std: 4.81
          Mean value_function loss: 49.8117
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 90.6723
                       Mean reward: 769.41
               Mean episode length: 243.15
    Episode_Reward/reaching_object: 1.5954
    Episode_Reward/rotating_object: 148.8263
        Episode_Reward/action_rate: -0.1600
          Episode_Reward/joint_vel: -0.0317
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 138510336
                    Iteration time: 1.98s
                      Time elapsed: 00:53:23
                               ETA: 01:00:19

################################################################################
                     [1m Learning iteration 1409/3000 [0m                     

                       Computation: 50641 steps/s (collection: 1.842s, learning 0.100s)
             Mean action noise std: 4.81
          Mean value_function loss: 52.5266
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 90.6849
                       Mean reward: 756.57
               Mean episode length: 237.78
    Episode_Reward/reaching_object: 1.5729
    Episode_Reward/rotating_object: 144.6491
        Episode_Reward/action_rate: -0.1586
          Episode_Reward/joint_vel: -0.0336
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 138608640
                    Iteration time: 1.94s
                      Time elapsed: 00:53:25
                               ETA: 01:00:17

################################################################################
                     [1m Learning iteration 1410/3000 [0m                     

                       Computation: 49694 steps/s (collection: 1.859s, learning 0.119s)
             Mean action noise std: 4.81
          Mean value_function loss: 51.3027
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 90.7020
                       Mean reward: 734.20
               Mean episode length: 231.17
    Episode_Reward/reaching_object: 1.6009
    Episode_Reward/rotating_object: 149.1161
        Episode_Reward/action_rate: -0.1603
          Episode_Reward/joint_vel: -0.0320
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 138706944
                    Iteration time: 1.98s
                      Time elapsed: 00:53:27
                               ETA: 01:00:14

################################################################################
                     [1m Learning iteration 1411/3000 [0m                     

                       Computation: 51230 steps/s (collection: 1.820s, learning 0.099s)
             Mean action noise std: 4.82
          Mean value_function loss: 60.2229
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 90.7230
                       Mean reward: 760.38
               Mean episode length: 237.66
    Episode_Reward/reaching_object: 1.5903
    Episode_Reward/rotating_object: 146.3096
        Episode_Reward/action_rate: -0.1595
          Episode_Reward/joint_vel: -0.0337
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 138805248
                    Iteration time: 1.92s
                      Time elapsed: 00:53:29
                               ETA: 01:00:12

################################################################################
                     [1m Learning iteration 1412/3000 [0m                     

                       Computation: 51171 steps/s (collection: 1.816s, learning 0.105s)
             Mean action noise std: 4.82
          Mean value_function loss: 50.7550
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 90.7499
                       Mean reward: 742.41
               Mean episode length: 235.35
    Episode_Reward/reaching_object: 1.5710
    Episode_Reward/rotating_object: 145.5181
        Episode_Reward/action_rate: -0.1576
          Episode_Reward/joint_vel: -0.0327
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.1250
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 138903552
                    Iteration time: 1.92s
                      Time elapsed: 00:53:31
                               ETA: 01:00:09

################################################################################
                     [1m Learning iteration 1413/3000 [0m                     

                       Computation: 50332 steps/s (collection: 1.843s, learning 0.110s)
             Mean action noise std: 4.82
          Mean value_function loss: 55.1266
               Mean surrogate loss: -0.0030
                 Mean entropy loss: 90.7698
                       Mean reward: 736.78
               Mean episode length: 234.22
    Episode_Reward/reaching_object: 1.5966
    Episode_Reward/rotating_object: 147.3294
        Episode_Reward/action_rate: -0.1605
          Episode_Reward/joint_vel: -0.0335
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 139001856
                    Iteration time: 1.95s
                      Time elapsed: 00:53:33
                               ETA: 01:00:06

################################################################################
                     [1m Learning iteration 1414/3000 [0m                     

                       Computation: 51115 steps/s (collection: 1.829s, learning 0.094s)
             Mean action noise std: 4.83
          Mean value_function loss: 54.7431
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 90.7845
                       Mean reward: 739.56
               Mean episode length: 231.60
    Episode_Reward/reaching_object: 1.5709
    Episode_Reward/rotating_object: 145.8615
        Episode_Reward/action_rate: -0.1580
          Episode_Reward/joint_vel: -0.0325
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 139100160
                    Iteration time: 1.92s
                      Time elapsed: 00:53:35
                               ETA: 01:00:04

################################################################################
                     [1m Learning iteration 1415/3000 [0m                     

                       Computation: 51335 steps/s (collection: 1.810s, learning 0.105s)
             Mean action noise std: 4.83
          Mean value_function loss: 47.5375
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 90.8042
                       Mean reward: 751.19
               Mean episode length: 236.34
    Episode_Reward/reaching_object: 1.5882
    Episode_Reward/rotating_object: 151.2584
        Episode_Reward/action_rate: -0.1618
          Episode_Reward/joint_vel: -0.0324
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 139198464
                    Iteration time: 1.91s
                      Time elapsed: 00:53:37
                               ETA: 01:00:01

################################################################################
                     [1m Learning iteration 1416/3000 [0m                     

                       Computation: 50979 steps/s (collection: 1.833s, learning 0.095s)
             Mean action noise std: 4.83
          Mean value_function loss: 49.5362
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 90.8243
                       Mean reward: 748.02
               Mean episode length: 237.59
    Episode_Reward/reaching_object: 1.6121
    Episode_Reward/rotating_object: 150.0971
        Episode_Reward/action_rate: -0.1625
          Episode_Reward/joint_vel: -0.0329
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 139296768
                    Iteration time: 1.93s
                      Time elapsed: 00:53:39
                               ETA: 00:59:58

################################################################################
                     [1m Learning iteration 1417/3000 [0m                     

                       Computation: 50647 steps/s (collection: 1.832s, learning 0.109s)
             Mean action noise std: 4.84
          Mean value_function loss: 51.2262
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 90.8391
                       Mean reward: 762.15
               Mean episode length: 236.54
    Episode_Reward/reaching_object: 1.6019
    Episode_Reward/rotating_object: 151.1021
        Episode_Reward/action_rate: -0.1622
          Episode_Reward/joint_vel: -0.0322
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 139395072
                    Iteration time: 1.94s
                      Time elapsed: 00:53:41
                               ETA: 00:59:56

################################################################################
                     [1m Learning iteration 1418/3000 [0m                     

                       Computation: 51055 steps/s (collection: 1.821s, learning 0.104s)
             Mean action noise std: 4.84
          Mean value_function loss: 49.6537
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 90.8552
                       Mean reward: 734.10
               Mean episode length: 234.85
    Episode_Reward/reaching_object: 1.5857
    Episode_Reward/rotating_object: 147.7146
        Episode_Reward/action_rate: -0.1606
          Episode_Reward/joint_vel: -0.0327
      Episode_Termination/time_out: 15.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 139493376
                    Iteration time: 1.93s
                      Time elapsed: 00:53:43
                               ETA: 00:59:53

################################################################################
                     [1m Learning iteration 1419/3000 [0m                     

                       Computation: 50615 steps/s (collection: 1.803s, learning 0.140s)
             Mean action noise std: 4.84
          Mean value_function loss: 49.0942
               Mean surrogate loss: -0.0026
                 Mean entropy loss: 90.8665
                       Mean reward: 728.74
               Mean episode length: 234.25
    Episode_Reward/reaching_object: 1.5874
    Episode_Reward/rotating_object: 147.4367
        Episode_Reward/action_rate: -0.1610
          Episode_Reward/joint_vel: -0.0329
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 139591680
                    Iteration time: 1.94s
                      Time elapsed: 00:53:45
                               ETA: 00:59:50

################################################################################
                     [1m Learning iteration 1420/3000 [0m                     

                       Computation: 46820 steps/s (collection: 1.950s, learning 0.149s)
             Mean action noise std: 4.84
          Mean value_function loss: 57.6161
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 90.8795
                       Mean reward: 739.66
               Mean episode length: 236.03
    Episode_Reward/reaching_object: 1.5862
    Episode_Reward/rotating_object: 146.7397
        Episode_Reward/action_rate: -0.1606
          Episode_Reward/joint_vel: -0.0334
      Episode_Termination/time_out: 14.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 139689984
                    Iteration time: 2.10s
                      Time elapsed: 00:53:47
                               ETA: 00:59:48

################################################################################
                     [1m Learning iteration 1421/3000 [0m                     

                       Computation: 49991 steps/s (collection: 1.798s, learning 0.169s)
             Mean action noise std: 4.85
          Mean value_function loss: 61.3792
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 90.8914
                       Mean reward: 738.84
               Mean episode length: 232.43
    Episode_Reward/reaching_object: 1.6012
    Episode_Reward/rotating_object: 148.0342
        Episode_Reward/action_rate: -0.1620
          Episode_Reward/joint_vel: -0.0337
      Episode_Termination/time_out: 17.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2083
--------------------------------------------------------------------------------
                   Total timesteps: 139788288
                    Iteration time: 1.97s
                      Time elapsed: 00:53:49
                               ETA: 00:59:45

################################################################################
                     [1m Learning iteration 1422/3000 [0m                     

                       Computation: 50016 steps/s (collection: 1.830s, learning 0.136s)
             Mean action noise std: 4.85
          Mean value_function loss: 50.1889
               Mean surrogate loss: -0.0066
                 Mean entropy loss: 90.9089
                       Mean reward: 749.09
               Mean episode length: 241.14
    Episode_Reward/reaching_object: 1.5990
    Episode_Reward/rotating_object: 150.1165
        Episode_Reward/action_rate: -0.1628
          Episode_Reward/joint_vel: -0.0330
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 139886592
                    Iteration time: 1.97s
                      Time elapsed: 00:53:51
                               ETA: 00:59:43

################################################################################
                     [1m Learning iteration 1423/3000 [0m                     

                       Computation: 49209 steps/s (collection: 1.834s, learning 0.163s)
             Mean action noise std: 4.85
          Mean value_function loss: 59.8722
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 90.9269
                       Mean reward: 786.56
               Mean episode length: 242.08
    Episode_Reward/reaching_object: 1.5659
    Episode_Reward/rotating_object: 146.4733
        Episode_Reward/action_rate: -0.1614
          Episode_Reward/joint_vel: -0.0348
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 139984896
                    Iteration time: 2.00s
                      Time elapsed: 00:53:53
                               ETA: 00:59:40

################################################################################
                     [1m Learning iteration 1424/3000 [0m                     

                       Computation: 51232 steps/s (collection: 1.800s, learning 0.119s)
             Mean action noise std: 4.86
          Mean value_function loss: 52.7162
               Mean surrogate loss: -0.0073
                 Mean entropy loss: 90.9455
                       Mean reward: 751.01
               Mean episode length: 237.49
    Episode_Reward/reaching_object: 1.5953
    Episode_Reward/rotating_object: 149.6687
        Episode_Reward/action_rate: -0.1631
          Episode_Reward/joint_vel: -0.0329
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 140083200
                    Iteration time: 1.92s
                      Time elapsed: 00:53:55
                               ETA: 00:59:37

################################################################################
                     [1m Learning iteration 1425/3000 [0m                     

                       Computation: 50353 steps/s (collection: 1.853s, learning 0.099s)
             Mean action noise std: 4.86
          Mean value_function loss: 44.2665
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 90.9736
                       Mean reward: 758.35
               Mean episode length: 237.36
    Episode_Reward/reaching_object: 1.6001
    Episode_Reward/rotating_object: 150.4834
        Episode_Reward/action_rate: -0.1639
          Episode_Reward/joint_vel: -0.0335
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 140181504
                    Iteration time: 1.95s
                      Time elapsed: 00:53:57
                               ETA: 00:59:35

################################################################################
                     [1m Learning iteration 1426/3000 [0m                     

                       Computation: 50599 steps/s (collection: 1.817s, learning 0.126s)
             Mean action noise std: 4.86
          Mean value_function loss: 45.5308
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 90.9870
                       Mean reward: 781.58
               Mean episode length: 246.49
    Episode_Reward/reaching_object: 1.6089
    Episode_Reward/rotating_object: 149.9613
        Episode_Reward/action_rate: -0.1647
          Episode_Reward/joint_vel: -0.0333
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8750
--------------------------------------------------------------------------------
                   Total timesteps: 140279808
                    Iteration time: 1.94s
                      Time elapsed: 00:53:58
                               ETA: 00:59:32

################################################################################
                     [1m Learning iteration 1427/3000 [0m                     

                       Computation: 51074 steps/s (collection: 1.812s, learning 0.113s)
             Mean action noise std: 4.86
          Mean value_function loss: 44.6786
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 91.0037
                       Mean reward: 767.56
               Mean episode length: 244.49
    Episode_Reward/reaching_object: 1.5943
    Episode_Reward/rotating_object: 149.9748
        Episode_Reward/action_rate: -0.1644
          Episode_Reward/joint_vel: -0.0330
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 140378112
                    Iteration time: 1.92s
                      Time elapsed: 00:54:00
                               ETA: 00:59:30

################################################################################
                     [1m Learning iteration 1428/3000 [0m                     

                       Computation: 50939 steps/s (collection: 1.806s, learning 0.123s)
             Mean action noise std: 4.87
          Mean value_function loss: 46.5352
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 91.0295
                       Mean reward: 761.98
               Mean episode length: 239.23
    Episode_Reward/reaching_object: 1.5856
    Episode_Reward/rotating_object: 147.1905
        Episode_Reward/action_rate: -0.1641
          Episode_Reward/joint_vel: -0.0352
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 140476416
                    Iteration time: 1.93s
                      Time elapsed: 00:54:02
                               ETA: 00:59:27

################################################################################
                     [1m Learning iteration 1429/3000 [0m                     

                       Computation: 51593 steps/s (collection: 1.792s, learning 0.113s)
             Mean action noise std: 4.87
          Mean value_function loss: 52.2074
               Mean surrogate loss: -0.0065
                 Mean entropy loss: 91.0487
                       Mean reward: 768.98
               Mean episode length: 242.12
    Episode_Reward/reaching_object: 1.5853
    Episode_Reward/rotating_object: 148.0760
        Episode_Reward/action_rate: -0.1629
          Episode_Reward/joint_vel: -0.0337
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 140574720
                    Iteration time: 1.91s
                      Time elapsed: 00:54:04
                               ETA: 00:59:24

################################################################################
                     [1m Learning iteration 1430/3000 [0m                     

                       Computation: 49925 steps/s (collection: 1.831s, learning 0.138s)
             Mean action noise std: 4.88
          Mean value_function loss: 50.4762
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 91.0735
                       Mean reward: 741.51
               Mean episode length: 234.12
    Episode_Reward/reaching_object: 1.5936
    Episode_Reward/rotating_object: 149.9834
        Episode_Reward/action_rate: -0.1654
          Episode_Reward/joint_vel: -0.0343
      Episode_Termination/time_out: 15.6667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 140673024
                    Iteration time: 1.97s
                      Time elapsed: 00:54:06
                               ETA: 00:59:22

################################################################################
                     [1m Learning iteration 1431/3000 [0m                     

                       Computation: 50879 steps/s (collection: 1.842s, learning 0.091s)
             Mean action noise std: 4.88
          Mean value_function loss: 58.8692
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 91.0939
                       Mean reward: 749.05
               Mean episode length: 234.85
    Episode_Reward/reaching_object: 1.5757
    Episode_Reward/rotating_object: 146.1437
        Episode_Reward/action_rate: -0.1627
          Episode_Reward/joint_vel: -0.0340
      Episode_Termination/time_out: 16.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 140771328
                    Iteration time: 1.93s
                      Time elapsed: 00:54:08
                               ETA: 00:59:19

################################################################################
                     [1m Learning iteration 1432/3000 [0m                     

                       Computation: 50328 steps/s (collection: 1.858s, learning 0.096s)
             Mean action noise std: 4.88
          Mean value_function loss: 59.0072
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 91.1116
                       Mean reward: 731.62
               Mean episode length: 233.85
    Episode_Reward/reaching_object: 1.5698
    Episode_Reward/rotating_object: 146.1456
        Episode_Reward/action_rate: -0.1630
          Episode_Reward/joint_vel: -0.0339
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 140869632
                    Iteration time: 1.95s
                      Time elapsed: 00:54:10
                               ETA: 00:59:16

################################################################################
                     [1m Learning iteration 1433/3000 [0m                     

                       Computation: 50793 steps/s (collection: 1.840s, learning 0.096s)
             Mean action noise std: 4.88
          Mean value_function loss: 66.7696
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 91.1297
                       Mean reward: 705.60
               Mean episode length: 229.17
    Episode_Reward/reaching_object: 1.5613
    Episode_Reward/rotating_object: 145.3136
        Episode_Reward/action_rate: -0.1615
          Episode_Reward/joint_vel: -0.0338
      Episode_Termination/time_out: 15.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 140967936
                    Iteration time: 1.94s
                      Time elapsed: 00:54:12
                               ETA: 00:59:14

################################################################################
                     [1m Learning iteration 1434/3000 [0m                     

                       Computation: 49703 steps/s (collection: 1.863s, learning 0.115s)
             Mean action noise std: 4.89
          Mean value_function loss: 62.8618
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 91.1468
                       Mean reward: 729.48
               Mean episode length: 230.91
    Episode_Reward/reaching_object: 1.5628
    Episode_Reward/rotating_object: 145.5687
        Episode_Reward/action_rate: -0.1618
          Episode_Reward/joint_vel: -0.0343
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 141066240
                    Iteration time: 1.98s
                      Time elapsed: 00:54:14
                               ETA: 00:59:11

################################################################################
                     [1m Learning iteration 1435/3000 [0m                     

                       Computation: 48890 steps/s (collection: 1.899s, learning 0.112s)
             Mean action noise std: 4.89
          Mean value_function loss: 57.8760
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 91.1688
                       Mean reward: 747.72
               Mean episode length: 236.94
    Episode_Reward/reaching_object: 1.5788
    Episode_Reward/rotating_object: 148.0973
        Episode_Reward/action_rate: -0.1640
          Episode_Reward/joint_vel: -0.0339
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 141164544
                    Iteration time: 2.01s
                      Time elapsed: 00:54:16
                               ETA: 00:59:09

################################################################################
                     [1m Learning iteration 1436/3000 [0m                     

                       Computation: 49196 steps/s (collection: 1.887s, learning 0.112s)
             Mean action noise std: 4.89
          Mean value_function loss: 61.3551
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 91.1876
                       Mean reward: 755.98
               Mean episode length: 237.01
    Episode_Reward/reaching_object: 1.5552
    Episode_Reward/rotating_object: 145.9415
        Episode_Reward/action_rate: -0.1618
          Episode_Reward/joint_vel: -0.0329
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 141262848
                    Iteration time: 2.00s
                      Time elapsed: 00:54:18
                               ETA: 00:59:06

################################################################################
                     [1m Learning iteration 1437/3000 [0m                     

                       Computation: 50511 steps/s (collection: 1.833s, learning 0.113s)
             Mean action noise std: 4.90
          Mean value_function loss: 56.3402
               Mean surrogate loss: -0.0036
                 Mean entropy loss: 91.2043
                       Mean reward: 758.42
               Mean episode length: 237.22
    Episode_Reward/reaching_object: 1.5890
    Episode_Reward/rotating_object: 148.8575
        Episode_Reward/action_rate: -0.1660
          Episode_Reward/joint_vel: -0.0344
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 141361152
                    Iteration time: 1.95s
                      Time elapsed: 00:54:20
                               ETA: 00:59:03

################################################################################
                     [1m Learning iteration 1438/3000 [0m                     

                       Computation: 50675 steps/s (collection: 1.821s, learning 0.119s)
             Mean action noise std: 4.90
          Mean value_function loss: 55.4608
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 91.2108
                       Mean reward: 738.33
               Mean episode length: 235.71
    Episode_Reward/reaching_object: 1.5481
    Episode_Reward/rotating_object: 143.6003
        Episode_Reward/action_rate: -0.1627
          Episode_Reward/joint_vel: -0.0351
      Episode_Termination/time_out: 15.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 141459456
                    Iteration time: 1.94s
                      Time elapsed: 00:54:22
                               ETA: 00:59:01

################################################################################
                     [1m Learning iteration 1439/3000 [0m                     

                       Computation: 49953 steps/s (collection: 1.839s, learning 0.129s)
             Mean action noise std: 4.90
          Mean value_function loss: 54.5804
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 91.2181
                       Mean reward: 729.66
               Mean episode length: 235.56
    Episode_Reward/reaching_object: 1.5763
    Episode_Reward/rotating_object: 147.3256
        Episode_Reward/action_rate: -0.1658
          Episode_Reward/joint_vel: -0.0347
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 141557760
                    Iteration time: 1.97s
                      Time elapsed: 00:54:24
                               ETA: 00:58:58

################################################################################
                     [1m Learning iteration 1440/3000 [0m                     

                       Computation: 50928 steps/s (collection: 1.821s, learning 0.109s)
             Mean action noise std: 4.90
          Mean value_function loss: 57.8115
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 91.2294
                       Mean reward: 732.84
               Mean episode length: 234.49
    Episode_Reward/reaching_object: 1.5690
    Episode_Reward/rotating_object: 146.2394
        Episode_Reward/action_rate: -0.1655
          Episode_Reward/joint_vel: -0.0357
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 141656064
                    Iteration time: 1.93s
                      Time elapsed: 00:54:26
                               ETA: 00:58:56

################################################################################
                     [1m Learning iteration 1441/3000 [0m                     

                       Computation: 49359 steps/s (collection: 1.852s, learning 0.140s)
             Mean action noise std: 4.90
          Mean value_function loss: 44.7828
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 91.2487
                       Mean reward: 778.17
               Mean episode length: 241.44
    Episode_Reward/reaching_object: 1.5866
    Episode_Reward/rotating_object: 148.1242
        Episode_Reward/action_rate: -0.1655
          Episode_Reward/joint_vel: -0.0339
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 141754368
                    Iteration time: 1.99s
                      Time elapsed: 00:54:28
                               ETA: 00:58:53

################################################################################
                     [1m Learning iteration 1442/3000 [0m                     

                       Computation: 49056 steps/s (collection: 1.851s, learning 0.153s)
             Mean action noise std: 4.91
          Mean value_function loss: 53.3142
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 91.2690
                       Mean reward: 771.95
               Mean episode length: 240.81
    Episode_Reward/reaching_object: 1.6151
    Episode_Reward/rotating_object: 150.9216
        Episode_Reward/action_rate: -0.1676
          Episode_Reward/joint_vel: -0.0338
      Episode_Termination/time_out: 17.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 141852672
                    Iteration time: 2.00s
                      Time elapsed: 00:54:30
                               ETA: 00:58:50

################################################################################
                     [1m Learning iteration 1443/3000 [0m                     

                       Computation: 50170 steps/s (collection: 1.841s, learning 0.118s)
             Mean action noise std: 4.91
          Mean value_function loss: 50.1420
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 91.2841
                       Mean reward: 740.49
               Mean episode length: 235.89
    Episode_Reward/reaching_object: 1.6037
    Episode_Reward/rotating_object: 149.1491
        Episode_Reward/action_rate: -0.1659
          Episode_Reward/joint_vel: -0.0334
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 141950976
                    Iteration time: 1.96s
                      Time elapsed: 00:54:32
                               ETA: 00:58:48

################################################################################
                     [1m Learning iteration 1444/3000 [0m                     

                       Computation: 49345 steps/s (collection: 1.890s, learning 0.103s)
             Mean action noise std: 4.91
          Mean value_function loss: 45.1283
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 91.3067
                       Mean reward: 776.50
               Mean episode length: 244.18
    Episode_Reward/reaching_object: 1.6022
    Episode_Reward/rotating_object: 150.2395
        Episode_Reward/action_rate: -0.1686
          Episode_Reward/joint_vel: -0.0349
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 142049280
                    Iteration time: 1.99s
                      Time elapsed: 00:54:34
                               ETA: 00:58:45

################################################################################
                     [1m Learning iteration 1445/3000 [0m                     

                       Computation: 50285 steps/s (collection: 1.827s, learning 0.128s)
             Mean action noise std: 4.92
          Mean value_function loss: 55.6794
               Mean surrogate loss: -0.0028
                 Mean entropy loss: 91.3274
                       Mean reward: 759.03
               Mean episode length: 237.43
    Episode_Reward/reaching_object: 1.5759
    Episode_Reward/rotating_object: 148.6834
        Episode_Reward/action_rate: -0.1658
          Episode_Reward/joint_vel: -0.0338
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 142147584
                    Iteration time: 1.95s
                      Time elapsed: 00:54:36
                               ETA: 00:58:43

################################################################################
                     [1m Learning iteration 1446/3000 [0m                     

                       Computation: 49796 steps/s (collection: 1.831s, learning 0.144s)
             Mean action noise std: 4.92
          Mean value_function loss: 52.0840
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 91.3409
                       Mean reward: 792.57
               Mean episode length: 245.58
    Episode_Reward/reaching_object: 1.6040
    Episode_Reward/rotating_object: 148.9044
        Episode_Reward/action_rate: -0.1682
          Episode_Reward/joint_vel: -0.0340
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 142245888
                    Iteration time: 1.97s
                      Time elapsed: 00:54:38
                               ETA: 00:58:40

################################################################################
                     [1m Learning iteration 1447/3000 [0m                     

                       Computation: 49925 steps/s (collection: 1.831s, learning 0.138s)
             Mean action noise std: 4.92
          Mean value_function loss: 53.2625
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 91.3554
                       Mean reward: 753.63
               Mean episode length: 235.94
    Episode_Reward/reaching_object: 1.6100
    Episode_Reward/rotating_object: 152.5550
        Episode_Reward/action_rate: -0.1703
          Episode_Reward/joint_vel: -0.0343
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.8333
--------------------------------------------------------------------------------
                   Total timesteps: 142344192
                    Iteration time: 1.97s
                      Time elapsed: 00:54:40
                               ETA: 00:58:38

################################################################################
                     [1m Learning iteration 1448/3000 [0m                     

                       Computation: 49550 steps/s (collection: 1.877s, learning 0.107s)
             Mean action noise std: 4.92
          Mean value_function loss: 57.8411
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 91.3707
                       Mean reward: 737.48
               Mean episode length: 233.34
    Episode_Reward/reaching_object: 1.5912
    Episode_Reward/rotating_object: 148.8503
        Episode_Reward/action_rate: -0.1666
          Episode_Reward/joint_vel: -0.0333
      Episode_Termination/time_out: 16.0833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 142442496
                    Iteration time: 1.98s
                      Time elapsed: 00:54:42
                               ETA: 00:58:35

################################################################################
                     [1m Learning iteration 1449/3000 [0m                     

                       Computation: 50166 steps/s (collection: 1.862s, learning 0.097s)
             Mean action noise std: 4.92
          Mean value_function loss: 64.1283
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 91.3773
                       Mean reward: 775.28
               Mean episode length: 245.53
    Episode_Reward/reaching_object: 1.5872
    Episode_Reward/rotating_object: 148.4782
        Episode_Reward/action_rate: -0.1671
          Episode_Reward/joint_vel: -0.0334
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 142540800
                    Iteration time: 1.96s
                      Time elapsed: 00:54:44
                               ETA: 00:58:32

################################################################################
                     [1m Learning iteration 1450/3000 [0m                     

                       Computation: 46446 steps/s (collection: 1.952s, learning 0.164s)
             Mean action noise std: 4.93
          Mean value_function loss: 48.6154
               Mean surrogate loss: -0.0069
                 Mean entropy loss: 91.3895
                       Mean reward: 785.43
               Mean episode length: 244.59
    Episode_Reward/reaching_object: 1.5940
    Episode_Reward/rotating_object: 147.8468
        Episode_Reward/action_rate: -0.1678
          Episode_Reward/joint_vel: -0.0348
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 142639104
                    Iteration time: 2.12s
                      Time elapsed: 00:54:46
                               ETA: 00:58:30

################################################################################
                     [1m Learning iteration 1451/3000 [0m                     

                       Computation: 45913 steps/s (collection: 1.960s, learning 0.181s)
             Mean action noise std: 4.93
          Mean value_function loss: 67.8058
               Mean surrogate loss: -0.0031
                 Mean entropy loss: 91.4051
                       Mean reward: 721.63
               Mean episode length: 228.37
    Episode_Reward/reaching_object: 1.5833
    Episode_Reward/rotating_object: 147.8416
        Episode_Reward/action_rate: -0.1669
          Episode_Reward/joint_vel: -0.0343
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 142737408
                    Iteration time: 2.14s
                      Time elapsed: 00:54:48
                               ETA: 00:58:28

################################################################################
                     [1m Learning iteration 1452/3000 [0m                     

                       Computation: 41213 steps/s (collection: 2.221s, learning 0.165s)
             Mean action noise std: 4.93
          Mean value_function loss: 62.9832
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 91.4193
                       Mean reward: 739.88
               Mean episode length: 235.66
    Episode_Reward/reaching_object: 1.5717
    Episode_Reward/rotating_object: 147.0670
        Episode_Reward/action_rate: -0.1681
          Episode_Reward/joint_vel: -0.0358
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 142835712
                    Iteration time: 2.39s
                      Time elapsed: 00:54:50
                               ETA: 00:58:25

################################################################################
                     [1m Learning iteration 1453/3000 [0m                     

                       Computation: 42882 steps/s (collection: 2.184s, learning 0.109s)
             Mean action noise std: 4.93
          Mean value_function loss: 51.5381
               Mean surrogate loss: -0.0042
                 Mean entropy loss: 91.4312
                       Mean reward: 734.93
               Mean episode length: 234.82
    Episode_Reward/reaching_object: 1.5890
    Episode_Reward/rotating_object: 148.6396
        Episode_Reward/action_rate: -0.1686
          Episode_Reward/joint_vel: -0.0346
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 142934016
                    Iteration time: 2.29s
                      Time elapsed: 00:54:53
                               ETA: 00:58:23

################################################################################
                     [1m Learning iteration 1454/3000 [0m                     

                       Computation: 48705 steps/s (collection: 1.886s, learning 0.132s)
             Mean action noise std: 4.94
          Mean value_function loss: 66.1320
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 91.4445
                       Mean reward: 752.62
               Mean episode length: 237.03
    Episode_Reward/reaching_object: 1.5686
    Episode_Reward/rotating_object: 146.3976
        Episode_Reward/action_rate: -0.1668
          Episode_Reward/joint_vel: -0.0354
      Episode_Termination/time_out: 14.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3333
--------------------------------------------------------------------------------
                   Total timesteps: 143032320
                    Iteration time: 2.02s
                      Time elapsed: 00:54:55
                               ETA: 00:58:21

################################################################################
                     [1m Learning iteration 1455/3000 [0m                     

                       Computation: 45088 steps/s (collection: 1.991s, learning 0.190s)
             Mean action noise std: 4.94
          Mean value_function loss: 51.0344
               Mean surrogate loss: -0.0034
                 Mean entropy loss: 91.4554
                       Mean reward: 768.48
               Mean episode length: 239.99
    Episode_Reward/reaching_object: 1.5987
    Episode_Reward/rotating_object: 149.4596
        Episode_Reward/action_rate: -0.1700
          Episode_Reward/joint_vel: -0.0351
      Episode_Termination/time_out: 17.3750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 143130624
                    Iteration time: 2.18s
                      Time elapsed: 00:54:57
                               ETA: 00:58:18

################################################################################
                     [1m Learning iteration 1456/3000 [0m                     

                       Computation: 44338 steps/s (collection: 2.014s, learning 0.204s)
             Mean action noise std: 4.94
          Mean value_function loss: 56.1833
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 91.4658
                       Mean reward: 705.74
               Mean episode length: 227.88
    Episode_Reward/reaching_object: 1.5623
    Episode_Reward/rotating_object: 145.5807
        Episode_Reward/action_rate: -0.1661
          Episode_Reward/joint_vel: -0.0339
      Episode_Termination/time_out: 15.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 143228928
                    Iteration time: 2.22s
                      Time elapsed: 00:54:59
                               ETA: 00:58:16

################################################################################
                     [1m Learning iteration 1457/3000 [0m                     

                       Computation: 47009 steps/s (collection: 1.974s, learning 0.118s)
             Mean action noise std: 4.94
          Mean value_function loss: 56.3631
               Mean surrogate loss: -0.0050
                 Mean entropy loss: 91.4823
                       Mean reward: 732.57
               Mean episode length: 230.22
    Episode_Reward/reaching_object: 1.5839
    Episode_Reward/rotating_object: 149.8083
        Episode_Reward/action_rate: -0.1683
          Episode_Reward/joint_vel: -0.0332
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 143327232
                    Iteration time: 2.09s
                      Time elapsed: 00:55:01
                               ETA: 00:58:14

################################################################################
                     [1m Learning iteration 1458/3000 [0m                     

                       Computation: 47229 steps/s (collection: 1.927s, learning 0.155s)
             Mean action noise std: 4.95
          Mean value_function loss: 53.5510
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 91.5004
                       Mean reward: 755.74
               Mean episode length: 243.19
    Episode_Reward/reaching_object: 1.5871
    Episode_Reward/rotating_object: 148.4891
        Episode_Reward/action_rate: -0.1705
          Episode_Reward/joint_vel: -0.0349
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 143425536
                    Iteration time: 2.08s
                      Time elapsed: 00:55:03
                               ETA: 00:58:11

################################################################################
                     [1m Learning iteration 1459/3000 [0m                     

                       Computation: 43571 steps/s (collection: 2.123s, learning 0.133s)
             Mean action noise std: 4.95
          Mean value_function loss: 57.7152
               Mean surrogate loss: -0.0032
                 Mean entropy loss: 91.5196
                       Mean reward: 764.85
               Mean episode length: 238.40
    Episode_Reward/reaching_object: 1.5420
    Episode_Reward/rotating_object: 143.8134
        Episode_Reward/action_rate: -0.1666
          Episode_Reward/joint_vel: -0.0355
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4167
--------------------------------------------------------------------------------
                   Total timesteps: 143523840
                    Iteration time: 2.26s
                      Time elapsed: 00:55:05
                               ETA: 00:58:09

################################################################################
                     [1m Learning iteration 1460/3000 [0m                     

                       Computation: 46596 steps/s (collection: 1.949s, learning 0.161s)
             Mean action noise std: 4.95
          Mean value_function loss: 54.6545
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 91.5349
                       Mean reward: 785.80
               Mean episode length: 242.18
    Episode_Reward/reaching_object: 1.5774
    Episode_Reward/rotating_object: 149.0730
        Episode_Reward/action_rate: -0.1686
          Episode_Reward/joint_vel: -0.0333
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 143622144
                    Iteration time: 2.11s
                      Time elapsed: 00:55:07
                               ETA: 00:58:06

################################################################################
                     [1m Learning iteration 1461/3000 [0m                     

                       Computation: 48235 steps/s (collection: 1.935s, learning 0.103s)
             Mean action noise std: 4.96
          Mean value_function loss: 53.9738
               Mean surrogate loss: -0.0044
                 Mean entropy loss: 91.5523
                       Mean reward: 775.58
               Mean episode length: 243.34
    Episode_Reward/reaching_object: 1.5878
    Episode_Reward/rotating_object: 148.2631
        Episode_Reward/action_rate: -0.1702
          Episode_Reward/joint_vel: -0.0346
      Episode_Termination/time_out: 15.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 143720448
                    Iteration time: 2.04s
                      Time elapsed: 00:55:10
                               ETA: 00:58:04

################################################################################
                     [1m Learning iteration 1462/3000 [0m                     

                       Computation: 50662 steps/s (collection: 1.833s, learning 0.108s)
             Mean action noise std: 4.96
          Mean value_function loss: 43.1446
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 91.5738
                       Mean reward: 772.54
               Mean episode length: 242.92
    Episode_Reward/reaching_object: 1.6068
    Episode_Reward/rotating_object: 150.2224
        Episode_Reward/action_rate: -0.1717
          Episode_Reward/joint_vel: -0.0356
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 143818752
                    Iteration time: 1.94s
                      Time elapsed: 00:55:11
                               ETA: 00:58:01

################################################################################
                     [1m Learning iteration 1463/3000 [0m                     

                       Computation: 50170 steps/s (collection: 1.845s, learning 0.114s)
             Mean action noise std: 4.96
          Mean value_function loss: 49.5774
               Mean surrogate loss: -0.0012
                 Mean entropy loss: 91.5919
                       Mean reward: 756.86
               Mean episode length: 238.28
    Episode_Reward/reaching_object: 1.6039
    Episode_Reward/rotating_object: 151.3717
        Episode_Reward/action_rate: -0.1719
          Episode_Reward/joint_vel: -0.0347
      Episode_Termination/time_out: 17.0000
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 143917056
                    Iteration time: 1.96s
                      Time elapsed: 00:55:13
                               ETA: 00:57:59

################################################################################
                     [1m Learning iteration 1464/3000 [0m                     

                       Computation: 51111 steps/s (collection: 1.813s, learning 0.110s)
             Mean action noise std: 4.96
          Mean value_function loss: 44.1865
               Mean surrogate loss: -0.0058
                 Mean entropy loss: 91.6030
                       Mean reward: 761.20
               Mean episode length: 242.23
    Episode_Reward/reaching_object: 1.5929
    Episode_Reward/rotating_object: 149.8291
        Episode_Reward/action_rate: -0.1723
          Episode_Reward/joint_vel: -0.0351
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 144015360
                    Iteration time: 1.92s
                      Time elapsed: 00:55:15
                               ETA: 00:57:56

################################################################################
                     [1m Learning iteration 1465/3000 [0m                     

                       Computation: 51278 steps/s (collection: 1.797s, learning 0.121s)
             Mean action noise std: 4.97
          Mean value_function loss: 46.9930
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 91.6178
                       Mean reward: 756.04
               Mean episode length: 238.87
    Episode_Reward/reaching_object: 1.5779
    Episode_Reward/rotating_object: 149.9615
        Episode_Reward/action_rate: -0.1706
          Episode_Reward/joint_vel: -0.0344
      Episode_Termination/time_out: 16.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 144113664
                    Iteration time: 1.92s
                      Time elapsed: 00:55:17
                               ETA: 00:57:53

################################################################################
                     [1m Learning iteration 1466/3000 [0m                     

                       Computation: 48830 steps/s (collection: 1.898s, learning 0.115s)
             Mean action noise std: 4.97
          Mean value_function loss: 48.7948
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 91.6326
                       Mean reward: 765.37
               Mean episode length: 240.97
    Episode_Reward/reaching_object: 1.5562
    Episode_Reward/rotating_object: 148.1769
        Episode_Reward/action_rate: -0.1701
          Episode_Reward/joint_vel: -0.0358
      Episode_Termination/time_out: 17.2500
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 144211968
                    Iteration time: 2.01s
                      Time elapsed: 00:55:19
                               ETA: 00:57:51

################################################################################
                     [1m Learning iteration 1467/3000 [0m                     

                       Computation: 49429 steps/s (collection: 1.876s, learning 0.113s)
             Mean action noise std: 4.97
          Mean value_function loss: 58.8228
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 91.6532
                       Mean reward: 759.02
               Mean episode length: 237.48
    Episode_Reward/reaching_object: 1.5551
    Episode_Reward/rotating_object: 146.8432
        Episode_Reward/action_rate: -0.1692
          Episode_Reward/joint_vel: -0.0364
      Episode_Termination/time_out: 15.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 144310272
                    Iteration time: 1.99s
                      Time elapsed: 00:55:21
                               ETA: 00:57:48

################################################################################
                     [1m Learning iteration 1468/3000 [0m                     

                       Computation: 46253 steps/s (collection: 1.910s, learning 0.216s)
             Mean action noise std: 4.98
          Mean value_function loss: 64.6940
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 91.6667
                       Mean reward: 780.96
               Mean episode length: 243.28
    Episode_Reward/reaching_object: 1.5797
    Episode_Reward/rotating_object: 148.5485
        Episode_Reward/action_rate: -0.1708
          Episode_Reward/joint_vel: -0.0349
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 144408576
                    Iteration time: 2.13s
                      Time elapsed: 00:55:23
                               ETA: 00:57:46

################################################################################
                     [1m Learning iteration 1469/3000 [0m                     

                       Computation: 47551 steps/s (collection: 1.973s, learning 0.094s)
             Mean action noise std: 4.98
          Mean value_function loss: 51.4345
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 91.6916
                       Mean reward: 711.40
               Mean episode length: 230.15
    Episode_Reward/reaching_object: 1.5559
    Episode_Reward/rotating_object: 146.4195
        Episode_Reward/action_rate: -0.1696
          Episode_Reward/joint_vel: -0.0364
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 144506880
                    Iteration time: 2.07s
                      Time elapsed: 00:55:25
                               ETA: 00:57:43

################################################################################
                     [1m Learning iteration 1470/3000 [0m                     

                       Computation: 50178 steps/s (collection: 1.852s, learning 0.107s)
             Mean action noise std: 4.98
          Mean value_function loss: 59.9187
               Mean surrogate loss: -0.0048
                 Mean entropy loss: 91.7178
                       Mean reward: 728.51
               Mean episode length: 230.68
    Episode_Reward/reaching_object: 1.5705
    Episode_Reward/rotating_object: 148.4484
        Episode_Reward/action_rate: -0.1694
          Episode_Reward/joint_vel: -0.0328
      Episode_Termination/time_out: 15.7917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 144605184
                    Iteration time: 1.96s
                      Time elapsed: 00:55:27
                               ETA: 00:57:41

################################################################################
                     [1m Learning iteration 1471/3000 [0m                     

                       Computation: 50631 steps/s (collection: 1.842s, learning 0.100s)
             Mean action noise std: 4.99
          Mean value_function loss: 48.6549
               Mean surrogate loss: -0.0027
                 Mean entropy loss: 91.7398
                       Mean reward: 770.54
               Mean episode length: 241.25
    Episode_Reward/reaching_object: 1.5599
    Episode_Reward/rotating_object: 147.5803
        Episode_Reward/action_rate: -0.1712
          Episode_Reward/joint_vel: -0.0352
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 144703488
                    Iteration time: 1.94s
                      Time elapsed: 00:55:29
                               ETA: 00:57:38

################################################################################
                     [1m Learning iteration 1472/3000 [0m                     

                       Computation: 51254 steps/s (collection: 1.808s, learning 0.110s)
             Mean action noise std: 4.99
          Mean value_function loss: 57.7317
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 91.7513
                       Mean reward: 751.53
               Mean episode length: 239.01
    Episode_Reward/reaching_object: 1.5558
    Episode_Reward/rotating_object: 147.5402
        Episode_Reward/action_rate: -0.1693
          Episode_Reward/joint_vel: -0.0336
      Episode_Termination/time_out: 15.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 144801792
                    Iteration time: 1.92s
                      Time elapsed: 00:55:31
                               ETA: 00:57:36

################################################################################
                     [1m Learning iteration 1473/3000 [0m                     

                       Computation: 49550 steps/s (collection: 1.866s, learning 0.118s)
             Mean action noise std: 4.99
          Mean value_function loss: 51.4846
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 91.7627
                       Mean reward: 751.74
               Mean episode length: 236.02
    Episode_Reward/reaching_object: 1.5780
    Episode_Reward/rotating_object: 149.2512
        Episode_Reward/action_rate: -0.1716
          Episode_Reward/joint_vel: -0.0335
      Episode_Termination/time_out: 16.7083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 144900096
                    Iteration time: 1.98s
                      Time elapsed: 00:55:33
                               ETA: 00:57:33

################################################################################
                     [1m Learning iteration 1474/3000 [0m                     

                       Computation: 49940 steps/s (collection: 1.824s, learning 0.144s)
             Mean action noise std: 5.00
          Mean value_function loss: 56.4342
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 91.7870
                       Mean reward: 736.20
               Mean episode length: 230.74
    Episode_Reward/reaching_object: 1.5483
    Episode_Reward/rotating_object: 146.8179
        Episode_Reward/action_rate: -0.1694
          Episode_Reward/joint_vel: -0.0339
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5000
--------------------------------------------------------------------------------
                   Total timesteps: 144998400
                    Iteration time: 1.97s
                      Time elapsed: 00:55:35
                               ETA: 00:57:31

################################################################################
                     [1m Learning iteration 1475/3000 [0m                     

                       Computation: 50441 steps/s (collection: 1.844s, learning 0.105s)
             Mean action noise std: 5.00
          Mean value_function loss: 60.8399
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 91.8071
                       Mean reward: 742.00
               Mean episode length: 232.78
    Episode_Reward/reaching_object: 1.5816
    Episode_Reward/rotating_object: 149.5224
        Episode_Reward/action_rate: -0.1728
          Episode_Reward/joint_vel: -0.0341
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 145096704
                    Iteration time: 1.95s
                      Time elapsed: 00:55:37
                               ETA: 00:57:28

################################################################################
                     [1m Learning iteration 1476/3000 [0m                     

                       Computation: 49661 steps/s (collection: 1.843s, learning 0.137s)
             Mean action noise std: 5.00
          Mean value_function loss: 49.3639
               Mean surrogate loss: -0.0054
                 Mean entropy loss: 91.8239
                       Mean reward: 740.70
               Mean episode length: 239.73
    Episode_Reward/reaching_object: 1.6011
    Episode_Reward/rotating_object: 150.7300
        Episode_Reward/action_rate: -0.1743
          Episode_Reward/joint_vel: -0.0342
      Episode_Termination/time_out: 16.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7917
--------------------------------------------------------------------------------
                   Total timesteps: 145195008
                    Iteration time: 1.98s
                      Time elapsed: 00:55:39
                               ETA: 00:57:25

################################################################################
                     [1m Learning iteration 1477/3000 [0m                     

                       Computation: 49515 steps/s (collection: 1.859s, learning 0.126s)
             Mean action noise std: 5.01
          Mean value_function loss: 57.2339
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 91.8448
                       Mean reward: 739.92
               Mean episode length: 238.90
    Episode_Reward/reaching_object: 1.5694
    Episode_Reward/rotating_object: 145.6453
        Episode_Reward/action_rate: -0.1720
          Episode_Reward/joint_vel: -0.0357
      Episode_Termination/time_out: 16.0417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 145293312
                    Iteration time: 1.99s
                      Time elapsed: 00:55:41
                               ETA: 00:57:23

################################################################################
                     [1m Learning iteration 1478/3000 [0m                     

                       Computation: 50222 steps/s (collection: 1.861s, learning 0.096s)
             Mean action noise std: 5.01
          Mean value_function loss: 52.4149
               Mean surrogate loss: -0.0061
                 Mean entropy loss: 91.8624
                       Mean reward: 749.70
               Mean episode length: 237.10
    Episode_Reward/reaching_object: 1.5764
    Episode_Reward/rotating_object: 147.4978
        Episode_Reward/action_rate: -0.1726
          Episode_Reward/joint_vel: -0.0351
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.2917
--------------------------------------------------------------------------------
                   Total timesteps: 145391616
                    Iteration time: 1.96s
                      Time elapsed: 00:55:43
                               ETA: 00:57:20

################################################################################
                     [1m Learning iteration 1479/3000 [0m                     

                       Computation: 46282 steps/s (collection: 1.965s, learning 0.159s)
             Mean action noise std: 5.01
          Mean value_function loss: 45.0335
               Mean surrogate loss: -0.0049
                 Mean entropy loss: 91.8761
                       Mean reward: 734.79
               Mean episode length: 231.45
    Episode_Reward/reaching_object: 1.5858
    Episode_Reward/rotating_object: 149.6481
        Episode_Reward/action_rate: -0.1746
          Episode_Reward/joint_vel: -0.0340
      Episode_Termination/time_out: 16.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 145489920
                    Iteration time: 2.12s
                      Time elapsed: 00:55:45
                               ETA: 00:57:18

################################################################################
                     [1m Learning iteration 1480/3000 [0m                     

                       Computation: 50736 steps/s (collection: 1.829s, learning 0.109s)
             Mean action noise std: 5.01
          Mean value_function loss: 43.5039
               Mean surrogate loss: -0.0062
                 Mean entropy loss: 91.8909
                       Mean reward: 772.23
               Mean episode length: 245.57
    Episode_Reward/reaching_object: 1.6063
    Episode_Reward/rotating_object: 147.0745
        Episode_Reward/action_rate: -0.1759
          Episode_Reward/joint_vel: -0.0366
      Episode_Termination/time_out: 15.5833
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 145588224
                    Iteration time: 1.94s
                      Time elapsed: 00:55:47
                               ETA: 00:57:15

################################################################################
                     [1m Learning iteration 1481/3000 [0m                     

                       Computation: 49303 steps/s (collection: 1.851s, learning 0.143s)
             Mean action noise std: 5.01
          Mean value_function loss: 48.7509
               Mean surrogate loss: -0.0040
                 Mean entropy loss: 91.9045
                       Mean reward: 769.65
               Mean episode length: 240.32
    Episode_Reward/reaching_object: 1.5990
    Episode_Reward/rotating_object: 150.3998
        Episode_Reward/action_rate: -0.1752
          Episode_Reward/joint_vel: -0.0344
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.7500
--------------------------------------------------------------------------------
                   Total timesteps: 145686528
                    Iteration time: 1.99s
                      Time elapsed: 00:55:49
                               ETA: 00:57:13

################################################################################
                     [1m Learning iteration 1482/3000 [0m                     

                       Computation: 48756 steps/s (collection: 1.866s, learning 0.151s)
             Mean action noise std: 5.02
          Mean value_function loss: 55.1377
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 91.9162
                       Mean reward: 741.44
               Mean episode length: 237.50
    Episode_Reward/reaching_object: 1.5791
    Episode_Reward/rotating_object: 148.3528
        Episode_Reward/action_rate: -0.1740
          Episode_Reward/joint_vel: -0.0340
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 145784832
                    Iteration time: 2.02s
                      Time elapsed: 00:55:51
                               ETA: 00:57:10

################################################################################
                     [1m Learning iteration 1483/3000 [0m                     

                       Computation: 48824 steps/s (collection: 1.896s, learning 0.117s)
             Mean action noise std: 5.02
          Mean value_function loss: 48.1237
               Mean surrogate loss: -0.0053
                 Mean entropy loss: 91.9410
                       Mean reward: 768.03
               Mean episode length: 243.71
    Episode_Reward/reaching_object: 1.5799
    Episode_Reward/rotating_object: 150.5147
        Episode_Reward/action_rate: -0.1756
          Episode_Reward/joint_vel: -0.0344
      Episode_Termination/time_out: 16.4583
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 145883136
                    Iteration time: 2.01s
                      Time elapsed: 00:55:53
                               ETA: 00:57:08

################################################################################
                     [1m Learning iteration 1484/3000 [0m                     

                       Computation: 48957 steps/s (collection: 1.829s, learning 0.179s)
             Mean action noise std: 5.03
          Mean value_function loss: 62.5762
               Mean surrogate loss: -0.0046
                 Mean entropy loss: 91.9675
                       Mean reward: 751.12
               Mean episode length: 235.71
    Episode_Reward/reaching_object: 1.5489
    Episode_Reward/rotating_object: 146.4805
        Episode_Reward/action_rate: -0.1720
          Episode_Reward/joint_vel: -0.0344
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.4583
--------------------------------------------------------------------------------
                   Total timesteps: 145981440
                    Iteration time: 2.01s
                      Time elapsed: 00:55:55
                               ETA: 00:57:05

################################################################################
                     [1m Learning iteration 1485/3000 [0m                     

                       Computation: 49759 steps/s (collection: 1.875s, learning 0.101s)
             Mean action noise std: 5.03
          Mean value_function loss: 47.8441
               Mean surrogate loss: -0.0047
                 Mean entropy loss: 91.9860
                       Mean reward: 751.61
               Mean episode length: 238.50
    Episode_Reward/reaching_object: 1.5864
    Episode_Reward/rotating_object: 150.4860
        Episode_Reward/action_rate: -0.1759
          Episode_Reward/joint_vel: -0.0344
      Episode_Termination/time_out: 15.5000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 146079744
                    Iteration time: 1.98s
                      Time elapsed: 00:55:57
                               ETA: 00:57:03

################################################################################
                     [1m Learning iteration 1486/3000 [0m                     

                       Computation: 50941 steps/s (collection: 1.840s, learning 0.090s)
             Mean action noise std: 5.03
          Mean value_function loss: 45.7483
               Mean surrogate loss: -0.0051
                 Mean entropy loss: 91.9984
                       Mean reward: 762.29
               Mean episode length: 244.25
    Episode_Reward/reaching_object: 1.6069
    Episode_Reward/rotating_object: 150.5236
        Episode_Reward/action_rate: -0.1791
          Episode_Reward/joint_vel: -0.0366
      Episode_Termination/time_out: 16.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 146178048
                    Iteration time: 1.93s
                      Time elapsed: 00:55:59
                               ETA: 00:57:00

################################################################################
                     [1m Learning iteration 1487/3000 [0m                     

                       Computation: 51201 steps/s (collection: 1.816s, learning 0.104s)
             Mean action noise std: 5.03
          Mean value_function loss: 56.7921
               Mean surrogate loss: -0.0059
                 Mean entropy loss: 92.0088
                       Mean reward: 732.48
               Mean episode length: 235.33
    Episode_Reward/reaching_object: 1.5731
    Episode_Reward/rotating_object: 150.8772
        Episode_Reward/action_rate: -0.1775
          Episode_Reward/joint_vel: -0.0346
      Episode_Termination/time_out: 16.1667
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 146276352
                    Iteration time: 1.92s
                      Time elapsed: 00:56:01
                               ETA: 00:56:58

################################################################################
                     [1m Learning iteration 1488/3000 [0m                     

                       Computation: 50133 steps/s (collection: 1.841s, learning 0.120s)
             Mean action noise std: 5.03
          Mean value_function loss: 51.9287
               Mean surrogate loss: -0.0020
                 Mean entropy loss: 92.0218
                       Mean reward: 763.57
               Mean episode length: 239.86
    Episode_Reward/reaching_object: 1.5745
    Episode_Reward/rotating_object: 149.3998
        Episode_Reward/action_rate: -0.1758
          Episode_Reward/joint_vel: -0.0342
      Episode_Termination/time_out: 16.8750
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1667
--------------------------------------------------------------------------------
                   Total timesteps: 146374656
                    Iteration time: 1.96s
                      Time elapsed: 00:56:03
                               ETA: 00:56:55

################################################################################
                     [1m Learning iteration 1489/3000 [0m                     

                       Computation: 51081 steps/s (collection: 1.823s, learning 0.102s)
             Mean action noise std: 5.04
          Mean value_function loss: 52.7608
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 92.0363
                       Mean reward: 769.85
               Mean episode length: 238.85
    Episode_Reward/reaching_object: 1.5824
    Episode_Reward/rotating_object: 150.4197
        Episode_Reward/action_rate: -0.1761
          Episode_Reward/joint_vel: -0.0344
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.0000
--------------------------------------------------------------------------------
                   Total timesteps: 146472960
                    Iteration time: 1.92s
                      Time elapsed: 00:56:05
                               ETA: 00:56:52

################################################################################
                     [1m Learning iteration 1490/3000 [0m                     

                       Computation: 48389 steps/s (collection: 1.891s, learning 0.141s)
             Mean action noise std: 5.04
          Mean value_function loss: 51.3721
               Mean surrogate loss: -0.0016
                 Mean entropy loss: 92.0567
                       Mean reward: 771.37
               Mean episode length: 243.27
    Episode_Reward/reaching_object: 1.5873
    Episode_Reward/rotating_object: 149.2352
        Episode_Reward/action_rate: -0.1771
          Episode_Reward/joint_vel: -0.0334
      Episode_Termination/time_out: 15.9167
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9583
--------------------------------------------------------------------------------
                   Total timesteps: 146571264
                    Iteration time: 2.03s
                      Time elapsed: 00:56:07
                               ETA: 00:56:50

################################################################################
                     [1m Learning iteration 1491/3000 [0m                     

                       Computation: 51402 steps/s (collection: 1.810s, learning 0.102s)
             Mean action noise std: 5.04
          Mean value_function loss: 50.9155
               Mean surrogate loss: -0.0060
                 Mean entropy loss: 92.0641
                       Mean reward: 757.81
               Mean episode length: 239.18
    Episode_Reward/reaching_object: 1.5685
    Episode_Reward/rotating_object: 146.7014
        Episode_Reward/action_rate: -0.1749
          Episode_Reward/joint_vel: -0.0348
      Episode_Termination/time_out: 16.0000
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 1.2500
--------------------------------------------------------------------------------
                   Total timesteps: 146669568
                    Iteration time: 1.91s
                      Time elapsed: 00:56:09
                               ETA: 00:56:47

################################################################################
                     [1m Learning iteration 1492/3000 [0m                     

                       Computation: 50994 steps/s (collection: 1.824s, learning 0.104s)
             Mean action noise std: 5.04
          Mean value_function loss: 52.8340
               Mean surrogate loss: -0.0035
                 Mean entropy loss: 92.0775
                       Mean reward: 773.85
               Mean episode length: 243.93
    Episode_Reward/reaching_object: 1.5964
    Episode_Reward/rotating_object: 148.9990
        Episode_Reward/action_rate: -0.1775
          Episode_Reward/joint_vel: -0.0339
      Episode_Termination/time_out: 15.5417
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0417
--------------------------------------------------------------------------------
                   Total timesteps: 146767872
                    Iteration time: 1.93s
                      Time elapsed: 00:56:11
                               ETA: 00:56:45

################################################################################
                     [1m Learning iteration 1493/3000 [0m                     

                       Computation: 50823 steps/s (collection: 1.838s, learning 0.096s)
             Mean action noise std: 5.05
          Mean value_function loss: 64.2491
               Mean surrogate loss: -0.0057
                 Mean entropy loss: 92.0987
                       Mean reward: 720.57
               Mean episode length: 227.11
    Episode_Reward/reaching_object: 1.5610
    Episode_Reward/rotating_object: 145.1891
        Episode_Reward/action_rate: -0.1728
          Episode_Reward/joint_vel: -0.0340
      Episode_Termination/time_out: 16.2917
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5833
--------------------------------------------------------------------------------
                   Total timesteps: 146866176
                    Iteration time: 1.93s
                      Time elapsed: 00:56:13
                               ETA: 00:56:42

################################################################################
                     [1m Learning iteration 1494/3000 [0m                     

                       Computation: 50820 steps/s (collection: 1.840s, learning 0.094s)
             Mean action noise std: 5.05
          Mean value_function loss: 48.6518
               Mean surrogate loss: -0.0055
                 Mean entropy loss: 92.1304
                       Mean reward: 741.97
               Mean episode length: 235.15
    Episode_Reward/reaching_object: 1.5989
    Episode_Reward/rotating_object: 149.0682
        Episode_Reward/action_rate: -0.1774
          Episode_Reward/joint_vel: -0.0350
      Episode_Termination/time_out: 16.6250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.0833
--------------------------------------------------------------------------------
                   Total timesteps: 146964480
                    Iteration time: 1.93s
                      Time elapsed: 00:56:15
                               ETA: 00:56:39

################################################################################
                     [1m Learning iteration 1495/3000 [0m                     

                       Computation: 50493 steps/s (collection: 1.840s, learning 0.107s)
             Mean action noise std: 5.05
          Mean value_function loss: 60.2573
               Mean surrogate loss: -0.0024
                 Mean entropy loss: 92.1487
                       Mean reward: 748.06
               Mean episode length: 239.27
    Episode_Reward/reaching_object: 1.5792
    Episode_Reward/rotating_object: 146.4964
        Episode_Reward/action_rate: -0.1757
          Episode_Reward/joint_vel: -0.0342
      Episode_Termination/time_out: 16.1250
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.3750
--------------------------------------------------------------------------------
                   Total timesteps: 147062784
                    Iteration time: 1.95s
                      Time elapsed: 00:56:17
                               ETA: 00:56:37

################################################################################
                     [1m Learning iteration 1496/3000 [0m                     

                       Computation: 50697 steps/s (collection: 1.839s, learning 0.100s)
             Mean action noise std: 5.06
          Mean value_function loss: 66.1573
               Mean surrogate loss: -0.0064
                 Mean entropy loss: 92.1593
                       Mean reward: 715.05
               Mean episode length: 228.09
    Episode_Reward/reaching_object: 1.5554
    Episode_Reward/rotating_object: 144.0700
        Episode_Reward/action_rate: -0.1745
          Episode_Reward/joint_vel: -0.0353
      Episode_Termination/time_out: 15.8333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.5417
--------------------------------------------------------------------------------
                   Total timesteps: 147161088
                    Iteration time: 1.94s
                      Time elapsed: 00:56:19
                               ETA: 00:56:34

################################################################################
                     [1m Learning iteration 1497/3000 [0m                     

                       Computation: 51643 steps/s (collection: 1.803s, learning 0.101s)
             Mean action noise std: 5.06
          Mean value_function loss: 41.8689
               Mean surrogate loss: -0.0052
                 Mean entropy loss: 92.1762
                       Mean reward: 776.22
               Mean episode length: 242.89
    Episode_Reward/reaching_object: 1.6005
    Episode_Reward/rotating_object: 148.9288
        Episode_Reward/action_rate: -0.1793
          Episode_Reward/joint_vel: -0.0357
      Episode_Termination/time_out: 16.2083
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 1.1250
--------------------------------------------------------------------------------
                   Total timesteps: 147259392
                    Iteration time: 1.90s
                      Time elapsed: 00:56:20
                               ETA: 00:56:32

################################################################################
                     [1m Learning iteration 1498/3000 [0m                     

                       Computation: 51215 steps/s (collection: 1.815s, learning 0.104s)
             Mean action noise std: 5.06
          Mean value_function loss: 48.2312
               Mean surrogate loss: -0.0045
                 Mean entropy loss: 92.1891
                       Mean reward: 762.47
               Mean episode length: 240.15
    Episode_Reward/reaching_object: 1.6087
    Episode_Reward/rotating_object: 152.1967
        Episode_Reward/action_rate: -0.1810
          Episode_Reward/joint_vel: -0.0350
      Episode_Termination/time_out: 15.9583
Episode_Termination/object_dropping: 0.0417
     Episode_Termination/robot_out: 0.7083
--------------------------------------------------------------------------------
                   Total timesteps: 147357696
                    Iteration time: 1.92s
                      Time elapsed: 00:56:22
                               ETA: 00:56:29

################################################################################
                     [1m Learning iteration 1499/3000 [0m                     

                       Computation: 51389 steps/s (collection: 1.816s, learning 0.097s)
             Mean action noise std: 5.07
          Mean value_function loss: 46.8354
               Mean surrogate loss: -0.0043
                 Mean entropy loss: 92.2054
                       Mean reward: 756.71
               Mean episode length: 237.06
    Episode_Reward/reaching_object: 1.5958
    Episode_Reward/rotating_object: 151.8896
        Episode_Reward/action_rate: -0.1791
          Episode_Reward/joint_vel: -0.0339
      Episode_Termination/time_out: 16.3333
Episode_Termination/object_dropping: 0.0000
     Episode_Termination/robot_out: 0.9167
--------------------------------------------------------------------------------
                   Total timesteps: 147456000
                    Iteration time: 1.91s
                      Time elapsed: 00:56:24
                               ETA: 00:56:27
